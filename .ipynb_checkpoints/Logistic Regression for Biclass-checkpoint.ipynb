{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5e2fcbba4a60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'..'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/bank-full.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = os.path.join(__file__, '..', '/bank-full.csv')\n",
    "print (path)\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_toNumber(data):\n",
    "    data1 = data.copy()\n",
    "    label_dict = {}\n",
    "    for i in data1.columns:\n",
    "        if (data1[i].dtype == object):\n",
    "            uniques = data1[i].unique()\n",
    "            count = 0\n",
    "            map_dict = {}\n",
    "            for j in uniques:\n",
    "                map_dict[j] = count\n",
    "                count += 1\n",
    "            data1[i] = data1[i].map(map_dict)\n",
    "            \n",
    "            label_dict[i] = map_dict\n",
    "    return data1, label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, class_name):\n",
    "    ## Transforming data to zero mean\n",
    "    \n",
    "    Y = data[class_name]\n",
    "    data = data.drop(class_name, axis = 1)\n",
    "    #data = data - data.mean()\n",
    "    data = data / data.max()\n",
    "    data = np.array(data)\n",
    "    return data, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a discriminative classification algorithm which uses the logit function to make predicition. \n",
    "\n",
    "A logit function is:\n",
    "\n",
    "$$P(X) = \\frac{1}{1 + e^{Q^T X}}$$\n",
    "\n",
    "Logit function is also known as Sigmoid function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to find the cost function for the logistic regression. \n",
    "The cost function is the function which use to estimate the natural parameters of any probability distribution. \n",
    "\n",
    "\n",
    "Cost Function for a Logistic Regression is:\n",
    "\n",
    "$$L(Q) = -\\frac{1}{N} \\Sigma_{i = 1}^{N} \\bigg[ c^i log_e(\\frac{1}{1 + e^{Q^TX}}) + (1 - c^i) log_e\\big(1 - \\frac{1}{1 + e^{Q^TX}}\\big) \\bigg]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative for the cost function is:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta}\\big[-log_e L(\\theta) \\big] = \\frac{1}{N}\\frac{\\partial}{\\partial\\theta} {\\Sigma_{i = 0}^{N} (H(\\theta) - c^i}) x^i$$\n",
    "\n",
    "where $$H(\\theta) = \\frac{1}{1 + e ^{-(\\theta^T x)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_dic = Convert_toNumber(data)\n",
    "proc_data, Y = preprocess(data, 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    \n",
    "    def __init__(self, alpha = 0.1, tolerance = 0.001, fit_intercept = True):\n",
    "        self.alpha = alpha\n",
    "        self.tolerance = tolerance \n",
    "        self.intercept = fit_intercept\n",
    "        pass\n",
    "    \n",
    "    def __sigmoid__(self, X, weight):\n",
    "        sig = 1 / (1 + np.e ** -(np.dot(X, weight)))\n",
    "        return sig\n",
    "    \n",
    "    def __add_0th_feature__(self, X):\n",
    "        \n",
    "#         if X.shape[0] == self.theta.shape:\n",
    "#             return (np.concatenate(([1], X)))\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((ones, X), axis = 1)\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.intercept:\n",
    "            X = self.__add_0th_feature__(X)\n",
    "        \n",
    "        logit = self.__sigmoid__(X, self.theta).reshape((X.shape[0], 1))\n",
    "        return np.concatenate((1 - logit, logit), axis = 1)\n",
    "        \n",
    "    def __loss__(self, theta, X, Y):\n",
    "        \n",
    "        v = self.__sigmoid__(X, theta)\n",
    "        return ((Y * np.log(v)) + ((1 - Y) * np.log(1 - v))).mean()\n",
    "        \n",
    "    def __gradient_descent__(self, X, Y):\n",
    "        \n",
    "        theta_old = np.zeros(X.shape[1])\n",
    "        \n",
    "        while True:\n",
    "#             cal_sig = self.__sigmoid__(X, theta_old)\n",
    "#             sub_class = cal_sig - Y  \n",
    "#             mul_X = np.dot(sub_class, X)\n",
    "#             dec = self.alpha * mul_X\n",
    "#             reduce = dec / Y.shape[0]\n",
    "#             theta_new = theta_old - reduce\n",
    "            theta_new = theta_old - self.alpha * (np.dot((self.__sigmoid__(X, theta_old) - Y), X) / Y.shape[0])\n",
    "#             return theta_new\n",
    "            loss = abs(self.__loss__(theta_new, X, Y) - self.__loss__(theta_old, X, Y))\n",
    "            if loss < self.tolerance:\n",
    "                break\n",
    "            print ('Loss Value: ', loss)\n",
    "            theta_old = theta_new\n",
    "            \n",
    "        self.theta = theta_old\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        if (self.intercept):\n",
    "            X = self.__add_0th_feature__(X)\n",
    "        self.__gradient_descent__(X, Y)\n",
    "#         raise(NotImplementedError('Not Imp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Value:  0.034984164317147015\n",
      "Loss Value:  0.032187214839536016\n",
      "Loss Value:  0.029623184933553315\n",
      "Loss Value:  0.027277823699848103\n",
      "Loss Value:  0.02513601637155216\n",
      "Loss Value:  0.023182380018681226\n",
      "Loss Value:  0.02140171428606874\n",
      "Loss Value:  0.0197793261500967\n",
      "Loss Value:  0.018301250089113985\n",
      "Loss Value:  0.016954384741320605\n",
      "Loss Value:  0.015726565201733933\n",
      "Loss Value:  0.014606587421084172\n",
      "Loss Value:  0.013584198274349701\n",
      "Loss Value:  0.01265006210408326\n",
      "Loss Value:  0.011795712091753674\n",
      "Loss Value:  0.011013492739269048\n",
      "Loss Value:  0.010296498057049408\n",
      "Loss Value:  0.009638508722613182\n",
      "Loss Value:  0.009033930446520122\n",
      "Loss Value:  0.008477735008208198\n",
      "Loss Value:  0.00796540485296482\n",
      "Loss Value:  0.007492881728884626\n",
      "Loss Value:  0.0070565195522211965\n",
      "Loss Value:  0.006653041490904232\n",
      "Loss Value:  0.006279501125297293\n",
      "Loss Value:  0.005933247464075142\n",
      "Loss Value:  0.005611893547231961\n",
      "Loss Value:  0.0053132883471150305\n",
      "Loss Value:  0.005035491674178827\n",
      "Loss Value:  0.004776751801080004\n",
      "Loss Value:  0.004535485532688954\n",
      "Loss Value:  0.004310260467622895\n",
      "Loss Value:  0.004099779216950705\n",
      "Loss Value:  0.0039028653663991386\n",
      "Loss Value:  0.0037184509887820683\n",
      "Loss Value:  0.0035455655328650304\n",
      "Loss Value:  0.0033833259331558785\n",
      "Loss Value:  0.00323092780198031\n",
      "Loss Value:  0.0030876375805851952\n",
      "Loss Value:  0.0029527855399364977\n",
      "Loss Value:  0.0028257595343877395\n",
      "Loss Value:  0.002705999422579264\n",
      "Loss Value:  0.002592992079885753\n",
      "Loss Value:  0.002486266935560588\n",
      "Loss Value:  0.0023853919755574826\n",
      "Loss Value:  0.0022899701589126353\n",
      "Loss Value:  0.0021996362016742377\n",
      "Loss Value:  0.0021140536877437555\n",
      "Loss Value:  0.0020329124707263446\n",
      "Loss Value:  0.0019559263350541756\n",
      "Loss Value:  0.0018828308883201417\n",
      "Loss Value:  0.001813381659988983\n",
      "Loss Value:  0.0017473523844888372\n",
      "Loss Value:  0.0016845334491972508\n",
      "Loss Value:  0.0016247304900378345\n",
      "Loss Value:  0.0015677631193386499\n",
      "Loss Value:  0.0015134637723289157\n",
      "Loss Value:  0.0014616766601506792\n",
      "Loss Value:  0.0014122568185977735\n",
      "Loss Value:  0.0013650692429788558\n",
      "Loss Value:  0.001319988100530134\n",
      "Loss Value:  0.0012768960127381712\n",
      "Loss Value:  0.0012356834007389017\n",
      "Loss Value:  0.0011962478876888227\n",
      "Loss Value:  0.0011584937526354089\n",
      "Loss Value:  0.001122331431000212\n",
      "Loss Value:  0.0010876770572725292\n",
      "Loss Value:  0.0010544520459807583\n",
      "Loss Value:  0.001022582707395081\n"
     ]
    }
   ],
   "source": [
    "t = lb.fit(proc_data[:100], Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lb.predict_prob(proc_data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = np.argmax(pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39825"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(Y[100:] == loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8828223714836736"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "39825 / proc_data[100:].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val = lb.predict_prob(proc_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(Y[:100] == np.argmax(pred_val, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
