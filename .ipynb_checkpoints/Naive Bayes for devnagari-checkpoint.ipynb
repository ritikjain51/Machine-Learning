{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), '..', 'DevanagariHandwrittenCharacterDataset')\n",
    "\n",
    "train_path = os.path.join(path, 'train')\n",
    "test_path = os.path.join(path, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(path):\n",
    "    labels = ''\n",
    "    images = []\n",
    "    for folder in tqdm(os.listdir(path)):\n",
    "        label = folder.split('_')[-1]\n",
    "        image_paths = os.listdir(os.path.join(path, folder))\n",
    "        data = list(map( lambda image: plt.imread(os.path.join(path, folder, image)).reshape(1024), image_paths))\n",
    "        images.extend(data)\n",
    "        labels += (label + ',') * len(image_paths)\n",
    "    labels = labels.split(',')\n",
    "    return np.array(images), np.array(labels[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2e0b1f0d244597ad791baec152fe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=46), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "images, labels = generate_data(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Numpy array to Pandas Dataframe\n",
    "df = pd.DataFrame(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to normalize the dataframe.\n",
    "# df = df - df.mean()\n",
    "df = df / df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the unique classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' 'adna' 'ba' 'bha' 'cha' 'chha'\n",
      " 'chhya' 'da' 'daa' 'dha' 'dhaa' 'ga' 'gha' 'gya' 'ha' 'ja' 'jha' 'ka'\n",
      " 'kha' 'kna' 'la' 'ma' 'motosaw' 'na' 'pa' 'patalosaw' 'petchiryakha'\n",
      " 'pha' 'ra' 'taamatar' 'tabala' 'tha' 'thaa' 'tra' 'waw' 'yaw' 'yna']\n"
     ]
    }
   ],
   "source": [
    "unique_classes = np.unique(labels)\n",
    "print (unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  1014  \\\n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance is a measure of the extent to which corresponding elements from two sets of ordered data move in the same direction. We use the following formula to compute covariance.\n",
    "\n",
    "Covariance matrix is a symmatric and squared matrix. \n",
    "\n",
    "We need the covariance matrix to be \n",
    "- Non-Singular\n",
    "- Positive Definite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-Singularity of a matrix is some of the matrix vectors are linearly dependent.<br>\n",
    "We can check the non-singularity of the matrix \n",
    "- Calculating the determinant of the covariance matrix ( If determinant is zero that means matrix is singular). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritik\\AppData\\Local\\Continuum\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\numpy\\linalg\\linalg.py:2022: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant of Covariance Matrix: nan\n"
     ]
    }
   ],
   "source": [
    "## Calculating the determinant\n",
    "cov = df.cov()\n",
    "det = np.linalg.det(cov)\n",
    "print ('Determinant of Covariance Matrix: %.1f'%det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinant of Covariance matrix is 0. That means that matrix is Singular. \n",
    "\n",
    "So, now we have to choose the columns which are linearly independent. For that we can use \n",
    "\n",
    "**Principle Component Analysis**<br>\n",
    "PCA is a dimensionality reduction algorithm, which we use to when we have too many dimensions. So, it will be computationally complex to make calculation for 1million feature. So, we have to take only those feature vector which having very high variance. And leave others.\n",
    "\n",
    "\n",
    "PCA is using Singular Value Decomposition to extract features with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA(data, labels):\n",
    "    \n",
    "    ## We are taking the data columns. \n",
    "    global unique_classes\n",
    "    \n",
    "    cov_mat = list(map(lambda y: data[y == labels].cov(), unique_classes))\n",
    "\n",
    "    svd_mat = list(map(lambda x: np.linalg.svd(x), cov_mat))\n",
    "    \n",
    "    ## Taking column number \n",
    "    col_no = np.array(list(map(lambda x: np.argmax(x[0], axis = 1), svd_mat)))\n",
    "    \n",
    "    \n",
    "    col_val = list(map(lambda x: set(col_no[:, x]), np.arange(col_no.shape[1])))\n",
    "\n",
    "    cols = []\n",
    "    \n",
    "    for i in col_val:\n",
    "        if (len(i) == 1):\n",
    "            cols.extend(i)\n",
    "        \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = PCA(df, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I got the data columns for every class labels. Now, i have to find all the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[column_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, i am spliting my normalized and filtered data into training data and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x, y, test_split = 0.5, rand_state = 10):\n",
    "    np.random.seed(rand_state)\n",
    "    mask = np.random.rand(x.shape[0]) < test_split\n",
    "    x_test = x[mask]\n",
    "    y_test = y[mask]\n",
    "    x_train = x[~mask]\n",
    "    y_train = y[~mask]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_split = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to are nt able to find the Solution for the dataset using PCA (Principle Component Analysis). So now, we have to find the columns using RDA (Regularized Discriminant Analysis).\n",
    "\n",
    "RDA is a decision boundary technique which creates a non-linear decision boundary using a hybrid approach of linear and non-linear decision boundary. \n",
    "\n",
    "In the following approach we have are adding the LDA and QDA. \n",
    "\n",
    "$$\\Sigma_{RDA} = \\Gamma \\Sigma_{p} + (1 - \\Gamma) \\Sigma_{pooled}$$\n",
    "\n",
    "To find Pooled Covariance Matrix.\n",
    "\n",
    "$$\\Sigma_{pool} =  \\frac{\\Sigma_{i = 1}^{K} n_i\\Sigma_i}{N - K} $$\n",
    "Where $n$ is the number rows of each classes<br>\n",
    "$N$ is the total number of rows in dataset.<br>\n",
    "$K$ is number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RDA(data, labels):\n",
    "    \n",
    "    global unique_classes\n",
    "    \n",
    "    cov_mat_estimate = list(map(lambda x:data[labels == x].cov() , unique_classes))\n",
    "    mat = []\n",
    "    mat.extend(map(lambda x, y: np.count_nonzero(labels == y) * x, cov_mat_estimate, unique_classes))\n",
    "    \n",
    "    first_param = 0.1  \n",
    "    \n",
    "    pooled_matrix = (1 - first_param) * sum(mat) / (labels.shape[0] - np.unique(labels).shape[0])\n",
    "\n",
    "    cov_pool_matrix = list(map(lambda x: (x * first_param) + ((1 - first_param) * pooled_matrix), cov_mat_estimate))\n",
    "\n",
    "    second_param = 0.13\n",
    "    \n",
    "    sigma = list(map( lambda x: np.trace(x) / x.shape[0], cov_pool_matrix))\n",
    "    cov_rda_mat = list(map(lambda x, y: ((1 - second_param) * x) + (second_param * y * np.eye(x.shape[0])),cov_pool_matrix, sigma))\n",
    "    \n",
    "    return cov_rda_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = RDA(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get Non-singular covariance matrix. <br>\n",
    "We have to find the mean value for each class. <br>\n",
    "We have to apply sampling distribution to estimate the mean value for classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_class_mean(x_train, y_train):\n",
    "    \n",
    "    global unique_classes\n",
    "    ##we have to perform random sampling for every class. \n",
    "    ## Calculate the mean on the samples \n",
    "    ## Find the mean for the value. \n",
    "#     est_sample_mean = []\n",
    "#     for i in np.unique(y_train):\n",
    "        \n",
    "#         mask = i == y_train\n",
    "#         sample = x_train[mask].mean()\n",
    "#         est_sample_mean.append(sample)\n",
    "        \n",
    "#     estiamted_mean = list(map(lambda y: np.mean(np.random.choice(x_train[y_train == y], (100, 10)), axis = 1), np.unique(y_train)))\n",
    "    est_sample_mean = list(map( lambda y: x_train[y == y_train].mean(), unique_classes))\n",
    "    return est_sample_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_value = estimate_class_mean(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing code for joint gaussian probability distribution. \n",
    "\n",
    "Formula \n",
    "\n",
    "\\begin{equation}\n",
    "P(X_0 = x_0 \\cap X_1 = x_1 \\cap ... \\cap X_N = x_n | y = à¤…) = \\frac{P(Y = à¤… | X_0 = x_0 \\cap X_1 = x_1 \\cap ... \\cap X_N = x_n)P(à¤…)}{Total Porbability} \\end{equation}<br>\n",
    "So, we are assuming all the feature are gaussianly distributed. \n",
    "Then we can use <b>Gaussian Probabilty Distribution Function</b> to calculate the probability for every character. \n",
    "\n",
    "$$P(X_0 = x_0 \\cap X_1 = x_1 \\cap ... \\cap X_N = x_n | y = à¤…) = P(X_0 = x_0 | y = à¤…)\\thinspace \\cap P(X_0 = x_0 | y = à¤…) \\thinspace\\cap... \\cap\\thinspace P(X_N = x_N | y = à¤…) $$\n",
    "\n",
    "Every image have total 1024 pixels. So we have to create the probability distribution function for 1024 values. Which is computationally expensive. \n",
    "So, we can use a different type of distribution where instead of dealing with one pixel per pdf. We can input all the pixels at once and make computation on all parameters at once. \n",
    "This type of probability distribution function is known as **Joint Probability Distribution Function**. \n",
    "\n",
    "So, Joint PDF for Gaussian Distribution is:\n",
    "\n",
    "\n",
    "$$P(X_0 = x_0 \\cap X_1 = x_1\\cap...\\cap X_N = x_n) = \\frac{1}{\\sqrt{({2 \\pi})^2} {\\sqrt{\\det({\\Sigma})}}} e ^ {-\\frac{1}{2}{\\begin{bmatrix} x_0 - \\mu_{x_0} \\\\ . \\\\ .\\\\ x_N - \\mu_{x_n}\\end{bmatrix}}^T \\thinspace\\Sigma^{-1} \\begin{bmatrix} x_0 - \\mu_{x_0} \\\\ . \\\\ .\\\\ x_N - \\mu_{x_n}\\end{bmatrix}  } $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gauss_joint_pdf(x, mu, cov):\n",
    "    \n",
    "    x = np.array(x)\n",
    "    mu = np.array(mu)\n",
    "    \n",
    "    first = 1 / ((np.sqrt((2 * np.pi) ** x.shape[1]) * (np.sqrt(np.linalg.det(cov)))))\n",
    "    \n",
    "    zero_mean_val = x - mu\n",
    "    f = zero_mean_val.dot(np.linalg.inv(cov))\n",
    "    print(f.shape)\n",
    "    print(zero_mean_val.shape)\n",
    "    g = f.dot(zero_mean_val.T)\n",
    "    second = np.e ** -((1/2) * g)\n",
    "    \n",
    "    return (first * second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "(1, 62)\n",
      "[[3528435.72672038]]\n",
      "Iteration: 1\n",
      "(1, 62)\n",
      "[[346923.27748933]]\n",
      "Iteration: 2\n",
      "(1, 62)\n",
      "[[4959941.74980474]]\n",
      "Iteration: 3\n",
      "(1, 62)\n",
      "[[3085768.30686106]]\n",
      "Iteration: 4\n",
      "(1, 62)\n",
      "[[1.91610218e+09]]\n",
      "Iteration: 5\n",
      "(1, 62)\n",
      "[[16911571.34948738]]\n",
      "Iteration: 6\n",
      "(1, 62)\n",
      "[[4127947.85000885]]\n",
      "Iteration: 7\n",
      "(1, 62)\n",
      "[[285058.59575498]]\n",
      "Iteration: 8\n",
      "(1, 62)\n",
      "[[14284205.6320907]]\n",
      "Iteration: 9\n",
      "(1, 62)\n",
      "[[17463525.96152098]]\n",
      "Iteration: 10\n",
      "(1, 62)\n",
      "[[3.95268981e+08]]\n",
      "Iteration: 11\n",
      "(1, 62)\n",
      "[[43420480.62240541]]\n",
      "Iteration: 12\n",
      "(1, 62)\n",
      "[[3.25145258e+08]]\n",
      "Iteration: 13\n",
      "(1, 62)\n",
      "[[21629576.02450593]]\n",
      "Iteration: 14\n",
      "(1, 62)\n",
      "[[13643738.24883924]]\n",
      "Iteration: 15\n",
      "(1, 62)\n",
      "[[1.49983625e+08]]\n",
      "Iteration: 16\n",
      "(1, 62)\n",
      "[[26429540.16220537]]\n",
      "Iteration: 17\n",
      "(1, 62)\n",
      "[[2.66622207e+08]]\n",
      "Iteration: 18\n",
      "(1, 62)\n",
      "[[82456420.50069888]]\n",
      "Iteration: 19\n",
      "(1, 62)\n",
      "[[20693351.19261232]]\n",
      "Iteration: 20\n",
      "(1, 62)\n",
      "[[1.73299492e+09]]\n",
      "Iteration: 21\n",
      "(1, 62)\n",
      "[[1.00109077e+08]]\n",
      "Iteration: 22\n",
      "(1, 62)\n",
      "[[5.35701791e+08]]\n",
      "Iteration: 23\n",
      "(1, 62)\n",
      "[[5.49142358e+08]]\n",
      "Iteration: 24\n",
      "(1, 62)\n",
      "[[1.23357773e+10]]\n",
      "Iteration: 25\n",
      "(1, 62)\n",
      "[[1.32508656e+08]]\n",
      "Iteration: 26\n",
      "(1, 62)\n",
      "[[4872608.55751674]]\n",
      "Iteration: 27\n",
      "(1, 62)\n",
      "[[49091303.93280306]]\n",
      "Iteration: 28\n",
      "(1, 62)\n",
      "[[4.01948089e+08]]\n",
      "Iteration: 29\n",
      "(1, 62)\n",
      "[[1.96529928e+10]]\n",
      "Iteration: 30\n",
      "(1, 62)\n",
      "[[1.42330042e+08]]\n",
      "Iteration: 31\n",
      "(1, 62)\n",
      "[[6.91052957e+08]]\n",
      "Iteration: 32\n",
      "(1, 62)\n",
      "[[1.85697715e+09]]\n",
      "Iteration: 33\n",
      "(1, 62)\n",
      "[[53631805.84241766]]\n",
      "Iteration: 34\n",
      "(1, 62)\n",
      "[[1.37191184e+08]]\n",
      "Iteration: 35\n",
      "(1, 62)\n",
      "[[67195344.69244158]]\n",
      "Iteration: 36\n",
      "(1, 62)\n",
      "[[4350875.0165042]]\n",
      "Iteration: 37\n",
      "(1, 62)\n",
      "[[21051733.96350649]]\n",
      "Iteration: 38\n",
      "(1, 62)\n",
      "[[3.92731079e+08]]\n",
      "Iteration: 39\n",
      "(1, 62)\n",
      "[[2.20746771e+09]]\n",
      "Iteration: 40\n",
      "(1, 62)\n",
      "[[1.06127171e+08]]\n",
      "Iteration: 41\n",
      "(1, 62)\n",
      "[[37402708.15858098]]\n",
      "Iteration: 42\n",
      "(1, 62)\n",
      "[[9.59459243e+08]]\n",
      "Iteration: 43\n",
      "(1, 62)\n",
      "[[1.59597126e+08]]\n",
      "Iteration: 44\n",
      "(1, 62)\n",
      "[[1.46454008e+08]]\n",
      "Iteration: 45\n",
      "(1, 62)\n",
      "[[6.68782162e+08]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(46):\n",
    "    print (f'Iteration: {i}')\n",
    "    print (Gauss_joint_pdf(x_train.iloc[0:1], mu_value[i], cov[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-25-e8420ce4fab4>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-e8420ce4fab4>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def predict_prob(x_test, mu, cov):\n",
    "    \n",
    "    x = []\n",
    "    for i in range(46):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
