{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372450, 785)\n",
      "   label  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.639  0.640  \\\n",
      "0      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "2      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "3      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "4      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
      "\n",
      "   0.641  0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
      "0      0      0      0      0      0      0      0      0  \n",
      "1      0      0      0      0      0      0      0      0  \n",
      "2      0      0      0      0      0      0      0      0  \n",
      "3      0      0      0      0      0      0      0      0  \n",
      "4      0      0      0      0      0      0      0      0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('..//Dataset//A_Z Handwritten Data.csv')\n",
    "df = pd.read_csv('..//Dataset/MNIST Digit Dataset.csv')\n",
    "print(data.shape) # (372451, 785)\n",
    "\n",
    "data.rename(columns={'0':'label'}, inplace=True)\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "X = data.drop('label',axis = 1)\n",
    "y = data['label']\n",
    "X.columns = np.arange(1, 785)\n",
    "x = df.drop('label', axis = 1)\n",
    "x.columns = np.arange(1, 785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = dict(zip(df['label'].unique(), df['label'].unique() + 26))\n",
    "df['label'] = list(map(lambda x: label[x],df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414450, 784)\n"
     ]
    }
   ],
   "source": [
    "X = X.append(x, ignore_index = True)\n",
    "print (X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_data(images, size):\n",
    "     n = len(images)\n",
    "     plt.figure()\n",
    "     plt.gca().set_axis_off()\n",
    "     im = np.vstack([np.hstack([images[np.random.choice(n)] for i in range(size)])\n",
    "     for i in range(size)])\n",
    "     plt.imshow(im)\n",
    "     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414450,)\n"
     ]
    }
   ],
   "source": [
    "y = y.append(df['label'], ignore_index=True)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310837, 28, 28, 1)\n",
      "(103613, 36)\n"
     ]
    }
   ],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, y)\n",
    "\n",
    "standard_scaler = MinMaxScaler()\n",
    "standard_scaler.fit(X_train)\n",
    "\n",
    "X_train = standard_scaler.transform(X_train)\n",
    "X_test = standard_scaler.transform(X_test)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32')\n",
    "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32')\n",
    "\n",
    "print(X_train.shape) \n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "print(Y_test.shape) \n",
    "\n",
    "num_classes = Y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 310837 samples, validate on 103613 samples\n",
      "Epoch 1/5\n",
      "310837/310837 [==============================] - 159s 512us/step - loss: 0.2022 - acc: 0.9453 - val_loss: 0.0769 - val_acc: 0.9792\n",
      "Epoch 2/5\n",
      "310837/310837 [==============================] - 154s 494us/step - loss: 0.0715 - acc: 0.9802 - val_loss: 0.0632 - val_acc: 0.9822\n",
      "Epoch 3/5\n",
      "310837/310837 [==============================] - 153s 492us/step - loss: 0.0541 - acc: 0.9848 - val_loss: 0.0521 - val_acc: 0.9855\n",
      "Epoch 4/5\n",
      "310837/310837 [==============================] - 153s 494us/step - loss: 0.0434 - acc: 0.9875 - val_loss: 0.0495 - val_acc: 0.9862\n",
      "Epoch 5/5\n",
      "310837/310837 [==============================] - 155s 499us/step - loss: 0.0352 - acc: 0.9896 - val_loss: 0.0402 - val_acc: 0.9889\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(28, 28, 1), activation='relu', data_format=\"channels_last\", padding=\"same\"))\n",
    "model.add(Conv2D(64, (5, 5), input_shape=(28, 28, 1), activation='relu', data_format=\"channels_last\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', data_format=\"channels_last\", padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', data_format=\"channels_last\", padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                4644      \n",
      "=================================================================\n",
      "Total params: 1,133,156\n",
      "Trainable params: 1,133,156\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
