{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Multiclass Logistic Regression\n",
    "\n",
    "The Prediction function is:\n",
    "$$S(\\theta_0, \\theta) = \\frac{e ^{\\theta_0 + \\theta^T X}}{\\Sigma_{i = 0}^{k} e ^ {\\theta_{i0} + \\theta_i^T X}}$$\n",
    "\n",
    "Gradient Descent Function\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta} \\log(L(\\theta_0, \\theta) = \\frac{1}{N} \\Sigma_{i = 0}^{N} \\big(c_0^i - S_i(\\theta_0, \\theta)\\big) X^i$$\n",
    "\n",
    "Loss function:\n",
    "\n",
    "$$L(\\theta_0, \\theta) = -\\frac{1}{N}\\Sigma_{i = 0}^{N}\\Sigma_{j = 0}^{K}C_i^j log_e(S(\\theta_0^j, \\theta^j))$$\n",
    "\n",
    "Where $N$ is number of example in dataset. <br>\n",
    "$K$ number of classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression(object):\n",
    "    \n",
    "    def __init__(self, alpha = 0.1, tolerance = 0.01, fit_intercept = True, theta_init = 'rand'):\n",
    "        '''\n",
    "        : alpha: \n",
    "              It is the learning rate default (0.01)\n",
    "          tolerance:\n",
    "              Minimum value to reach default (0.001)\n",
    "          fit_intercept:\n",
    "              Adding 0th Vetor default (True)\n",
    "          theta_init:\n",
    "              Initial value of theta\n",
    "              rand - random values for initial vector (Default)\n",
    "              zero - zero values for initial vector\n",
    "              value - Giving own values\n",
    "        '''\n",
    "        self.alpha = alpha\n",
    "        self.tolerance = tolerance \n",
    "        self.intercept = fit_intercept\n",
    "        self.theta_init = theta_init\n",
    "    \n",
    "    def __softmax__(self, X, weight):\n",
    "        softmax_val = np.exp(np.dot(X, weight))\n",
    "        total_val = np.sum(softmax_val, axis = 1)\n",
    "        return softmax_val / total_val\n",
    "    \n",
    "    \n",
    "    def __add_0th_feature__(self, X):\n",
    "        \n",
    "#         if X.shape[0] == self.theta.shape:\n",
    "#             return (np.concatenate(([1], X)))\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((ones, X), axis = 1)\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.intercept:\n",
    "            X = self.__add_0th_feature__(X)\n",
    "        \n",
    "        logit = self.__sigmoid__(X, self.theta).reshape((X.shape[0], 1))\n",
    "        return np.concatenate((1 - logit, logit), axis = 1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        val = self.predict_prob(X)\n",
    "        return np.argmax(val, axis = 1)\n",
    "    \n",
    "    def one_hot_encoding(self, Y):\n",
    "        \n",
    "        lab_vector = None\n",
    "        if np.min(Y) == 0:\n",
    "            mat = np.eye(np.max(Y) + 1)\n",
    "            lab_vector = mat[Y]\n",
    "        else:\n",
    "            mat = np.eye(np.max(Y))\n",
    "            lab_vector = mat[Y - 1]\n",
    "        return lab_vector\n",
    "        \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.xlabel('# of interation -->')\n",
    "        plt.ylabel('Rate of loss -->')\n",
    "        plt.title('Gradient loss graph')\n",
    "        plt.plot(range(self.count), self.loss_history)\n",
    "    \n",
    "    def __loss__(self, X, W):\n",
    "        \n",
    "            \n",
    "    def __gradient_descent__(self, X, Y):\n",
    "        if self.intercept:\n",
    "            w = np.random.randn(X.shape[1] + 1, np.unique(Y).shape[0])\n",
    "        else:\n",
    "            w = np.random.randn(X.shape[1], np.unique(Y).shape[0])\n",
    "        Converged = False\n",
    "        vec = self.one_hot_encoding(Y)\n",
    "        while not Converged:\n",
    "            del_theta = np.mean((vec - self.__softmax__(X, w)) @ X)\n",
    "            w_new = w - (self.alpha * del_theta)\n",
    "            \n",
    "            pass\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "#         if (self.intercept):\n",
    "#             X = self.__add_0th_feature__(X)\n",
    "            \n",
    "        \n",
    "        loss = self.__gradient_descent__(X, Y)\n",
    "        return loss \n",
    "#         raise(NotImplementedError('Not Imp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = MultiClassLogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(1, 10, (4, 5))\n",
    "w = np.random.randn(5, 4)\n",
    "l = lb.__softmax__(x, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.34016381e-04, 1.00126892e-14, 5.83185673e-02, 1.38762086e-22],\n",
       "       [4.23535375e-03, 1.65919812e-16, 9.84275756e-08, 3.35339064e-17],\n",
       "       [1.10103091e-04, 1.91204106e-11, 9.99993578e-01, 5.28709605e-20],\n",
       "       [1.13636975e+00, 6.45526378e-17, 2.58449876e-02, 6.74304964e-21]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = np.exp(x @ w)\n",
    "total = np.sum(val, axis = 1)\n",
    "val / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.10133632e+04, 3.48638631e-09, 8.21682182e+07, 1.80113756e-14],\n",
       "       [3.48058117e+05, 5.77727472e-11, 1.38679993e+02, 4.35271478e-09],\n",
       "       [9.04818744e+03, 6.65766571e-06, 1.40894563e+09, 6.86267231e-12],\n",
       "       [9.33859930e+07, 2.24770217e-11, 3.64144163e+07, 8.75250603e-13]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058452583681010015"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1.34016381e-04, 1.00126892e-14, 5.83185673e-02, 1.38762086e-22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.51875529e+02, 8.52119840e-01, 1.85850736e+06, 9.34363118e+02,\n",
       "       1.09357981e-01])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0, 1, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = lb.one_hot_encoding(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.47473085e+00,  6.53251335e+00,  5.53264736e+00,\n",
       "         4.94101135e+00,  7.88229073e+00],\n",
       "       [ 1.98729305e+00,  5.97035174e+00,  9.74587090e-01,\n",
       "         8.97882313e+00,  6.96611697e+00],\n",
       "       [-6.00027251e+00, -3.00071935e+00, -6.09243245e-04,\n",
       "         7.99945591e+00,  4.99913202e+00],\n",
       "       [ 5.35828586e+00, -1.61348163e-01,  9.75021588e-01,\n",
       "        -4.70769375e+00, -7.14264799e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(c - l) @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.34016381e-04, 1.00126892e-14, 5.83185673e-02, 1.38762086e-22],\n",
       "       [4.23535375e-03, 1.65919812e-16, 9.84275756e-08, 3.35339064e-17],\n",
       "       [1.10103091e-04, 1.91204106e-11, 9.99993578e-01, 5.28709605e-20],\n",
       "       [1.13636975e+00, 6.45526378e-17, 2.58449876e-02, 6.74304964e-21]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,4) (4,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-58b0a0ce119b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,4) (4,5) "
     ]
    }
   ],
   "source": [
    "(c - np.max(l * c, axis = 0)) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.81960925e-02, -6.01610329e-02, -4.93113134e-07,\n",
       "        -4.98997783e-05],\n",
       "       [-9.81803907e-01,  9.39838967e-01, -4.93113134e-07,\n",
       "        -4.98997783e-05],\n",
       "       [-9.81803907e-01, -6.01610329e-02, -4.93113134e-07,\n",
       "         9.99950100e-01],\n",
       "       [-9.81803907e-01, -6.01610329e-02,  9.99999507e-01,\n",
       "        -4.98997783e-05]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c - np.max(l * c, axis = 0).reshape(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
