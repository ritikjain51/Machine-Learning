{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, i am implementing logistic regression on a bi-class dataset. \n",
    "I am trying to make a classification boundary between two class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been collected from the \n",
    "<a href = 'https://www.kaggle.com/sonujha090/bank-marketing'>Bank Marketing Dataset</a>\n",
    "\n",
    "The dataset having total rows of 45.7k with 16 features and class label as 'Y'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education default  balance housing loan  \\\n",
       "0   58    management  married   tertiary      no     2143     yes   no   \n",
       "1   44    technician   single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
       "4   33       unknown   single    unknown      no        1      no   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '..','bank-full.csv')\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I am trying to convert the qualitative data into quantitative data. I am converting all the text values into the numbers. <br>\n",
    "\n",
    "In above data columns, most of the columns having text values like management, married, may etc. I am giving every text label a respective number. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert_toNumber(data):\n",
    "    data1 = data.copy()\n",
    "    label_dict = {}\n",
    "    for i in data1.columns:\n",
    "        if (data1[i].dtype == object):\n",
    "            uniques = data1[i].unique()\n",
    "            count = 0\n",
    "            map_dict = {}\n",
    "            for j in uniques:\n",
    "                map_dict[j] = count\n",
    "                count += 1\n",
    "            data1[i] = data1[i].map(map_dict)\n",
    "            \n",
    "            label_dict[i] = map_dict\n",
    "    return data1, label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after converting the values into numbers. We have to normalize the data and seperate out the feature data with class labels. \n",
    "\n",
    "I am transforming, by dividing the number with maximum value of the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, class_name):\n",
    "    ## Here we are normalizing the dataset.\n",
    "    Y = data[class_name]\n",
    "    data = data.drop(class_name, axis = 1)\n",
    "    data = data / data.max()\n",
    "    data = np.array(data)\n",
    "    return data, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_dic = Convert_toNumber(data)\n",
    "proc_data, Y = preprocess(data, 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a discriminative classification algorithm which uses the logit function to make predicition. \n",
    "\n",
    "A logit function is:\n",
    "\n",
    "$$P(X) = \\frac{1}{1 + e^{Q^T X}}$$\n",
    "\n",
    "Logit function is also known as Sigmoid function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to find the cost function for the logistic regression. \n",
    "The cost function is the function which use to estimate the natural parameters of any probability distribution. \n",
    "\n",
    "\n",
    "Cost Function for a Logistic Regression is:\n",
    "\n",
    "$$L(Q) = -\\frac{1}{N} \\Sigma_{i = 1}^{N} \\bigg[ c^i log_e(\\frac{1}{1 + e^{Q^TX}}) + (1 - c^i) log_e\\big(1 - \\frac{1}{1 + e^{Q^TX}}\\big) \\bigg]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivative for the cost function is:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta}\\big[-log_e L(\\theta) \\big] = \\frac{1}{N}\\frac{\\partial}{\\partial\\theta} {\\Sigma_{i = 0}^{N} (H(\\theta) - c^i}) x^i$$\n",
    "\n",
    "where $$H(\\theta) = \\frac{1}{1 + e ^{-(\\theta^T x)}}$$\n",
    "$c^i$ is the class label for $i^{th}$ row. <br>\n",
    "$N$ is total no. of rows in the training dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using above cost function we can make modelling error of overfitting or underfitting.<br>\n",
    "*Overfitting* is a type of modelling error occurs when we trying to fit model to the limited data points. Through this technique we can make our best fit for the training dataset and get highest accuracy but when will try it on testing dataset we will loose the accuracy. To avoid this type of error we are using **technique of regularization**. \n",
    "\n",
    "*Underfitting* is another modelling error where we are not provide the right fit for the training dataset. \n",
    "\n",
    "*Regularization Techniques*: Regularization technique is used to solve the problem of overfitting and underfitting over any dataset. In the regularization, we are penalizing the theta parameters by which they are not going too high or too low. We are using two regulaization technique.\n",
    "    - L1 Regularization\n",
    "    - L2 Regularization\n",
    "    \n",
    "$$L(\\theta) = (cost\\_function) + (regularization\\_func)$$\n",
    "_L1 Regularization_: It is the absolute values of the theta parameters. \n",
    "\n",
    "$$L1 = |\\theta_1| + |\\theta_2| + ... + |\\theta_n|$$\n",
    "$$L1 = \\Sigma_{i = 0}^{N}|\\theta_i|$$\n",
    "\n",
    "_L2 Regularization_:\n",
    "$$L2 = \\theta_1^2 + \\theta_2^2 + ... + \\theta_n^2$$\n",
    "$$L2 = \\Sigma_{i = 0}^{N}\\theta_i^2$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    \n",
    "    def __init__(self, alpha = 0.01, tolerance = 0.001, fit_intercept = True, theta_init = 'rand', l1_penalty = 0.001, l2_penalty = 0.001, \n",
    "                penalty = 'l2'):\n",
    "        '''\n",
    "        : alpha: \n",
    "              It is the learning rate default (0.01)\n",
    "          tolerance:\n",
    "              Minimum value to reach default (0.001)\n",
    "          fit_intercept:\n",
    "              Adding 0th Vetor default (True)\n",
    "          theta_init:\n",
    "              Initial value of theta\n",
    "              rand - random values for initial vector (Default)\n",
    "              zero - zero values for initial vector\n",
    "              value - Giving own values\n",
    "          l1_penalty:\n",
    "              Value of L1 regularized penalty\n",
    "          l2_penalty:\n",
    "              Value of L2 regularized penalty\n",
    "          penalty:\n",
    "              l1: Enable l1 regularization\n",
    "              l2: Enable l2 regularization\n",
    "        '''\n",
    "        self.alpha = alpha\n",
    "        self.tolerance = tolerance \n",
    "        self.intercept = fit_intercept\n",
    "        self.theta_init = theta_init\n",
    "        self.penalty = penalty\n",
    "        self.l2_penalty = l2_penalty\n",
    "        self.l1_penalty = l1_penalty\n",
    "            \n",
    "    \n",
    "    def __sigmoid__(self, X, weight):\n",
    "        sig = 1 / (1 + np.e ** -(np.dot(X, weight)))\n",
    "        return sig\n",
    "    \n",
    "    def __add_0th_feature__(self, X):\n",
    "        \n",
    "#         if X.shape[0] == self.theta.shape:\n",
    "#             return (np.concatenate(([1], X)))\n",
    "        ones = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((ones, X), axis = 1)\n",
    "    \n",
    "    def predict_prob(self, X):\n",
    "        if self.intercept:\n",
    "            X = self.__add_0th_feature__(X)\n",
    "        \n",
    "        logit = self.__sigmoid__(X, self.theta).reshape((X.shape[0], 1))\n",
    "        return np.concatenate((1 - logit, logit), axis = 1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        val = self.predict_prob(X)\n",
    "        return np.argmax(val, axis = 1)\n",
    "        \n",
    "    def __loss__(self, theta, X, Y):\n",
    "        \n",
    "        v = self.__sigmoid__(X, theta)\n",
    "        return ((Y * np.log(v)) + ((1 - Y) * np.log(1 - v))).mean()\n",
    "        \n",
    "    def __gradient_descent__(self, X, Y):\n",
    "        \n",
    "        if self.theta_init == 'rand':\n",
    "            theta_old = np.random.rand(X.shape[1])\n",
    "        elif self.theta_init == 'zero':\n",
    "            theta_old = np.zeros(X.shape[1])\n",
    "        else:\n",
    "            if len(self.theta_init) == X.shape[1]:\n",
    "                theta_old = np.array(self.theta_init)\n",
    "            else:\n",
    "                raise(ValueError('Different dimension for the value: {} and feature: {}'.format(len(self.theta_init), X.shape[1])))\n",
    "        self.loss_history = []\n",
    "        self.count = 1\n",
    "        \n",
    "        if self.penalty == 'l1':\n",
    "            func = lambda x: self.l1_penalty * np.sum(np.abs(x))\n",
    "        elif self.penalty == 'l2':\n",
    "            func = lambda x: self.l2_penalty * np.dot(x.T,x)\n",
    "            \n",
    "        \n",
    "        while True:\n",
    "            theta_new = theta_old - self.alpha * (np.dot((self.__sigmoid__(X, theta_old) - Y), X) / Y.shape[0]) + func(theta_old)\n",
    "            loss = abs(self.__loss__(theta_new, X, Y) - self.__loss__(theta_old, X, Y))\n",
    "            self.loss_history.append(loss)\n",
    "            if loss < self.tolerance:\n",
    "                break\n",
    "            print ('Iteration: {} Loss Value: {}'.format(self.count, loss))\n",
    "            theta_old = theta_new\n",
    "            self.count += 1 \n",
    "        \n",
    "        self.theta = theta_old\n",
    "        \n",
    "    \n",
    "    def plot_loss(self):\n",
    "        plt.xlabel('# of interation -->')\n",
    "        plt.ylabel('Rate of loss -->')\n",
    "        plt.title('Gradient loss graph')\n",
    "        plt.plot(range(self.count), self.loss_history)\n",
    "            \n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        if (self.intercept):\n",
    "            X = self.__add_0th_feature__(X)\n",
    "            \n",
    "        \n",
    "        loss = self.__gradient_descent__(X, Y)\n",
    "        return loss \n",
    "#         raise(NotImplementedError('Not Imp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score_Matrix(object):\n",
    "    \n",
    "    '''\n",
    "    This class has all score matrix by which we can check efficiency of our algorithm on given dataset.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, y_actual, y_pred):\n",
    "        self.y_actual = y_actual\n",
    "        self.y_pred = np.array(y_pred)\n",
    "        \n",
    "    def confusion_matrix(self):\n",
    "        self.data = pd.crosstab(self.y_actual, self.y_pred, rownames= ['actual'], colnames = ['predicted'], margins = True)\n",
    "        return self.data\n",
    "        \n",
    "    def recall(self):\n",
    "        '''\n",
    "        data:\n",
    "            Dataframe of confusion matrix\n",
    "        '''\n",
    "        sumVal = 0\n",
    "        self.confusion_matrix()\n",
    "        for i in self.data.columns[:-1]:\n",
    "            sumVal += (self.data[i][i] / self.data['All'][i])\n",
    "        return np.round(sumVal / (self.data.shape[0] - 1), 3)\n",
    "    \n",
    "    def check_accuracy(self):\n",
    "        val = np.count_nonzero(self.y_actual == self.y_pred)\n",
    "        return val / self.y_actual.shape[0]\n",
    "        \n",
    "    def precision(self):\n",
    "        sumVal = 0\n",
    "        self.confusion_matrix()\n",
    "        for i in self.data.columns[:-1]:\n",
    "            sumVal += (self.data[i][i] / self.data[i]['All'])\n",
    "        avg = sumVal / (self.data.shape[0]- 1)\n",
    "        return np.round(avg,3)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Logistic Regression on the **random theta vector** without **Regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LogisticRegression(l2_penalty = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss Value: 0.01188790229619352\n",
      "Iteration: 2 Loss Value: 0.011850812393245924\n",
      "Iteration: 3 Loss Value: 0.01181344782969651\n",
      "Iteration: 4 Loss Value: 0.011775809747060606\n",
      "Iteration: 5 Loss Value: 0.011737899362600501\n",
      "Iteration: 6 Loss Value: 0.01169971796983127\n",
      "Iteration: 7 Loss Value: 0.011661266938979509\n",
      "Iteration: 8 Loss Value: 0.011622547717395904\n",
      "Iteration: 9 Loss Value: 0.011583561829934919\n",
      "Iteration: 10 Loss Value: 0.011544310879289643\n",
      "Iteration: 11 Loss Value: 0.01150479654626535\n",
      "Iteration: 12 Loss Value: 0.011465020590039288\n",
      "Iteration: 13 Loss Value: 0.01142498484834853\n",
      "Iteration: 14 Loss Value: 0.011384691237626754\n",
      "Iteration: 15 Loss Value: 0.011344141753124815\n",
      "Iteration: 16 Loss Value: 0.011303338468944935\n",
      "Iteration: 17 Loss Value: 0.011262283538048035\n",
      "Iteration: 18 Loss Value: 0.011220979192199998\n",
      "Iteration: 19 Loss Value: 0.011179427741875969\n",
      "Iteration: 20 Loss Value: 0.011137631576095153\n",
      "Iteration: 21 Loss Value: 0.0110955931622303\n",
      "Iteration: 22 Loss Value: 0.011053315045728596\n",
      "Iteration: 23 Loss Value: 0.011010799849815456\n",
      "Iteration: 24 Loss Value: 0.01096805027511527\n",
      "Iteration: 25 Loss Value: 0.010925069099235074\n",
      "Iteration: 26 Loss Value: 0.010881859176284703\n",
      "Iteration: 27 Loss Value: 0.010838423436341005\n",
      "Iteration: 28 Loss Value: 0.010794764884869856\n",
      "Iteration: 29 Loss Value: 0.01075088660207002\n",
      "Iteration: 30 Loss Value: 0.010706791742188582\n",
      "Iteration: 31 Loss Value: 0.010662483532753564\n",
      "Iteration: 32 Loss Value: 0.010617965273767904\n",
      "Iteration: 33 Loss Value: 0.010573240336858802\n",
      "Iteration: 34 Loss Value: 0.010528312164333364\n",
      "Iteration: 35 Loss Value: 0.010483184268227141\n",
      "Iteration: 36 Loss Value: 0.010437860229260076\n",
      "Iteration: 37 Loss Value: 0.010392343695766026\n",
      "Iteration: 38 Loss Value: 0.01034663838254346\n",
      "Iteration: 39 Loss Value: 0.010300748069682841\n",
      "Iteration: 40 Loss Value: 0.010254676601316293\n",
      "Iteration: 41 Loss Value: 0.010208427884325966\n",
      "Iteration: 42 Loss Value: 0.010162005887005554\n",
      "Iteration: 43 Loss Value: 0.010115414637672071\n",
      "Iteration: 44 Loss Value: 0.010068658223216342\n",
      "Iteration: 45 Loss Value: 0.010021740787625522\n",
      "Iteration: 46 Loss Value: 0.00997466653043566\n",
      "Iteration: 47 Loss Value: 0.009927439705176067\n",
      "Iteration: 48 Loss Value: 0.009880064617712625\n",
      "Iteration: 49 Loss Value: 0.009832545624612665\n",
      "Iteration: 50 Loss Value: 0.009784887131421227\n",
      "Iteration: 51 Loss Value: 0.009737093590913348\n",
      "Iteration: 52 Loss Value: 0.00968916950131371\n",
      "Iteration: 53 Loss Value: 0.009641119404471876\n",
      "Iteration: 54 Loss Value: 0.00959294788400289\n",
      "Iteration: 55 Loss Value: 0.009544659563393454\n",
      "Iteration: 56 Loss Value: 0.009496259104082805\n",
      "Iteration: 57 Loss Value: 0.009447751203504717\n",
      "Iteration: 58 Loss Value: 0.00939914059310154\n",
      "Iteration: 59 Loss Value: 0.009350432036322243\n",
      "Iteration: 60 Loss Value: 0.0093016303265816\n",
      "Iteration: 61 Loss Value: 0.009252740285208949\n",
      "Iteration: 62 Loss Value: 0.0092037667593583\n",
      "Iteration: 63 Loss Value: 0.00915471461992512\n",
      "Iteration: 64 Loss Value: 0.009105588759427796\n",
      "Iteration: 65 Loss Value: 0.009056394089862696\n",
      "Iteration: 66 Loss Value: 0.009007135540590738\n",
      "Iteration: 67 Loss Value: 0.008957818056161804\n",
      "Iteration: 68 Loss Value: 0.008908446594153352\n",
      "Iteration: 69 Loss Value: 0.008859026123020586\n",
      "Iteration: 70 Loss Value: 0.008809561619895545\n",
      "Iteration: 71 Loss Value: 0.008760058068432608\n",
      "Iteration: 72 Loss Value: 0.008710520456623794\n",
      "Iteration: 73 Loss Value: 0.008660953774616731\n",
      "Iteration: 74 Loss Value: 0.008611363012559714\n",
      "Iteration: 75 Loss Value: 0.008561753158415009\n",
      "Iteration: 76 Loss Value: 0.008512129195815232\n",
      "Iteration: 77 Loss Value: 0.00846249610191041\n",
      "Iteration: 78 Loss Value: 0.008412858845229909\n",
      "Iteration: 79 Loss Value: 0.008363222383555469\n",
      "Iteration: 80 Loss Value: 0.008313591661825326\n",
      "Iteration: 81 Loss Value: 0.008263971610025456\n",
      "Iteration: 82 Loss Value: 0.008214367141139656\n",
      "Iteration: 83 Loss Value: 0.0081647831490812\n",
      "Iteration: 84 Loss Value: 0.00811522450667801\n",
      "Iteration: 85 Loss Value: 0.008065696063672023\n",
      "Iteration: 86 Loss Value: 0.00801620264472791\n",
      "Iteration: 87 Loss Value: 0.007966749047511934\n",
      "Iteration: 88 Loss Value: 0.007917340040751286\n",
      "Iteration: 89 Loss Value: 0.00786798036236247\n",
      "Iteration: 90 Loss Value: 0.007818674717595675\n",
      "Iteration: 91 Loss Value: 0.007769427777214011\n",
      "Iteration: 92 Loss Value: 0.007720244175712487\n",
      "Iteration: 93 Loss Value: 0.007671128509577629\n",
      "Iteration: 94 Loss Value: 0.007622085335573958\n",
      "Iteration: 95 Loss Value: 0.00757311916908332\n",
      "Iteration: 96 Loss Value: 0.007524234482472192\n",
      "Iteration: 97 Loss Value: 0.00747543570351672\n",
      "Iteration: 98 Loss Value: 0.0074267272138541784\n",
      "Iteration: 99 Loss Value: 0.007378113347490833\n",
      "Iteration: 100 Loss Value: 0.007329598389345993\n",
      "Iteration: 101 Loss Value: 0.007281186573853571\n",
      "Iteration: 102 Loss Value: 0.007232882083592074\n",
      "Iteration: 103 Loss Value: 0.007184689047981863\n",
      "Iteration: 104 Loss Value: 0.0071366115420130605\n",
      "Iteration: 105 Loss Value: 0.007088653585035187\n",
      "Iteration: 106 Loss Value: 0.007040819139586985\n",
      "Iteration: 107 Loss Value: 0.006993112110279975\n",
      "Iteration: 108 Loss Value: 0.00694553634273154\n",
      "Iteration: 109 Loss Value: 0.006898095622541511\n",
      "Iteration: 110 Loss Value: 0.006850793674331834\n",
      "Iteration: 111 Loss Value: 0.0068036341608253\n",
      "Iteration: 112 Loss Value: 0.006756620681981129\n",
      "Iteration: 113 Loss Value: 0.006709756774172071\n",
      "Iteration: 114 Loss Value: 0.006663045909429455\n",
      "Iteration: 115 Loss Value: 0.006616491494723542\n",
      "Iteration: 116 Loss Value: 0.0065700968712905095\n",
      "Iteration: 117 Loss Value: 0.006523865314034483\n",
      "Iteration: 118 Loss Value: 0.006477800030949332\n",
      "Iteration: 119 Loss Value: 0.006431904162607527\n",
      "Iteration: 120 Loss Value: 0.006386180781699613\n",
      "Iteration: 121 Loss Value: 0.006340632892607223\n",
      "Iteration: 122 Loss Value: 0.006295263431042253\n",
      "Iteration: 123 Loss Value: 0.006250075263727561\n",
      "Iteration: 124 Loss Value: 0.006205071188115419\n",
      "Iteration: 125 Loss Value: 0.006160253932162796\n",
      "Iteration: 126 Loss Value: 0.006115626154163278\n",
      "Iteration: 127 Loss Value: 0.006071190442589414\n",
      "Iteration: 128 Loss Value: 0.006026949316023433\n",
      "Iteration: 129 Loss Value: 0.005982905223096413\n",
      "Iteration: 130 Loss Value: 0.005939060542492269\n",
      "Iteration: 131 Loss Value: 0.0058954175829804\n",
      "Iteration: 132 Loss Value: 0.005851978583504613\n",
      "Iteration: 133 Loss Value: 0.005808745713290375\n",
      "Iteration: 134 Loss Value: 0.005765721072018559\n",
      "Iteration: 135 Loss Value: 0.005722906690019514\n",
      "Iteration: 136 Loss Value: 0.0056803045285027665\n",
      "Iteration: 137 Loss Value: 0.0056379164798395776\n",
      "Iteration: 138 Loss Value: 0.0055957443678732455\n",
      "Iteration: 139 Loss Value: 0.005553789948250398\n",
      "Iteration: 140 Loss Value: 0.005512054908815567\n",
      "Iteration: 141 Loss Value: 0.005470540870005314\n",
      "Iteration: 142 Loss Value: 0.005429249385304202\n",
      "Iteration: 143 Loss Value: 0.005388181941707537\n",
      "Iteration: 144 Loss Value: 0.005347339960228958\n",
      "Iteration: 145 Loss Value: 0.005306724796428797\n",
      "Iteration: 146 Loss Value: 0.005266337740970295\n",
      "Iteration: 147 Loss Value: 0.005226180020208915\n",
      "Iteration: 148 Loss Value: 0.005186252796798629\n",
      "Iteration: 149 Loss Value: 0.005146557170321642\n",
      "Iteration: 150 Loss Value: 0.005107094177954741\n",
      "Iteration: 151 Loss Value: 0.005067864795136545\n",
      "Iteration: 152 Loss Value: 0.0050288699362779354\n",
      "Iteration: 153 Loss Value: 0.004990110455471708\n",
      "Iteration: 154 Loss Value: 0.00495158714723809\n",
      "Iteration: 155 Loss Value: 0.0049133007472779155\n",
      "Iteration: 156 Loss Value: 0.004875251933242453\n",
      "Iteration: 157 Loss Value: 0.004837441325529546\n",
      "Iteration: 158 Loss Value: 0.004799869488079422\n",
      "Iteration: 159 Loss Value: 0.004762536929192707\n",
      "Iteration: 160 Loss Value: 0.004725444102364751\n",
      "Iteration: 161 Loss Value: 0.004688591407123077\n",
      "Iteration: 162 Loss Value: 0.004651979189877364\n",
      "Iteration: 163 Loss Value: 0.0046156077447903066\n",
      "Iteration: 164 Loss Value: 0.004579477314637703\n",
      "Iteration: 165 Loss Value: 0.004543588091694417\n",
      "Iteration: 166 Loss Value: 0.004507940218620998\n",
      "Iteration: 167 Loss Value: 0.004472533789349642\n",
      "Iteration: 168 Loss Value: 0.0044373688499931285\n",
      "Iteration: 169 Loss Value: 0.004402445399736221\n",
      "Iteration: 170 Loss Value: 0.004367763391751156\n",
      "Iteration: 171 Loss Value: 0.0043333227341010305\n",
      "Iteration: 172 Loss Value: 0.0042991232906557375\n",
      "Iteration: 173 Loss Value: 0.00426516488200579\n",
      "Iteration: 174 Loss Value: 0.004231447286371148\n",
      "Iteration: 175 Loss Value: 0.004197970240525928\n",
      "Iteration: 176 Loss Value: 0.004164733440700119\n",
      "Iteration: 177 Loss Value: 0.0041317365435062925\n",
      "Iteration: 178 Loss Value: 0.004098979166837102\n",
      "Iteration: 179 Loss Value: 0.004066460890783219\n",
      "Iteration: 180 Loss Value: 0.004034181258537717\n",
      "Iteration: 181 Loss Value: 0.004002139777296909\n",
      "Iteration: 182 Loss Value: 0.003970335919154078\n",
      "Iteration: 183 Loss Value: 0.00393876912200497\n",
      "Iteration: 184 Loss Value: 0.003907438790423878\n",
      "Iteration: 185 Loss Value: 0.0038763442965518147\n",
      "Iteration: 186 Loss Value: 0.003845484980976588\n",
      "Iteration: 187 Loss Value: 0.0038148601535960003\n",
      "Iteration: 188 Loss Value: 0.0037844690944858206\n",
      "Iteration: 189 Loss Value: 0.003754311054756654\n",
      "Iteration: 190 Loss Value: 0.003724385257398266\n",
      "Iteration: 191 Loss Value: 0.003694690898124242\n",
      "Iteration: 192 Loss Value: 0.0036652271462028763\n",
      "Iteration: 193 Loss Value: 0.0036359931452782934\n",
      "Iteration: 194 Loss Value: 0.003606988014187129\n",
      "Iteration: 195 Loss Value: 0.0035782108477645513\n",
      "Iteration: 196 Loss Value: 0.003549660717636516\n",
      "Iteration: 197 Loss Value: 0.0035213366730095785\n",
      "Iteration: 198 Loss Value: 0.003493237741443833\n",
      "Iteration: 199 Loss Value: 0.003465362929619409\n",
      "Iteration: 200 Loss Value: 0.0034377112240926433\n",
      "Iteration: 201 Loss Value: 0.003410281592039821\n",
      "Iteration: 202 Loss Value: 0.003383072981991142\n",
      "Iteration: 203 Loss Value: 0.003356084324554698\n",
      "Iteration: 204 Loss Value: 0.0033293145331272367\n",
      "Iteration: 205 Loss Value: 0.003302762504595491\n",
      "Iteration: 206 Loss Value: 0.003276427120027292\n",
      "Iteration: 207 Loss Value: 0.003250307245346029\n",
      "Iteration: 208 Loss Value: 0.0032244017320030016\n",
      "Iteration: 209 Loss Value: 0.0031987094176284536\n",
      "Iteration: 210 Loss Value: 0.0031732291266766133\n",
      "Iteration: 211 Loss Value: 0.0031479596710602964\n",
      "Iteration: 212 Loss Value: 0.003122899850765748\n",
      "Iteration: 213 Loss Value: 0.003098048454469593\n",
      "Iteration: 214 Loss Value: 0.0030734042601295863\n",
      "Iteration: 215 Loss Value: 0.003048966035574474\n",
      "Iteration: 216 Loss Value: 0.0030247325390756474\n",
      "Iteration: 217 Loss Value: 0.0030007025199095816\n",
      "Iteration: 218 Loss Value: 0.0029768747189140576\n",
      "Iteration: 219 Loss Value: 0.0029532478690171837\n",
      "Iteration: 220 Loss Value: 0.0029298206957770745\n",
      "Iteration: 221 Loss Value: 0.0029065919178878907\n",
      "Iteration: 222 Loss Value: 0.0028835602476934286\n",
      "Iteration: 223 Loss Value: 0.0028607243916747294\n",
      "Iteration: 224 Loss Value: 0.0028380830509350252\n",
      "Iteration: 225 Loss Value: 0.0028156349216714727\n",
      "Iteration: 226 Loss Value: 0.002793378695634119\n",
      "Iteration: 227 Loss Value: 0.002771313060575875\n",
      "Iteration: 228 Loss Value: 0.0027494367006898335\n",
      "Iteration: 229 Loss Value: 0.0027277482970391453\n",
      "Iteration: 230 Loss Value: 0.002706246527969247\n",
      "Iteration: 231 Loss Value: 0.0026849300695208633\n",
      "Iteration: 232 Loss Value: 0.0026637975958174742\n",
      "Iteration: 233 Loss Value: 0.002642847779458446\n",
      "Iteration: 234 Loss Value: 0.002622079291888957\n",
      "Iteration: 235 Loss Value: 0.002601490803767148\n",
      "Iteration: 236 Loss Value: 0.00258108098531884\n",
      "Iteration: 237 Loss Value: 0.0025608485066833664\n",
      "Iteration: 238 Loss Value: 0.002540792038246087\n",
      "Iteration: 239 Loss Value: 0.002520910250969899\n",
      "Iteration: 240 Loss Value: 0.002501201816705656\n",
      "Iteration: 241 Loss Value: 0.002481665408502143\n",
      "Iteration: 242 Loss Value: 0.0024622997009069447\n",
      "Iteration: 243 Loss Value: 0.0024431033702460025\n",
      "Iteration: 244 Loss Value: 0.002424075094916489\n",
      "Iteration: 245 Loss Value: 0.0024052135556474896\n",
      "Iteration: 246 Loss Value: 0.0023865174357680097\n",
      "Iteration: 247 Loss Value: 0.0023679854214589957\n",
      "Iteration: 248 Loss Value: 0.002349616202002358\n",
      "Iteration: 249 Loss Value: 0.002331408470013896\n",
      "Iteration: 250 Loss Value: 0.002313360921676999\n",
      "Iteration: 251 Loss Value: 0.002295472256963138\n",
      "Iteration: 252 Loss Value: 0.002277741179846249\n",
      "Iteration: 253 Loss Value: 0.0022601663985096776\n",
      "Iteration: 254 Loss Value: 0.002242746625543912\n",
      "Iteration: 255 Loss Value: 0.0022254805781399822\n",
      "Iteration: 256 Loss Value: 0.002208366978274312\n",
      "Iteration: 257 Loss Value: 0.0021914045528853565\n",
      "Iteration: 258 Loss Value: 0.0021745920340442426\n",
      "Iteration: 259 Loss Value: 0.002157928159122524\n",
      "Iteration: 260 Loss Value: 0.002141411670943172\n",
      "Iteration: 261 Loss Value: 0.0021250413179392247\n",
      "Iteration: 262 Loss Value: 0.0021088158542936775\n",
      "Iteration: 263 Loss Value: 0.0020927340400803685\n",
      "Iteration: 264 Loss Value: 0.0020767946413947636\n",
      "Iteration: 265 Loss Value: 0.0020609964304849626\n",
      "Iteration: 266 Loss Value: 0.002045338185867829\n",
      "Iteration: 267 Loss Value: 0.0020298186924493367\n",
      "Iteration: 268 Loss Value: 0.0020144367416292663\n",
      "Iteration: 269 Loss Value: 0.0019991911314127253\n",
      "Iteration: 270 Loss Value: 0.0019840806665036848\n",
      "Iteration: 271 Loss Value: 0.0019691041584011804\n",
      "Iteration: 272 Loss Value: 0.0019542604254934037\n",
      "Iteration: 273 Loss Value: 0.001939548293132809\n",
      "Iteration: 274 Loss Value: 0.0019249665937268734\n",
      "Iteration: 275 Loss Value: 0.0019105141668044334\n",
      "Iteration: 276 Loss Value: 0.0018961898590946213\n",
      "Iteration: 277 Loss Value: 0.0018819925245840419\n",
      "Iteration: 278 Loss Value: 0.0018679210245896583\n",
      "Iteration: 279 Loss Value: 0.0018539742278070315\n",
      "Iteration: 280 Loss Value: 0.0018401510103731589\n",
      "Iteration: 281 Loss Value: 0.001826450255910439\n",
      "Iteration: 282 Loss Value: 0.001812870855574522\n",
      "Iteration: 283 Loss Value: 0.0017994117081003846\n",
      "Iteration: 284 Loss Value: 0.0017860717198376896\n",
      "Iteration: 285 Loss Value: 0.0017728498047876462\n",
      "Iteration: 286 Loss Value: 0.0017597448846369823\n",
      "Iteration: 287 Loss Value: 0.0017467558887838686\n",
      "Iteration: 288 Loss Value: 0.0017338817543662288\n",
      "Iteration: 289 Loss Value: 0.0017211214262838892\n",
      "Iteration: 290 Loss Value: 0.0017084738572190616\n",
      "Iteration: 291 Loss Value: 0.0016959380076498887\n",
      "Iteration: 292 Loss Value: 0.0016835128458698168\n",
      "Iteration: 293 Loss Value: 0.0016711973479933695\n",
      "Iteration: 294 Loss Value: 0.0016589904979694703\n",
      "Iteration: 295 Loss Value: 0.0016468912875853836\n",
      "Iteration: 296 Loss Value: 0.001634898716468991\n",
      "Iteration: 297 Loss Value: 0.0016230117920925657\n",
      "Iteration: 298 Loss Value: 0.0016112295297708856\n",
      "Iteration: 299 Loss Value: 0.0015995509526579021\n",
      "Iteration: 300 Loss Value: 0.0015879750917397462\n",
      "Iteration: 301 Loss Value: 0.0015765009858290657\n",
      "Iteration: 302 Loss Value: 0.0015651276815561443\n",
      "Iteration: 303 Loss Value: 0.0015538542333536909\n",
      "Iteration: 304 Loss Value: 0.0015426797034482354\n",
      "Iteration: 305 Loss Value: 0.0015316031618399784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 306 Loss Value: 0.0015206236862909117\n",
      "Iteration: 307 Loss Value: 0.0015097403623009487\n",
      "Iteration: 308 Loss Value: 0.0014989522830930468\n",
      "Iteration: 309 Loss Value: 0.0014882585495865075\n",
      "Iteration: 310 Loss Value: 0.0014776582703762697\n",
      "Iteration: 311 Loss Value: 0.0014671505617085967\n",
      "Iteration: 312 Loss Value: 0.0014567345474539861\n",
      "Iteration: 313 Loss Value: 0.0014464093590779714\n",
      "Iteration: 314 Loss Value: 0.0014361741356169189\n",
      "Iteration: 315 Loss Value: 0.0014260280236444989\n",
      "Iteration: 316 Loss Value: 0.0014159701772396005\n",
      "Iteration: 317 Loss Value: 0.0014059997579600747\n",
      "Iteration: 318 Loss Value: 0.0013961159348019891\n",
      "Iteration: 319 Loss Value: 0.0013863178841696522\n",
      "Iteration: 320 Loss Value: 0.0013766047898411404\n",
      "Iteration: 321 Loss Value: 0.0013669758429283863\n",
      "Iteration: 322 Loss Value: 0.001357430241843871\n",
      "Iteration: 323 Loss Value: 0.0013479671922596026\n",
      "Iteration: 324 Loss Value: 0.0013385859070719208\n",
      "Iteration: 325 Loss Value: 0.0013292856063572\n",
      "Iteration: 326 Loss Value: 0.0013200655173368214\n",
      "Iteration: 327 Loss Value: 0.0013109248743331525\n",
      "Iteration: 328 Loss Value: 0.001301862918728136\n",
      "Iteration: 329 Loss Value: 0.0012928788989226003\n",
      "Iteration: 330 Loss Value: 0.0012839720702931268\n",
      "Iteration: 331 Loss Value: 0.0012751416951474748\n",
      "Iteration: 332 Loss Value: 0.0012663870426822266\n",
      "Iteration: 333 Loss Value: 0.0012577073889385448\n",
      "Iteration: 334 Loss Value: 0.001249102016756487\n",
      "Iteration: 335 Loss Value: 0.0012405702157312626\n",
      "Iteration: 336 Loss Value: 0.001232111282166548\n",
      "Iteration: 337 Loss Value: 0.001223724519028968\n",
      "Iteration: 338 Loss Value: 0.001215409235903242\n",
      "Iteration: 339 Loss Value: 0.00120716474894339\n",
      "Iteration: 340 Loss Value: 0.0011989903808279911\n",
      "Iteration: 341 Loss Value: 0.0011908854607121655\n",
      "Iteration: 342 Loss Value: 0.0011828493241800575\n",
      "Iteration: 343 Loss Value: 0.0011748813131995939\n",
      "Iteration: 344 Loss Value: 0.0011669807760714135\n",
      "Iteration: 345 Loss Value: 0.0011591470673839588\n",
      "Iteration: 346 Loss Value: 0.001151379547964293\n",
      "Iteration: 347 Loss Value: 0.0011436775848295277\n",
      "Iteration: 348 Loss Value: 0.0011360405511415261\n",
      "Iteration: 349 Loss Value: 0.0011284678261538894\n",
      "Iteration: 350 Loss Value: 0.0011209587951685474\n",
      "Iteration: 351 Loss Value: 0.001113512849484355\n",
      "Iteration: 352 Loss Value: 0.001106129386348853\n",
      "Iteration: 353 Loss Value: 0.0010988078089128606\n",
      "Iteration: 354 Loss Value: 0.00109154752617735\n",
      "Iteration: 355 Loss Value: 0.0010843479529500377\n",
      "Iteration: 356 Loss Value: 0.0010772085097916495\n",
      "Iteration: 357 Loss Value: 0.0010701286229750084\n",
      "Iteration: 358 Loss Value: 0.0010631077244284692\n",
      "Iteration: 359 Loss Value: 0.001056145251693008\n",
      "Iteration: 360 Loss Value: 0.0010492406478747607\n",
      "Iteration: 361 Loss Value: 0.001042393361592231\n",
      "Iteration: 362 Loss Value: 0.0010356028469341583\n",
      "Iteration: 363 Loss Value: 0.0010288685634079475\n",
      "Iteration: 364 Loss Value: 0.0010221899758926511\n",
      "Iteration: 365 Loss Value: 0.0010155665545928394\n",
      "Iteration: 366 Loss Value: 0.0010089977749908607\n",
      "Iteration: 367 Loss Value: 0.0010024831177987692\n"
     ]
    }
   ],
   "source": [
    "lb.fit(proc_data[:100], Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lb.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lb.predict(proc_data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing dataset: 0.848\n"
     ]
    }
   ],
   "source": [
    "sm = Score_Matrix(Y[100:], pred)\n",
    "print ('Accuracy on testing dataset: %.3f'%sm.check_accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36856</td>\n",
       "      <td>2969</td>\n",
       "      <td>39825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3877</td>\n",
       "      <td>1409</td>\n",
       "      <td>5286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>40733</td>\n",
       "      <td>4378</td>\n",
       "      <td>45111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted      0     1    All\n",
       "actual                       \n",
       "0          36856  2969  39825\n",
       "1           3877  1409   5286\n",
       "All        40733  4378  45111"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Logistic Regression on the zero theta vector with **L2 regularization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LogisticRegression(theta_init = 'zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss Value: 0.0035640551544977583\n",
      "Iteration: 2 Loss Value: 0.003534943648440647\n",
      "Iteration: 3 Loss Value: 0.003505972529070034\n",
      "Iteration: 4 Loss Value: 0.00347714395185994\n",
      "Iteration: 5 Loss Value: 0.0034484599907197433\n",
      "Iteration: 6 Loss Value: 0.0034199226389259874\n",
      "Iteration: 7 Loss Value: 0.0033915338100689585\n",
      "Iteration: 8 Loss Value: 0.0033632953390352327\n",
      "Iteration: 9 Loss Value: 0.0033352089830126497\n",
      "Iteration: 10 Loss Value: 0.0033072764225102746\n",
      "Iteration: 11 Loss Value: 0.0032794992624144426\n",
      "Iteration: 12 Loss Value: 0.003251879033048466\n",
      "Iteration: 13 Loss Value: 0.0032244171912653163\n",
      "Iteration: 14 Loss Value: 0.0031971151215437477\n",
      "Iteration: 15 Loss Value: 0.003169974137109288\n",
      "Iteration: 16 Loss Value: 0.0031429954810673344\n",
      "Iteration: 17 Loss Value: 0.0031161803275426836\n",
      "Iteration: 18 Loss Value: 0.0030895297828416046\n",
      "Iteration: 19 Loss Value: 0.003063044886607469\n",
      "Iteration: 20 Loss Value: 0.003036726613004581\n",
      "Iteration: 21 Loss Value: 0.0030105758718923514\n",
      "Iteration: 22 Loss Value: 0.002984593510014011\n",
      "Iteration: 23 Loss Value: 0.0029587803121875478\n",
      "Iteration: 24 Loss Value: 0.0029331370025035275\n",
      "Iteration: 25 Loss Value: 0.0029076642455212465\n",
      "Iteration: 26 Loss Value: 0.002882362647467107\n",
      "Iteration: 27 Loss Value: 0.0028572327574377665\n",
      "Iteration: 28 Loss Value: 0.0028322750685967346\n",
      "Iteration: 29 Loss Value: 0.0028074900193734154\n",
      "Iteration: 30 Loss Value: 0.002782877994659705\n",
      "Iteration: 31 Loss Value: 0.0027584393269993734\n",
      "Iteration: 32 Loss Value: 0.0027341742977786687\n",
      "Iteration: 33 Loss Value: 0.002710083138408037\n",
      "Iteration: 34 Loss Value: 0.0026861660315006253\n",
      "Iteration: 35 Loss Value: 0.0026624231120400133\n",
      "Iteration: 36 Loss Value: 0.0026388544685473914\n",
      "Iteration: 37 Loss Value: 0.002615460144234416\n",
      "Iteration: 38 Loss Value: 0.0025922401381510696\n",
      "Iteration: 39 Loss Value: 0.0025691944063238603\n",
      "Iteration: 40 Loss Value: 0.0025463228628813672\n",
      "Iteration: 41 Loss Value: 0.002523625381175454\n",
      "Iteration: 42 Loss Value: 0.0025011017948850522\n",
      "Iteration: 43 Loss Value: 0.0024787518991141733\n",
      "Iteration: 44 Loss Value: 0.0024565754514713767\n",
      "Iteration: 45 Loss Value: 0.0024345721731469094\n",
      "Iteration: 46 Loss Value: 0.0024127417499679726\n",
      "Iteration: 47 Loss Value: 0.0023910838334439966\n",
      "Iteration: 48 Loss Value: 0.0023695980418018125\n",
      "Iteration: 49 Loss Value: 0.0023482839610040607\n",
      "Iteration: 50 Loss Value: 0.002327141145750944\n",
      "Iteration: 51 Loss Value: 0.00230616912047632\n",
      "Iteration: 52 Loss Value: 0.002285367380320702\n",
      "Iteration: 53 Loss Value: 0.0022647353920927094\n",
      "Iteration: 54 Loss Value: 0.002244272595220642\n",
      "Iteration: 55 Loss Value: 0.0022239784026764076\n",
      "Iteration: 56 Loss Value: 0.002203852201901335\n",
      "Iteration: 57 Loss Value: 0.0021838933557003504\n",
      "Iteration: 58 Loss Value: 0.002164101203134594\n",
      "Iteration: 59 Loss Value: 0.002144475060385842\n",
      "Iteration: 60 Loss Value: 0.0021250142216162615\n",
      "Iteration: 61 Loss Value: 0.002105717959806519\n",
      "Iteration: 62 Loss Value: 0.0020865855275803424\n",
      "Iteration: 63 Loss Value: 0.0020676161580104324\n",
      "Iteration: 64 Loss Value: 0.002048809065414825\n",
      "Iteration: 65 Loss Value: 0.002030163446129829\n",
      "Iteration: 66 Loss Value: 0.002011678479276191\n",
      "Iteration: 67 Loss Value: 0.001993353327500391\n",
      "Iteration: 68 Loss Value: 0.0019751871377082786\n",
      "Iteration: 69 Loss Value: 0.001957179041775059\n",
      "Iteration: 70 Loss Value: 0.0019393281572517296\n",
      "Iteration: 71 Loss Value: 0.0019216335880430924\n",
      "Iteration: 72 Loss Value: 0.0019040944250789948\n",
      "Iteration: 73 Loss Value: 0.0018867097469685845\n",
      "Iteration: 74 Loss Value: 0.0018694786206370773\n",
      "Iteration: 75 Loss Value: 0.0018524001019512015\n",
      "Iteration: 76 Loss Value: 0.0018354732363277115\n",
      "Iteration: 77 Loss Value: 0.001818697059327079\n",
      "Iteration: 78 Loss Value: 0.0018020705972358053\n",
      "Iteration: 79 Loss Value: 0.0017855928676286936\n",
      "Iteration: 80 Loss Value: 0.0017692628799219068\n",
      "Iteration: 81 Loss Value: 0.001753079635912036\n",
      "Iteration: 82 Loss Value: 0.001737042130297628\n",
      "Iteration: 83 Loss Value: 0.0017211493511888887\n",
      "Iteration: 84 Loss Value: 0.0017054002806051183\n",
      "Iteration: 85 Loss Value: 0.0016897938949585467\n",
      "Iteration: 86 Loss Value: 0.0016743291655238468\n",
      "Iteration: 87 Loss Value: 0.001659005058894436\n",
      "Iteration: 88 Loss Value: 0.0016438205374265102\n",
      "Iteration: 89 Loss Value: 0.0016287745596734737\n",
      "Iteration: 90 Loss Value: 0.0016138660808041605\n",
      "Iteration: 91 Loss Value: 0.0015990940530072328\n",
      "Iteration: 92 Loss Value: 0.0015844574258914168\n",
      "Iteration: 93 Loss Value: 0.0015699551468674744\n",
      "Iteration: 94 Loss Value: 0.0015555861615179079\n",
      "Iteration: 95 Loss Value: 0.0015413494139600026\n",
      "Iteration: 96 Loss Value: 0.00152724384719638\n",
      "Iteration: 97 Loss Value: 0.0015132684034499522\n",
      "Iteration: 98 Loss Value: 0.0014994220244971546\n",
      "Iteration: 99 Loss Value: 0.0014857036519789757\n",
      "Iteration: 100 Loss Value: 0.0014721122277145948\n",
      "Iteration: 101 Loss Value: 0.0014586466939929266\n",
      "Iteration: 102 Loss Value: 0.0014453059938632218\n",
      "Iteration: 103 Loss Value: 0.0014320890714094592\n",
      "Iteration: 104 Loss Value: 0.0014189948720211287\n",
      "Iteration: 105 Loss Value: 0.00140602234264936\n",
      "Iteration: 106 Loss Value: 0.0013931704320566118\n",
      "Iteration: 107 Loss Value: 0.0013804380910588665\n",
      "Iteration: 108 Loss Value: 0.0013678242727540035\n",
      "Iteration: 109 Loss Value: 0.0013553279327471746\n",
      "Iteration: 110 Loss Value: 0.0013429480293658536\n",
      "Iteration: 111 Loss Value: 0.001330683523864562\n",
      "Iteration: 112 Loss Value: 0.0013185333806252642\n",
      "Iteration: 113 Loss Value: 0.0013064965673459383\n",
      "Iteration: 114 Loss Value: 0.0012945720552263729\n",
      "Iteration: 115 Loss Value: 0.0012827588191413608\n",
      "Iteration: 116 Loss Value: 0.001271055837812285\n",
      "Iteration: 117 Loss Value: 0.001259462093964936\n",
      "Iteration: 118 Loss Value: 0.0012479765744858873\n",
      "Iteration: 119 Loss Value: 0.0012365982705705991\n",
      "Iteration: 120 Loss Value: 0.0012253261778648605\n",
      "Iteration: 121 Loss Value: 0.001214159296596351\n",
      "Iteration: 122 Loss Value: 0.0012030966317085334\n",
      "Iteration: 123 Loss Value: 0.0011921371929795588\n",
      "Iteration: 124 Loss Value: 0.0011812799951377295\n",
      "Iteration: 125 Loss Value: 0.0011705240579767962\n",
      "Iteration: 126 Loss Value: 0.0011598684064573206\n",
      "Iteration: 127 Loss Value: 0.0011493120708083726\n",
      "Iteration: 128 Loss Value: 0.001138854086620622\n",
      "Iteration: 129 Loss Value: 0.0011284934949378211\n",
      "Iteration: 130 Loss Value: 0.001118229342338517\n",
      "Iteration: 131 Loss Value: 0.0011080606810168203\n",
      "Iteration: 132 Loss Value: 0.0010979865688587886\n",
      "Iteration: 133 Loss Value: 0.0010880060695083738\n",
      "Iteration: 134 Loss Value: 0.0010781182524365884\n",
      "Iteration: 135 Loss Value: 0.0010683221930022357\n",
      "Iteration: 136 Loss Value: 0.0010586169725074202\n",
      "Iteration: 137 Loss Value: 0.0010490016782523925\n",
      "Iteration: 138 Loss Value: 0.0010394754035829568\n",
      "Iteration: 139 Loss Value: 0.0010300372479369324\n",
      "Iteration: 140 Loss Value: 0.0010206863168858993\n",
      "Iteration: 141 Loss Value: 0.0010114217221700583\n",
      "Iteration: 142 Loss Value: 0.001002242581737034\n"
     ]
    }
   ],
   "source": [
    "lb.fit(proc_data[:100], Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lb.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lb.predict(proc_data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = Score_Matrix(Y[100:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing dataset: 0.883\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy on testing dataset: %.3f'%sm.check_accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39825</td>\n",
       "      <td>39825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5286</td>\n",
       "      <td>5286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>45111</td>\n",
       "      <td>45111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted      0    All\n",
       "actual                 \n",
       "0          39825  39825\n",
       "1           5286   5286\n",
       "All        45111  45111"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Logistic Regression on zero theta vector and **L1 Regularization**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lb = LogisticRegression(theta_init = 'zero', penalty='l1', l1_penalty=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Loss Value: 0.0035640551544977583\n",
      "Iteration: 2 Loss Value: 0.003534796083763614\n",
      "Iteration: 3 Loss Value: 0.0035057793818951133\n",
      "Iteration: 4 Loss Value: 0.0034770038903444433\n",
      "Iteration: 5 Loss Value: 0.0034484684281612665\n",
      "Iteration: 6 Loss Value: 0.0034201717929066566\n",
      "Iteration: 7 Loss Value: 0.0033921127615286206\n",
      "Iteration: 8 Loss Value: 0.003364290091249167\n",
      "Iteration: 9 Loss Value: 0.0033367025204165124\n",
      "Iteration: 10 Loss Value: 0.0033093487693496293\n",
      "Iteration: 11 Loss Value: 0.003282227541173799\n",
      "Iteration: 12 Loss Value: 0.0032553375226315184\n",
      "Iteration: 13 Loss Value: 0.003228677384882306\n",
      "Iteration: 14 Loss Value: 0.003202245784291513\n",
      "Iteration: 15 Loss Value: 0.0031760413631966022\n",
      "Iteration: 16 Loss Value: 0.00315006275066243\n",
      "Iteration: 17 Loss Value: 0.0031243085632232104\n",
      "Iteration: 18 Loss Value: 0.003098777405601938\n",
      "Iteration: 19 Loss Value: 0.0030734678714248176\n",
      "Iteration: 20 Loss Value: 0.0030483785439111566\n",
      "Iteration: 21 Loss Value: 0.0030235079965545975\n",
      "Iteration: 22 Loss Value: 0.002998854793784478\n",
      "Iteration: 23 Loss Value: 0.0029744174916166433\n",
      "Iteration: 24 Loss Value: 0.0029501946382873845\n",
      "Iteration: 25 Loss Value: 0.002926184774867613\n",
      "Iteration: 26 Loss Value: 0.0029023864358767026\n",
      "Iteration: 27 Loss Value: 0.0028787981498588078\n",
      "Iteration: 28 Loss Value: 0.00285541843997128\n",
      "Iteration: 29 Loss Value: 0.002832245824536006\n",
      "Iteration: 30 Loss Value: 0.002809278817587524\n",
      "Iteration: 31 Loss Value: 0.002786515929409261\n",
      "Iteration: 32 Loss Value: 0.002763955667045792\n",
      "Iteration: 33 Loss Value: 0.0027415965348119853\n",
      "Iteration: 34 Loss Value: 0.0027194370347819463\n",
      "Iteration: 35 Loss Value: 0.0026974756672620837\n",
      "Iteration: 36 Loss Value: 0.0026757109312637306\n",
      "Iteration: 37 Loss Value: 0.002654141324943571\n",
      "Iteration: 38 Loss Value: 0.002632765346050836\n",
      "Iteration: 39 Loss Value: 0.0026115814923428626\n",
      "Iteration: 40 Loss Value: 0.002590588262003868\n",
      "Iteration: 41 Loss Value: 0.002569784154041299\n",
      "Iteration: 42 Loss Value: 0.0025491676686738574\n",
      "Iteration: 43 Loss Value: 0.0025287373077081954\n",
      "Iteration: 44 Loss Value: 0.0025084915748989633\n",
      "Iteration: 45 Loss Value: 0.002488428976303525\n",
      "Iteration: 46 Loss Value: 0.002468548020621464\n",
      "Iteration: 47 Loss Value: 0.0024488472195213218\n",
      "Iteration: 48 Loss Value: 0.0024293250879621198\n",
      "Iteration: 49 Loss Value: 0.0024099801444968927\n",
      "Iteration: 50 Loss Value: 0.0023908109115712284\n",
      "Iteration: 51 Loss Value: 0.002371815915807929\n",
      "Iteration: 52 Loss Value: 0.0023529936882826785\n",
      "Iteration: 53 Loss Value: 0.0023343427647878334\n",
      "Iteration: 54 Loss Value: 0.0023158616860938785\n",
      "Iteration: 55 Loss Value: 0.0022975489981854613\n",
      "Iteration: 56 Loss Value: 0.002279403252507528\n",
      "Iteration: 57 Loss Value: 0.0022614230061867024\n",
      "Iteration: 58 Loss Value: 0.0022436068222503325\n",
      "Iteration: 59 Loss Value: 0.002225953269837211\n",
      "Iteration: 60 Loss Value: 0.002208460924396527\n",
      "Iteration: 61 Loss Value: 0.0021911283678798243\n",
      "Iteration: 62 Loss Value: 0.002173954188926852\n",
      "Iteration: 63 Loss Value: 0.0021569369830382046\n",
      "Iteration: 64 Loss Value: 0.0021400753527447414\n",
      "Iteration: 65 Loss Value: 0.0021233679077672374\n",
      "Iteration: 66 Loss Value: 0.0021068132651699267\n",
      "Iteration: 67 Loss Value: 0.0020904100495025\n",
      "Iteration: 68 Loss Value: 0.002074156892942436\n",
      "Iteration: 69 Loss Value: 0.0020580524354224528\n",
      "Iteration: 70 Loss Value: 0.002042095324755522\n",
      "Iteration: 71 Loss Value: 0.002026284216754104\n",
      "Iteration: 72 Loss Value: 0.0020106177753385635\n",
      "Iteration: 73 Loss Value: 0.0019950946726447483\n",
      "Iteration: 74 Loss Value: 0.001979713589118859\n",
      "Iteration: 75 Loss Value: 0.00196447321361487\n",
      "Iteration: 76 Loss Value: 0.0019493722434781868\n",
      "Iteration: 77 Loss Value: 0.0019344093846269672\n",
      "Iteration: 78 Loss Value: 0.0019195833516288952\n",
      "Iteration: 79 Loss Value: 0.001904892867773511\n",
      "Iteration: 80 Loss Value: 0.0018903366651327747\n",
      "Iteration: 81 Loss Value: 0.0018759134846256798\n",
      "Iteration: 82 Loss Value: 0.0018616220760715452\n",
      "Iteration: 83 Loss Value: 0.001847461198241418\n",
      "Iteration: 84 Loss Value: 0.0018334296189045363\n",
      "Iteration: 85 Loss Value: 0.001819526114868908\n",
      "Iteration: 86 Loss Value: 0.0018057494720193357\n",
      "Iteration: 87 Loss Value: 0.0017920984853507238\n",
      "Iteration: 88 Loss Value: 0.0017785719589974436\n",
      "Iteration: 89 Loss Value: 0.001765168706257536\n",
      "Iteration: 90 Loss Value: 0.0017518875496155828\n",
      "Iteration: 91 Loss Value: 0.001738727320759359\n",
      "Iteration: 92 Loss Value: 0.0017256868605939335\n",
      "Iteration: 93 Loss Value: 0.0017127650192543253\n",
      "Iteration: 94 Loss Value: 0.0016999606561106106\n",
      "Iteration: 95 Loss Value: 0.0016872726397735294\n",
      "Iteration: 96 Loss Value: 0.0016746998480963171\n",
      "Iteration: 97 Loss Value: 0.001662241168169154\n",
      "Iteration: 98 Loss Value: 0.001649895496323106\n",
      "Iteration: 99 Loss Value: 0.001637661738109808\n",
      "Iteration: 100 Loss Value: 0.0016255388083052935\n",
      "Iteration: 101 Loss Value: 0.0016135256308860702\n",
      "Iteration: 102 Loss Value: 0.0016016211390212365\n",
      "Iteration: 103 Loss Value: 0.0015898242750496117\n",
      "Iteration: 104 Loss Value: 0.0015781339904660796\n",
      "Iteration: 105 Loss Value: 0.0015665492458927788\n",
      "Iteration: 106 Loss Value: 0.0015550690110602838\n",
      "Iteration: 107 Loss Value: 0.0015436922647774631\n",
      "Iteration: 108 Loss Value: 0.0015324179949072203\n",
      "Iteration: 109 Loss Value: 0.0015212451983333541\n",
      "Iteration: 110 Loss Value: 0.001510172880929972\n",
      "Iteration: 111 Loss Value: 0.0014992000575277387\n",
      "Iteration: 112 Loss Value: 0.0014883257518794046\n",
      "Iteration: 113 Loss Value: 0.0014775489966216693\n",
      "Iteration: 114 Loss Value: 0.0014668688332381552\n",
      "Iteration: 115 Loss Value: 0.0014562843120192737\n",
      "Iteration: 116 Loss Value: 0.0014457944920213128\n",
      "Iteration: 117 Loss Value: 0.0014353984410236942\n",
      "Iteration: 118 Loss Value: 0.001425095235486229\n",
      "Iteration: 119 Loss Value: 0.0014148839605023777\n",
      "Iteration: 120 Loss Value: 0.0014047637097561183\n",
      "Iteration: 121 Loss Value: 0.0013947335854731513\n",
      "Iteration: 122 Loss Value: 0.001384792698372661\n",
      "Iteration: 123 Loss Value: 0.0013749401676205752\n",
      "Iteration: 124 Loss Value: 0.0013651751207757745\n",
      "Iteration: 125 Loss Value: 0.0013554966937445179\n",
      "Iteration: 126 Loss Value: 0.0013459040307237657\n",
      "Iteration: 127 Loss Value: 0.0013363962841541621\n",
      "Iteration: 128 Loss Value: 0.0013269726146607486\n",
      "Iteration: 129 Loss Value: 0.0013176321910058353\n",
      "Iteration: 130 Loss Value: 0.0013083741900304369\n",
      "Iteration: 131 Loss Value: 0.001299197796601037\n",
      "Iteration: 132 Loss Value: 0.0012901022035545773\n",
      "Iteration: 133 Loss Value: 0.0012810866116405584\n",
      "Iteration: 134 Loss Value: 0.0012721502294674725\n",
      "Iteration: 135 Loss Value: 0.00126329227344385\n",
      "Iteration: 136 Loss Value: 0.0012545119677228045\n",
      "Iteration: 137 Loss Value: 0.001245808544141691\n",
      "Iteration: 138 Loss Value: 0.0012371812421697603\n",
      "Iteration: 139 Loss Value: 0.0012286293088429323\n",
      "Iteration: 140 Loss Value: 0.0012201519987110054\n",
      "Iteration: 141 Loss Value: 0.0012117485737772604\n",
      "Iteration: 142 Loss Value: 0.0012034183034378976\n",
      "Iteration: 143 Loss Value: 0.0011951604644270253\n",
      "Iteration: 144 Loss Value: 0.0011869743407527111\n",
      "Iteration: 145 Loss Value: 0.0011788592236419149\n",
      "Iteration: 146 Loss Value: 0.0011708144114794261\n",
      "Iteration: 147 Loss Value: 0.0011628392097474682\n",
      "Iteration: 148 Loss Value: 0.0011549329309681333\n",
      "Iteration: 149 Loss Value: 0.0011470948946431525\n",
      "Iteration: 150 Loss Value: 0.001139324427194388\n",
      "Iteration: 151 Loss Value: 0.001131620861904048\n",
      "Iteration: 152 Loss Value: 0.001123983538855955\n",
      "Iteration: 153 Loss Value: 0.0011164118048751503\n",
      "Iteration: 154 Loss Value: 0.0011089050134711065\n",
      "Iteration: 155 Loss Value: 0.0011014625247754983\n",
      "Iteration: 156 Loss Value: 0.0010940837054836394\n",
      "Iteration: 157 Loss Value: 0.0010867679287991927\n",
      "Iteration: 158 Loss Value: 0.0010795145743694445\n",
      "Iteration: 159 Loss Value: 0.0010723230282319585\n",
      "Iteration: 160 Loss Value: 0.0010651926827526248\n",
      "Iteration: 161 Loss Value: 0.0010581229365694278\n",
      "Iteration: 162 Loss Value: 0.0010511131945337149\n",
      "Iteration: 163 Loss Value: 0.0010441628676517434\n",
      "Iteration: 164 Loss Value: 0.0010372713730278926\n",
      "Iteration: 165 Loss Value: 0.0010304381338070434\n",
      "Iteration: 166 Loss Value: 0.0010236625791172904\n",
      "Iteration: 167 Loss Value: 0.0010169441440124882\n",
      "Iteration: 168 Loss Value: 0.0010102822694172398\n",
      "Iteration: 169 Loss Value: 0.001003676402068554\n"
     ]
    }
   ],
   "source": [
    "lb.fit(proc_data[:100], Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lb.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lb.predict(proc_data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = Score_Matrix(Y[100:], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing dataset: 0.883\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy on testing dataset: %.3f'%sm.check_accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39825</td>\n",
       "      <td>39825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5286</td>\n",
       "      <td>5286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>45111</td>\n",
       "      <td>45111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted      0    All\n",
       "actual                 \n",
       "0          39825  39825\n",
       "1           5286   5286\n",
       "All        45111  45111"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Logistic Regression using Scikit-Learn and checking for the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_sklearn = LogisticRegression(verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritik\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_sklearn.fit(proc_data[:100], Y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sklearn = l_sklearn.predict(proc_data[100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_sm = Score_Matrix(Y[100:], pred_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing dataset: 0.883\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy on testing dataset: %.3f'%sklearn_sm.check_accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39825</td>\n",
       "      <td>39825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5286</td>\n",
       "      <td>5286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>45111</td>\n",
       "      <td>45111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predicted      0    All\n",
       "actual                 \n",
       "0          39825  39825\n",
       "1           5286   5286\n",
       "All        45111  45111"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_sm.confusion_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
