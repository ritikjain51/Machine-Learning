{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist as mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-5300fea9c6a3>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data = mnist.input_data.read_data_sets('/tmp/data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data.train.images\n",
    "label = data.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ritik\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, (None, 784))\n",
    "w = tf.Variable(tf.random_normal([784, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(tf.random_normal([1, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.placeholder(tf.float32, [None, 10])\n",
    "y_pred = tf.matmul(x, w) + b\n",
    "print (y_true)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-092d1321e872>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_true, logits = y_pred))\n",
    "gd_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.equal(tf.argmax(y_pred, axis = 1), tf.argmax(y_true, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Loss:  10.78586   Accuracy:  0.171875\n",
      "Iteration:  1  Loss:  10.398654   Accuracy:  0.1171875\n",
      "Iteration:  2  Loss:  9.105162   Accuracy:  0.1640625\n",
      "Iteration:  3  Loss:  7.6073275   Accuracy:  0.1640625\n",
      "Iteration:  4  Loss:  7.836631   Accuracy:  0.203125\n",
      "Iteration:  5  Loss:  6.526205   Accuracy:  0.1640625\n",
      "Iteration:  6  Loss:  6.254746   Accuracy:  0.21875\n",
      "Iteration:  7  Loss:  6.480485   Accuracy:  0.2265625\n",
      "Iteration:  8  Loss:  4.880606   Accuracy:  0.2734375\n",
      "Iteration:  9  Loss:  5.038391   Accuracy:  0.296875\n",
      "Iteration:  10  Loss:  4.4854503   Accuracy:  0.359375\n",
      "Iteration:  11  Loss:  4.5636044   Accuracy:  0.328125\n",
      "Iteration:  12  Loss:  4.129335   Accuracy:  0.3515625\n",
      "Iteration:  13  Loss:  4.3763494   Accuracy:  0.3671875\n",
      "Iteration:  14  Loss:  4.6738386   Accuracy:  0.3671875\n",
      "Iteration:  15  Loss:  3.385322   Accuracy:  0.484375\n",
      "Iteration:  16  Loss:  3.3269465   Accuracy:  0.5078125\n",
      "Iteration:  17  Loss:  3.3992507   Accuracy:  0.421875\n",
      "Iteration:  18  Loss:  3.5331876   Accuracy:  0.4453125\n",
      "Iteration:  19  Loss:  3.1914485   Accuracy:  0.4609375\n",
      "Iteration:  20  Loss:  3.1074944   Accuracy:  0.515625\n",
      "Iteration:  21  Loss:  4.3074994   Accuracy:  0.40625\n",
      "Iteration:  22  Loss:  3.3517015   Accuracy:  0.4375\n",
      "Iteration:  23  Loss:  2.6454692   Accuracy:  0.5078125\n",
      "Iteration:  24  Loss:  3.2617657   Accuracy:  0.4609375\n",
      "Iteration:  25  Loss:  2.665126   Accuracy:  0.5546875\n",
      "Iteration:  26  Loss:  2.6216455   Accuracy:  0.546875\n",
      "Iteration:  27  Loss:  1.9166677   Accuracy:  0.6171875\n",
      "Iteration:  28  Loss:  2.6502523   Accuracy:  0.5546875\n",
      "Iteration:  29  Loss:  2.167509   Accuracy:  0.5859375\n",
      "Iteration:  30  Loss:  2.6409988   Accuracy:  0.515625\n",
      "Iteration:  31  Loss:  2.0276923   Accuracy:  0.6328125\n",
      "Iteration:  32  Loss:  2.1837153   Accuracy:  0.640625\n",
      "Iteration:  33  Loss:  2.5532255   Accuracy:  0.5625\n",
      "Iteration:  34  Loss:  2.0578861   Accuracy:  0.6015625\n",
      "Iteration:  35  Loss:  2.7947679   Accuracy:  0.53125\n",
      "Iteration:  36  Loss:  2.438477   Accuracy:  0.5625\n",
      "Iteration:  37  Loss:  2.037655   Accuracy:  0.6015625\n",
      "Iteration:  38  Loss:  2.0341907   Accuracy:  0.6328125\n",
      "Iteration:  39  Loss:  2.502269   Accuracy:  0.640625\n",
      "Iteration:  40  Loss:  2.4554808   Accuracy:  0.609375\n",
      "Iteration:  41  Loss:  2.2787614   Accuracy:  0.5390625\n",
      "Iteration:  42  Loss:  2.4916756   Accuracy:  0.59375\n",
      "Iteration:  43  Loss:  2.0827446   Accuracy:  0.640625\n",
      "Iteration:  44  Loss:  1.7272412   Accuracy:  0.625\n",
      "Iteration:  45  Loss:  1.9341394   Accuracy:  0.640625\n",
      "Iteration:  46  Loss:  2.724949   Accuracy:  0.5625\n",
      "Iteration:  47  Loss:  2.4313874   Accuracy:  0.546875\n",
      "Iteration:  48  Loss:  1.596626   Accuracy:  0.625\n",
      "Iteration:  49  Loss:  2.3943577   Accuracy:  0.609375\n",
      "Iteration:  50  Loss:  1.6995772   Accuracy:  0.65625\n",
      "Iteration:  51  Loss:  1.5277758   Accuracy:  0.6953125\n",
      "Iteration:  52  Loss:  1.6029423   Accuracy:  0.6328125\n",
      "Iteration:  53  Loss:  1.9205079   Accuracy:  0.65625\n",
      "Iteration:  54  Loss:  2.3243742   Accuracy:  0.546875\n",
      "Iteration:  55  Loss:  1.716484   Accuracy:  0.671875\n",
      "Iteration:  56  Loss:  1.6007848   Accuracy:  0.640625\n",
      "Iteration:  57  Loss:  1.9448313   Accuracy:  0.6640625\n",
      "Iteration:  58  Loss:  1.7271922   Accuracy:  0.640625\n",
      "Iteration:  59  Loss:  1.6725798   Accuracy:  0.671875\n",
      "Iteration:  60  Loss:  1.7359711   Accuracy:  0.6953125\n",
      "Iteration:  61  Loss:  2.261538   Accuracy:  0.640625\n",
      "Iteration:  62  Loss:  1.8224669   Accuracy:  0.703125\n",
      "Iteration:  63  Loss:  1.3906993   Accuracy:  0.7109375\n",
      "Iteration:  64  Loss:  1.3781507   Accuracy:  0.71875\n",
      "Iteration:  65  Loss:  2.083918   Accuracy:  0.6015625\n",
      "Iteration:  66  Loss:  1.8879478   Accuracy:  0.7109375\n",
      "Iteration:  67  Loss:  1.862633   Accuracy:  0.6953125\n",
      "Iteration:  68  Loss:  1.6022753   Accuracy:  0.734375\n",
      "Iteration:  69  Loss:  1.7047117   Accuracy:  0.6796875\n",
      "Iteration:  70  Loss:  1.6080444   Accuracy:  0.6171875\n",
      "Iteration:  71  Loss:  1.9332197   Accuracy:  0.65625\n",
      "Iteration:  72  Loss:  1.9427097   Accuracy:  0.625\n",
      "Iteration:  73  Loss:  1.1415865   Accuracy:  0.765625\n",
      "Iteration:  74  Loss:  2.432114   Accuracy:  0.6484375\n",
      "Iteration:  75  Loss:  1.170054   Accuracy:  0.7734375\n",
      "Iteration:  76  Loss:  1.3610418   Accuracy:  0.734375\n",
      "Iteration:  77  Loss:  1.1367626   Accuracy:  0.734375\n",
      "Iteration:  78  Loss:  1.0603898   Accuracy:  0.7734375\n",
      "Iteration:  79  Loss:  1.8220267   Accuracy:  0.6484375\n",
      "Iteration:  80  Loss:  1.343991   Accuracy:  0.6875\n",
      "Iteration:  81  Loss:  1.2657822   Accuracy:  0.7265625\n",
      "Iteration:  82  Loss:  1.4445655   Accuracy:  0.703125\n",
      "Iteration:  83  Loss:  1.9667444   Accuracy:  0.6875\n",
      "Iteration:  84  Loss:  1.5400867   Accuracy:  0.7265625\n",
      "Iteration:  85  Loss:  1.2425847   Accuracy:  0.75\n",
      "Iteration:  86  Loss:  1.3861922   Accuracy:  0.7421875\n",
      "Iteration:  87  Loss:  1.4646158   Accuracy:  0.703125\n",
      "Iteration:  88  Loss:  1.9161825   Accuracy:  0.6953125\n",
      "Iteration:  89  Loss:  1.7269776   Accuracy:  0.7421875\n",
      "Iteration:  90  Loss:  1.0332925   Accuracy:  0.7578125\n",
      "Iteration:  91  Loss:  0.9738417   Accuracy:  0.7734375\n",
      "Iteration:  92  Loss:  1.7187337   Accuracy:  0.6796875\n",
      "Iteration:  93  Loss:  1.5626426   Accuracy:  0.65625\n",
      "Iteration:  94  Loss:  1.3034382   Accuracy:  0.7421875\n",
      "Iteration:  95  Loss:  1.5619348   Accuracy:  0.75\n",
      "Iteration:  96  Loss:  0.9213115   Accuracy:  0.7578125\n",
      "Iteration:  97  Loss:  1.4381659   Accuracy:  0.703125\n",
      "Iteration:  98  Loss:  1.4334865   Accuracy:  0.6875\n",
      "Iteration:  99  Loss:  1.1776564   Accuracy:  0.765625\n",
      "Iteration:  100  Loss:  1.731772   Accuracy:  0.71875\n",
      "Iteration:  101  Loss:  1.400094   Accuracy:  0.7890625\n",
      "Iteration:  102  Loss:  1.1387683   Accuracy:  0.78125\n",
      "Iteration:  103  Loss:  1.6674504   Accuracy:  0.7578125\n",
      "Iteration:  104  Loss:  1.4705191   Accuracy:  0.7109375\n",
      "Iteration:  105  Loss:  0.78991914   Accuracy:  0.796875\n",
      "Iteration:  106  Loss:  1.7544721   Accuracy:  0.671875\n",
      "Iteration:  107  Loss:  1.4655465   Accuracy:  0.7265625\n",
      "Iteration:  108  Loss:  1.2144618   Accuracy:  0.7578125\n",
      "Iteration:  109  Loss:  1.2482615   Accuracy:  0.7421875\n",
      "Iteration:  110  Loss:  1.1810666   Accuracy:  0.765625\n",
      "Iteration:  111  Loss:  1.0719364   Accuracy:  0.75\n",
      "Iteration:  112  Loss:  1.3692732   Accuracy:  0.7734375\n",
      "Iteration:  113  Loss:  1.202887   Accuracy:  0.734375\n",
      "Iteration:  114  Loss:  1.3548255   Accuracy:  0.7421875\n",
      "Iteration:  115  Loss:  0.7925366   Accuracy:  0.8125\n",
      "Iteration:  116  Loss:  1.6646144   Accuracy:  0.6953125\n",
      "Iteration:  117  Loss:  2.1470568   Accuracy:  0.65625\n",
      "Iteration:  118  Loss:  0.8132893   Accuracy:  0.8046875\n",
      "Iteration:  119  Loss:  1.4919536   Accuracy:  0.6875\n",
      "Iteration:  120  Loss:  1.3893789   Accuracy:  0.6875\n",
      "Iteration:  121  Loss:  1.369129   Accuracy:  0.765625\n",
      "Iteration:  122  Loss:  1.1138599   Accuracy:  0.7578125\n",
      "Iteration:  123  Loss:  1.2959954   Accuracy:  0.7890625\n",
      "Iteration:  124  Loss:  0.83924264   Accuracy:  0.8203125\n",
      "Iteration:  125  Loss:  1.6702902   Accuracy:  0.703125\n",
      "Iteration:  126  Loss:  1.17435   Accuracy:  0.7265625\n",
      "Iteration:  127  Loss:  1.2894101   Accuracy:  0.7890625\n",
      "Iteration:  128  Loss:  1.1637094   Accuracy:  0.7421875\n",
      "Iteration:  129  Loss:  1.4369853   Accuracy:  0.7265625\n",
      "Iteration:  130  Loss:  1.5636163   Accuracy:  0.734375\n",
      "Iteration:  131  Loss:  1.9192705   Accuracy:  0.6640625\n",
      "Iteration:  132  Loss:  1.2632959   Accuracy:  0.7265625\n",
      "Iteration:  133  Loss:  0.9979248   Accuracy:  0.8046875\n",
      "Iteration:  134  Loss:  0.86943364   Accuracy:  0.8046875\n",
      "Iteration:  135  Loss:  0.8414379   Accuracy:  0.734375\n",
      "Iteration:  136  Loss:  0.908476   Accuracy:  0.8125\n",
      "Iteration:  137  Loss:  1.3466904   Accuracy:  0.75\n",
      "Iteration:  138  Loss:  0.99306047   Accuracy:  0.7578125\n",
      "Iteration:  139  Loss:  0.99526954   Accuracy:  0.78125\n",
      "Iteration:  140  Loss:  0.722877   Accuracy:  0.796875\n",
      "Iteration:  141  Loss:  1.3586798   Accuracy:  0.671875\n",
      "Iteration:  142  Loss:  1.3439379   Accuracy:  0.7734375\n",
      "Iteration:  143  Loss:  1.2303445   Accuracy:  0.703125\n",
      "Iteration:  144  Loss:  1.1063559   Accuracy:  0.796875\n",
      "Iteration:  145  Loss:  0.7080293   Accuracy:  0.8359375\n",
      "Iteration:  146  Loss:  1.2070544   Accuracy:  0.765625\n",
      "Iteration:  147  Loss:  1.0854743   Accuracy:  0.78125\n",
      "Iteration:  148  Loss:  1.5776653   Accuracy:  0.703125\n",
      "Iteration:  149  Loss:  1.1900697   Accuracy:  0.765625\n",
      "Iteration:  150  Loss:  1.4481854   Accuracy:  0.7421875\n",
      "Iteration:  151  Loss:  1.2276733   Accuracy:  0.75\n",
      "Iteration:  152  Loss:  0.88948715   Accuracy:  0.8125\n",
      "Iteration:  153  Loss:  0.86373526   Accuracy:  0.8203125\n",
      "Iteration:  154  Loss:  1.196698   Accuracy:  0.765625\n",
      "Iteration:  155  Loss:  0.8177505   Accuracy:  0.8125\n",
      "Iteration:  156  Loss:  0.82091737   Accuracy:  0.8125\n",
      "Iteration:  157  Loss:  0.93298745   Accuracy:  0.8359375\n",
      "Iteration:  158  Loss:  0.72869456   Accuracy:  0.8359375\n",
      "Iteration:  159  Loss:  0.9815656   Accuracy:  0.7890625\n",
      "Iteration:  160  Loss:  1.1460993   Accuracy:  0.7890625\n",
      "Iteration:  161  Loss:  0.87155366   Accuracy:  0.8203125\n",
      "Iteration:  162  Loss:  0.87100655   Accuracy:  0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  163  Loss:  0.82502615   Accuracy:  0.765625\n",
      "Iteration:  164  Loss:  0.8007231   Accuracy:  0.765625\n",
      "Iteration:  165  Loss:  0.8357997   Accuracy:  0.796875\n",
      "Iteration:  166  Loss:  1.2930776   Accuracy:  0.765625\n",
      "Iteration:  167  Loss:  1.3479524   Accuracy:  0.7734375\n",
      "Iteration:  168  Loss:  0.8596008   Accuracy:  0.828125\n",
      "Iteration:  169  Loss:  1.1753569   Accuracy:  0.75\n",
      "Iteration:  170  Loss:  1.2398026   Accuracy:  0.734375\n",
      "Iteration:  171  Loss:  1.3930999   Accuracy:  0.765625\n",
      "Iteration:  172  Loss:  1.1856512   Accuracy:  0.796875\n",
      "Iteration:  173  Loss:  1.4623609   Accuracy:  0.75\n",
      "Iteration:  174  Loss:  1.1268992   Accuracy:  0.765625\n",
      "Iteration:  175  Loss:  0.7920197   Accuracy:  0.796875\n",
      "Iteration:  176  Loss:  1.0086375   Accuracy:  0.828125\n",
      "Iteration:  177  Loss:  1.1125722   Accuracy:  0.765625\n",
      "Iteration:  178  Loss:  1.3254364   Accuracy:  0.734375\n",
      "Iteration:  179  Loss:  0.95953   Accuracy:  0.796875\n",
      "Iteration:  180  Loss:  1.0643601   Accuracy:  0.765625\n",
      "Iteration:  181  Loss:  0.8645366   Accuracy:  0.78125\n",
      "Iteration:  182  Loss:  0.776428   Accuracy:  0.8359375\n",
      "Iteration:  183  Loss:  1.1989639   Accuracy:  0.7421875\n",
      "Iteration:  184  Loss:  1.3029491   Accuracy:  0.7578125\n",
      "Iteration:  185  Loss:  1.4550548   Accuracy:  0.765625\n",
      "Iteration:  186  Loss:  1.0672724   Accuracy:  0.7578125\n",
      "Iteration:  187  Loss:  0.6117797   Accuracy:  0.875\n",
      "Iteration:  188  Loss:  1.1520002   Accuracy:  0.796875\n",
      "Iteration:  189  Loss:  0.7804965   Accuracy:  0.828125\n",
      "Iteration:  190  Loss:  0.8753074   Accuracy:  0.8203125\n",
      "Iteration:  191  Loss:  1.2262065   Accuracy:  0.78125\n",
      "Iteration:  192  Loss:  1.1688666   Accuracy:  0.765625\n",
      "Iteration:  193  Loss:  0.83735466   Accuracy:  0.7890625\n",
      "Iteration:  194  Loss:  1.3502977   Accuracy:  0.765625\n",
      "Iteration:  195  Loss:  1.1738136   Accuracy:  0.7578125\n",
      "Iteration:  196  Loss:  0.9011661   Accuracy:  0.7890625\n",
      "Iteration:  197  Loss:  0.8579029   Accuracy:  0.7890625\n",
      "Iteration:  198  Loss:  0.6343155   Accuracy:  0.8359375\n",
      "Iteration:  199  Loss:  1.3759912   Accuracy:  0.765625\n",
      "Iteration:  200  Loss:  0.6807069   Accuracy:  0.796875\n",
      "Iteration:  201  Loss:  0.91953486   Accuracy:  0.7890625\n",
      "Iteration:  202  Loss:  0.9365984   Accuracy:  0.8046875\n",
      "Iteration:  203  Loss:  0.77860224   Accuracy:  0.8515625\n",
      "Iteration:  204  Loss:  0.92935264   Accuracy:  0.8125\n",
      "Iteration:  205  Loss:  0.86887485   Accuracy:  0.8125\n",
      "Iteration:  206  Loss:  0.94880056   Accuracy:  0.78125\n",
      "Iteration:  207  Loss:  1.353267   Accuracy:  0.8046875\n",
      "Iteration:  208  Loss:  1.1596049   Accuracy:  0.765625\n",
      "Iteration:  209  Loss:  1.2071166   Accuracy:  0.8203125\n",
      "Iteration:  210  Loss:  0.80992097   Accuracy:  0.828125\n",
      "Iteration:  211  Loss:  0.79523945   Accuracy:  0.8046875\n",
      "Iteration:  212  Loss:  0.8968272   Accuracy:  0.8203125\n",
      "Iteration:  213  Loss:  1.3579321   Accuracy:  0.7890625\n",
      "Iteration:  214  Loss:  0.9346063   Accuracy:  0.8046875\n",
      "Iteration:  215  Loss:  0.8019045   Accuracy:  0.8125\n",
      "Iteration:  216  Loss:  1.1004469   Accuracy:  0.796875\n",
      "Iteration:  217  Loss:  0.94233406   Accuracy:  0.8046875\n",
      "Iteration:  218  Loss:  0.7793745   Accuracy:  0.8203125\n",
      "Iteration:  219  Loss:  0.65521926   Accuracy:  0.84375\n",
      "Iteration:  220  Loss:  0.9124482   Accuracy:  0.8359375\n",
      "Iteration:  221  Loss:  1.0201235   Accuracy:  0.8203125\n",
      "Iteration:  222  Loss:  0.64372164   Accuracy:  0.8359375\n",
      "Iteration:  223  Loss:  0.67073953   Accuracy:  0.859375\n",
      "Iteration:  224  Loss:  0.83277637   Accuracy:  0.8359375\n",
      "Iteration:  225  Loss:  0.7349936   Accuracy:  0.8515625\n",
      "Iteration:  226  Loss:  0.57581335   Accuracy:  0.84375\n",
      "Iteration:  227  Loss:  0.6236594   Accuracy:  0.84375\n",
      "Iteration:  228  Loss:  1.0849502   Accuracy:  0.765625\n",
      "Iteration:  229  Loss:  1.1027505   Accuracy:  0.796875\n",
      "Iteration:  230  Loss:  0.94599354   Accuracy:  0.78125\n",
      "Iteration:  231  Loss:  0.77949715   Accuracy:  0.859375\n",
      "Iteration:  232  Loss:  0.6905744   Accuracy:  0.8359375\n",
      "Iteration:  233  Loss:  0.815544   Accuracy:  0.765625\n",
      "Iteration:  234  Loss:  0.7029201   Accuracy:  0.8203125\n",
      "Iteration:  235  Loss:  0.8149074   Accuracy:  0.8359375\n",
      "Iteration:  236  Loss:  1.2884111   Accuracy:  0.78125\n",
      "Iteration:  237  Loss:  0.7468653   Accuracy:  0.8515625\n",
      "Iteration:  238  Loss:  0.6017276   Accuracy:  0.84375\n",
      "Iteration:  239  Loss:  1.054442   Accuracy:  0.78125\n",
      "Iteration:  240  Loss:  0.71672034   Accuracy:  0.8203125\n",
      "Iteration:  241  Loss:  1.0515857   Accuracy:  0.78125\n",
      "Iteration:  242  Loss:  1.0960312   Accuracy:  0.75\n",
      "Iteration:  243  Loss:  0.96065426   Accuracy:  0.828125\n",
      "Iteration:  244  Loss:  0.78074133   Accuracy:  0.84375\n",
      "Iteration:  245  Loss:  0.7990389   Accuracy:  0.8125\n",
      "Iteration:  246  Loss:  1.0134166   Accuracy:  0.8046875\n",
      "Iteration:  247  Loss:  0.8894338   Accuracy:  0.8125\n",
      "Iteration:  248  Loss:  0.6684755   Accuracy:  0.8125\n",
      "Iteration:  249  Loss:  1.041347   Accuracy:  0.796875\n",
      "Iteration:  250  Loss:  1.3264502   Accuracy:  0.7421875\n",
      "Iteration:  251  Loss:  0.6603826   Accuracy:  0.8125\n",
      "Iteration:  252  Loss:  1.2488576   Accuracy:  0.7578125\n",
      "Iteration:  253  Loss:  0.7688222   Accuracy:  0.7734375\n",
      "Iteration:  254  Loss:  0.81084555   Accuracy:  0.8515625\n",
      "Iteration:  255  Loss:  0.6914894   Accuracy:  0.84375\n",
      "Iteration:  256  Loss:  0.60368884   Accuracy:  0.8359375\n",
      "Iteration:  257  Loss:  0.94002223   Accuracy:  0.7734375\n",
      "Iteration:  258  Loss:  0.8651725   Accuracy:  0.8125\n",
      "Iteration:  259  Loss:  0.62594414   Accuracy:  0.8203125\n",
      "Iteration:  260  Loss:  0.67826986   Accuracy:  0.8046875\n",
      "Iteration:  261  Loss:  0.87129885   Accuracy:  0.8203125\n",
      "Iteration:  262  Loss:  0.7791767   Accuracy:  0.84375\n",
      "Iteration:  263  Loss:  0.98014146   Accuracy:  0.7890625\n",
      "Iteration:  264  Loss:  0.683905   Accuracy:  0.796875\n",
      "Iteration:  265  Loss:  0.80931354   Accuracy:  0.8671875\n",
      "Iteration:  266  Loss:  0.7891895   Accuracy:  0.859375\n",
      "Iteration:  267  Loss:  1.2193407   Accuracy:  0.8046875\n",
      "Iteration:  268  Loss:  1.2427747   Accuracy:  0.78125\n",
      "Iteration:  269  Loss:  1.0564361   Accuracy:  0.8125\n",
      "Iteration:  270  Loss:  0.7841918   Accuracy:  0.8671875\n",
      "Iteration:  271  Loss:  1.0027227   Accuracy:  0.8359375\n",
      "Iteration:  272  Loss:  0.66612685   Accuracy:  0.8359375\n",
      "Iteration:  273  Loss:  0.89380085   Accuracy:  0.796875\n",
      "Iteration:  274  Loss:  0.9931113   Accuracy:  0.78125\n",
      "Iteration:  275  Loss:  0.77198434   Accuracy:  0.8125\n",
      "Iteration:  276  Loss:  1.0409732   Accuracy:  0.8359375\n",
      "Iteration:  277  Loss:  0.72049046   Accuracy:  0.8515625\n",
      "Iteration:  278  Loss:  0.6005131   Accuracy:  0.859375\n",
      "Iteration:  279  Loss:  0.9322873   Accuracy:  0.7890625\n",
      "Iteration:  280  Loss:  1.3482559   Accuracy:  0.7890625\n",
      "Iteration:  281  Loss:  0.8311658   Accuracy:  0.8359375\n",
      "Iteration:  282  Loss:  0.9548089   Accuracy:  0.84375\n",
      "Iteration:  283  Loss:  0.49927032   Accuracy:  0.875\n",
      "Iteration:  284  Loss:  0.8027591   Accuracy:  0.8671875\n",
      "Iteration:  285  Loss:  0.5875047   Accuracy:  0.8359375\n",
      "Iteration:  286  Loss:  0.7620753   Accuracy:  0.8125\n",
      "Iteration:  287  Loss:  0.7391709   Accuracy:  0.8203125\n",
      "Iteration:  288  Loss:  1.2380733   Accuracy:  0.8203125\n",
      "Iteration:  289  Loss:  0.72288895   Accuracy:  0.8515625\n",
      "Iteration:  290  Loss:  0.8598883   Accuracy:  0.8203125\n",
      "Iteration:  291  Loss:  0.9664391   Accuracy:  0.8359375\n",
      "Iteration:  292  Loss:  1.26543   Accuracy:  0.71875\n",
      "Iteration:  293  Loss:  1.031455   Accuracy:  0.78125\n",
      "Iteration:  294  Loss:  0.7617836   Accuracy:  0.796875\n",
      "Iteration:  295  Loss:  0.6875833   Accuracy:  0.8515625\n",
      "Iteration:  296  Loss:  0.7271972   Accuracy:  0.8203125\n",
      "Iteration:  297  Loss:  0.4866809   Accuracy:  0.890625\n",
      "Iteration:  298  Loss:  1.0101466   Accuracy:  0.8046875\n",
      "Iteration:  299  Loss:  0.7095306   Accuracy:  0.8203125\n",
      "Iteration:  300  Loss:  0.6456212   Accuracy:  0.8125\n",
      "Iteration:  301  Loss:  0.8764839   Accuracy:  0.8203125\n",
      "Iteration:  302  Loss:  0.56760657   Accuracy:  0.8828125\n",
      "Iteration:  303  Loss:  0.6988226   Accuracy:  0.8671875\n",
      "Iteration:  304  Loss:  0.955565   Accuracy:  0.8203125\n",
      "Iteration:  305  Loss:  0.87412864   Accuracy:  0.765625\n",
      "Iteration:  306  Loss:  1.066779   Accuracy:  0.7890625\n",
      "Iteration:  307  Loss:  0.36760026   Accuracy:  0.8828125\n",
      "Iteration:  308  Loss:  1.2257966   Accuracy:  0.8125\n",
      "Iteration:  309  Loss:  0.81606656   Accuracy:  0.8515625\n",
      "Iteration:  310  Loss:  0.56398106   Accuracy:  0.8671875\n",
      "Iteration:  311  Loss:  0.8865998   Accuracy:  0.84375\n",
      "Iteration:  312  Loss:  0.6359348   Accuracy:  0.8515625\n",
      "Iteration:  313  Loss:  0.68502295   Accuracy:  0.8515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  314  Loss:  0.8119367   Accuracy:  0.8203125\n",
      "Iteration:  315  Loss:  0.7090665   Accuracy:  0.8671875\n",
      "Iteration:  316  Loss:  0.8201089   Accuracy:  0.8203125\n",
      "Iteration:  317  Loss:  0.85068595   Accuracy:  0.8203125\n",
      "Iteration:  318  Loss:  0.82931995   Accuracy:  0.84375\n",
      "Iteration:  319  Loss:  0.56579316   Accuracy:  0.859375\n",
      "Iteration:  320  Loss:  0.64139235   Accuracy:  0.8359375\n",
      "Iteration:  321  Loss:  0.9853546   Accuracy:  0.8359375\n",
      "Iteration:  322  Loss:  0.69617766   Accuracy:  0.859375\n",
      "Iteration:  323  Loss:  0.7803729   Accuracy:  0.8515625\n",
      "Iteration:  324  Loss:  1.0813243   Accuracy:  0.8125\n",
      "Iteration:  325  Loss:  1.1111757   Accuracy:  0.8046875\n",
      "Iteration:  326  Loss:  1.0450273   Accuracy:  0.8046875\n",
      "Iteration:  327  Loss:  1.4010512   Accuracy:  0.7578125\n",
      "Iteration:  328  Loss:  1.0620762   Accuracy:  0.8125\n",
      "Iteration:  329  Loss:  0.5535244   Accuracy:  0.859375\n",
      "Iteration:  330  Loss:  0.7215409   Accuracy:  0.8125\n",
      "Iteration:  331  Loss:  0.7428131   Accuracy:  0.78125\n",
      "Iteration:  332  Loss:  0.5819659   Accuracy:  0.875\n",
      "Iteration:  333  Loss:  0.7489436   Accuracy:  0.8671875\n",
      "Iteration:  334  Loss:  0.7610147   Accuracy:  0.8671875\n",
      "Iteration:  335  Loss:  0.8431399   Accuracy:  0.8203125\n",
      "Iteration:  336  Loss:  0.7973663   Accuracy:  0.828125\n",
      "Iteration:  337  Loss:  1.3025023   Accuracy:  0.8203125\n",
      "Iteration:  338  Loss:  0.66671735   Accuracy:  0.8984375\n",
      "Iteration:  339  Loss:  0.5597167   Accuracy:  0.8359375\n",
      "Iteration:  340  Loss:  0.7450681   Accuracy:  0.8515625\n",
      "Iteration:  341  Loss:  0.8940744   Accuracy:  0.8359375\n",
      "Iteration:  342  Loss:  0.57702523   Accuracy:  0.828125\n",
      "Iteration:  343  Loss:  0.8120447   Accuracy:  0.8125\n",
      "Iteration:  344  Loss:  0.7836196   Accuracy:  0.8125\n",
      "Iteration:  345  Loss:  0.93153346   Accuracy:  0.78125\n",
      "Iteration:  346  Loss:  0.4489456   Accuracy:  0.875\n",
      "Iteration:  347  Loss:  0.7468121   Accuracy:  0.796875\n",
      "Iteration:  348  Loss:  1.0154294   Accuracy:  0.8125\n",
      "Iteration:  349  Loss:  0.8993503   Accuracy:  0.8359375\n",
      "Iteration:  350  Loss:  0.90951693   Accuracy:  0.8203125\n",
      "Iteration:  351  Loss:  0.6339195   Accuracy:  0.859375\n",
      "Iteration:  352  Loss:  1.3896619   Accuracy:  0.7734375\n",
      "Iteration:  353  Loss:  1.0572929   Accuracy:  0.8125\n",
      "Iteration:  354  Loss:  0.955986   Accuracy:  0.78125\n",
      "Iteration:  355  Loss:  0.9542775   Accuracy:  0.828125\n",
      "Iteration:  356  Loss:  0.7067502   Accuracy:  0.828125\n",
      "Iteration:  357  Loss:  0.6181611   Accuracy:  0.8671875\n",
      "Iteration:  358  Loss:  0.75052774   Accuracy:  0.8359375\n",
      "Iteration:  359  Loss:  0.6577497   Accuracy:  0.8515625\n",
      "Iteration:  360  Loss:  0.9890348   Accuracy:  0.8046875\n",
      "Iteration:  361  Loss:  0.63653755   Accuracy:  0.8515625\n",
      "Iteration:  362  Loss:  0.78384185   Accuracy:  0.796875\n",
      "Iteration:  363  Loss:  0.97130835   Accuracy:  0.7734375\n",
      "Iteration:  364  Loss:  0.4731121   Accuracy:  0.875\n",
      "Iteration:  365  Loss:  0.60365087   Accuracy:  0.8359375\n",
      "Iteration:  366  Loss:  1.0051296   Accuracy:  0.8203125\n",
      "Iteration:  367  Loss:  0.7959259   Accuracy:  0.8359375\n",
      "Iteration:  368  Loss:  0.6675533   Accuracy:  0.8359375\n",
      "Iteration:  369  Loss:  1.1007507   Accuracy:  0.8046875\n",
      "Iteration:  370  Loss:  0.9574122   Accuracy:  0.7734375\n",
      "Iteration:  371  Loss:  0.6586922   Accuracy:  0.8125\n",
      "Iteration:  372  Loss:  0.70793265   Accuracy:  0.8515625\n",
      "Iteration:  373  Loss:  1.0881668   Accuracy:  0.8046875\n",
      "Iteration:  374  Loss:  0.74499476   Accuracy:  0.8125\n",
      "Iteration:  375  Loss:  1.1511389   Accuracy:  0.734375\n",
      "Iteration:  376  Loss:  0.6263032   Accuracy:  0.8359375\n",
      "Iteration:  377  Loss:  0.8829565   Accuracy:  0.8203125\n",
      "Iteration:  378  Loss:  1.160777   Accuracy:  0.78125\n",
      "Iteration:  379  Loss:  0.6770923   Accuracy:  0.8359375\n",
      "Iteration:  380  Loss:  0.88370025   Accuracy:  0.7734375\n",
      "Iteration:  381  Loss:  0.6464422   Accuracy:  0.828125\n",
      "Iteration:  382  Loss:  0.6826086   Accuracy:  0.8515625\n",
      "Iteration:  383  Loss:  0.9638019   Accuracy:  0.859375\n",
      "Iteration:  384  Loss:  0.44020954   Accuracy:  0.90625\n",
      "Iteration:  385  Loss:  0.78052795   Accuracy:  0.828125\n",
      "Iteration:  386  Loss:  0.34812304   Accuracy:  0.9296875\n",
      "Iteration:  387  Loss:  0.7855355   Accuracy:  0.84375\n",
      "Iteration:  388  Loss:  0.8467026   Accuracy:  0.828125\n",
      "Iteration:  389  Loss:  0.927063   Accuracy:  0.796875\n",
      "Iteration:  390  Loss:  0.6381693   Accuracy:  0.859375\n",
      "Iteration:  391  Loss:  1.2654374   Accuracy:  0.8125\n",
      "Iteration:  392  Loss:  0.8288487   Accuracy:  0.8359375\n",
      "Iteration:  393  Loss:  0.6798301   Accuracy:  0.8359375\n",
      "Iteration:  394  Loss:  0.29351103   Accuracy:  0.890625\n",
      "Iteration:  395  Loss:  0.91082776   Accuracy:  0.8046875\n",
      "Iteration:  396  Loss:  0.62790954   Accuracy:  0.8515625\n",
      "Iteration:  397  Loss:  0.9766946   Accuracy:  0.8359375\n",
      "Iteration:  398  Loss:  0.78916055   Accuracy:  0.8671875\n",
      "Iteration:  399  Loss:  0.56449497   Accuracy:  0.8515625\n",
      "Iteration:  400  Loss:  0.6657055   Accuracy:  0.8359375\n",
      "Iteration:  401  Loss:  0.497425   Accuracy:  0.8828125\n",
      "Iteration:  402  Loss:  0.65289253   Accuracy:  0.8359375\n",
      "Iteration:  403  Loss:  1.0455234   Accuracy:  0.78125\n",
      "Iteration:  404  Loss:  0.6676259   Accuracy:  0.8359375\n",
      "Iteration:  405  Loss:  0.7048768   Accuracy:  0.8828125\n",
      "Iteration:  406  Loss:  0.63070345   Accuracy:  0.84375\n",
      "Iteration:  407  Loss:  0.6702881   Accuracy:  0.84375\n",
      "Iteration:  408  Loss:  0.4513032   Accuracy:  0.890625\n",
      "Iteration:  409  Loss:  0.879251   Accuracy:  0.8046875\n",
      "Iteration:  410  Loss:  0.5151436   Accuracy:  0.8671875\n",
      "Iteration:  411  Loss:  0.6727426   Accuracy:  0.8203125\n",
      "Iteration:  412  Loss:  0.65624905   Accuracy:  0.8515625\n",
      "Iteration:  413  Loss:  0.61108184   Accuracy:  0.84375\n",
      "Iteration:  414  Loss:  0.8421967   Accuracy:  0.8515625\n",
      "Iteration:  415  Loss:  0.9376709   Accuracy:  0.8203125\n",
      "Iteration:  416  Loss:  1.0310385   Accuracy:  0.8125\n",
      "Iteration:  417  Loss:  0.6392352   Accuracy:  0.8984375\n",
      "Iteration:  418  Loss:  0.5052835   Accuracy:  0.8828125\n",
      "Iteration:  419  Loss:  0.6095977   Accuracy:  0.828125\n",
      "Iteration:  420  Loss:  0.38997266   Accuracy:  0.8828125\n",
      "Iteration:  421  Loss:  0.9241849   Accuracy:  0.8125\n",
      "Iteration:  422  Loss:  0.6726099   Accuracy:  0.8671875\n",
      "Iteration:  423  Loss:  0.30333668   Accuracy:  0.8984375\n",
      "Iteration:  424  Loss:  0.5532806   Accuracy:  0.8671875\n",
      "Iteration:  425  Loss:  0.6548315   Accuracy:  0.8828125\n",
      "Iteration:  426  Loss:  0.5958291   Accuracy:  0.8125\n",
      "Iteration:  427  Loss:  0.5510077   Accuracy:  0.8984375\n",
      "Iteration:  428  Loss:  0.84433895   Accuracy:  0.8203125\n",
      "Iteration:  429  Loss:  0.62064564   Accuracy:  0.8671875\n",
      "Iteration:  430  Loss:  0.49909467   Accuracy:  0.8671875\n",
      "Iteration:  431  Loss:  0.66029936   Accuracy:  0.828125\n",
      "Iteration:  432  Loss:  0.68184185   Accuracy:  0.875\n",
      "Iteration:  433  Loss:  0.6193968   Accuracy:  0.8671875\n",
      "Iteration:  434  Loss:  0.43012303   Accuracy:  0.890625\n",
      "Iteration:  435  Loss:  0.908431   Accuracy:  0.875\n",
      "Iteration:  436  Loss:  1.0264887   Accuracy:  0.828125\n",
      "Iteration:  437  Loss:  0.6169847   Accuracy:  0.8515625\n",
      "Iteration:  438  Loss:  0.64657974   Accuracy:  0.8828125\n",
      "Iteration:  439  Loss:  0.59846306   Accuracy:  0.875\n",
      "Iteration:  440  Loss:  0.7435521   Accuracy:  0.8359375\n",
      "Iteration:  441  Loss:  0.92488295   Accuracy:  0.84375\n",
      "Iteration:  442  Loss:  1.2078984   Accuracy:  0.8046875\n",
      "Iteration:  443  Loss:  0.60944647   Accuracy:  0.84375\n",
      "Iteration:  444  Loss:  0.83525586   Accuracy:  0.8046875\n",
      "Iteration:  445  Loss:  0.5190817   Accuracy:  0.8671875\n",
      "Iteration:  446  Loss:  0.608712   Accuracy:  0.8671875\n",
      "Iteration:  447  Loss:  0.9204283   Accuracy:  0.84375\n",
      "Iteration:  448  Loss:  0.5035463   Accuracy:  0.859375\n",
      "Iteration:  449  Loss:  0.79954517   Accuracy:  0.84375\n",
      "Iteration:  450  Loss:  0.7057976   Accuracy:  0.890625\n",
      "Iteration:  451  Loss:  0.8446201   Accuracy:  0.8203125\n",
      "Iteration:  452  Loss:  0.83557236   Accuracy:  0.8671875\n",
      "Iteration:  453  Loss:  1.0140529   Accuracy:  0.7578125\n",
      "Iteration:  454  Loss:  0.7297677   Accuracy:  0.8515625\n",
      "Iteration:  455  Loss:  0.6216844   Accuracy:  0.84375\n",
      "Iteration:  456  Loss:  0.5995912   Accuracy:  0.8671875\n",
      "Iteration:  457  Loss:  0.81149393   Accuracy:  0.8359375\n",
      "Iteration:  458  Loss:  1.1118569   Accuracy:  0.8046875\n",
      "Iteration:  459  Loss:  0.46429184   Accuracy:  0.8671875\n",
      "Iteration:  460  Loss:  0.87994313   Accuracy:  0.8203125\n",
      "Iteration:  461  Loss:  0.6779654   Accuracy:  0.8671875\n",
      "Iteration:  462  Loss:  1.2085209   Accuracy:  0.7890625\n",
      "Iteration:  463  Loss:  0.5418555   Accuracy:  0.84375\n",
      "Iteration:  464  Loss:  0.7740666   Accuracy:  0.8671875\n",
      "Iteration:  465  Loss:  0.26285613   Accuracy:  0.90625\n",
      "Iteration:  466  Loss:  0.44044885   Accuracy:  0.890625\n",
      "Iteration:  467  Loss:  0.3805723   Accuracy:  0.8671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  468  Loss:  0.779375   Accuracy:  0.8203125\n",
      "Iteration:  469  Loss:  0.5503051   Accuracy:  0.8828125\n",
      "Iteration:  470  Loss:  0.8591393   Accuracy:  0.8046875\n",
      "Iteration:  471  Loss:  0.8232142   Accuracy:  0.8359375\n",
      "Iteration:  472  Loss:  0.83158696   Accuracy:  0.8203125\n",
      "Iteration:  473  Loss:  0.71639633   Accuracy:  0.890625\n",
      "Iteration:  474  Loss:  0.7717814   Accuracy:  0.8515625\n",
      "Iteration:  475  Loss:  0.18611321   Accuracy:  0.9296875\n",
      "Iteration:  476  Loss:  0.80373734   Accuracy:  0.8671875\n",
      "Iteration:  477  Loss:  0.6428949   Accuracy:  0.8828125\n",
      "Iteration:  478  Loss:  0.7454032   Accuracy:  0.875\n",
      "Iteration:  479  Loss:  1.0041548   Accuracy:  0.828125\n",
      "Iteration:  480  Loss:  1.0214643   Accuracy:  0.828125\n",
      "Iteration:  481  Loss:  0.9279804   Accuracy:  0.8203125\n",
      "Iteration:  482  Loss:  0.7375416   Accuracy:  0.84375\n",
      "Iteration:  483  Loss:  0.6280698   Accuracy:  0.875\n",
      "Iteration:  484  Loss:  0.56359714   Accuracy:  0.84375\n",
      "Iteration:  485  Loss:  0.49997106   Accuracy:  0.90625\n",
      "Iteration:  486  Loss:  0.43977004   Accuracy:  0.8984375\n",
      "Iteration:  487  Loss:  0.37944376   Accuracy:  0.84375\n",
      "Iteration:  488  Loss:  0.6514179   Accuracy:  0.8359375\n",
      "Iteration:  489  Loss:  0.7837567   Accuracy:  0.828125\n",
      "Iteration:  490  Loss:  0.66603863   Accuracy:  0.859375\n",
      "Iteration:  491  Loss:  0.46850917   Accuracy:  0.8984375\n",
      "Iteration:  492  Loss:  0.897606   Accuracy:  0.8125\n",
      "Iteration:  493  Loss:  0.5460538   Accuracy:  0.84375\n",
      "Iteration:  494  Loss:  0.681406   Accuracy:  0.8515625\n",
      "Iteration:  495  Loss:  0.5535293   Accuracy:  0.8046875\n",
      "Iteration:  496  Loss:  0.43836203   Accuracy:  0.90625\n",
      "Iteration:  497  Loss:  0.5267792   Accuracy:  0.8359375\n",
      "Iteration:  498  Loss:  0.70238376   Accuracy:  0.8515625\n",
      "Iteration:  499  Loss:  0.7322719   Accuracy:  0.8828125\n",
      "Iteration:  500  Loss:  0.72553915   Accuracy:  0.8203125\n",
      "Iteration:  501  Loss:  0.64383423   Accuracy:  0.8515625\n",
      "Iteration:  502  Loss:  0.85817933   Accuracy:  0.828125\n",
      "Iteration:  503  Loss:  0.4731002   Accuracy:  0.8984375\n",
      "Iteration:  504  Loss:  0.7107633   Accuracy:  0.828125\n",
      "Iteration:  505  Loss:  0.6712009   Accuracy:  0.875\n",
      "Iteration:  506  Loss:  0.5925497   Accuracy:  0.8515625\n",
      "Iteration:  507  Loss:  0.68730867   Accuracy:  0.8359375\n",
      "Iteration:  508  Loss:  0.3667865   Accuracy:  0.9140625\n",
      "Iteration:  509  Loss:  0.72472245   Accuracy:  0.859375\n",
      "Iteration:  510  Loss:  0.7104211   Accuracy:  0.859375\n",
      "Iteration:  511  Loss:  0.8716952   Accuracy:  0.828125\n",
      "Iteration:  512  Loss:  0.7531852   Accuracy:  0.8671875\n",
      "Iteration:  513  Loss:  0.65985644   Accuracy:  0.84375\n",
      "Iteration:  514  Loss:  0.8946607   Accuracy:  0.7734375\n",
      "Iteration:  515  Loss:  0.67570055   Accuracy:  0.8515625\n",
      "Iteration:  516  Loss:  0.7185306   Accuracy:  0.8125\n",
      "Iteration:  517  Loss:  0.83010304   Accuracy:  0.7890625\n",
      "Iteration:  518  Loss:  0.76374245   Accuracy:  0.8515625\n",
      "Iteration:  519  Loss:  0.5679848   Accuracy:  0.875\n",
      "Iteration:  520  Loss:  0.7872172   Accuracy:  0.8046875\n",
      "Iteration:  521  Loss:  1.1030235   Accuracy:  0.8203125\n",
      "Iteration:  522  Loss:  0.74903035   Accuracy:  0.8515625\n",
      "Iteration:  523  Loss:  0.85152835   Accuracy:  0.8203125\n",
      "Iteration:  524  Loss:  0.8779353   Accuracy:  0.8671875\n",
      "Iteration:  525  Loss:  0.7331945   Accuracy:  0.8671875\n",
      "Iteration:  526  Loss:  1.2119577   Accuracy:  0.828125\n",
      "Iteration:  527  Loss:  0.8720716   Accuracy:  0.84375\n",
      "Iteration:  528  Loss:  0.71836215   Accuracy:  0.828125\n",
      "Iteration:  529  Loss:  0.7200199   Accuracy:  0.828125\n",
      "Iteration:  530  Loss:  0.8987835   Accuracy:  0.8515625\n",
      "Iteration:  531  Loss:  0.54868424   Accuracy:  0.890625\n",
      "Iteration:  532  Loss:  0.7978258   Accuracy:  0.828125\n",
      "Iteration:  533  Loss:  0.98244226   Accuracy:  0.8203125\n",
      "Iteration:  534  Loss:  0.7914204   Accuracy:  0.859375\n",
      "Iteration:  535  Loss:  0.96803355   Accuracy:  0.78125\n",
      "Iteration:  536  Loss:  0.8445883   Accuracy:  0.7890625\n",
      "Iteration:  537  Loss:  0.66383344   Accuracy:  0.828125\n",
      "Iteration:  538  Loss:  0.5681888   Accuracy:  0.8515625\n",
      "Iteration:  539  Loss:  0.80240476   Accuracy:  0.8359375\n",
      "Iteration:  540  Loss:  0.74567854   Accuracy:  0.8203125\n",
      "Iteration:  541  Loss:  0.55333173   Accuracy:  0.875\n",
      "Iteration:  542  Loss:  0.6142659   Accuracy:  0.8828125\n",
      "Iteration:  543  Loss:  0.4601076   Accuracy:  0.875\n",
      "Iteration:  544  Loss:  0.47250956   Accuracy:  0.8828125\n",
      "Iteration:  545  Loss:  0.43637577   Accuracy:  0.8828125\n",
      "Iteration:  546  Loss:  0.69123936   Accuracy:  0.8359375\n",
      "Iteration:  547  Loss:  0.59514624   Accuracy:  0.8671875\n",
      "Iteration:  548  Loss:  0.4310395   Accuracy:  0.8515625\n",
      "Iteration:  549  Loss:  0.5861559   Accuracy:  0.890625\n",
      "Iteration:  550  Loss:  0.7348204   Accuracy:  0.84375\n",
      "Iteration:  551  Loss:  0.681721   Accuracy:  0.859375\n",
      "Iteration:  552  Loss:  0.82034117   Accuracy:  0.84375\n",
      "Iteration:  553  Loss:  0.9559077   Accuracy:  0.796875\n",
      "Iteration:  554  Loss:  0.59152395   Accuracy:  0.875\n",
      "Iteration:  555  Loss:  0.8736788   Accuracy:  0.8203125\n",
      "Iteration:  556  Loss:  0.7028957   Accuracy:  0.8515625\n",
      "Iteration:  557  Loss:  0.96144116   Accuracy:  0.8125\n",
      "Iteration:  558  Loss:  0.5240351   Accuracy:  0.859375\n",
      "Iteration:  559  Loss:  0.5009908   Accuracy:  0.90625\n",
      "Iteration:  560  Loss:  0.73931545   Accuracy:  0.84375\n",
      "Iteration:  561  Loss:  0.38711995   Accuracy:  0.8671875\n",
      "Iteration:  562  Loss:  1.0637387   Accuracy:  0.796875\n",
      "Iteration:  563  Loss:  0.7267726   Accuracy:  0.8671875\n",
      "Iteration:  564  Loss:  0.6754999   Accuracy:  0.8125\n",
      "Iteration:  565  Loss:  0.55192447   Accuracy:  0.8671875\n",
      "Iteration:  566  Loss:  0.72417355   Accuracy:  0.84375\n",
      "Iteration:  567  Loss:  0.5559158   Accuracy:  0.875\n",
      "Iteration:  568  Loss:  0.48144057   Accuracy:  0.8828125\n",
      "Iteration:  569  Loss:  0.8210722   Accuracy:  0.84375\n",
      "Iteration:  570  Loss:  0.5883864   Accuracy:  0.890625\n",
      "Iteration:  571  Loss:  0.78047407   Accuracy:  0.84375\n",
      "Iteration:  572  Loss:  0.4924898   Accuracy:  0.8671875\n",
      "Iteration:  573  Loss:  0.74701196   Accuracy:  0.7890625\n",
      "Iteration:  574  Loss:  0.6357485   Accuracy:  0.8984375\n",
      "Iteration:  575  Loss:  0.67089725   Accuracy:  0.8203125\n",
      "Iteration:  576  Loss:  0.4824888   Accuracy:  0.8671875\n",
      "Iteration:  577  Loss:  0.8493901   Accuracy:  0.796875\n",
      "Iteration:  578  Loss:  0.5544038   Accuracy:  0.8515625\n",
      "Iteration:  579  Loss:  0.56400675   Accuracy:  0.8671875\n",
      "Iteration:  580  Loss:  0.7791197   Accuracy:  0.828125\n",
      "Iteration:  581  Loss:  0.8376967   Accuracy:  0.7890625\n",
      "Iteration:  582  Loss:  0.55088884   Accuracy:  0.8828125\n",
      "Iteration:  583  Loss:  0.8090639   Accuracy:  0.875\n",
      "Iteration:  584  Loss:  0.5519867   Accuracy:  0.8828125\n",
      "Iteration:  585  Loss:  0.7650583   Accuracy:  0.859375\n",
      "Iteration:  586  Loss:  0.64251816   Accuracy:  0.859375\n",
      "Iteration:  587  Loss:  0.37870947   Accuracy:  0.8828125\n",
      "Iteration:  588  Loss:  0.51412225   Accuracy:  0.859375\n",
      "Iteration:  589  Loss:  0.4243342   Accuracy:  0.890625\n",
      "Iteration:  590  Loss:  0.6147641   Accuracy:  0.84375\n",
      "Iteration:  591  Loss:  0.494542   Accuracy:  0.8828125\n",
      "Iteration:  592  Loss:  0.8356252   Accuracy:  0.8515625\n",
      "Iteration:  593  Loss:  0.53162336   Accuracy:  0.8515625\n",
      "Iteration:  594  Loss:  0.8024524   Accuracy:  0.84375\n",
      "Iteration:  595  Loss:  0.47467902   Accuracy:  0.875\n",
      "Iteration:  596  Loss:  0.6378683   Accuracy:  0.796875\n",
      "Iteration:  597  Loss:  0.54276526   Accuracy:  0.859375\n",
      "Iteration:  598  Loss:  0.4404948   Accuracy:  0.8828125\n",
      "Iteration:  599  Loss:  0.7014741   Accuracy:  0.859375\n",
      "Iteration:  600  Loss:  0.61801314   Accuracy:  0.84375\n",
      "Iteration:  601  Loss:  0.4073081   Accuracy:  0.8828125\n",
      "Iteration:  602  Loss:  0.6334265   Accuracy:  0.828125\n",
      "Iteration:  603  Loss:  0.8190791   Accuracy:  0.8125\n",
      "Iteration:  604  Loss:  0.7928131   Accuracy:  0.8125\n",
      "Iteration:  605  Loss:  0.2990942   Accuracy:  0.90625\n",
      "Iteration:  606  Loss:  0.68692124   Accuracy:  0.8359375\n",
      "Iteration:  607  Loss:  0.81583256   Accuracy:  0.828125\n",
      "Iteration:  608  Loss:  0.7330321   Accuracy:  0.875\n",
      "Iteration:  609  Loss:  0.7640268   Accuracy:  0.828125\n",
      "Iteration:  610  Loss:  0.87465215   Accuracy:  0.8203125\n",
      "Iteration:  611  Loss:  0.4069998   Accuracy:  0.9140625\n",
      "Iteration:  612  Loss:  0.44123822   Accuracy:  0.8984375\n",
      "Iteration:  613  Loss:  0.48035276   Accuracy:  0.921875\n",
      "Iteration:  614  Loss:  0.60553694   Accuracy:  0.8671875\n",
      "Iteration:  615  Loss:  0.53420925   Accuracy:  0.8671875\n",
      "Iteration:  616  Loss:  0.646494   Accuracy:  0.875\n",
      "Iteration:  617  Loss:  0.5285895   Accuracy:  0.84375\n",
      "Iteration:  618  Loss:  0.8880467   Accuracy:  0.8515625\n",
      "Iteration:  619  Loss:  0.78937364   Accuracy:  0.859375\n",
      "Iteration:  620  Loss:  1.0030303   Accuracy:  0.78125\n",
      "Iteration:  621  Loss:  0.7021519   Accuracy:  0.8671875\n",
      "Iteration:  622  Loss:  0.37168115   Accuracy:  0.90625\n",
      "Iteration:  623  Loss:  0.6372758   Accuracy:  0.8515625\n",
      "Iteration:  624  Loss:  0.47015566   Accuracy:  0.859375\n",
      "Iteration:  625  Loss:  0.7360842   Accuracy:  0.8203125\n",
      "Iteration:  626  Loss:  0.406336   Accuracy:  0.875\n",
      "Iteration:  627  Loss:  0.79305625   Accuracy:  0.859375\n",
      "Iteration:  628  Loss:  0.55574894   Accuracy:  0.8671875\n",
      "Iteration:  629  Loss:  0.6148913   Accuracy:  0.90625\n",
      "Iteration:  630  Loss:  0.58298934   Accuracy:  0.84375\n",
      "Iteration:  631  Loss:  0.56070036   Accuracy:  0.8359375\n",
      "Iteration:  632  Loss:  0.5565733   Accuracy:  0.890625\n",
      "Iteration:  633  Loss:  0.6837868   Accuracy:  0.875\n",
      "Iteration:  634  Loss:  0.60042137   Accuracy:  0.8671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  635  Loss:  0.65999615   Accuracy:  0.8828125\n",
      "Iteration:  636  Loss:  0.9524889   Accuracy:  0.8359375\n",
      "Iteration:  637  Loss:  0.5956303   Accuracy:  0.8828125\n",
      "Iteration:  638  Loss:  0.8693608   Accuracy:  0.8359375\n",
      "Iteration:  639  Loss:  0.6908823   Accuracy:  0.8515625\n",
      "Iteration:  640  Loss:  0.3491397   Accuracy:  0.9296875\n",
      "Iteration:  641  Loss:  0.60760677   Accuracy:  0.8984375\n",
      "Iteration:  642  Loss:  0.5898303   Accuracy:  0.875\n",
      "Iteration:  643  Loss:  0.6296388   Accuracy:  0.8359375\n",
      "Iteration:  644  Loss:  0.46059555   Accuracy:  0.890625\n",
      "Iteration:  645  Loss:  0.5943029   Accuracy:  0.8125\n",
      "Iteration:  646  Loss:  0.5723257   Accuracy:  0.8828125\n",
      "Iteration:  647  Loss:  0.79421663   Accuracy:  0.7890625\n",
      "Iteration:  648  Loss:  0.6205718   Accuracy:  0.875\n",
      "Iteration:  649  Loss:  0.41158643   Accuracy:  0.8984375\n",
      "Iteration:  650  Loss:  0.9073478   Accuracy:  0.796875\n",
      "Iteration:  651  Loss:  0.85023576   Accuracy:  0.8203125\n",
      "Iteration:  652  Loss:  0.82057256   Accuracy:  0.8125\n",
      "Iteration:  653  Loss:  0.5027741   Accuracy:  0.875\n",
      "Iteration:  654  Loss:  0.5508691   Accuracy:  0.875\n",
      "Iteration:  655  Loss:  0.91398835   Accuracy:  0.8203125\n",
      "Iteration:  656  Loss:  0.7815245   Accuracy:  0.828125\n",
      "Iteration:  657  Loss:  0.71391726   Accuracy:  0.8359375\n",
      "Iteration:  658  Loss:  0.5231241   Accuracy:  0.8515625\n",
      "Iteration:  659  Loss:  0.61058563   Accuracy:  0.8671875\n",
      "Iteration:  660  Loss:  0.6872752   Accuracy:  0.875\n",
      "Iteration:  661  Loss:  0.61627394   Accuracy:  0.8359375\n",
      "Iteration:  662  Loss:  1.0604081   Accuracy:  0.8125\n",
      "Iteration:  663  Loss:  0.98674464   Accuracy:  0.8671875\n",
      "Iteration:  664  Loss:  0.85300726   Accuracy:  0.8125\n",
      "Iteration:  665  Loss:  0.4347652   Accuracy:  0.890625\n",
      "Iteration:  666  Loss:  0.8470102   Accuracy:  0.828125\n",
      "Iteration:  667  Loss:  0.59165084   Accuracy:  0.8828125\n",
      "Iteration:  668  Loss:  0.42839688   Accuracy:  0.90625\n",
      "Iteration:  669  Loss:  0.45966884   Accuracy:  0.90625\n",
      "Iteration:  670  Loss:  0.71192145   Accuracy:  0.859375\n",
      "Iteration:  671  Loss:  0.63970417   Accuracy:  0.875\n",
      "Iteration:  672  Loss:  0.6900874   Accuracy:  0.8359375\n",
      "Iteration:  673  Loss:  0.62502533   Accuracy:  0.875\n",
      "Iteration:  674  Loss:  0.54568386   Accuracy:  0.875\n",
      "Iteration:  675  Loss:  0.32542902   Accuracy:  0.8984375\n",
      "Iteration:  676  Loss:  0.5641843   Accuracy:  0.8828125\n",
      "Iteration:  677  Loss:  0.6429152   Accuracy:  0.84375\n",
      "Iteration:  678  Loss:  0.7430595   Accuracy:  0.875\n",
      "Iteration:  679  Loss:  0.70995903   Accuracy:  0.875\n",
      "Iteration:  680  Loss:  0.795101   Accuracy:  0.8203125\n",
      "Iteration:  681  Loss:  0.54980874   Accuracy:  0.8515625\n",
      "Iteration:  682  Loss:  0.64189786   Accuracy:  0.859375\n",
      "Iteration:  683  Loss:  0.6915412   Accuracy:  0.859375\n",
      "Iteration:  684  Loss:  0.5813083   Accuracy:  0.8125\n",
      "Iteration:  685  Loss:  0.46024483   Accuracy:  0.90625\n",
      "Iteration:  686  Loss:  0.4660076   Accuracy:  0.8359375\n",
      "Iteration:  687  Loss:  0.771449   Accuracy:  0.828125\n",
      "Iteration:  688  Loss:  0.7060405   Accuracy:  0.84375\n",
      "Iteration:  689  Loss:  0.76874155   Accuracy:  0.8359375\n",
      "Iteration:  690  Loss:  0.6631803   Accuracy:  0.8515625\n",
      "Iteration:  691  Loss:  0.54878986   Accuracy:  0.875\n",
      "Iteration:  692  Loss:  0.44631743   Accuracy:  0.8671875\n",
      "Iteration:  693  Loss:  0.7699667   Accuracy:  0.84375\n",
      "Iteration:  694  Loss:  0.54223466   Accuracy:  0.890625\n",
      "Iteration:  695  Loss:  0.4123778   Accuracy:  0.875\n",
      "Iteration:  696  Loss:  0.19350965   Accuracy:  0.921875\n",
      "Iteration:  697  Loss:  0.7509314   Accuracy:  0.8359375\n",
      "Iteration:  698  Loss:  0.7094423   Accuracy:  0.8828125\n",
      "Iteration:  699  Loss:  0.8451439   Accuracy:  0.84375\n",
      "Iteration:  700  Loss:  0.5586413   Accuracy:  0.8828125\n",
      "Iteration:  701  Loss:  0.63682795   Accuracy:  0.8359375\n",
      "Iteration:  702  Loss:  0.9131182   Accuracy:  0.8359375\n",
      "Iteration:  703  Loss:  0.66409564   Accuracy:  0.8515625\n",
      "Iteration:  704  Loss:  0.75411344   Accuracy:  0.8125\n",
      "Iteration:  705  Loss:  0.6577699   Accuracy:  0.8671875\n",
      "Iteration:  706  Loss:  0.60346496   Accuracy:  0.859375\n",
      "Iteration:  707  Loss:  0.66354024   Accuracy:  0.8046875\n",
      "Iteration:  708  Loss:  0.66836095   Accuracy:  0.875\n",
      "Iteration:  709  Loss:  0.26436612   Accuracy:  0.890625\n",
      "Iteration:  710  Loss:  0.6097856   Accuracy:  0.8828125\n",
      "Iteration:  711  Loss:  0.9533953   Accuracy:  0.8359375\n",
      "Iteration:  712  Loss:  0.67833924   Accuracy:  0.8515625\n",
      "Iteration:  713  Loss:  0.95844644   Accuracy:  0.8046875\n",
      "Iteration:  714  Loss:  0.44645745   Accuracy:  0.875\n",
      "Iteration:  715  Loss:  0.7028825   Accuracy:  0.8671875\n",
      "Iteration:  716  Loss:  0.67591393   Accuracy:  0.8359375\n",
      "Iteration:  717  Loss:  0.7668675   Accuracy:  0.8359375\n",
      "Iteration:  718  Loss:  0.48963165   Accuracy:  0.8515625\n",
      "Iteration:  719  Loss:  0.42943418   Accuracy:  0.8828125\n",
      "Iteration:  720  Loss:  0.310816   Accuracy:  0.890625\n",
      "Iteration:  721  Loss:  0.6703006   Accuracy:  0.8671875\n",
      "Iteration:  722  Loss:  0.60815763   Accuracy:  0.8203125\n",
      "Iteration:  723  Loss:  0.7914823   Accuracy:  0.84375\n",
      "Iteration:  724  Loss:  0.5344089   Accuracy:  0.8515625\n",
      "Iteration:  725  Loss:  0.55131364   Accuracy:  0.859375\n",
      "Iteration:  726  Loss:  0.42535028   Accuracy:  0.875\n",
      "Iteration:  727  Loss:  0.8916796   Accuracy:  0.8515625\n",
      "Iteration:  728  Loss:  0.42992184   Accuracy:  0.8828125\n",
      "Iteration:  729  Loss:  0.24997443   Accuracy:  0.90625\n",
      "Iteration:  730  Loss:  0.53233445   Accuracy:  0.8828125\n",
      "Iteration:  731  Loss:  0.5015853   Accuracy:  0.859375\n",
      "Iteration:  732  Loss:  0.872066   Accuracy:  0.84375\n",
      "Iteration:  733  Loss:  0.60889995   Accuracy:  0.8515625\n",
      "Iteration:  734  Loss:  0.59769034   Accuracy:  0.8671875\n",
      "Iteration:  735  Loss:  0.5993854   Accuracy:  0.859375\n",
      "Iteration:  736  Loss:  0.45227033   Accuracy:  0.8828125\n",
      "Iteration:  737  Loss:  0.5600138   Accuracy:  0.875\n",
      "Iteration:  738  Loss:  0.46221805   Accuracy:  0.8984375\n",
      "Iteration:  739  Loss:  0.52186817   Accuracy:  0.859375\n",
      "Iteration:  740  Loss:  0.45140976   Accuracy:  0.890625\n",
      "Iteration:  741  Loss:  0.3084424   Accuracy:  0.9140625\n",
      "Iteration:  742  Loss:  0.7798537   Accuracy:  0.875\n",
      "Iteration:  743  Loss:  0.5427843   Accuracy:  0.8671875\n",
      "Iteration:  744  Loss:  0.6715399   Accuracy:  0.8671875\n",
      "Iteration:  745  Loss:  0.40768686   Accuracy:  0.890625\n",
      "Iteration:  746  Loss:  0.6616572   Accuracy:  0.84375\n",
      "Iteration:  747  Loss:  0.77733845   Accuracy:  0.859375\n",
      "Iteration:  748  Loss:  0.45989373   Accuracy:  0.8984375\n",
      "Iteration:  749  Loss:  0.79055876   Accuracy:  0.78125\n",
      "Iteration:  750  Loss:  0.46551916   Accuracy:  0.890625\n",
      "Iteration:  751  Loss:  0.45132303   Accuracy:  0.9140625\n",
      "Iteration:  752  Loss:  0.5539468   Accuracy:  0.828125\n",
      "Iteration:  753  Loss:  0.78896457   Accuracy:  0.7890625\n",
      "Iteration:  754  Loss:  0.89270914   Accuracy:  0.828125\n",
      "Iteration:  755  Loss:  0.79622775   Accuracy:  0.84375\n",
      "Iteration:  756  Loss:  0.8209895   Accuracy:  0.84375\n",
      "Iteration:  757  Loss:  0.80357623   Accuracy:  0.8359375\n",
      "Iteration:  758  Loss:  0.67986834   Accuracy:  0.8515625\n",
      "Iteration:  759  Loss:  0.4590459   Accuracy:  0.8828125\n",
      "Iteration:  760  Loss:  0.8793038   Accuracy:  0.8359375\n",
      "Iteration:  761  Loss:  0.42866296   Accuracy:  0.8984375\n",
      "Iteration:  762  Loss:  0.56286544   Accuracy:  0.890625\n",
      "Iteration:  763  Loss:  0.53721875   Accuracy:  0.890625\n",
      "Iteration:  764  Loss:  0.49277794   Accuracy:  0.8359375\n",
      "Iteration:  765  Loss:  0.8557167   Accuracy:  0.8359375\n",
      "Iteration:  766  Loss:  0.47873813   Accuracy:  0.8828125\n",
      "Iteration:  767  Loss:  0.57370627   Accuracy:  0.828125\n",
      "Iteration:  768  Loss:  0.35952556   Accuracy:  0.9296875\n",
      "Iteration:  769  Loss:  0.8605815   Accuracy:  0.8203125\n",
      "Iteration:  770  Loss:  1.2424357   Accuracy:  0.8515625\n",
      "Iteration:  771  Loss:  0.6555801   Accuracy:  0.859375\n",
      "Iteration:  772  Loss:  0.55072296   Accuracy:  0.8515625\n",
      "Iteration:  773  Loss:  0.6200172   Accuracy:  0.8671875\n",
      "Iteration:  774  Loss:  0.44778657   Accuracy:  0.875\n",
      "Iteration:  775  Loss:  0.38895705   Accuracy:  0.890625\n",
      "Iteration:  776  Loss:  0.4237158   Accuracy:  0.890625\n",
      "Iteration:  777  Loss:  0.71557534   Accuracy:  0.8359375\n",
      "Iteration:  778  Loss:  0.76794684   Accuracy:  0.859375\n",
      "Iteration:  779  Loss:  0.26419204   Accuracy:  0.9296875\n",
      "Iteration:  780  Loss:  0.780385   Accuracy:  0.8515625\n",
      "Iteration:  781  Loss:  0.7350066   Accuracy:  0.84375\n",
      "Iteration:  782  Loss:  0.5243282   Accuracy:  0.8359375\n",
      "Iteration:  783  Loss:  0.7560225   Accuracy:  0.8359375\n",
      "Iteration:  784  Loss:  0.7216776   Accuracy:  0.84375\n",
      "Iteration:  785  Loss:  0.5551603   Accuracy:  0.8515625\n",
      "Iteration:  786  Loss:  0.65506107   Accuracy:  0.8828125\n",
      "Iteration:  787  Loss:  0.8538965   Accuracy:  0.8515625\n",
      "Iteration:  788  Loss:  0.48576412   Accuracy:  0.890625\n",
      "Iteration:  789  Loss:  0.646081   Accuracy:  0.8671875\n",
      "Iteration:  790  Loss:  0.49745885   Accuracy:  0.875\n",
      "Iteration:  791  Loss:  0.9040593   Accuracy:  0.796875\n",
      "Iteration:  792  Loss:  0.37546062   Accuracy:  0.8984375\n",
      "Iteration:  793  Loss:  0.41983518   Accuracy:  0.8671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  794  Loss:  0.71146953   Accuracy:  0.8515625\n",
      "Iteration:  795  Loss:  0.52386844   Accuracy:  0.890625\n",
      "Iteration:  796  Loss:  0.39134324   Accuracy:  0.875\n",
      "Iteration:  797  Loss:  0.52184945   Accuracy:  0.8828125\n",
      "Iteration:  798  Loss:  0.7388644   Accuracy:  0.8359375\n",
      "Iteration:  799  Loss:  0.5189859   Accuracy:  0.875\n",
      "Iteration:  800  Loss:  0.40333092   Accuracy:  0.9140625\n",
      "Iteration:  801  Loss:  0.4455611   Accuracy:  0.90625\n",
      "Iteration:  802  Loss:  0.5068341   Accuracy:  0.859375\n",
      "Iteration:  803  Loss:  0.59920573   Accuracy:  0.8671875\n",
      "Iteration:  804  Loss:  0.70638794   Accuracy:  0.8515625\n",
      "Iteration:  805  Loss:  0.72340953   Accuracy:  0.8515625\n",
      "Iteration:  806  Loss:  0.7903682   Accuracy:  0.84375\n",
      "Iteration:  807  Loss:  0.44374135   Accuracy:  0.90625\n",
      "Iteration:  808  Loss:  0.71267605   Accuracy:  0.8359375\n",
      "Iteration:  809  Loss:  0.8855667   Accuracy:  0.84375\n",
      "Iteration:  810  Loss:  0.6210382   Accuracy:  0.8828125\n",
      "Iteration:  811  Loss:  0.688405   Accuracy:  0.875\n",
      "Iteration:  812  Loss:  0.69361013   Accuracy:  0.8671875\n",
      "Iteration:  813  Loss:  0.5612344   Accuracy:  0.8046875\n",
      "Iteration:  814  Loss:  0.50204176   Accuracy:  0.8671875\n",
      "Iteration:  815  Loss:  0.47793964   Accuracy:  0.90625\n",
      "Iteration:  816  Loss:  0.26927957   Accuracy:  0.90625\n",
      "Iteration:  817  Loss:  0.61768764   Accuracy:  0.8125\n",
      "Iteration:  818  Loss:  0.44537455   Accuracy:  0.8671875\n",
      "Iteration:  819  Loss:  0.52644354   Accuracy:  0.859375\n",
      "Iteration:  820  Loss:  0.2598794   Accuracy:  0.921875\n",
      "Iteration:  821  Loss:  0.61481476   Accuracy:  0.8671875\n",
      "Iteration:  822  Loss:  0.36590555   Accuracy:  0.8828125\n",
      "Iteration:  823  Loss:  0.4706095   Accuracy:  0.859375\n",
      "Iteration:  824  Loss:  0.5605999   Accuracy:  0.8828125\n",
      "Iteration:  825  Loss:  0.88102067   Accuracy:  0.8828125\n",
      "Iteration:  826  Loss:  0.44101644   Accuracy:  0.890625\n",
      "Iteration:  827  Loss:  0.43829036   Accuracy:  0.8671875\n",
      "Iteration:  828  Loss:  0.49311098   Accuracy:  0.859375\n",
      "Iteration:  829  Loss:  0.6415674   Accuracy:  0.84375\n",
      "Iteration:  830  Loss:  0.61688817   Accuracy:  0.8828125\n",
      "Iteration:  831  Loss:  0.9067064   Accuracy:  0.8046875\n",
      "Iteration:  832  Loss:  0.3943936   Accuracy:  0.875\n",
      "Iteration:  833  Loss:  0.45258045   Accuracy:  0.8671875\n",
      "Iteration:  834  Loss:  1.0558336   Accuracy:  0.8515625\n",
      "Iteration:  835  Loss:  0.87814534   Accuracy:  0.8046875\n",
      "Iteration:  836  Loss:  0.45379385   Accuracy:  0.90625\n",
      "Iteration:  837  Loss:  0.58715135   Accuracy:  0.8671875\n",
      "Iteration:  838  Loss:  0.5588875   Accuracy:  0.8671875\n",
      "Iteration:  839  Loss:  0.66529197   Accuracy:  0.8515625\n",
      "Iteration:  840  Loss:  0.75579506   Accuracy:  0.8203125\n",
      "Iteration:  841  Loss:  0.39303446   Accuracy:  0.8828125\n",
      "Iteration:  842  Loss:  0.3930777   Accuracy:  0.921875\n",
      "Iteration:  843  Loss:  0.701196   Accuracy:  0.8671875\n",
      "Iteration:  844  Loss:  0.60997385   Accuracy:  0.890625\n",
      "Iteration:  845  Loss:  0.5549769   Accuracy:  0.875\n",
      "Iteration:  846  Loss:  0.5766504   Accuracy:  0.828125\n",
      "Iteration:  847  Loss:  0.45252988   Accuracy:  0.875\n",
      "Iteration:  848  Loss:  0.50402343   Accuracy:  0.875\n",
      "Iteration:  849  Loss:  0.60550135   Accuracy:  0.84375\n",
      "Iteration:  850  Loss:  0.3682605   Accuracy:  0.9140625\n",
      "Iteration:  851  Loss:  0.85267353   Accuracy:  0.8203125\n",
      "Iteration:  852  Loss:  0.8983163   Accuracy:  0.8359375\n",
      "Iteration:  853  Loss:  0.63702875   Accuracy:  0.8671875\n",
      "Iteration:  854  Loss:  0.62687796   Accuracy:  0.8671875\n",
      "Iteration:  855  Loss:  0.5225776   Accuracy:  0.875\n",
      "Iteration:  856  Loss:  0.38688955   Accuracy:  0.9296875\n",
      "Iteration:  857  Loss:  0.64131   Accuracy:  0.859375\n",
      "Iteration:  858  Loss:  0.80180097   Accuracy:  0.84375\n",
      "Iteration:  859  Loss:  0.64503306   Accuracy:  0.8671875\n",
      "Iteration:  860  Loss:  0.72854006   Accuracy:  0.84375\n",
      "Iteration:  861  Loss:  0.3540341   Accuracy:  0.90625\n",
      "Iteration:  862  Loss:  0.40330207   Accuracy:  0.890625\n",
      "Iteration:  863  Loss:  0.32519662   Accuracy:  0.8984375\n",
      "Iteration:  864  Loss:  0.9828229   Accuracy:  0.8203125\n",
      "Iteration:  865  Loss:  0.69579816   Accuracy:  0.8359375\n",
      "Iteration:  866  Loss:  0.76995075   Accuracy:  0.8359375\n",
      "Iteration:  867  Loss:  0.628356   Accuracy:  0.84375\n",
      "Iteration:  868  Loss:  0.5514721   Accuracy:  0.8671875\n",
      "Iteration:  869  Loss:  0.4884877   Accuracy:  0.890625\n",
      "Iteration:  870  Loss:  0.6076109   Accuracy:  0.875\n",
      "Iteration:  871  Loss:  0.41795647   Accuracy:  0.921875\n",
      "Iteration:  872  Loss:  0.48152852   Accuracy:  0.8828125\n",
      "Iteration:  873  Loss:  0.648714   Accuracy:  0.8359375\n",
      "Iteration:  874  Loss:  0.35743266   Accuracy:  0.890625\n",
      "Iteration:  875  Loss:  0.71692383   Accuracy:  0.8515625\n",
      "Iteration:  876  Loss:  0.8158611   Accuracy:  0.8125\n",
      "Iteration:  877  Loss:  0.41920716   Accuracy:  0.890625\n",
      "Iteration:  878  Loss:  0.5218328   Accuracy:  0.9296875\n",
      "Iteration:  879  Loss:  0.5865735   Accuracy:  0.875\n",
      "Iteration:  880  Loss:  0.30844456   Accuracy:  0.90625\n",
      "Iteration:  881  Loss:  0.49496982   Accuracy:  0.875\n",
      "Iteration:  882  Loss:  0.47026843   Accuracy:  0.9140625\n",
      "Iteration:  883  Loss:  0.4632125   Accuracy:  0.8984375\n",
      "Iteration:  884  Loss:  0.5352731   Accuracy:  0.8671875\n",
      "Iteration:  885  Loss:  0.8683136   Accuracy:  0.8359375\n",
      "Iteration:  886  Loss:  0.5591545   Accuracy:  0.875\n",
      "Iteration:  887  Loss:  0.59774697   Accuracy:  0.890625\n",
      "Iteration:  888  Loss:  0.4039597   Accuracy:  0.8828125\n",
      "Iteration:  889  Loss:  0.58680266   Accuracy:  0.8125\n",
      "Iteration:  890  Loss:  0.5249908   Accuracy:  0.890625\n",
      "Iteration:  891  Loss:  0.6019395   Accuracy:  0.8203125\n",
      "Iteration:  892  Loss:  0.8126292   Accuracy:  0.875\n",
      "Iteration:  893  Loss:  0.6264594   Accuracy:  0.8828125\n",
      "Iteration:  894  Loss:  0.7544408   Accuracy:  0.8125\n",
      "Iteration:  895  Loss:  0.9035288   Accuracy:  0.8515625\n",
      "Iteration:  896  Loss:  0.9020697   Accuracy:  0.84375\n",
      "Iteration:  897  Loss:  0.7143163   Accuracy:  0.8515625\n",
      "Iteration:  898  Loss:  0.41142702   Accuracy:  0.90625\n",
      "Iteration:  899  Loss:  0.38087815   Accuracy:  0.8671875\n",
      "Iteration:  900  Loss:  0.5547472   Accuracy:  0.890625\n",
      "Iteration:  901  Loss:  0.7327482   Accuracy:  0.828125\n",
      "Iteration:  902  Loss:  0.8185205   Accuracy:  0.890625\n",
      "Iteration:  903  Loss:  0.67694896   Accuracy:  0.859375\n",
      "Iteration:  904  Loss:  0.38536415   Accuracy:  0.8671875\n",
      "Iteration:  905  Loss:  1.0312643   Accuracy:  0.796875\n",
      "Iteration:  906  Loss:  0.43875766   Accuracy:  0.875\n",
      "Iteration:  907  Loss:  0.33278912   Accuracy:  0.8984375\n",
      "Iteration:  908  Loss:  0.32471597   Accuracy:  0.890625\n",
      "Iteration:  909  Loss:  0.54456455   Accuracy:  0.890625\n",
      "Iteration:  910  Loss:  0.33339387   Accuracy:  0.9296875\n",
      "Iteration:  911  Loss:  0.54878885   Accuracy:  0.875\n",
      "Iteration:  912  Loss:  0.522091   Accuracy:  0.8984375\n",
      "Iteration:  913  Loss:  0.44179037   Accuracy:  0.8984375\n",
      "Iteration:  914  Loss:  0.68252116   Accuracy:  0.84375\n",
      "Iteration:  915  Loss:  0.35854572   Accuracy:  0.921875\n",
      "Iteration:  916  Loss:  0.8325922   Accuracy:  0.8359375\n",
      "Iteration:  917  Loss:  0.4085514   Accuracy:  0.8671875\n",
      "Iteration:  918  Loss:  0.5614743   Accuracy:  0.84375\n",
      "Iteration:  919  Loss:  0.58727676   Accuracy:  0.8515625\n",
      "Iteration:  920  Loss:  0.52480733   Accuracy:  0.828125\n",
      "Iteration:  921  Loss:  0.53277135   Accuracy:  0.875\n",
      "Iteration:  922  Loss:  0.643778   Accuracy:  0.8828125\n",
      "Iteration:  923  Loss:  0.6502252   Accuracy:  0.7890625\n",
      "Iteration:  924  Loss:  0.4765123   Accuracy:  0.859375\n",
      "Iteration:  925  Loss:  0.44218886   Accuracy:  0.8984375\n",
      "Iteration:  926  Loss:  0.7127677   Accuracy:  0.8515625\n",
      "Iteration:  927  Loss:  0.60410726   Accuracy:  0.8515625\n",
      "Iteration:  928  Loss:  0.437339   Accuracy:  0.890625\n",
      "Iteration:  929  Loss:  0.4956956   Accuracy:  0.890625\n",
      "Iteration:  930  Loss:  0.62862885   Accuracy:  0.8984375\n",
      "Iteration:  931  Loss:  0.4244616   Accuracy:  0.90625\n",
      "Iteration:  932  Loss:  0.54622024   Accuracy:  0.875\n",
      "Iteration:  933  Loss:  0.6689914   Accuracy:  0.890625\n",
      "Iteration:  934  Loss:  0.6114335   Accuracy:  0.875\n",
      "Iteration:  935  Loss:  0.41522828   Accuracy:  0.8828125\n",
      "Iteration:  936  Loss:  0.68135643   Accuracy:  0.84375\n",
      "Iteration:  937  Loss:  1.0651639   Accuracy:  0.796875\n",
      "Iteration:  938  Loss:  0.35707814   Accuracy:  0.921875\n",
      "Iteration:  939  Loss:  0.40363693   Accuracy:  0.8984375\n",
      "Iteration:  940  Loss:  0.4969849   Accuracy:  0.859375\n",
      "Iteration:  941  Loss:  0.72405744   Accuracy:  0.8828125\n",
      "Iteration:  942  Loss:  0.6116854   Accuracy:  0.8359375\n",
      "Iteration:  943  Loss:  0.705266   Accuracy:  0.8671875\n",
      "Iteration:  944  Loss:  0.50987613   Accuracy:  0.875\n",
      "Iteration:  945  Loss:  0.42453468   Accuracy:  0.90625\n",
      "Iteration:  946  Loss:  0.46513614   Accuracy:  0.8671875\n",
      "Iteration:  947  Loss:  0.3936848   Accuracy:  0.8828125\n",
      "Iteration:  948  Loss:  0.61746824   Accuracy:  0.84375\n",
      "Iteration:  949  Loss:  0.4828121   Accuracy:  0.875\n",
      "Iteration:  950  Loss:  0.9278439   Accuracy:  0.8046875\n",
      "Iteration:  951  Loss:  0.7360965   Accuracy:  0.8671875\n",
      "Iteration:  952  Loss:  0.5685769   Accuracy:  0.8515625\n",
      "Iteration:  953  Loss:  0.29834196   Accuracy:  0.90625\n",
      "Iteration:  954  Loss:  0.9554816   Accuracy:  0.8359375\n",
      "Iteration:  955  Loss:  0.24402156   Accuracy:  0.9140625\n",
      "Iteration:  956  Loss:  0.584023   Accuracy:  0.875\n",
      "Iteration:  957  Loss:  0.5722826   Accuracy:  0.890625\n",
      "Iteration:  958  Loss:  0.73997265   Accuracy:  0.8828125\n",
      "Iteration:  959  Loss:  0.57854843   Accuracy:  0.859375\n",
      "Iteration:  960  Loss:  0.26218006   Accuracy:  0.8828125\n",
      "Iteration:  961  Loss:  0.29581955   Accuracy:  0.8828125\n",
      "Iteration:  962  Loss:  0.6012882   Accuracy:  0.859375\n",
      "Iteration:  963  Loss:  0.48718143   Accuracy:  0.890625\n",
      "Iteration:  964  Loss:  0.6343347   Accuracy:  0.8828125\n",
      "Iteration:  965  Loss:  0.4752248   Accuracy:  0.9140625\n",
      "Iteration:  966  Loss:  0.5309052   Accuracy:  0.875\n",
      "Iteration:  967  Loss:  0.62181175   Accuracy:  0.8828125\n",
      "Iteration:  968  Loss:  0.3049337   Accuracy:  0.9140625\n",
      "Iteration:  969  Loss:  0.540015   Accuracy:  0.8515625\n",
      "Iteration:  970  Loss:  0.501538   Accuracy:  0.8984375\n",
      "Iteration:  971  Loss:  0.7706599   Accuracy:  0.78125\n",
      "Iteration:  972  Loss:  0.7615721   Accuracy:  0.84375\n",
      "Iteration:  973  Loss:  0.70857424   Accuracy:  0.8046875\n",
      "Iteration:  974  Loss:  0.7690833   Accuracy:  0.84375\n",
      "Iteration:  975  Loss:  0.4381522   Accuracy:  0.9140625\n",
      "Iteration:  976  Loss:  0.36112922   Accuracy:  0.8828125\n",
      "Iteration:  977  Loss:  0.5803741   Accuracy:  0.8984375\n",
      "Iteration:  978  Loss:  0.7336068   Accuracy:  0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  979  Loss:  0.3071486   Accuracy:  0.9140625\n",
      "Iteration:  980  Loss:  0.33149672   Accuracy:  0.890625\n",
      "Iteration:  981  Loss:  0.63227165   Accuracy:  0.8828125\n",
      "Iteration:  982  Loss:  0.5150042   Accuracy:  0.890625\n",
      "Iteration:  983  Loss:  0.48960507   Accuracy:  0.921875\n",
      "Iteration:  984  Loss:  0.7576912   Accuracy:  0.84375\n",
      "Iteration:  985  Loss:  0.4467986   Accuracy:  0.8515625\n",
      "Iteration:  986  Loss:  0.49869326   Accuracy:  0.90625\n",
      "Iteration:  987  Loss:  0.46656537   Accuracy:  0.890625\n",
      "Iteration:  988  Loss:  0.60919887   Accuracy:  0.8671875\n",
      "Iteration:  989  Loss:  0.6533853   Accuracy:  0.875\n",
      "Iteration:  990  Loss:  0.33946037   Accuracy:  0.859375\n",
      "Iteration:  991  Loss:  0.5838153   Accuracy:  0.8828125\n",
      "Iteration:  992  Loss:  0.42264295   Accuracy:  0.921875\n",
      "Iteration:  993  Loss:  0.4918276   Accuracy:  0.8828125\n",
      "Iteration:  994  Loss:  0.73541474   Accuracy:  0.8359375\n",
      "Iteration:  995  Loss:  0.6019176   Accuracy:  0.859375\n",
      "Iteration:  996  Loss:  0.78073835   Accuracy:  0.8515625\n",
      "Iteration:  997  Loss:  0.68737173   Accuracy:  0.890625\n",
      "Iteration:  998  Loss:  0.6433232   Accuracy:  0.8046875\n",
      "Iteration:  999  Loss:  0.522297   Accuracy:  0.859375\n",
      "Iteration:  1000  Loss:  0.45254058   Accuracy:  0.875\n",
      "Iteration:  1001  Loss:  0.7848022   Accuracy:  0.859375\n",
      "Iteration:  1002  Loss:  0.54595923   Accuracy:  0.8671875\n",
      "Iteration:  1003  Loss:  0.67239314   Accuracy:  0.8671875\n",
      "Iteration:  1004  Loss:  0.74894345   Accuracy:  0.84375\n",
      "Iteration:  1005  Loss:  0.34555978   Accuracy:  0.890625\n",
      "Iteration:  1006  Loss:  0.67820877   Accuracy:  0.8828125\n",
      "Iteration:  1007  Loss:  0.47964334   Accuracy:  0.875\n",
      "Iteration:  1008  Loss:  0.3831097   Accuracy:  0.890625\n",
      "Iteration:  1009  Loss:  0.39193636   Accuracy:  0.8671875\n",
      "Iteration:  1010  Loss:  0.3276475   Accuracy:  0.9140625\n",
      "Iteration:  1011  Loss:  0.8023445   Accuracy:  0.828125\n",
      "Iteration:  1012  Loss:  0.3618214   Accuracy:  0.90625\n",
      "Iteration:  1013  Loss:  0.47390297   Accuracy:  0.921875\n",
      "Iteration:  1014  Loss:  0.3778711   Accuracy:  0.90625\n",
      "Iteration:  1015  Loss:  0.37514836   Accuracy:  0.890625\n",
      "Iteration:  1016  Loss:  0.86743546   Accuracy:  0.8515625\n",
      "Iteration:  1017  Loss:  0.3070801   Accuracy:  0.90625\n",
      "Iteration:  1018  Loss:  0.5715809   Accuracy:  0.8671875\n",
      "Iteration:  1019  Loss:  0.58540976   Accuracy:  0.8359375\n",
      "Iteration:  1020  Loss:  0.6585445   Accuracy:  0.8671875\n",
      "Iteration:  1021  Loss:  0.33263895   Accuracy:  0.8984375\n",
      "Iteration:  1022  Loss:  0.65858215   Accuracy:  0.8828125\n",
      "Iteration:  1023  Loss:  0.41809124   Accuracy:  0.8984375\n",
      "Iteration:  1024  Loss:  0.72019786   Accuracy:  0.875\n",
      "Iteration:  1025  Loss:  0.2653389   Accuracy:  0.9140625\n",
      "Iteration:  1026  Loss:  0.658291   Accuracy:  0.8203125\n",
      "Iteration:  1027  Loss:  0.5258238   Accuracy:  0.8359375\n",
      "Iteration:  1028  Loss:  0.5076132   Accuracy:  0.890625\n",
      "Iteration:  1029  Loss:  0.25464404   Accuracy:  0.9375\n",
      "Iteration:  1030  Loss:  0.4103681   Accuracy:  0.90625\n",
      "Iteration:  1031  Loss:  0.67196244   Accuracy:  0.8203125\n",
      "Iteration:  1032  Loss:  0.5252603   Accuracy:  0.875\n",
      "Iteration:  1033  Loss:  0.57197237   Accuracy:  0.8984375\n",
      "Iteration:  1034  Loss:  0.5595709   Accuracy:  0.875\n",
      "Iteration:  1035  Loss:  0.5075638   Accuracy:  0.84375\n",
      "Iteration:  1036  Loss:  0.3385953   Accuracy:  0.890625\n",
      "Iteration:  1037  Loss:  0.49610746   Accuracy:  0.890625\n",
      "Iteration:  1038  Loss:  0.9117287   Accuracy:  0.84375\n",
      "Iteration:  1039  Loss:  0.5078803   Accuracy:  0.828125\n",
      "Iteration:  1040  Loss:  0.53225315   Accuracy:  0.890625\n",
      "Iteration:  1041  Loss:  0.6028795   Accuracy:  0.875\n",
      "Iteration:  1042  Loss:  0.8824023   Accuracy:  0.8203125\n",
      "Iteration:  1043  Loss:  0.35170764   Accuracy:  0.8984375\n",
      "Iteration:  1044  Loss:  0.6218469   Accuracy:  0.859375\n",
      "Iteration:  1045  Loss:  0.5892674   Accuracy:  0.8515625\n",
      "Iteration:  1046  Loss:  0.6565186   Accuracy:  0.8671875\n",
      "Iteration:  1047  Loss:  0.6948031   Accuracy:  0.8203125\n",
      "Iteration:  1048  Loss:  0.58678955   Accuracy:  0.859375\n",
      "Iteration:  1049  Loss:  0.5340442   Accuracy:  0.8984375\n",
      "Iteration:  1050  Loss:  0.78661025   Accuracy:  0.84375\n",
      "Iteration:  1051  Loss:  0.42912263   Accuracy:  0.9140625\n",
      "Iteration:  1052  Loss:  0.6983096   Accuracy:  0.8828125\n",
      "Iteration:  1053  Loss:  0.768525   Accuracy:  0.8359375\n",
      "Iteration:  1054  Loss:  0.68431765   Accuracy:  0.8515625\n",
      "Iteration:  1055  Loss:  0.6461687   Accuracy:  0.84375\n",
      "Iteration:  1056  Loss:  0.9428699   Accuracy:  0.8046875\n",
      "Iteration:  1057  Loss:  0.3256877   Accuracy:  0.921875\n",
      "Iteration:  1058  Loss:  0.73660266   Accuracy:  0.859375\n",
      "Iteration:  1059  Loss:  0.5681881   Accuracy:  0.8515625\n",
      "Iteration:  1060  Loss:  0.5987536   Accuracy:  0.8671875\n",
      "Iteration:  1061  Loss:  0.6217033   Accuracy:  0.8671875\n",
      "Iteration:  1062  Loss:  0.35651812   Accuracy:  0.8828125\n",
      "Iteration:  1063  Loss:  0.5006083   Accuracy:  0.8671875\n",
      "Iteration:  1064  Loss:  0.5108947   Accuracy:  0.8984375\n",
      "Iteration:  1065  Loss:  0.24762352   Accuracy:  0.9296875\n",
      "Iteration:  1066  Loss:  0.57701635   Accuracy:  0.8984375\n",
      "Iteration:  1067  Loss:  0.48774147   Accuracy:  0.90625\n",
      "Iteration:  1068  Loss:  0.43014395   Accuracy:  0.9140625\n",
      "Iteration:  1069  Loss:  0.5154619   Accuracy:  0.890625\n",
      "Iteration:  1070  Loss:  0.38777745   Accuracy:  0.890625\n",
      "Iteration:  1071  Loss:  0.7962866   Accuracy:  0.8828125\n",
      "Iteration:  1072  Loss:  0.43663347   Accuracy:  0.875\n",
      "Iteration:  1073  Loss:  0.74952984   Accuracy:  0.8125\n",
      "Iteration:  1074  Loss:  0.38623595   Accuracy:  0.8671875\n",
      "Iteration:  1075  Loss:  0.85102713   Accuracy:  0.84375\n",
      "Iteration:  1076  Loss:  0.62606406   Accuracy:  0.859375\n",
      "Iteration:  1077  Loss:  0.42991254   Accuracy:  0.890625\n",
      "Iteration:  1078  Loss:  0.7149453   Accuracy:  0.875\n",
      "Iteration:  1079  Loss:  0.45764282   Accuracy:  0.8828125\n",
      "Iteration:  1080  Loss:  0.61925507   Accuracy:  0.84375\n",
      "Iteration:  1081  Loss:  0.536985   Accuracy:  0.859375\n",
      "Iteration:  1082  Loss:  0.361261   Accuracy:  0.90625\n",
      "Iteration:  1083  Loss:  0.7446484   Accuracy:  0.84375\n",
      "Iteration:  1084  Loss:  0.22617811   Accuracy:  0.90625\n",
      "Iteration:  1085  Loss:  0.43537587   Accuracy:  0.8984375\n",
      "Iteration:  1086  Loss:  0.6612586   Accuracy:  0.8828125\n",
      "Iteration:  1087  Loss:  0.34555784   Accuracy:  0.8984375\n",
      "Iteration:  1088  Loss:  0.771116   Accuracy:  0.859375\n",
      "Iteration:  1089  Loss:  0.5267744   Accuracy:  0.84375\n",
      "Iteration:  1090  Loss:  0.4972828   Accuracy:  0.8828125\n",
      "Iteration:  1091  Loss:  0.484052   Accuracy:  0.875\n",
      "Iteration:  1092  Loss:  0.34242126   Accuracy:  0.921875\n",
      "Iteration:  1093  Loss:  0.3555374   Accuracy:  0.8828125\n",
      "Iteration:  1094  Loss:  0.45089713   Accuracy:  0.8828125\n",
      "Iteration:  1095  Loss:  0.44255447   Accuracy:  0.875\n",
      "Iteration:  1096  Loss:  0.7745914   Accuracy:  0.875\n",
      "Iteration:  1097  Loss:  0.85470146   Accuracy:  0.8671875\n",
      "Iteration:  1098  Loss:  0.49417132   Accuracy:  0.875\n",
      "Iteration:  1099  Loss:  0.9152588   Accuracy:  0.875\n",
      "Iteration:  1100  Loss:  0.5610284   Accuracy:  0.890625\n",
      "Iteration:  1101  Loss:  0.4084977   Accuracy:  0.8984375\n",
      "Iteration:  1102  Loss:  0.4105718   Accuracy:  0.890625\n",
      "Iteration:  1103  Loss:  0.31941473   Accuracy:  0.890625\n",
      "Iteration:  1104  Loss:  0.39415365   Accuracy:  0.9140625\n",
      "Iteration:  1105  Loss:  0.5596962   Accuracy:  0.8671875\n",
      "Iteration:  1106  Loss:  0.63770133   Accuracy:  0.8828125\n",
      "Iteration:  1107  Loss:  0.4023869   Accuracy:  0.8984375\n",
      "Iteration:  1108  Loss:  0.42823994   Accuracy:  0.8984375\n",
      "Iteration:  1109  Loss:  0.41508883   Accuracy:  0.8671875\n",
      "Iteration:  1110  Loss:  0.33153975   Accuracy:  0.8984375\n",
      "Iteration:  1111  Loss:  0.6502981   Accuracy:  0.84375\n",
      "Iteration:  1112  Loss:  0.5662089   Accuracy:  0.875\n",
      "Iteration:  1113  Loss:  0.57876277   Accuracy:  0.875\n",
      "Iteration:  1114  Loss:  0.59609634   Accuracy:  0.84375\n",
      "Iteration:  1115  Loss:  0.3439967   Accuracy:  0.8984375\n",
      "Iteration:  1116  Loss:  0.73183274   Accuracy:  0.875\n",
      "Iteration:  1117  Loss:  0.26824152   Accuracy:  0.921875\n",
      "Iteration:  1118  Loss:  0.4428016   Accuracy:  0.8671875\n",
      "Iteration:  1119  Loss:  0.60493565   Accuracy:  0.8671875\n",
      "Iteration:  1120  Loss:  0.5834564   Accuracy:  0.875\n",
      "Iteration:  1121  Loss:  0.52739865   Accuracy:  0.890625\n",
      "Iteration:  1122  Loss:  0.3630203   Accuracy:  0.8984375\n",
      "Iteration:  1123  Loss:  0.47924364   Accuracy:  0.90625\n",
      "Iteration:  1124  Loss:  0.53034776   Accuracy:  0.859375\n",
      "Iteration:  1125  Loss:  0.8002316   Accuracy:  0.8359375\n",
      "Iteration:  1126  Loss:  0.6113218   Accuracy:  0.8359375\n",
      "Iteration:  1127  Loss:  0.87865865   Accuracy:  0.8671875\n",
      "Iteration:  1128  Loss:  0.6491835   Accuracy:  0.875\n",
      "Iteration:  1129  Loss:  0.29998648   Accuracy:  0.9140625\n",
      "Iteration:  1130  Loss:  0.27944002   Accuracy:  0.90625\n",
      "Iteration:  1131  Loss:  0.32341   Accuracy:  0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1132  Loss:  0.4246534   Accuracy:  0.8984375\n",
      "Iteration:  1133  Loss:  0.27001077   Accuracy:  0.859375\n",
      "Iteration:  1134  Loss:  0.3929488   Accuracy:  0.8828125\n",
      "Iteration:  1135  Loss:  0.75765437   Accuracy:  0.828125\n",
      "Iteration:  1136  Loss:  0.5290402   Accuracy:  0.8515625\n",
      "Iteration:  1137  Loss:  0.6999219   Accuracy:  0.8671875\n",
      "Iteration:  1138  Loss:  0.5286921   Accuracy:  0.8671875\n",
      "Iteration:  1139  Loss:  0.67842185   Accuracy:  0.890625\n",
      "Iteration:  1140  Loss:  0.18660325   Accuracy:  0.9375\n",
      "Iteration:  1141  Loss:  0.69795394   Accuracy:  0.8515625\n",
      "Iteration:  1142  Loss:  0.5695997   Accuracy:  0.8984375\n",
      "Iteration:  1143  Loss:  0.36767584   Accuracy:  0.8671875\n",
      "Iteration:  1144  Loss:  0.5982441   Accuracy:  0.8828125\n",
      "Iteration:  1145  Loss:  0.61650497   Accuracy:  0.84375\n",
      "Iteration:  1146  Loss:  0.3488204   Accuracy:  0.9140625\n",
      "Iteration:  1147  Loss:  0.576679   Accuracy:  0.890625\n",
      "Iteration:  1148  Loss:  0.5817441   Accuracy:  0.8671875\n",
      "Iteration:  1149  Loss:  0.339194   Accuracy:  0.9140625\n",
      "Iteration:  1150  Loss:  0.3336159   Accuracy:  0.890625\n",
      "Iteration:  1151  Loss:  0.38748968   Accuracy:  0.8828125\n",
      "Iteration:  1152  Loss:  0.60365355   Accuracy:  0.8671875\n",
      "Iteration:  1153  Loss:  0.56252766   Accuracy:  0.8515625\n",
      "Iteration:  1154  Loss:  0.5113121   Accuracy:  0.8515625\n",
      "Iteration:  1155  Loss:  0.3174948   Accuracy:  0.890625\n",
      "Iteration:  1156  Loss:  0.45216477   Accuracy:  0.8984375\n",
      "Iteration:  1157  Loss:  0.40213764   Accuracy:  0.8984375\n",
      "Iteration:  1158  Loss:  0.6256694   Accuracy:  0.875\n",
      "Iteration:  1159  Loss:  0.4530908   Accuracy:  0.8671875\n",
      "Iteration:  1160  Loss:  0.58099854   Accuracy:  0.84375\n",
      "Iteration:  1161  Loss:  0.49277613   Accuracy:  0.84375\n",
      "Iteration:  1162  Loss:  0.7687858   Accuracy:  0.875\n",
      "Iteration:  1163  Loss:  0.75537634   Accuracy:  0.859375\n",
      "Iteration:  1164  Loss:  0.78991264   Accuracy:  0.8515625\n",
      "Iteration:  1165  Loss:  0.4119298   Accuracy:  0.8671875\n",
      "Iteration:  1166  Loss:  0.6106768   Accuracy:  0.8828125\n",
      "Iteration:  1167  Loss:  0.6095386   Accuracy:  0.8828125\n",
      "Iteration:  1168  Loss:  0.3004161   Accuracy:  0.9140625\n",
      "Iteration:  1169  Loss:  0.62192076   Accuracy:  0.8203125\n",
      "Iteration:  1170  Loss:  0.5211707   Accuracy:  0.8828125\n",
      "Iteration:  1171  Loss:  0.45307088   Accuracy:  0.875\n",
      "Iteration:  1172  Loss:  1.0957116   Accuracy:  0.8203125\n",
      "Iteration:  1173  Loss:  0.7119739   Accuracy:  0.8046875\n",
      "Iteration:  1174  Loss:  0.6657091   Accuracy:  0.8359375\n",
      "Iteration:  1175  Loss:  0.46492514   Accuracy:  0.875\n",
      "Iteration:  1176  Loss:  0.1898363   Accuracy:  0.9609375\n",
      "Iteration:  1177  Loss:  0.6969841   Accuracy:  0.828125\n",
      "Iteration:  1178  Loss:  0.4826458   Accuracy:  0.84375\n",
      "Iteration:  1179  Loss:  0.5246415   Accuracy:  0.8828125\n",
      "Iteration:  1180  Loss:  0.52145684   Accuracy:  0.8515625\n",
      "Iteration:  1181  Loss:  0.42426828   Accuracy:  0.890625\n",
      "Iteration:  1182  Loss:  0.39149398   Accuracy:  0.921875\n",
      "Iteration:  1183  Loss:  0.6671709   Accuracy:  0.859375\n",
      "Iteration:  1184  Loss:  0.39704567   Accuracy:  0.8984375\n",
      "Iteration:  1185  Loss:  0.57844734   Accuracy:  0.8515625\n",
      "Iteration:  1186  Loss:  0.37517676   Accuracy:  0.8828125\n",
      "Iteration:  1187  Loss:  0.4520105   Accuracy:  0.890625\n",
      "Iteration:  1188  Loss:  0.4748224   Accuracy:  0.859375\n",
      "Iteration:  1189  Loss:  0.3272084   Accuracy:  0.859375\n",
      "Iteration:  1190  Loss:  0.71351254   Accuracy:  0.8515625\n",
      "Iteration:  1191  Loss:  0.45745754   Accuracy:  0.875\n",
      "Iteration:  1192  Loss:  0.47832882   Accuracy:  0.9296875\n",
      "Iteration:  1193  Loss:  0.27944002   Accuracy:  0.9140625\n",
      "Iteration:  1194  Loss:  0.42214274   Accuracy:  0.890625\n",
      "Iteration:  1195  Loss:  0.61894864   Accuracy:  0.8359375\n",
      "Iteration:  1196  Loss:  0.48090988   Accuracy:  0.890625\n",
      "Iteration:  1197  Loss:  0.29314283   Accuracy:  0.9140625\n",
      "Iteration:  1198  Loss:  0.44086382   Accuracy:  0.890625\n",
      "Iteration:  1199  Loss:  0.6323766   Accuracy:  0.8515625\n",
      "Iteration:  1200  Loss:  0.39380062   Accuracy:  0.90625\n",
      "Iteration:  1201  Loss:  0.55054504   Accuracy:  0.859375\n",
      "Iteration:  1202  Loss:  0.52879494   Accuracy:  0.8671875\n",
      "Iteration:  1203  Loss:  0.6280916   Accuracy:  0.84375\n",
      "Iteration:  1204  Loss:  0.6980726   Accuracy:  0.8515625\n",
      "Iteration:  1205  Loss:  0.7633564   Accuracy:  0.7890625\n",
      "Iteration:  1206  Loss:  0.61576104   Accuracy:  0.8828125\n",
      "Iteration:  1207  Loss:  0.33161885   Accuracy:  0.9140625\n",
      "Iteration:  1208  Loss:  0.64143574   Accuracy:  0.8125\n",
      "Iteration:  1209  Loss:  0.5445356   Accuracy:  0.828125\n",
      "Iteration:  1210  Loss:  0.7076491   Accuracy:  0.890625\n",
      "Iteration:  1211  Loss:  0.5040083   Accuracy:  0.8984375\n",
      "Iteration:  1212  Loss:  0.2762947   Accuracy:  0.921875\n",
      "Iteration:  1213  Loss:  0.7526111   Accuracy:  0.8828125\n",
      "Iteration:  1214  Loss:  0.17638215   Accuracy:  0.953125\n",
      "Iteration:  1215  Loss:  0.3565392   Accuracy:  0.9140625\n",
      "Iteration:  1216  Loss:  0.33898187   Accuracy:  0.90625\n",
      "Iteration:  1217  Loss:  0.5471266   Accuracy:  0.8984375\n",
      "Iteration:  1218  Loss:  0.45825624   Accuracy:  0.8984375\n",
      "Iteration:  1219  Loss:  0.6353166   Accuracy:  0.8515625\n",
      "Iteration:  1220  Loss:  0.80012715   Accuracy:  0.8515625\n",
      "Iteration:  1221  Loss:  0.39310426   Accuracy:  0.890625\n",
      "Iteration:  1222  Loss:  0.52264076   Accuracy:  0.828125\n",
      "Iteration:  1223  Loss:  0.44664565   Accuracy:  0.8515625\n",
      "Iteration:  1224  Loss:  0.5659833   Accuracy:  0.859375\n",
      "Iteration:  1225  Loss:  0.28734177   Accuracy:  0.9375\n",
      "Iteration:  1226  Loss:  0.3985554   Accuracy:  0.890625\n",
      "Iteration:  1227  Loss:  0.41755813   Accuracy:  0.875\n",
      "Iteration:  1228  Loss:  0.7821426   Accuracy:  0.875\n",
      "Iteration:  1229  Loss:  0.87333304   Accuracy:  0.7734375\n",
      "Iteration:  1230  Loss:  0.76850396   Accuracy:  0.859375\n",
      "Iteration:  1231  Loss:  0.46831748   Accuracy:  0.8828125\n",
      "Iteration:  1232  Loss:  0.82416743   Accuracy:  0.8359375\n",
      "Iteration:  1233  Loss:  0.29250807   Accuracy:  0.90625\n",
      "Iteration:  1234  Loss:  0.5426509   Accuracy:  0.8671875\n",
      "Iteration:  1235  Loss:  0.47031754   Accuracy:  0.8984375\n",
      "Iteration:  1236  Loss:  0.7455918   Accuracy:  0.84375\n",
      "Iteration:  1237  Loss:  0.39531925   Accuracy:  0.890625\n",
      "Iteration:  1238  Loss:  0.4347995   Accuracy:  0.9140625\n",
      "Iteration:  1239  Loss:  0.45088214   Accuracy:  0.8671875\n",
      "Iteration:  1240  Loss:  0.4316016   Accuracy:  0.8984375\n",
      "Iteration:  1241  Loss:  0.6035774   Accuracy:  0.8359375\n",
      "Iteration:  1242  Loss:  0.574011   Accuracy:  0.875\n",
      "Iteration:  1243  Loss:  0.48003358   Accuracy:  0.8828125\n",
      "Iteration:  1244  Loss:  0.6167074   Accuracy:  0.8515625\n",
      "Iteration:  1245  Loss:  0.51273334   Accuracy:  0.8984375\n",
      "Iteration:  1246  Loss:  0.47852805   Accuracy:  0.875\n",
      "Iteration:  1247  Loss:  0.3828993   Accuracy:  0.90625\n",
      "Iteration:  1248  Loss:  0.779261   Accuracy:  0.8359375\n",
      "Iteration:  1249  Loss:  0.6234523   Accuracy:  0.8515625\n",
      "Iteration:  1250  Loss:  0.6109749   Accuracy:  0.84375\n",
      "Iteration:  1251  Loss:  0.39635646   Accuracy:  0.8828125\n",
      "Iteration:  1252  Loss:  0.7148101   Accuracy:  0.8125\n",
      "Iteration:  1253  Loss:  0.8220144   Accuracy:  0.8828125\n",
      "Iteration:  1254  Loss:  0.66679615   Accuracy:  0.828125\n",
      "Iteration:  1255  Loss:  0.5466403   Accuracy:  0.9296875\n",
      "Iteration:  1256  Loss:  0.29174888   Accuracy:  0.9140625\n",
      "Iteration:  1257  Loss:  0.55060935   Accuracy:  0.859375\n",
      "Iteration:  1258  Loss:  0.5347123   Accuracy:  0.890625\n",
      "Iteration:  1259  Loss:  0.3729573   Accuracy:  0.9140625\n",
      "Iteration:  1260  Loss:  0.21838006   Accuracy:  0.9140625\n",
      "Iteration:  1261  Loss:  0.4390873   Accuracy:  0.8671875\n",
      "Iteration:  1262  Loss:  0.5666423   Accuracy:  0.875\n",
      "Iteration:  1263  Loss:  0.60768473   Accuracy:  0.875\n",
      "Iteration:  1264  Loss:  0.512428   Accuracy:  0.8515625\n",
      "Iteration:  1265  Loss:  0.42902696   Accuracy:  0.921875\n",
      "Iteration:  1266  Loss:  0.20939335   Accuracy:  0.9140625\n",
      "Iteration:  1267  Loss:  0.5181386   Accuracy:  0.875\n",
      "Iteration:  1268  Loss:  0.42784825   Accuracy:  0.8828125\n",
      "Iteration:  1269  Loss:  0.48618272   Accuracy:  0.875\n",
      "Iteration:  1270  Loss:  0.6799681   Accuracy:  0.8515625\n",
      "Iteration:  1271  Loss:  0.9789909   Accuracy:  0.78125\n",
      "Iteration:  1272  Loss:  0.33935323   Accuracy:  0.8984375\n",
      "Iteration:  1273  Loss:  0.8070012   Accuracy:  0.8203125\n",
      "Iteration:  1274  Loss:  0.8938514   Accuracy:  0.828125\n",
      "Iteration:  1275  Loss:  0.58325434   Accuracy:  0.8671875\n",
      "Iteration:  1276  Loss:  0.34519735   Accuracy:  0.875\n",
      "Iteration:  1277  Loss:  0.3350049   Accuracy:  0.859375\n",
      "Iteration:  1278  Loss:  0.90259486   Accuracy:  0.8203125\n",
      "Iteration:  1279  Loss:  0.8689616   Accuracy:  0.8359375\n",
      "Iteration:  1280  Loss:  0.51920325   Accuracy:  0.890625\n",
      "Iteration:  1281  Loss:  0.4469306   Accuracy:  0.875\n",
      "Iteration:  1282  Loss:  0.5665804   Accuracy:  0.8828125\n",
      "Iteration:  1283  Loss:  0.5160014   Accuracy:  0.8671875\n",
      "Iteration:  1284  Loss:  0.49778086   Accuracy:  0.8671875\n",
      "Iteration:  1285  Loss:  0.3378631   Accuracy:  0.9140625\n",
      "Iteration:  1286  Loss:  0.3161868   Accuracy:  0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1287  Loss:  0.4157797   Accuracy:  0.875\n",
      "Iteration:  1288  Loss:  0.48235443   Accuracy:  0.8984375\n",
      "Iteration:  1289  Loss:  0.94704497   Accuracy:  0.84375\n",
      "Iteration:  1290  Loss:  0.3603054   Accuracy:  0.8984375\n",
      "Iteration:  1291  Loss:  0.3735308   Accuracy:  0.921875\n",
      "Iteration:  1292  Loss:  0.53431803   Accuracy:  0.90625\n",
      "Iteration:  1293  Loss:  0.45645297   Accuracy:  0.890625\n",
      "Iteration:  1294  Loss:  0.3002714   Accuracy:  0.921875\n",
      "Iteration:  1295  Loss:  0.43979648   Accuracy:  0.875\n",
      "Iteration:  1296  Loss:  0.48706186   Accuracy:  0.8984375\n",
      "Iteration:  1297  Loss:  0.6293489   Accuracy:  0.84375\n",
      "Iteration:  1298  Loss:  0.37237886   Accuracy:  0.890625\n",
      "Iteration:  1299  Loss:  0.7830333   Accuracy:  0.875\n",
      "Iteration:  1300  Loss:  0.8209195   Accuracy:  0.90625\n",
      "Iteration:  1301  Loss:  0.47719017   Accuracy:  0.8828125\n",
      "Iteration:  1302  Loss:  0.39459938   Accuracy:  0.8671875\n",
      "Iteration:  1303  Loss:  0.6797014   Accuracy:  0.828125\n",
      "Iteration:  1304  Loss:  0.49481824   Accuracy:  0.8828125\n",
      "Iteration:  1305  Loss:  0.74770725   Accuracy:  0.8515625\n",
      "Iteration:  1306  Loss:  0.5004974   Accuracy:  0.875\n",
      "Iteration:  1307  Loss:  0.41240555   Accuracy:  0.890625\n",
      "Iteration:  1308  Loss:  0.25973698   Accuracy:  0.921875\n",
      "Iteration:  1309  Loss:  0.6057706   Accuracy:  0.8984375\n",
      "Iteration:  1310  Loss:  0.64568967   Accuracy:  0.875\n",
      "Iteration:  1311  Loss:  0.3932809   Accuracy:  0.8828125\n",
      "Iteration:  1312  Loss:  0.44193822   Accuracy:  0.890625\n",
      "Iteration:  1313  Loss:  0.37110743   Accuracy:  0.8984375\n",
      "Iteration:  1314  Loss:  0.44858432   Accuracy:  0.8984375\n",
      "Iteration:  1315  Loss:  0.6224401   Accuracy:  0.90625\n",
      "Iteration:  1316  Loss:  0.2200773   Accuracy:  0.921875\n",
      "Iteration:  1317  Loss:  0.8714881   Accuracy:  0.84375\n",
      "Iteration:  1318  Loss:  0.4261558   Accuracy:  0.8828125\n",
      "Iteration:  1319  Loss:  0.41648203   Accuracy:  0.8984375\n",
      "Iteration:  1320  Loss:  0.51024604   Accuracy:  0.890625\n",
      "Iteration:  1321  Loss:  0.5468732   Accuracy:  0.828125\n",
      "Iteration:  1322  Loss:  0.42205524   Accuracy:  0.90625\n",
      "Iteration:  1323  Loss:  0.32241637   Accuracy:  0.921875\n",
      "Iteration:  1324  Loss:  0.33639926   Accuracy:  0.9140625\n",
      "Iteration:  1325  Loss:  0.7486836   Accuracy:  0.828125\n",
      "Iteration:  1326  Loss:  0.468396   Accuracy:  0.8828125\n",
      "Iteration:  1327  Loss:  0.42580718   Accuracy:  0.8984375\n",
      "Iteration:  1328  Loss:  0.4044448   Accuracy:  0.90625\n",
      "Iteration:  1329  Loss:  0.4006555   Accuracy:  0.875\n",
      "Iteration:  1330  Loss:  0.5001114   Accuracy:  0.8828125\n",
      "Iteration:  1331  Loss:  0.66505486   Accuracy:  0.84375\n",
      "Iteration:  1332  Loss:  0.5039041   Accuracy:  0.8828125\n",
      "Iteration:  1333  Loss:  0.46254537   Accuracy:  0.921875\n",
      "Iteration:  1334  Loss:  0.24287003   Accuracy:  0.8984375\n",
      "Iteration:  1335  Loss:  0.31538826   Accuracy:  0.9140625\n",
      "Iteration:  1336  Loss:  0.51125467   Accuracy:  0.875\n",
      "Iteration:  1337  Loss:  0.50132763   Accuracy:  0.859375\n",
      "Iteration:  1338  Loss:  0.5210947   Accuracy:  0.8515625\n",
      "Iteration:  1339  Loss:  0.7321787   Accuracy:  0.8359375\n",
      "Iteration:  1340  Loss:  0.31532484   Accuracy:  0.8828125\n",
      "Iteration:  1341  Loss:  0.48497555   Accuracy:  0.8828125\n",
      "Iteration:  1342  Loss:  0.5930561   Accuracy:  0.828125\n",
      "Iteration:  1343  Loss:  0.6746599   Accuracy:  0.875\n",
      "Iteration:  1344  Loss:  0.8760639   Accuracy:  0.859375\n",
      "Iteration:  1345  Loss:  0.24790512   Accuracy:  0.890625\n",
      "Iteration:  1346  Loss:  0.3259502   Accuracy:  0.8984375\n",
      "Iteration:  1347  Loss:  0.4371531   Accuracy:  0.890625\n",
      "Iteration:  1348  Loss:  0.45776147   Accuracy:  0.8828125\n",
      "Iteration:  1349  Loss:  0.32387847   Accuracy:  0.8828125\n",
      "Iteration:  1350  Loss:  0.6170428   Accuracy:  0.859375\n",
      "Iteration:  1351  Loss:  0.49291068   Accuracy:  0.890625\n",
      "Iteration:  1352  Loss:  0.34884328   Accuracy:  0.890625\n",
      "Iteration:  1353  Loss:  0.41140622   Accuracy:  0.8984375\n",
      "Iteration:  1354  Loss:  0.2869942   Accuracy:  0.9140625\n",
      "Iteration:  1355  Loss:  0.5407594   Accuracy:  0.8671875\n",
      "Iteration:  1356  Loss:  0.4517157   Accuracy:  0.8828125\n",
      "Iteration:  1357  Loss:  0.6790856   Accuracy:  0.8828125\n",
      "Iteration:  1358  Loss:  0.43692884   Accuracy:  0.875\n",
      "Iteration:  1359  Loss:  0.7994112   Accuracy:  0.8203125\n",
      "Iteration:  1360  Loss:  0.8857706   Accuracy:  0.859375\n",
      "Iteration:  1361  Loss:  0.5672794   Accuracy:  0.8359375\n",
      "Iteration:  1362  Loss:  0.1971355   Accuracy:  0.9453125\n",
      "Iteration:  1363  Loss:  0.4036622   Accuracy:  0.90625\n",
      "Iteration:  1364  Loss:  0.5115493   Accuracy:  0.8828125\n",
      "Iteration:  1365  Loss:  0.43394795   Accuracy:  0.9296875\n",
      "Iteration:  1366  Loss:  0.56125754   Accuracy:  0.8828125\n",
      "Iteration:  1367  Loss:  0.5471549   Accuracy:  0.8359375\n",
      "Iteration:  1368  Loss:  0.37412977   Accuracy:  0.9375\n",
      "Iteration:  1369  Loss:  0.4290178   Accuracy:  0.90625\n",
      "Iteration:  1370  Loss:  0.95593464   Accuracy:  0.7890625\n",
      "Iteration:  1371  Loss:  0.31419954   Accuracy:  0.8828125\n",
      "Iteration:  1372  Loss:  0.46992692   Accuracy:  0.8828125\n",
      "Iteration:  1373  Loss:  0.5362021   Accuracy:  0.875\n",
      "Iteration:  1374  Loss:  0.33178484   Accuracy:  0.90625\n",
      "Iteration:  1375  Loss:  0.4040928   Accuracy:  0.8828125\n",
      "Iteration:  1376  Loss:  0.37666774   Accuracy:  0.8984375\n",
      "Iteration:  1377  Loss:  0.46638888   Accuracy:  0.90625\n",
      "Iteration:  1378  Loss:  0.81773126   Accuracy:  0.859375\n",
      "Iteration:  1379  Loss:  0.56383616   Accuracy:  0.875\n",
      "Iteration:  1380  Loss:  0.35959277   Accuracy:  0.8984375\n",
      "Iteration:  1381  Loss:  0.48754656   Accuracy:  0.9140625\n",
      "Iteration:  1382  Loss:  0.55482507   Accuracy:  0.84375\n",
      "Iteration:  1383  Loss:  0.6693916   Accuracy:  0.875\n",
      "Iteration:  1384  Loss:  0.6064439   Accuracy:  0.8515625\n",
      "Iteration:  1385  Loss:  0.33584028   Accuracy:  0.8984375\n",
      "Iteration:  1386  Loss:  0.58821857   Accuracy:  0.875\n",
      "Iteration:  1387  Loss:  0.45909238   Accuracy:  0.890625\n",
      "Iteration:  1388  Loss:  0.4367463   Accuracy:  0.8828125\n",
      "Iteration:  1389  Loss:  0.5256944   Accuracy:  0.8984375\n",
      "Iteration:  1390  Loss:  0.7061529   Accuracy:  0.8671875\n",
      "Iteration:  1391  Loss:  0.35766906   Accuracy:  0.8671875\n",
      "Iteration:  1392  Loss:  0.29385138   Accuracy:  0.8984375\n",
      "Iteration:  1393  Loss:  0.39798057   Accuracy:  0.8828125\n",
      "Iteration:  1394  Loss:  0.43000022   Accuracy:  0.8984375\n",
      "Iteration:  1395  Loss:  0.6685146   Accuracy:  0.875\n",
      "Iteration:  1396  Loss:  0.5528204   Accuracy:  0.796875\n",
      "Iteration:  1397  Loss:  0.4761396   Accuracy:  0.875\n",
      "Iteration:  1398  Loss:  0.3093139   Accuracy:  0.9140625\n",
      "Iteration:  1399  Loss:  0.40083992   Accuracy:  0.890625\n",
      "Iteration:  1400  Loss:  0.48635423   Accuracy:  0.859375\n",
      "Iteration:  1401  Loss:  0.4687099   Accuracy:  0.859375\n",
      "Iteration:  1402  Loss:  0.74720585   Accuracy:  0.8515625\n",
      "Iteration:  1403  Loss:  0.4278301   Accuracy:  0.90625\n",
      "Iteration:  1404  Loss:  0.46044913   Accuracy:  0.84375\n",
      "Iteration:  1405  Loss:  0.5710167   Accuracy:  0.8671875\n",
      "Iteration:  1406  Loss:  0.33179182   Accuracy:  0.9140625\n",
      "Iteration:  1407  Loss:  0.37118995   Accuracy:  0.90625\n",
      "Iteration:  1408  Loss:  0.39716238   Accuracy:  0.8828125\n",
      "Iteration:  1409  Loss:  0.2725994   Accuracy:  0.9140625\n",
      "Iteration:  1410  Loss:  0.54347265   Accuracy:  0.875\n",
      "Iteration:  1411  Loss:  0.40264344   Accuracy:  0.9140625\n",
      "Iteration:  1412  Loss:  0.50763917   Accuracy:  0.8984375\n",
      "Iteration:  1413  Loss:  0.34364343   Accuracy:  0.921875\n",
      "Iteration:  1414  Loss:  0.4162153   Accuracy:  0.859375\n",
      "Iteration:  1415  Loss:  0.56256425   Accuracy:  0.8984375\n",
      "Iteration:  1416  Loss:  0.38878173   Accuracy:  0.921875\n",
      "Iteration:  1417  Loss:  0.65595925   Accuracy:  0.875\n",
      "Iteration:  1418  Loss:  0.45957655   Accuracy:  0.9140625\n",
      "Iteration:  1419  Loss:  0.6408855   Accuracy:  0.828125\n",
      "Iteration:  1420  Loss:  0.43837798   Accuracy:  0.8984375\n",
      "Iteration:  1421  Loss:  0.2548134   Accuracy:  0.90625\n",
      "Iteration:  1422  Loss:  0.41627604   Accuracy:  0.8828125\n",
      "Iteration:  1423  Loss:  0.4782952   Accuracy:  0.890625\n",
      "Iteration:  1424  Loss:  0.32091656   Accuracy:  0.9140625\n",
      "Iteration:  1425  Loss:  0.5927663   Accuracy:  0.8671875\n",
      "Iteration:  1426  Loss:  0.61762387   Accuracy:  0.8671875\n",
      "Iteration:  1427  Loss:  0.6704198   Accuracy:  0.8359375\n",
      "Iteration:  1428  Loss:  0.69292533   Accuracy:  0.8359375\n",
      "Iteration:  1429  Loss:  0.38738984   Accuracy:  0.8984375\n",
      "Iteration:  1430  Loss:  0.33739042   Accuracy:  0.921875\n",
      "Iteration:  1431  Loss:  0.46590704   Accuracy:  0.859375\n",
      "Iteration:  1432  Loss:  0.66598403   Accuracy:  0.8984375\n",
      "Iteration:  1433  Loss:  0.5676782   Accuracy:  0.8828125\n",
      "Iteration:  1434  Loss:  0.39125746   Accuracy:  0.890625\n",
      "Iteration:  1435  Loss:  0.6175903   Accuracy:  0.8359375\n",
      "Iteration:  1436  Loss:  0.6430521   Accuracy:  0.8671875\n",
      "Iteration:  1437  Loss:  0.40748557   Accuracy:  0.859375\n",
      "Iteration:  1438  Loss:  0.41444185   Accuracy:  0.8828125\n",
      "Iteration:  1439  Loss:  0.44595844   Accuracy:  0.8828125\n",
      "Iteration:  1440  Loss:  0.92822474   Accuracy:  0.84375\n",
      "Iteration:  1441  Loss:  0.7300954   Accuracy:  0.8515625\n",
      "Iteration:  1442  Loss:  0.3715436   Accuracy:  0.8671875\n",
      "Iteration:  1443  Loss:  0.6103889   Accuracy:  0.859375\n",
      "Iteration:  1444  Loss:  0.30793577   Accuracy:  0.9296875\n",
      "Iteration:  1445  Loss:  0.3876342   Accuracy:  0.875\n",
      "Iteration:  1446  Loss:  0.53330106   Accuracy:  0.875\n",
      "Iteration:  1447  Loss:  0.42084613   Accuracy:  0.890625\n",
      "Iteration:  1448  Loss:  0.3672837   Accuracy:  0.9140625\n",
      "Iteration:  1449  Loss:  0.37530798   Accuracy:  0.8828125\n",
      "Iteration:  1450  Loss:  0.6798618   Accuracy:  0.8671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1451  Loss:  0.4655588   Accuracy:  0.8984375\n",
      "Iteration:  1452  Loss:  0.5818032   Accuracy:  0.875\n",
      "Iteration:  1453  Loss:  0.41389692   Accuracy:  0.890625\n",
      "Iteration:  1454  Loss:  0.48605025   Accuracy:  0.8984375\n",
      "Iteration:  1455  Loss:  0.30518356   Accuracy:  0.8984375\n",
      "Iteration:  1456  Loss:  0.34255263   Accuracy:  0.8984375\n",
      "Iteration:  1457  Loss:  0.55939835   Accuracy:  0.8671875\n",
      "Iteration:  1458  Loss:  0.48046413   Accuracy:  0.8828125\n",
      "Iteration:  1459  Loss:  0.3623839   Accuracy:  0.9140625\n",
      "Iteration:  1460  Loss:  0.38708028   Accuracy:  0.875\n",
      "Iteration:  1461  Loss:  0.41555446   Accuracy:  0.8984375\n",
      "Iteration:  1462  Loss:  0.50232184   Accuracy:  0.8828125\n",
      "Iteration:  1463  Loss:  0.7679435   Accuracy:  0.8515625\n",
      "Iteration:  1464  Loss:  0.4475725   Accuracy:  0.8671875\n",
      "Iteration:  1465  Loss:  0.48954993   Accuracy:  0.875\n",
      "Iteration:  1466  Loss:  0.6749789   Accuracy:  0.875\n",
      "Iteration:  1467  Loss:  0.43110877   Accuracy:  0.90625\n",
      "Iteration:  1468  Loss:  0.5963317   Accuracy:  0.890625\n",
      "Iteration:  1469  Loss:  0.41942793   Accuracy:  0.8515625\n",
      "Iteration:  1470  Loss:  0.56571287   Accuracy:  0.8984375\n",
      "Iteration:  1471  Loss:  0.31996143   Accuracy:  0.859375\n",
      "Iteration:  1472  Loss:  0.42489973   Accuracy:  0.875\n",
      "Iteration:  1473  Loss:  0.4787997   Accuracy:  0.9140625\n",
      "Iteration:  1474  Loss:  0.46439636   Accuracy:  0.890625\n",
      "Iteration:  1475  Loss:  0.4963429   Accuracy:  0.8671875\n",
      "Iteration:  1476  Loss:  0.28360355   Accuracy:  0.8984375\n",
      "Iteration:  1477  Loss:  0.43260488   Accuracy:  0.8671875\n",
      "Iteration:  1478  Loss:  0.885931   Accuracy:  0.8828125\n",
      "Iteration:  1479  Loss:  0.5101135   Accuracy:  0.90625\n",
      "Iteration:  1480  Loss:  0.76047   Accuracy:  0.8125\n",
      "Iteration:  1481  Loss:  0.653256   Accuracy:  0.8828125\n",
      "Iteration:  1482  Loss:  0.3487432   Accuracy:  0.8984375\n",
      "Iteration:  1483  Loss:  0.49516526   Accuracy:  0.875\n",
      "Iteration:  1484  Loss:  0.53298736   Accuracy:  0.8671875\n",
      "Iteration:  1485  Loss:  0.5061337   Accuracy:  0.8828125\n",
      "Iteration:  1486  Loss:  0.7239126   Accuracy:  0.8828125\n",
      "Iteration:  1487  Loss:  0.61419785   Accuracy:  0.890625\n",
      "Iteration:  1488  Loss:  0.5505395   Accuracy:  0.90625\n",
      "Iteration:  1489  Loss:  0.41721296   Accuracy:  0.9140625\n",
      "Iteration:  1490  Loss:  0.34291777   Accuracy:  0.8984375\n",
      "Iteration:  1491  Loss:  0.52136624   Accuracy:  0.8671875\n",
      "Iteration:  1492  Loss:  0.44314018   Accuracy:  0.8515625\n",
      "Iteration:  1493  Loss:  0.38381308   Accuracy:  0.890625\n",
      "Iteration:  1494  Loss:  0.44142014   Accuracy:  0.875\n",
      "Iteration:  1495  Loss:  0.53963727   Accuracy:  0.859375\n",
      "Iteration:  1496  Loss:  0.6443876   Accuracy:  0.8984375\n",
      "Iteration:  1497  Loss:  0.3615289   Accuracy:  0.8984375\n",
      "Iteration:  1498  Loss:  0.34436586   Accuracy:  0.90625\n",
      "Iteration:  1499  Loss:  0.30773017   Accuracy:  0.90625\n",
      "Iteration:  1500  Loss:  0.32376578   Accuracy:  0.8828125\n",
      "Iteration:  1501  Loss:  0.5170665   Accuracy:  0.875\n",
      "Iteration:  1502  Loss:  0.27613834   Accuracy:  0.921875\n",
      "Iteration:  1503  Loss:  0.39892653   Accuracy:  0.8984375\n",
      "Iteration:  1504  Loss:  0.52257085   Accuracy:  0.90625\n",
      "Iteration:  1505  Loss:  0.624604   Accuracy:  0.84375\n",
      "Iteration:  1506  Loss:  0.78691816   Accuracy:  0.8828125\n",
      "Iteration:  1507  Loss:  0.26920155   Accuracy:  0.9375\n",
      "Iteration:  1508  Loss:  0.475302   Accuracy:  0.8828125\n",
      "Iteration:  1509  Loss:  0.37840748   Accuracy:  0.8828125\n",
      "Iteration:  1510  Loss:  0.5725219   Accuracy:  0.8671875\n",
      "Iteration:  1511  Loss:  0.483235   Accuracy:  0.890625\n",
      "Iteration:  1512  Loss:  0.5919834   Accuracy:  0.8984375\n",
      "Iteration:  1513  Loss:  0.7311571   Accuracy:  0.828125\n",
      "Iteration:  1514  Loss:  0.43295833   Accuracy:  0.8828125\n",
      "Iteration:  1515  Loss:  0.438255   Accuracy:  0.890625\n",
      "Iteration:  1516  Loss:  0.43884057   Accuracy:  0.875\n",
      "Iteration:  1517  Loss:  0.5863471   Accuracy:  0.8203125\n",
      "Iteration:  1518  Loss:  0.6364149   Accuracy:  0.828125\n",
      "Iteration:  1519  Loss:  0.19146466   Accuracy:  0.921875\n",
      "Iteration:  1520  Loss:  0.34198743   Accuracy:  0.9140625\n",
      "Iteration:  1521  Loss:  0.3893659   Accuracy:  0.8671875\n",
      "Iteration:  1522  Loss:  0.71650815   Accuracy:  0.8515625\n",
      "Iteration:  1523  Loss:  0.5392262   Accuracy:  0.890625\n",
      "Iteration:  1524  Loss:  0.48778808   Accuracy:  0.9140625\n",
      "Iteration:  1525  Loss:  0.5443185   Accuracy:  0.8671875\n",
      "Iteration:  1526  Loss:  0.35952026   Accuracy:  0.8828125\n",
      "Iteration:  1527  Loss:  0.47541037   Accuracy:  0.890625\n",
      "Iteration:  1528  Loss:  0.37668723   Accuracy:  0.90625\n",
      "Iteration:  1529  Loss:  0.53550124   Accuracy:  0.875\n",
      "Iteration:  1530  Loss:  0.54949826   Accuracy:  0.859375\n",
      "Iteration:  1531  Loss:  0.49199954   Accuracy:  0.90625\n",
      "Iteration:  1532  Loss:  0.48290002   Accuracy:  0.90625\n",
      "Iteration:  1533  Loss:  0.3454714   Accuracy:  0.9140625\n",
      "Iteration:  1534  Loss:  0.28209728   Accuracy:  0.9453125\n",
      "Iteration:  1535  Loss:  0.5324295   Accuracy:  0.8984375\n",
      "Iteration:  1536  Loss:  0.49673724   Accuracy:  0.890625\n",
      "Iteration:  1537  Loss:  0.47405177   Accuracy:  0.859375\n",
      "Iteration:  1538  Loss:  0.6255064   Accuracy:  0.84375\n",
      "Iteration:  1539  Loss:  0.32512617   Accuracy:  0.890625\n",
      "Iteration:  1540  Loss:  0.7181748   Accuracy:  0.8203125\n",
      "Iteration:  1541  Loss:  0.57258373   Accuracy:  0.8828125\n",
      "Iteration:  1542  Loss:  0.61684567   Accuracy:  0.8671875\n",
      "Iteration:  1543  Loss:  0.43664518   Accuracy:  0.890625\n",
      "Iteration:  1544  Loss:  0.8042904   Accuracy:  0.8828125\n",
      "Iteration:  1545  Loss:  0.5381406   Accuracy:  0.8671875\n",
      "Iteration:  1546  Loss:  0.4845453   Accuracy:  0.90625\n",
      "Iteration:  1547  Loss:  0.37426555   Accuracy:  0.9140625\n",
      "Iteration:  1548  Loss:  0.32465136   Accuracy:  0.90625\n",
      "Iteration:  1549  Loss:  0.11752804   Accuracy:  0.953125\n",
      "Iteration:  1550  Loss:  0.45621848   Accuracy:  0.90625\n",
      "Iteration:  1551  Loss:  0.50853384   Accuracy:  0.8828125\n",
      "Iteration:  1552  Loss:  0.47750425   Accuracy:  0.8984375\n",
      "Iteration:  1553  Loss:  0.36836484   Accuracy:  0.890625\n",
      "Iteration:  1554  Loss:  0.584715   Accuracy:  0.8671875\n",
      "Iteration:  1555  Loss:  0.46724686   Accuracy:  0.890625\n",
      "Iteration:  1556  Loss:  0.73059744   Accuracy:  0.8984375\n",
      "Iteration:  1557  Loss:  0.42174146   Accuracy:  0.8671875\n",
      "Iteration:  1558  Loss:  0.3936497   Accuracy:  0.90625\n",
      "Iteration:  1559  Loss:  0.47513765   Accuracy:  0.8515625\n",
      "Iteration:  1560  Loss:  0.5892763   Accuracy:  0.890625\n",
      "Iteration:  1561  Loss:  0.53998643   Accuracy:  0.84375\n",
      "Iteration:  1562  Loss:  0.5755039   Accuracy:  0.859375\n",
      "Iteration:  1563  Loss:  0.72458684   Accuracy:  0.8359375\n",
      "Iteration:  1564  Loss:  0.4533032   Accuracy:  0.890625\n",
      "Iteration:  1565  Loss:  0.5167495   Accuracy:  0.90625\n",
      "Iteration:  1566  Loss:  0.4500236   Accuracy:  0.890625\n",
      "Iteration:  1567  Loss:  0.38779306   Accuracy:  0.8671875\n",
      "Iteration:  1568  Loss:  0.6476697   Accuracy:  0.8671875\n",
      "Iteration:  1569  Loss:  0.70450646   Accuracy:  0.8671875\n",
      "Iteration:  1570  Loss:  0.5463562   Accuracy:  0.875\n",
      "Iteration:  1571  Loss:  0.44304678   Accuracy:  0.875\n",
      "Iteration:  1572  Loss:  0.6342364   Accuracy:  0.8671875\n",
      "Iteration:  1573  Loss:  0.47554815   Accuracy:  0.9140625\n",
      "Iteration:  1574  Loss:  0.35023165   Accuracy:  0.9140625\n",
      "Iteration:  1575  Loss:  0.31228977   Accuracy:  0.875\n",
      "Iteration:  1576  Loss:  0.69005626   Accuracy:  0.8671875\n",
      "Iteration:  1577  Loss:  0.6843619   Accuracy:  0.875\n",
      "Iteration:  1578  Loss:  0.38247955   Accuracy:  0.9296875\n",
      "Iteration:  1579  Loss:  0.37411815   Accuracy:  0.9296875\n",
      "Iteration:  1580  Loss:  0.47569495   Accuracy:  0.8984375\n",
      "Iteration:  1581  Loss:  0.61382794   Accuracy:  0.8515625\n",
      "Iteration:  1582  Loss:  0.46749884   Accuracy:  0.8984375\n",
      "Iteration:  1583  Loss:  0.42236358   Accuracy:  0.8984375\n",
      "Iteration:  1584  Loss:  0.31639865   Accuracy:  0.8984375\n",
      "Iteration:  1585  Loss:  0.5180225   Accuracy:  0.8828125\n",
      "Iteration:  1586  Loss:  0.6272835   Accuracy:  0.875\n",
      "Iteration:  1587  Loss:  0.4177669   Accuracy:  0.9140625\n",
      "Iteration:  1588  Loss:  0.40315858   Accuracy:  0.875\n",
      "Iteration:  1589  Loss:  0.73150826   Accuracy:  0.8671875\n",
      "Iteration:  1590  Loss:  0.3265286   Accuracy:  0.8984375\n",
      "Iteration:  1591  Loss:  0.53526926   Accuracy:  0.8671875\n",
      "Iteration:  1592  Loss:  0.39189696   Accuracy:  0.9296875\n",
      "Iteration:  1593  Loss:  0.33198595   Accuracy:  0.9296875\n",
      "Iteration:  1594  Loss:  0.4202606   Accuracy:  0.875\n",
      "Iteration:  1595  Loss:  0.39310026   Accuracy:  0.859375\n",
      "Iteration:  1596  Loss:  0.5689075   Accuracy:  0.8671875\n",
      "Iteration:  1597  Loss:  0.43855712   Accuracy:  0.8984375\n",
      "Iteration:  1598  Loss:  0.6410116   Accuracy:  0.8671875\n",
      "Iteration:  1599  Loss:  0.51038337   Accuracy:  0.8828125\n",
      "Iteration:  1600  Loss:  0.48697472   Accuracy:  0.875\n",
      "Iteration:  1601  Loss:  0.48758426   Accuracy:  0.8828125\n",
      "Iteration:  1602  Loss:  0.46966466   Accuracy:  0.8671875\n",
      "Iteration:  1603  Loss:  0.3212035   Accuracy:  0.9140625\n",
      "Iteration:  1604  Loss:  0.5354594   Accuracy:  0.8828125\n",
      "Iteration:  1605  Loss:  0.59223413   Accuracy:  0.90625\n",
      "Iteration:  1606  Loss:  0.274915   Accuracy:  0.953125\n",
      "Iteration:  1607  Loss:  0.643764   Accuracy:  0.7890625\n",
      "Iteration:  1608  Loss:  0.6131181   Accuracy:  0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1609  Loss:  0.64337987   Accuracy:  0.8515625\n",
      "Iteration:  1610  Loss:  0.54607695   Accuracy:  0.8671875\n",
      "Iteration:  1611  Loss:  0.5588715   Accuracy:  0.8828125\n",
      "Iteration:  1612  Loss:  0.66115487   Accuracy:  0.875\n",
      "Iteration:  1613  Loss:  0.6828493   Accuracy:  0.859375\n",
      "Iteration:  1614  Loss:  0.46688002   Accuracy:  0.84375\n",
      "Iteration:  1615  Loss:  0.50711983   Accuracy:  0.8515625\n",
      "Iteration:  1616  Loss:  0.4035735   Accuracy:  0.9296875\n",
      "Iteration:  1617  Loss:  0.45393836   Accuracy:  0.875\n",
      "Iteration:  1618  Loss:  0.3702327   Accuracy:  0.9140625\n",
      "Iteration:  1619  Loss:  0.4506605   Accuracy:  0.90625\n",
      "Iteration:  1620  Loss:  0.36946982   Accuracy:  0.921875\n",
      "Iteration:  1621  Loss:  0.50086284   Accuracy:  0.859375\n",
      "Iteration:  1622  Loss:  0.34234813   Accuracy:  0.921875\n",
      "Iteration:  1623  Loss:  0.5778334   Accuracy:  0.84375\n",
      "Iteration:  1624  Loss:  0.4153063   Accuracy:  0.8984375\n",
      "Iteration:  1625  Loss:  0.2822876   Accuracy:  0.90625\n",
      "Iteration:  1626  Loss:  0.299107   Accuracy:  0.90625\n",
      "Iteration:  1627  Loss:  0.34264904   Accuracy:  0.8515625\n",
      "Iteration:  1628  Loss:  0.17229989   Accuracy:  0.9375\n",
      "Iteration:  1629  Loss:  0.28815138   Accuracy:  0.9453125\n",
      "Iteration:  1630  Loss:  0.42014822   Accuracy:  0.875\n",
      "Iteration:  1631  Loss:  0.4425426   Accuracy:  0.8984375\n",
      "Iteration:  1632  Loss:  0.31710473   Accuracy:  0.90625\n",
      "Iteration:  1633  Loss:  0.381693   Accuracy:  0.8984375\n",
      "Iteration:  1634  Loss:  0.36669236   Accuracy:  0.8828125\n",
      "Iteration:  1635  Loss:  0.48872414   Accuracy:  0.8984375\n",
      "Iteration:  1636  Loss:  0.47820848   Accuracy:  0.875\n",
      "Iteration:  1637  Loss:  0.44057754   Accuracy:  0.8828125\n",
      "Iteration:  1638  Loss:  0.25172806   Accuracy:  0.921875\n",
      "Iteration:  1639  Loss:  0.47252268   Accuracy:  0.875\n",
      "Iteration:  1640  Loss:  0.49546364   Accuracy:  0.90625\n",
      "Iteration:  1641  Loss:  0.37276617   Accuracy:  0.8984375\n",
      "Iteration:  1642  Loss:  0.77754   Accuracy:  0.8515625\n",
      "Iteration:  1643  Loss:  0.5871983   Accuracy:  0.8515625\n",
      "Iteration:  1644  Loss:  0.66124004   Accuracy:  0.859375\n",
      "Iteration:  1645  Loss:  0.6541305   Accuracy:  0.859375\n",
      "Iteration:  1646  Loss:  0.4225864   Accuracy:  0.890625\n",
      "Iteration:  1647  Loss:  0.53178203   Accuracy:  0.8515625\n",
      "Iteration:  1648  Loss:  0.3036731   Accuracy:  0.890625\n",
      "Iteration:  1649  Loss:  0.22296122   Accuracy:  0.9296875\n",
      "Iteration:  1650  Loss:  0.57087165   Accuracy:  0.8515625\n",
      "Iteration:  1651  Loss:  0.1510353   Accuracy:  0.9296875\n",
      "Iteration:  1652  Loss:  0.39155775   Accuracy:  0.9296875\n",
      "Iteration:  1653  Loss:  0.61228704   Accuracy:  0.8828125\n",
      "Iteration:  1654  Loss:  0.7086891   Accuracy:  0.8515625\n",
      "Iteration:  1655  Loss:  0.27064735   Accuracy:  0.9296875\n",
      "Iteration:  1656  Loss:  0.6749598   Accuracy:  0.8515625\n",
      "Iteration:  1657  Loss:  0.48669952   Accuracy:  0.8828125\n",
      "Iteration:  1658  Loss:  0.45814508   Accuracy:  0.8828125\n",
      "Iteration:  1659  Loss:  0.3630727   Accuracy:  0.8828125\n",
      "Iteration:  1660  Loss:  0.6044793   Accuracy:  0.890625\n",
      "Iteration:  1661  Loss:  0.3780734   Accuracy:  0.8984375\n",
      "Iteration:  1662  Loss:  0.35408482   Accuracy:  0.8984375\n",
      "Iteration:  1663  Loss:  0.64230394   Accuracy:  0.90625\n",
      "Iteration:  1664  Loss:  0.39873648   Accuracy:  0.90625\n",
      "Iteration:  1665  Loss:  0.24973854   Accuracy:  0.921875\n",
      "Iteration:  1666  Loss:  0.46607473   Accuracy:  0.8984375\n",
      "Iteration:  1667  Loss:  0.6982304   Accuracy:  0.8671875\n",
      "Iteration:  1668  Loss:  0.8993081   Accuracy:  0.890625\n",
      "Iteration:  1669  Loss:  0.4032495   Accuracy:  0.859375\n",
      "Iteration:  1670  Loss:  0.5458794   Accuracy:  0.875\n",
      "Iteration:  1671  Loss:  0.48254406   Accuracy:  0.84375\n",
      "Iteration:  1672  Loss:  0.5842357   Accuracy:  0.8671875\n",
      "Iteration:  1673  Loss:  0.5862157   Accuracy:  0.859375\n",
      "Iteration:  1674  Loss:  0.29750162   Accuracy:  0.9140625\n",
      "Iteration:  1675  Loss:  0.42649525   Accuracy:  0.90625\n",
      "Iteration:  1676  Loss:  0.7481099   Accuracy:  0.890625\n",
      "Iteration:  1677  Loss:  0.61772084   Accuracy:  0.859375\n",
      "Iteration:  1678  Loss:  0.5323256   Accuracy:  0.875\n",
      "Iteration:  1679  Loss:  0.44206142   Accuracy:  0.8984375\n",
      "Iteration:  1680  Loss:  0.49640262   Accuracy:  0.890625\n",
      "Iteration:  1681  Loss:  0.51642895   Accuracy:  0.8359375\n",
      "Iteration:  1682  Loss:  0.8344615   Accuracy:  0.875\n",
      "Iteration:  1683  Loss:  0.61269224   Accuracy:  0.890625\n",
      "Iteration:  1684  Loss:  0.3188188   Accuracy:  0.8984375\n",
      "Iteration:  1685  Loss:  0.51300067   Accuracy:  0.8984375\n",
      "Iteration:  1686  Loss:  0.44428307   Accuracy:  0.875\n",
      "Iteration:  1687  Loss:  0.5431965   Accuracy:  0.8515625\n",
      "Iteration:  1688  Loss:  0.38669625   Accuracy:  0.890625\n",
      "Iteration:  1689  Loss:  0.30233172   Accuracy:  0.90625\n",
      "Iteration:  1690  Loss:  0.666961   Accuracy:  0.8671875\n",
      "Iteration:  1691  Loss:  0.54066247   Accuracy:  0.84375\n",
      "Iteration:  1692  Loss:  0.5918409   Accuracy:  0.859375\n",
      "Iteration:  1693  Loss:  0.55064636   Accuracy:  0.875\n",
      "Iteration:  1694  Loss:  0.4185316   Accuracy:  0.8984375\n",
      "Iteration:  1695  Loss:  0.43534583   Accuracy:  0.890625\n",
      "Iteration:  1696  Loss:  0.28887954   Accuracy:  0.9140625\n",
      "Iteration:  1697  Loss:  0.4666601   Accuracy:  0.90625\n",
      "Iteration:  1698  Loss:  0.7990743   Accuracy:  0.84375\n",
      "Iteration:  1699  Loss:  0.5051575   Accuracy:  0.859375\n",
      "Iteration:  1700  Loss:  0.20551625   Accuracy:  0.9140625\n",
      "Iteration:  1701  Loss:  0.49543712   Accuracy:  0.9296875\n",
      "Iteration:  1702  Loss:  0.5408055   Accuracy:  0.8515625\n",
      "Iteration:  1703  Loss:  0.6548274   Accuracy:  0.8671875\n",
      "Iteration:  1704  Loss:  0.45579004   Accuracy:  0.8828125\n",
      "Iteration:  1705  Loss:  0.48434556   Accuracy:  0.859375\n",
      "Iteration:  1706  Loss:  0.39171046   Accuracy:  0.8984375\n",
      "Iteration:  1707  Loss:  0.28680122   Accuracy:  0.921875\n",
      "Iteration:  1708  Loss:  0.4800841   Accuracy:  0.875\n",
      "Iteration:  1709  Loss:  0.46427792   Accuracy:  0.8984375\n",
      "Iteration:  1710  Loss:  0.3762778   Accuracy:  0.8828125\n",
      "Iteration:  1711  Loss:  0.33798757   Accuracy:  0.890625\n",
      "Iteration:  1712  Loss:  0.26328087   Accuracy:  0.9140625\n",
      "Iteration:  1713  Loss:  0.49779418   Accuracy:  0.90625\n",
      "Iteration:  1714  Loss:  0.5687459   Accuracy:  0.84375\n",
      "Iteration:  1715  Loss:  0.28047007   Accuracy:  0.921875\n",
      "Iteration:  1716  Loss:  0.53281265   Accuracy:  0.8984375\n",
      "Iteration:  1717  Loss:  0.4594615   Accuracy:  0.875\n",
      "Iteration:  1718  Loss:  0.6932255   Accuracy:  0.859375\n",
      "Iteration:  1719  Loss:  0.42867595   Accuracy:  0.84375\n",
      "Iteration:  1720  Loss:  0.52899474   Accuracy:  0.8671875\n",
      "Iteration:  1721  Loss:  0.33894768   Accuracy:  0.9375\n",
      "Iteration:  1722  Loss:  0.3047788   Accuracy:  0.9140625\n",
      "Iteration:  1723  Loss:  0.27545246   Accuracy:  0.9296875\n",
      "Iteration:  1724  Loss:  0.487003   Accuracy:  0.875\n",
      "Iteration:  1725  Loss:  0.3822614   Accuracy:  0.8828125\n",
      "Iteration:  1726  Loss:  0.24179742   Accuracy:  0.921875\n",
      "Iteration:  1727  Loss:  0.4244546   Accuracy:  0.8984375\n",
      "Iteration:  1728  Loss:  0.72264606   Accuracy:  0.8984375\n",
      "Iteration:  1729  Loss:  0.70035774   Accuracy:  0.875\n",
      "Iteration:  1730  Loss:  0.632491   Accuracy:  0.8515625\n",
      "Iteration:  1731  Loss:  0.6202499   Accuracy:  0.8359375\n",
      "Iteration:  1732  Loss:  0.3504962   Accuracy:  0.9375\n",
      "Iteration:  1733  Loss:  0.55757904   Accuracy:  0.890625\n",
      "Iteration:  1734  Loss:  0.34695542   Accuracy:  0.9296875\n",
      "Iteration:  1735  Loss:  0.40855074   Accuracy:  0.9140625\n",
      "Iteration:  1736  Loss:  0.39367405   Accuracy:  0.875\n",
      "Iteration:  1737  Loss:  0.25898468   Accuracy:  0.90625\n",
      "Iteration:  1738  Loss:  0.4363609   Accuracy:  0.875\n",
      "Iteration:  1739  Loss:  0.49453503   Accuracy:  0.8515625\n",
      "Iteration:  1740  Loss:  0.4434077   Accuracy:  0.8828125\n",
      "Iteration:  1741  Loss:  0.5845064   Accuracy:  0.8671875\n",
      "Iteration:  1742  Loss:  0.51238304   Accuracy:  0.8984375\n",
      "Iteration:  1743  Loss:  0.50270987   Accuracy:  0.8828125\n",
      "Iteration:  1744  Loss:  0.33346704   Accuracy:  0.9140625\n",
      "Iteration:  1745  Loss:  0.22607763   Accuracy:  0.9375\n",
      "Iteration:  1746  Loss:  0.38477367   Accuracy:  0.90625\n",
      "Iteration:  1747  Loss:  0.5137014   Accuracy:  0.875\n",
      "Iteration:  1748  Loss:  0.67528796   Accuracy:  0.8203125\n",
      "Iteration:  1749  Loss:  0.4728158   Accuracy:  0.8359375\n",
      "Iteration:  1750  Loss:  0.27937397   Accuracy:  0.890625\n",
      "Iteration:  1751  Loss:  0.5273438   Accuracy:  0.890625\n",
      "Iteration:  1752  Loss:  0.64760244   Accuracy:  0.8359375\n",
      "Iteration:  1753  Loss:  0.46541154   Accuracy:  0.8984375\n",
      "Iteration:  1754  Loss:  0.9589898   Accuracy:  0.7890625\n",
      "Iteration:  1755  Loss:  0.5030664   Accuracy:  0.859375\n",
      "Iteration:  1756  Loss:  0.30422395   Accuracy:  0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1757  Loss:  0.5704422   Accuracy:  0.875\n",
      "Iteration:  1758  Loss:  0.46980152   Accuracy:  0.9140625\n",
      "Iteration:  1759  Loss:  0.6097225   Accuracy:  0.8515625\n",
      "Iteration:  1760  Loss:  0.26422876   Accuracy:  0.8984375\n",
      "Iteration:  1761  Loss:  0.5601748   Accuracy:  0.84375\n",
      "Iteration:  1762  Loss:  0.32890278   Accuracy:  0.9140625\n",
      "Iteration:  1763  Loss:  0.2827943   Accuracy:  0.953125\n",
      "Iteration:  1764  Loss:  0.7055159   Accuracy:  0.8671875\n",
      "Iteration:  1765  Loss:  0.2845555   Accuracy:  0.9296875\n",
      "Iteration:  1766  Loss:  0.40235573   Accuracy:  0.890625\n",
      "Iteration:  1767  Loss:  0.6142528   Accuracy:  0.859375\n",
      "Iteration:  1768  Loss:  0.36894208   Accuracy:  0.8828125\n",
      "Iteration:  1769  Loss:  0.23993778   Accuracy:  0.9296875\n",
      "Iteration:  1770  Loss:  0.593749   Accuracy:  0.875\n",
      "Iteration:  1771  Loss:  0.5712411   Accuracy:  0.8828125\n",
      "Iteration:  1772  Loss:  0.6031114   Accuracy:  0.875\n",
      "Iteration:  1773  Loss:  0.4157343   Accuracy:  0.90625\n",
      "Iteration:  1774  Loss:  0.45208094   Accuracy:  0.9140625\n",
      "Iteration:  1775  Loss:  0.52581066   Accuracy:  0.8671875\n",
      "Iteration:  1776  Loss:  0.2649062   Accuracy:  0.921875\n",
      "Iteration:  1777  Loss:  0.3442574   Accuracy:  0.890625\n",
      "Iteration:  1778  Loss:  0.5016978   Accuracy:  0.8125\n",
      "Iteration:  1779  Loss:  0.4950968   Accuracy:  0.859375\n",
      "Iteration:  1780  Loss:  0.5994814   Accuracy:  0.875\n",
      "Iteration:  1781  Loss:  0.41808742   Accuracy:  0.921875\n",
      "Iteration:  1782  Loss:  0.3444926   Accuracy:  0.890625\n",
      "Iteration:  1783  Loss:  0.6916595   Accuracy:  0.8828125\n",
      "Iteration:  1784  Loss:  0.34647477   Accuracy:  0.875\n",
      "Iteration:  1785  Loss:  0.37642637   Accuracy:  0.9140625\n",
      "Iteration:  1786  Loss:  0.17588216   Accuracy:  0.9453125\n",
      "Iteration:  1787  Loss:  0.4970935   Accuracy:  0.9140625\n",
      "Iteration:  1788  Loss:  0.49005085   Accuracy:  0.8984375\n",
      "Iteration:  1789  Loss:  0.39716715   Accuracy:  0.8671875\n",
      "Iteration:  1790  Loss:  0.34282494   Accuracy:  0.8984375\n",
      "Iteration:  1791  Loss:  0.30464083   Accuracy:  0.90625\n",
      "Iteration:  1792  Loss:  0.5103864   Accuracy:  0.890625\n",
      "Iteration:  1793  Loss:  0.7230459   Accuracy:  0.8828125\n",
      "Iteration:  1794  Loss:  0.60788566   Accuracy:  0.859375\n",
      "Iteration:  1795  Loss:  0.3489837   Accuracy:  0.90625\n",
      "Iteration:  1796  Loss:  0.33908772   Accuracy:  0.8984375\n",
      "Iteration:  1797  Loss:  0.6383499   Accuracy:  0.8671875\n",
      "Iteration:  1798  Loss:  0.45606637   Accuracy:  0.8828125\n",
      "Iteration:  1799  Loss:  0.65476024   Accuracy:  0.890625\n",
      "Iteration:  1800  Loss:  0.33422902   Accuracy:  0.921875\n",
      "Iteration:  1801  Loss:  0.5093049   Accuracy:  0.875\n",
      "Iteration:  1802  Loss:  0.3386334   Accuracy:  0.9375\n",
      "Iteration:  1803  Loss:  0.4688408   Accuracy:  0.890625\n",
      "Iteration:  1804  Loss:  0.4020533   Accuracy:  0.8984375\n",
      "Iteration:  1805  Loss:  0.28109702   Accuracy:  0.9140625\n",
      "Iteration:  1806  Loss:  0.5444312   Accuracy:  0.8515625\n",
      "Iteration:  1807  Loss:  0.28391168   Accuracy:  0.875\n",
      "Iteration:  1808  Loss:  0.27806813   Accuracy:  0.921875\n",
      "Iteration:  1809  Loss:  0.4926436   Accuracy:  0.8984375\n",
      "Iteration:  1810  Loss:  0.56059426   Accuracy:  0.828125\n",
      "Iteration:  1811  Loss:  0.35018477   Accuracy:  0.90625\n",
      "Iteration:  1812  Loss:  0.4444779   Accuracy:  0.90625\n",
      "Iteration:  1813  Loss:  0.3292251   Accuracy:  0.8828125\n",
      "Iteration:  1814  Loss:  0.20449813   Accuracy:  0.9453125\n",
      "Iteration:  1815  Loss:  0.68113613   Accuracy:  0.8828125\n",
      "Iteration:  1816  Loss:  0.6320163   Accuracy:  0.890625\n",
      "Iteration:  1817  Loss:  0.3529678   Accuracy:  0.921875\n",
      "Iteration:  1818  Loss:  0.31800497   Accuracy:  0.90625\n",
      "Iteration:  1819  Loss:  0.3411684   Accuracy:  0.890625\n",
      "Iteration:  1820  Loss:  0.25678843   Accuracy:  0.921875\n",
      "Iteration:  1821  Loss:  0.5264292   Accuracy:  0.890625\n",
      "Iteration:  1822  Loss:  0.23765801   Accuracy:  0.9375\n",
      "Iteration:  1823  Loss:  0.46180207   Accuracy:  0.8515625\n",
      "Iteration:  1824  Loss:  0.29001975   Accuracy:  0.90625\n",
      "Iteration:  1825  Loss:  0.2254036   Accuracy:  0.9453125\n",
      "Iteration:  1826  Loss:  0.35578302   Accuracy:  0.8671875\n",
      "Iteration:  1827  Loss:  0.7852168   Accuracy:  0.859375\n",
      "Iteration:  1828  Loss:  0.51338124   Accuracy:  0.8984375\n",
      "Iteration:  1829  Loss:  0.49269468   Accuracy:  0.921875\n",
      "Iteration:  1830  Loss:  0.30328783   Accuracy:  0.9375\n",
      "Iteration:  1831  Loss:  0.48562098   Accuracy:  0.8828125\n",
      "Iteration:  1832  Loss:  0.48522672   Accuracy:  0.84375\n",
      "Iteration:  1833  Loss:  0.33162895   Accuracy:  0.921875\n",
      "Iteration:  1834  Loss:  0.7679908   Accuracy:  0.828125\n",
      "Iteration:  1835  Loss:  0.29571033   Accuracy:  0.9375\n",
      "Iteration:  1836  Loss:  0.5364416   Accuracy:  0.8671875\n",
      "Iteration:  1837  Loss:  0.6039047   Accuracy:  0.84375\n",
      "Iteration:  1838  Loss:  0.3176818   Accuracy:  0.890625\n",
      "Iteration:  1839  Loss:  0.3511876   Accuracy:  0.875\n",
      "Iteration:  1840  Loss:  0.44312865   Accuracy:  0.90625\n",
      "Iteration:  1841  Loss:  0.42954996   Accuracy:  0.8984375\n",
      "Iteration:  1842  Loss:  0.36244124   Accuracy:  0.9140625\n",
      "Iteration:  1843  Loss:  0.4223402   Accuracy:  0.9296875\n",
      "Iteration:  1844  Loss:  0.7222264   Accuracy:  0.8515625\n",
      "Iteration:  1845  Loss:  0.6164297   Accuracy:  0.890625\n",
      "Iteration:  1846  Loss:  0.36737245   Accuracy:  0.8984375\n",
      "Iteration:  1847  Loss:  0.7848712   Accuracy:  0.8671875\n",
      "Iteration:  1848  Loss:  0.39399692   Accuracy:  0.875\n",
      "Iteration:  1849  Loss:  0.30989152   Accuracy:  0.9296875\n",
      "Iteration:  1850  Loss:  0.29095906   Accuracy:  0.890625\n",
      "Iteration:  1851  Loss:  0.6643495   Accuracy:  0.8671875\n",
      "Iteration:  1852  Loss:  0.31950888   Accuracy:  0.890625\n",
      "Iteration:  1853  Loss:  0.63697463   Accuracy:  0.8671875\n",
      "Iteration:  1854  Loss:  0.744809   Accuracy:  0.875\n",
      "Iteration:  1855  Loss:  0.52809   Accuracy:  0.90625\n",
      "Iteration:  1856  Loss:  0.5626937   Accuracy:  0.9140625\n",
      "Iteration:  1857  Loss:  0.49912083   Accuracy:  0.9296875\n",
      "Iteration:  1858  Loss:  0.5242888   Accuracy:  0.90625\n",
      "Iteration:  1859  Loss:  0.38831416   Accuracy:  0.8828125\n",
      "Iteration:  1860  Loss:  0.60987455   Accuracy:  0.859375\n",
      "Iteration:  1861  Loss:  0.43641296   Accuracy:  0.859375\n",
      "Iteration:  1862  Loss:  0.3528633   Accuracy:  0.875\n",
      "Iteration:  1863  Loss:  0.29255766   Accuracy:  0.9453125\n",
      "Iteration:  1864  Loss:  0.14492968   Accuracy:  0.9375\n",
      "Iteration:  1865  Loss:  0.34808308   Accuracy:  0.9140625\n",
      "Iteration:  1866  Loss:  0.32919842   Accuracy:  0.921875\n",
      "Iteration:  1867  Loss:  0.36983144   Accuracy:  0.890625\n",
      "Iteration:  1868  Loss:  0.509881   Accuracy:  0.8828125\n",
      "Iteration:  1869  Loss:  0.4496469   Accuracy:  0.859375\n",
      "Iteration:  1870  Loss:  0.5714531   Accuracy:  0.875\n",
      "Iteration:  1871  Loss:  0.5529006   Accuracy:  0.8671875\n",
      "Iteration:  1872  Loss:  0.6358191   Accuracy:  0.8125\n",
      "Iteration:  1873  Loss:  0.68006986   Accuracy:  0.8046875\n",
      "Iteration:  1874  Loss:  0.54583895   Accuracy:  0.8671875\n",
      "Iteration:  1875  Loss:  0.518844   Accuracy:  0.8671875\n",
      "Iteration:  1876  Loss:  0.695442   Accuracy:  0.8671875\n",
      "Iteration:  1877  Loss:  0.4459411   Accuracy:  0.90625\n",
      "Iteration:  1878  Loss:  0.35876063   Accuracy:  0.8984375\n",
      "Iteration:  1879  Loss:  0.4516244   Accuracy:  0.8984375\n",
      "Iteration:  1880  Loss:  0.47783333   Accuracy:  0.859375\n",
      "Iteration:  1881  Loss:  0.24429157   Accuracy:  0.9140625\n",
      "Iteration:  1882  Loss:  0.6948048   Accuracy:  0.859375\n",
      "Iteration:  1883  Loss:  0.50390947   Accuracy:  0.859375\n",
      "Iteration:  1884  Loss:  0.27857444   Accuracy:  0.90625\n",
      "Iteration:  1885  Loss:  0.34432614   Accuracy:  0.90625\n",
      "Iteration:  1886  Loss:  0.30690145   Accuracy:  0.8828125\n",
      "Iteration:  1887  Loss:  0.28257018   Accuracy:  0.9296875\n",
      "Iteration:  1888  Loss:  0.36222434   Accuracy:  0.9296875\n",
      "Iteration:  1889  Loss:  0.3107782   Accuracy:  0.9140625\n",
      "Iteration:  1890  Loss:  0.4688023   Accuracy:  0.875\n",
      "Iteration:  1891  Loss:  0.5192018   Accuracy:  0.8828125\n",
      "Iteration:  1892  Loss:  0.45622256   Accuracy:  0.8984375\n",
      "Iteration:  1893  Loss:  0.6277495   Accuracy:  0.84375\n",
      "Iteration:  1894  Loss:  0.35653433   Accuracy:  0.9140625\n",
      "Iteration:  1895  Loss:  0.33193403   Accuracy:  0.921875\n",
      "Iteration:  1896  Loss:  0.39752954   Accuracy:  0.8828125\n",
      "Iteration:  1897  Loss:  0.26895398   Accuracy:  0.8984375\n",
      "Iteration:  1898  Loss:  0.25837702   Accuracy:  0.9375\n",
      "Iteration:  1899  Loss:  0.45876873   Accuracy:  0.8984375\n",
      "Iteration:  1900  Loss:  0.69785786   Accuracy:  0.875\n",
      "Iteration:  1901  Loss:  0.55037194   Accuracy:  0.859375\n",
      "Iteration:  1902  Loss:  0.33511195   Accuracy:  0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1903  Loss:  0.20024867   Accuracy:  0.953125\n",
      "Iteration:  1904  Loss:  0.3918704   Accuracy:  0.90625\n",
      "Iteration:  1905  Loss:  0.4720132   Accuracy:  0.859375\n",
      "Iteration:  1906  Loss:  0.24448647   Accuracy:  0.9140625\n",
      "Iteration:  1907  Loss:  0.5027499   Accuracy:  0.875\n",
      "Iteration:  1908  Loss:  0.3423861   Accuracy:  0.9296875\n",
      "Iteration:  1909  Loss:  0.5729499   Accuracy:  0.8828125\n",
      "Iteration:  1910  Loss:  0.3130976   Accuracy:  0.90625\n",
      "Iteration:  1911  Loss:  0.4120492   Accuracy:  0.8828125\n",
      "Iteration:  1912  Loss:  0.5394036   Accuracy:  0.9140625\n",
      "Iteration:  1913  Loss:  0.21935889   Accuracy:  0.9296875\n",
      "Iteration:  1914  Loss:  0.85477245   Accuracy:  0.8203125\n",
      "Iteration:  1915  Loss:  0.3122327   Accuracy:  0.8984375\n",
      "Iteration:  1916  Loss:  0.45577496   Accuracy:  0.8671875\n",
      "Iteration:  1917  Loss:  0.42993125   Accuracy:  0.8828125\n",
      "Iteration:  1918  Loss:  0.53064775   Accuracy:  0.9140625\n",
      "Iteration:  1919  Loss:  0.37503013   Accuracy:  0.90625\n",
      "Iteration:  1920  Loss:  0.56494975   Accuracy:  0.8671875\n",
      "Iteration:  1921  Loss:  0.40122974   Accuracy:  0.890625\n",
      "Iteration:  1922  Loss:  0.7331722   Accuracy:  0.8515625\n",
      "Iteration:  1923  Loss:  0.6308796   Accuracy:  0.8828125\n",
      "Iteration:  1924  Loss:  0.3827045   Accuracy:  0.8828125\n",
      "Iteration:  1925  Loss:  0.18704344   Accuracy:  0.9375\n",
      "Iteration:  1926  Loss:  0.43969992   Accuracy:  0.8984375\n",
      "Iteration:  1927  Loss:  0.3728975   Accuracy:  0.8984375\n",
      "Iteration:  1928  Loss:  0.5771285   Accuracy:  0.8828125\n",
      "Iteration:  1929  Loss:  0.46531516   Accuracy:  0.890625\n",
      "Iteration:  1930  Loss:  0.40411782   Accuracy:  0.890625\n",
      "Iteration:  1931  Loss:  0.7075773   Accuracy:  0.8203125\n",
      "Iteration:  1932  Loss:  0.5140607   Accuracy:  0.859375\n",
      "Iteration:  1933  Loss:  0.6610192   Accuracy:  0.8671875\n",
      "Iteration:  1934  Loss:  0.5809292   Accuracy:  0.875\n",
      "Iteration:  1935  Loss:  0.5338818   Accuracy:  0.859375\n",
      "Iteration:  1936  Loss:  0.34844258   Accuracy:  0.890625\n",
      "Iteration:  1937  Loss:  0.4230214   Accuracy:  0.8984375\n",
      "Iteration:  1938  Loss:  0.47805715   Accuracy:  0.859375\n",
      "Iteration:  1939  Loss:  0.4865155   Accuracy:  0.859375\n",
      "Iteration:  1940  Loss:  0.2507215   Accuracy:  0.921875\n",
      "Iteration:  1941  Loss:  0.5375203   Accuracy:  0.8359375\n",
      "Iteration:  1942  Loss:  0.30404317   Accuracy:  0.9296875\n",
      "Iteration:  1943  Loss:  0.57658803   Accuracy:  0.8671875\n",
      "Iteration:  1944  Loss:  0.6158334   Accuracy:  0.859375\n",
      "Iteration:  1945  Loss:  0.34123078   Accuracy:  0.890625\n",
      "Iteration:  1946  Loss:  0.4014329   Accuracy:  0.8828125\n",
      "Iteration:  1947  Loss:  0.45677093   Accuracy:  0.90625\n",
      "Iteration:  1948  Loss:  0.41280892   Accuracy:  0.90625\n",
      "Iteration:  1949  Loss:  0.3444961   Accuracy:  0.9296875\n",
      "Iteration:  1950  Loss:  0.2960508   Accuracy:  0.890625\n",
      "Iteration:  1951  Loss:  0.3851711   Accuracy:  0.921875\n",
      "Iteration:  1952  Loss:  0.32298678   Accuracy:  0.8984375\n",
      "Iteration:  1953  Loss:  0.5889524   Accuracy:  0.8671875\n",
      "Iteration:  1954  Loss:  0.46877262   Accuracy:  0.8984375\n",
      "Iteration:  1955  Loss:  0.5391654   Accuracy:  0.875\n",
      "Iteration:  1956  Loss:  0.7001796   Accuracy:  0.875\n",
      "Iteration:  1957  Loss:  0.35135192   Accuracy:  0.890625\n",
      "Iteration:  1958  Loss:  0.5022507   Accuracy:  0.890625\n",
      "Iteration:  1959  Loss:  0.6369912   Accuracy:  0.8828125\n",
      "Iteration:  1960  Loss:  0.38840058   Accuracy:  0.859375\n",
      "Iteration:  1961  Loss:  0.5314968   Accuracy:  0.9140625\n",
      "Iteration:  1962  Loss:  0.47800416   Accuracy:  0.890625\n",
      "Iteration:  1963  Loss:  0.3942311   Accuracy:  0.890625\n",
      "Iteration:  1964  Loss:  0.6796644   Accuracy:  0.890625\n",
      "Iteration:  1965  Loss:  0.46854213   Accuracy:  0.890625\n",
      "Iteration:  1966  Loss:  0.6303102   Accuracy:  0.859375\n",
      "Iteration:  1967  Loss:  0.45584708   Accuracy:  0.8671875\n",
      "Iteration:  1968  Loss:  0.4713625   Accuracy:  0.859375\n",
      "Iteration:  1969  Loss:  0.50397664   Accuracy:  0.890625\n",
      "Iteration:  1970  Loss:  0.5105328   Accuracy:  0.890625\n",
      "Iteration:  1971  Loss:  0.5716784   Accuracy:  0.8828125\n",
      "Iteration:  1972  Loss:  0.4535538   Accuracy:  0.890625\n",
      "Iteration:  1973  Loss:  0.5361524   Accuracy:  0.875\n",
      "Iteration:  1974  Loss:  0.35583276   Accuracy:  0.90625\n",
      "Iteration:  1975  Loss:  0.20213996   Accuracy:  0.9296875\n",
      "Iteration:  1976  Loss:  0.5374993   Accuracy:  0.8828125\n",
      "Iteration:  1977  Loss:  0.3306642   Accuracy:  0.8984375\n",
      "Iteration:  1978  Loss:  0.47179538   Accuracy:  0.8984375\n",
      "Iteration:  1979  Loss:  0.48491925   Accuracy:  0.890625\n",
      "Iteration:  1980  Loss:  0.31976923   Accuracy:  0.8984375\n",
      "Iteration:  1981  Loss:  0.31238765   Accuracy:  0.90625\n",
      "Iteration:  1982  Loss:  0.38068005   Accuracy:  0.8984375\n",
      "Iteration:  1983  Loss:  0.3633775   Accuracy:  0.8984375\n",
      "Iteration:  1984  Loss:  0.2588966   Accuracy:  0.9140625\n",
      "Iteration:  1985  Loss:  0.2971961   Accuracy:  0.90625\n",
      "Iteration:  1986  Loss:  0.6040025   Accuracy:  0.8828125\n",
      "Iteration:  1987  Loss:  0.3471831   Accuracy:  0.8984375\n",
      "Iteration:  1988  Loss:  0.21616846   Accuracy:  0.9140625\n",
      "Iteration:  1989  Loss:  0.47958893   Accuracy:  0.9296875\n",
      "Iteration:  1990  Loss:  0.50306267   Accuracy:  0.8671875\n",
      "Iteration:  1991  Loss:  0.3946972   Accuracy:  0.8984375\n",
      "Iteration:  1992  Loss:  0.51204395   Accuracy:  0.84375\n",
      "Iteration:  1993  Loss:  0.39211816   Accuracy:  0.875\n",
      "Iteration:  1994  Loss:  0.54239124   Accuracy:  0.8671875\n",
      "Iteration:  1995  Loss:  0.41102886   Accuracy:  0.875\n",
      "Iteration:  1996  Loss:  0.24399622   Accuracy:  0.9140625\n",
      "Iteration:  1997  Loss:  0.2823173   Accuracy:  0.921875\n",
      "Iteration:  1998  Loss:  0.31970584   Accuracy:  0.9140625\n",
      "Iteration:  1999  Loss:  0.32961172   Accuracy:  0.90625\n",
      "Iteration:  2000  Loss:  0.7474858   Accuracy:  0.8671875\n",
      "Iteration:  2001  Loss:  0.528944   Accuracy:  0.859375\n",
      "Iteration:  2002  Loss:  0.47072628   Accuracy:  0.8828125\n",
      "Iteration:  2003  Loss:  0.40357813   Accuracy:  0.8828125\n",
      "Iteration:  2004  Loss:  0.524732   Accuracy:  0.8828125\n",
      "Iteration:  2005  Loss:  0.61886847   Accuracy:  0.859375\n",
      "Iteration:  2006  Loss:  0.43058223   Accuracy:  0.90625\n",
      "Iteration:  2007  Loss:  0.38560677   Accuracy:  0.8984375\n",
      "Iteration:  2008  Loss:  0.5861485   Accuracy:  0.859375\n",
      "Iteration:  2009  Loss:  0.63299036   Accuracy:  0.859375\n",
      "Iteration:  2010  Loss:  0.47124022   Accuracy:  0.875\n",
      "Iteration:  2011  Loss:  0.13227148   Accuracy:  0.9296875\n",
      "Iteration:  2012  Loss:  0.51724714   Accuracy:  0.859375\n",
      "Iteration:  2013  Loss:  0.2826171   Accuracy:  0.890625\n",
      "Iteration:  2014  Loss:  0.74175656   Accuracy:  0.9140625\n",
      "Iteration:  2015  Loss:  0.6286458   Accuracy:  0.875\n",
      "Iteration:  2016  Loss:  0.7101315   Accuracy:  0.890625\n",
      "Iteration:  2017  Loss:  0.46702313   Accuracy:  0.875\n",
      "Iteration:  2018  Loss:  0.4848101   Accuracy:  0.890625\n",
      "Iteration:  2019  Loss:  0.3192656   Accuracy:  0.90625\n",
      "Iteration:  2020  Loss:  0.3292377   Accuracy:  0.890625\n",
      "Iteration:  2021  Loss:  0.45922965   Accuracy:  0.8984375\n",
      "Iteration:  2022  Loss:  0.6714729   Accuracy:  0.8828125\n",
      "Iteration:  2023  Loss:  0.5325908   Accuracy:  0.8671875\n",
      "Iteration:  2024  Loss:  0.34105492   Accuracy:  0.8828125\n",
      "Iteration:  2025  Loss:  0.5224099   Accuracy:  0.8515625\n",
      "Iteration:  2026  Loss:  0.45740247   Accuracy:  0.890625\n",
      "Iteration:  2027  Loss:  0.6981541   Accuracy:  0.828125\n",
      "Iteration:  2028  Loss:  0.38329723   Accuracy:  0.8984375\n",
      "Iteration:  2029  Loss:  0.16518031   Accuracy:  0.9453125\n",
      "Iteration:  2030  Loss:  0.6171064   Accuracy:  0.859375\n",
      "Iteration:  2031  Loss:  0.5477739   Accuracy:  0.8671875\n",
      "Iteration:  2032  Loss:  0.4398141   Accuracy:  0.8828125\n",
      "Iteration:  2033  Loss:  0.3600384   Accuracy:  0.90625\n",
      "Iteration:  2034  Loss:  0.45261237   Accuracy:  0.90625\n",
      "Iteration:  2035  Loss:  0.28254193   Accuracy:  0.90625\n",
      "Iteration:  2036  Loss:  0.38573915   Accuracy:  0.890625\n",
      "Iteration:  2037  Loss:  0.41500798   Accuracy:  0.859375\n",
      "Iteration:  2038  Loss:  0.29119837   Accuracy:  0.9296875\n",
      "Iteration:  2039  Loss:  0.55737865   Accuracy:  0.8671875\n",
      "Iteration:  2040  Loss:  0.35484868   Accuracy:  0.9140625\n",
      "Iteration:  2041  Loss:  0.24206592   Accuracy:  0.9296875\n",
      "Iteration:  2042  Loss:  0.53608257   Accuracy:  0.875\n",
      "Iteration:  2043  Loss:  0.7252999   Accuracy:  0.8515625\n",
      "Iteration:  2044  Loss:  0.30706915   Accuracy:  0.9140625\n",
      "Iteration:  2045  Loss:  0.45753857   Accuracy:  0.8828125\n",
      "Iteration:  2046  Loss:  0.53826344   Accuracy:  0.8828125\n",
      "Iteration:  2047  Loss:  0.4610262   Accuracy:  0.890625\n",
      "Iteration:  2048  Loss:  0.3102559   Accuracy:  0.90625\n",
      "Iteration:  2049  Loss:  0.36091346   Accuracy:  0.875\n",
      "Iteration:  2050  Loss:  0.49912792   Accuracy:  0.90625\n",
      "Iteration:  2051  Loss:  0.4665971   Accuracy:  0.875\n",
      "Iteration:  2052  Loss:  0.3740703   Accuracy:  0.8828125\n",
      "Iteration:  2053  Loss:  0.35993573   Accuracy:  0.875\n",
      "Iteration:  2054  Loss:  0.37160644   Accuracy:  0.90625\n",
      "Iteration:  2055  Loss:  0.7150384   Accuracy:  0.859375\n",
      "Iteration:  2056  Loss:  0.69877934   Accuracy:  0.8515625\n",
      "Iteration:  2057  Loss:  0.3515742   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2058  Loss:  0.53936017   Accuracy:  0.875\n",
      "Iteration:  2059  Loss:  0.5063242   Accuracy:  0.859375\n",
      "Iteration:  2060  Loss:  0.23227936   Accuracy:  0.9296875\n",
      "Iteration:  2061  Loss:  0.6146942   Accuracy:  0.8515625\n",
      "Iteration:  2062  Loss:  0.4419191   Accuracy:  0.859375\n",
      "Iteration:  2063  Loss:  0.3679498   Accuracy:  0.875\n",
      "Iteration:  2064  Loss:  0.3555647   Accuracy:  0.890625\n",
      "Iteration:  2065  Loss:  0.3887463   Accuracy:  0.8828125\n",
      "Iteration:  2066  Loss:  0.5487908   Accuracy:  0.8828125\n",
      "Iteration:  2067  Loss:  0.272181   Accuracy:  0.9140625\n",
      "Iteration:  2068  Loss:  0.47783196   Accuracy:  0.8828125\n",
      "Iteration:  2069  Loss:  0.45181692   Accuracy:  0.875\n",
      "Iteration:  2070  Loss:  0.32495326   Accuracy:  0.9453125\n",
      "Iteration:  2071  Loss:  0.2216605   Accuracy:  0.9453125\n",
      "Iteration:  2072  Loss:  0.7287769   Accuracy:  0.890625\n",
      "Iteration:  2073  Loss:  0.43775612   Accuracy:  0.9140625\n",
      "Iteration:  2074  Loss:  0.51750636   Accuracy:  0.8671875\n",
      "Iteration:  2075  Loss:  0.70893276   Accuracy:  0.828125\n",
      "Iteration:  2076  Loss:  0.44846854   Accuracy:  0.8828125\n",
      "Iteration:  2077  Loss:  0.30370277   Accuracy:  0.875\n",
      "Iteration:  2078  Loss:  0.5018625   Accuracy:  0.890625\n",
      "Iteration:  2079  Loss:  0.35897887   Accuracy:  0.8828125\n",
      "Iteration:  2080  Loss:  0.5325794   Accuracy:  0.859375\n",
      "Iteration:  2081  Loss:  0.46961835   Accuracy:  0.9296875\n",
      "Iteration:  2082  Loss:  0.28641528   Accuracy:  0.90625\n",
      "Iteration:  2083  Loss:  0.35680884   Accuracy:  0.90625\n",
      "Iteration:  2084  Loss:  0.3958499   Accuracy:  0.8828125\n",
      "Iteration:  2085  Loss:  0.4526532   Accuracy:  0.8984375\n",
      "Iteration:  2086  Loss:  0.57266074   Accuracy:  0.8671875\n",
      "Iteration:  2087  Loss:  0.31127477   Accuracy:  0.9140625\n",
      "Iteration:  2088  Loss:  0.28407627   Accuracy:  0.9140625\n",
      "Iteration:  2089  Loss:  0.2839254   Accuracy:  0.90625\n",
      "Iteration:  2090  Loss:  0.5830369   Accuracy:  0.890625\n",
      "Iteration:  2091  Loss:  0.5594772   Accuracy:  0.875\n",
      "Iteration:  2092  Loss:  0.5550046   Accuracy:  0.8671875\n",
      "Iteration:  2093  Loss:  0.4056499   Accuracy:  0.859375\n",
      "Iteration:  2094  Loss:  0.5122727   Accuracy:  0.890625\n",
      "Iteration:  2095  Loss:  0.2697131   Accuracy:  0.8828125\n",
      "Iteration:  2096  Loss:  0.4547763   Accuracy:  0.875\n",
      "Iteration:  2097  Loss:  0.49223956   Accuracy:  0.859375\n",
      "Iteration:  2098  Loss:  0.60029304   Accuracy:  0.8515625\n",
      "Iteration:  2099  Loss:  0.4573382   Accuracy:  0.8671875\n",
      "Iteration:  2100  Loss:  0.5246789   Accuracy:  0.875\n",
      "Iteration:  2101  Loss:  0.52737236   Accuracy:  0.9140625\n",
      "Iteration:  2102  Loss:  0.6324711   Accuracy:  0.8359375\n",
      "Iteration:  2103  Loss:  0.44922987   Accuracy:  0.90625\n",
      "Iteration:  2104  Loss:  0.22567415   Accuracy:  0.9140625\n",
      "Iteration:  2105  Loss:  0.9277032   Accuracy:  0.8984375\n",
      "Iteration:  2106  Loss:  0.46853375   Accuracy:  0.84375\n",
      "Iteration:  2107  Loss:  0.3461138   Accuracy:  0.9140625\n",
      "Iteration:  2108  Loss:  0.2069467   Accuracy:  0.9140625\n",
      "Iteration:  2109  Loss:  0.39438587   Accuracy:  0.90625\n",
      "Iteration:  2110  Loss:  0.34205216   Accuracy:  0.8828125\n",
      "Iteration:  2111  Loss:  0.47098202   Accuracy:  0.8984375\n",
      "Iteration:  2112  Loss:  0.3341739   Accuracy:  0.90625\n",
      "Iteration:  2113  Loss:  0.45019144   Accuracy:  0.8671875\n",
      "Iteration:  2114  Loss:  0.46018124   Accuracy:  0.859375\n",
      "Iteration:  2115  Loss:  0.46511364   Accuracy:  0.8984375\n",
      "Iteration:  2116  Loss:  0.65147084   Accuracy:  0.8671875\n",
      "Iteration:  2117  Loss:  0.2853221   Accuracy:  0.8984375\n",
      "Iteration:  2118  Loss:  0.3189547   Accuracy:  0.9375\n",
      "Iteration:  2119  Loss:  0.40712535   Accuracy:  0.90625\n",
      "Iteration:  2120  Loss:  0.41969523   Accuracy:  0.8828125\n",
      "Iteration:  2121  Loss:  0.60414034   Accuracy:  0.8671875\n",
      "Iteration:  2122  Loss:  0.47745037   Accuracy:  0.8828125\n",
      "Iteration:  2123  Loss:  0.7337218   Accuracy:  0.84375\n",
      "Iteration:  2124  Loss:  0.5432441   Accuracy:  0.8984375\n",
      "Iteration:  2125  Loss:  0.41916952   Accuracy:  0.8828125\n",
      "Iteration:  2126  Loss:  0.19772835   Accuracy:  0.9296875\n",
      "Iteration:  2127  Loss:  0.4182905   Accuracy:  0.8828125\n",
      "Iteration:  2128  Loss:  0.25243908   Accuracy:  0.890625\n",
      "Iteration:  2129  Loss:  0.5091117   Accuracy:  0.9296875\n",
      "Iteration:  2130  Loss:  0.37076646   Accuracy:  0.90625\n",
      "Iteration:  2131  Loss:  0.30421197   Accuracy:  0.90625\n",
      "Iteration:  2132  Loss:  0.49147293   Accuracy:  0.84375\n",
      "Iteration:  2133  Loss:  0.4307685   Accuracy:  0.8671875\n",
      "Iteration:  2134  Loss:  0.4528196   Accuracy:  0.9140625\n",
      "Iteration:  2135  Loss:  0.5617649   Accuracy:  0.875\n",
      "Iteration:  2136  Loss:  0.5308079   Accuracy:  0.890625\n",
      "Iteration:  2137  Loss:  0.3227125   Accuracy:  0.8984375\n",
      "Iteration:  2138  Loss:  0.30198887   Accuracy:  0.9140625\n",
      "Iteration:  2139  Loss:  0.74403024   Accuracy:  0.8515625\n",
      "Iteration:  2140  Loss:  0.62060076   Accuracy:  0.8515625\n",
      "Iteration:  2141  Loss:  0.5490655   Accuracy:  0.8359375\n",
      "Iteration:  2142  Loss:  0.5424902   Accuracy:  0.8515625\n",
      "Iteration:  2143  Loss:  0.3960267   Accuracy:  0.875\n",
      "Iteration:  2144  Loss:  0.54308623   Accuracy:  0.890625\n",
      "Iteration:  2145  Loss:  0.48651758   Accuracy:  0.8828125\n",
      "Iteration:  2146  Loss:  0.471928   Accuracy:  0.8984375\n",
      "Iteration:  2147  Loss:  0.5783537   Accuracy:  0.8828125\n",
      "Iteration:  2148  Loss:  0.29141074   Accuracy:  0.9140625\n",
      "Iteration:  2149  Loss:  0.31596166   Accuracy:  0.875\n",
      "Iteration:  2150  Loss:  0.7149391   Accuracy:  0.8515625\n",
      "Iteration:  2151  Loss:  0.40442508   Accuracy:  0.8828125\n",
      "Iteration:  2152  Loss:  0.5120929   Accuracy:  0.890625\n",
      "Iteration:  2153  Loss:  0.3103217   Accuracy:  0.9140625\n",
      "Iteration:  2154  Loss:  0.63103646   Accuracy:  0.890625\n",
      "Iteration:  2155  Loss:  0.41088128   Accuracy:  0.859375\n",
      "Iteration:  2156  Loss:  0.7698599   Accuracy:  0.84375\n",
      "Iteration:  2157  Loss:  0.8111055   Accuracy:  0.875\n",
      "Iteration:  2158  Loss:  0.41109276   Accuracy:  0.921875\n",
      "Iteration:  2159  Loss:  0.31354526   Accuracy:  0.90625\n",
      "Iteration:  2160  Loss:  0.35222545   Accuracy:  0.90625\n",
      "Iteration:  2161  Loss:  0.58242965   Accuracy:  0.875\n",
      "Iteration:  2162  Loss:  0.23721457   Accuracy:  0.9453125\n",
      "Iteration:  2163  Loss:  0.5010905   Accuracy:  0.8828125\n",
      "Iteration:  2164  Loss:  0.54111   Accuracy:  0.875\n",
      "Iteration:  2165  Loss:  0.38415805   Accuracy:  0.8828125\n",
      "Iteration:  2166  Loss:  0.41097587   Accuracy:  0.921875\n",
      "Iteration:  2167  Loss:  0.5167062   Accuracy:  0.8671875\n",
      "Iteration:  2168  Loss:  0.44751257   Accuracy:  0.8828125\n",
      "Iteration:  2169  Loss:  0.41425562   Accuracy:  0.9140625\n",
      "Iteration:  2170  Loss:  0.3358731   Accuracy:  0.890625\n",
      "Iteration:  2171  Loss:  0.55462277   Accuracy:  0.890625\n",
      "Iteration:  2172  Loss:  0.551332   Accuracy:  0.8671875\n",
      "Iteration:  2173  Loss:  0.78163695   Accuracy:  0.875\n",
      "Iteration:  2174  Loss:  0.25199735   Accuracy:  0.90625\n",
      "Iteration:  2175  Loss:  0.43075562   Accuracy:  0.90625\n",
      "Iteration:  2176  Loss:  0.14099482   Accuracy:  0.9609375\n",
      "Iteration:  2177  Loss:  0.59064627   Accuracy:  0.8828125\n",
      "Iteration:  2178  Loss:  0.51364547   Accuracy:  0.859375\n",
      "Iteration:  2179  Loss:  0.52074945   Accuracy:  0.8515625\n",
      "Iteration:  2180  Loss:  0.50166976   Accuracy:  0.859375\n",
      "Iteration:  2181  Loss:  0.7337684   Accuracy:  0.8359375\n",
      "Iteration:  2182  Loss:  0.31009558   Accuracy:  0.8984375\n",
      "Iteration:  2183  Loss:  0.67661524   Accuracy:  0.84375\n",
      "Iteration:  2184  Loss:  0.31134567   Accuracy:  0.9140625\n",
      "Iteration:  2185  Loss:  0.54998136   Accuracy:  0.890625\n",
      "Iteration:  2186  Loss:  0.35998344   Accuracy:  0.90625\n",
      "Iteration:  2187  Loss:  0.3585286   Accuracy:  0.8671875\n",
      "Iteration:  2188  Loss:  0.52863795   Accuracy:  0.859375\n",
      "Iteration:  2189  Loss:  0.25615948   Accuracy:  0.9140625\n",
      "Iteration:  2190  Loss:  0.74447906   Accuracy:  0.84375\n",
      "Iteration:  2191  Loss:  0.4772336   Accuracy:  0.8671875\n",
      "Iteration:  2192  Loss:  0.23626639   Accuracy:  0.90625\n",
      "Iteration:  2193  Loss:  0.41721162   Accuracy:  0.875\n",
      "Iteration:  2194  Loss:  0.33609012   Accuracy:  0.90625\n",
      "Iteration:  2195  Loss:  0.48072228   Accuracy:  0.90625\n",
      "Iteration:  2196  Loss:  0.28780413   Accuracy:  0.890625\n",
      "Iteration:  2197  Loss:  0.46141112   Accuracy:  0.875\n",
      "Iteration:  2198  Loss:  0.37547284   Accuracy:  0.921875\n",
      "Iteration:  2199  Loss:  0.28108177   Accuracy:  0.8984375\n",
      "Iteration:  2200  Loss:  0.3647194   Accuracy:  0.875\n",
      "Iteration:  2201  Loss:  0.32820645   Accuracy:  0.875\n",
      "Iteration:  2202  Loss:  0.44720316   Accuracy:  0.9140625\n",
      "Iteration:  2203  Loss:  0.37347654   Accuracy:  0.90625\n",
      "Iteration:  2204  Loss:  0.44760603   Accuracy:  0.8671875\n",
      "Iteration:  2205  Loss:  0.4283189   Accuracy:  0.90625\n",
      "Iteration:  2206  Loss:  0.3060533   Accuracy:  0.890625\n",
      "Iteration:  2207  Loss:  0.24960531   Accuracy:  0.953125\n",
      "Iteration:  2208  Loss:  0.38375965   Accuracy:  0.90625\n",
      "Iteration:  2209  Loss:  0.7174509   Accuracy:  0.890625\n",
      "Iteration:  2210  Loss:  0.4483185   Accuracy:  0.8671875\n",
      "Iteration:  2211  Loss:  0.79632854   Accuracy:  0.875\n",
      "Iteration:  2212  Loss:  0.54784155   Accuracy:  0.8828125\n",
      "Iteration:  2213  Loss:  0.34451544   Accuracy:  0.90625\n",
      "Iteration:  2214  Loss:  0.284248   Accuracy:  0.9453125\n",
      "Iteration:  2215  Loss:  0.37741804   Accuracy:  0.8828125\n",
      "Iteration:  2216  Loss:  0.49270868   Accuracy:  0.8828125\n",
      "Iteration:  2217  Loss:  0.355327   Accuracy:  0.890625\n",
      "Iteration:  2218  Loss:  0.4726107   Accuracy:  0.8828125\n",
      "Iteration:  2219  Loss:  0.2972314   Accuracy:  0.921875\n",
      "Iteration:  2220  Loss:  0.5321182   Accuracy:  0.890625\n",
      "Iteration:  2221  Loss:  0.19908276   Accuracy:  0.9375\n",
      "Iteration:  2222  Loss:  0.2000117   Accuracy:  0.921875\n",
      "Iteration:  2223  Loss:  0.5149825   Accuracy:  0.90625\n",
      "Iteration:  2224  Loss:  0.45875758   Accuracy:  0.890625\n",
      "Iteration:  2225  Loss:  0.30413127   Accuracy:  0.9140625\n",
      "Iteration:  2226  Loss:  0.4636139   Accuracy:  0.8671875\n",
      "Iteration:  2227  Loss:  0.41460794   Accuracy:  0.90625\n",
      "Iteration:  2228  Loss:  0.37847996   Accuracy:  0.90625\n",
      "Iteration:  2229  Loss:  0.29436743   Accuracy:  0.90625\n",
      "Iteration:  2230  Loss:  0.59745264   Accuracy:  0.84375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2231  Loss:  0.5667654   Accuracy:  0.8359375\n",
      "Iteration:  2232  Loss:  0.3863168   Accuracy:  0.9140625\n",
      "Iteration:  2233  Loss:  0.5609231   Accuracy:  0.8671875\n",
      "Iteration:  2234  Loss:  0.5436076   Accuracy:  0.8515625\n",
      "Iteration:  2235  Loss:  0.2365123   Accuracy:  0.9140625\n",
      "Iteration:  2236  Loss:  0.5794408   Accuracy:  0.8828125\n",
      "Iteration:  2237  Loss:  0.5106295   Accuracy:  0.890625\n",
      "Iteration:  2238  Loss:  0.30383226   Accuracy:  0.8671875\n",
      "Iteration:  2239  Loss:  0.5174038   Accuracy:  0.8828125\n",
      "Iteration:  2240  Loss:  0.13302208   Accuracy:  0.9453125\n",
      "Iteration:  2241  Loss:  0.41922572   Accuracy:  0.8828125\n",
      "Iteration:  2242  Loss:  0.31517845   Accuracy:  0.9140625\n",
      "Iteration:  2243  Loss:  0.4927182   Accuracy:  0.921875\n",
      "Iteration:  2244  Loss:  0.33139718   Accuracy:  0.9375\n",
      "Iteration:  2245  Loss:  0.3274545   Accuracy:  0.921875\n",
      "Iteration:  2246  Loss:  0.5264816   Accuracy:  0.8828125\n",
      "Iteration:  2247  Loss:  0.4076152   Accuracy:  0.9140625\n",
      "Iteration:  2248  Loss:  0.5641708   Accuracy:  0.8515625\n",
      "Iteration:  2249  Loss:  0.57090575   Accuracy:  0.8515625\n",
      "Iteration:  2250  Loss:  0.36904782   Accuracy:  0.8984375\n",
      "Iteration:  2251  Loss:  0.27446902   Accuracy:  0.8984375\n",
      "Iteration:  2252  Loss:  0.37376362   Accuracy:  0.890625\n",
      "Iteration:  2253  Loss:  0.45401442   Accuracy:  0.9140625\n",
      "Iteration:  2254  Loss:  0.38515314   Accuracy:  0.9140625\n",
      "Iteration:  2255  Loss:  0.4306652   Accuracy:  0.8828125\n",
      "Iteration:  2256  Loss:  0.63058263   Accuracy:  0.8515625\n",
      "Iteration:  2257  Loss:  0.53686625   Accuracy:  0.890625\n",
      "Iteration:  2258  Loss:  0.36417496   Accuracy:  0.9296875\n",
      "Iteration:  2259  Loss:  0.3193508   Accuracy:  0.8984375\n",
      "Iteration:  2260  Loss:  0.3171919   Accuracy:  0.9140625\n",
      "Iteration:  2261  Loss:  0.45753396   Accuracy:  0.90625\n",
      "Iteration:  2262  Loss:  0.41919002   Accuracy:  0.9140625\n",
      "Iteration:  2263  Loss:  0.52718365   Accuracy:  0.84375\n",
      "Iteration:  2264  Loss:  0.5064074   Accuracy:  0.890625\n",
      "Iteration:  2265  Loss:  0.37575936   Accuracy:  0.859375\n",
      "Iteration:  2266  Loss:  0.39606887   Accuracy:  0.90625\n",
      "Iteration:  2267  Loss:  0.33624473   Accuracy:  0.8671875\n",
      "Iteration:  2268  Loss:  0.3203349   Accuracy:  0.8984375\n",
      "Iteration:  2269  Loss:  0.6086356   Accuracy:  0.859375\n",
      "Iteration:  2270  Loss:  0.17356186   Accuracy:  0.9453125\n",
      "Iteration:  2271  Loss:  0.65471554   Accuracy:  0.8984375\n",
      "Iteration:  2272  Loss:  0.39935255   Accuracy:  0.90625\n",
      "Iteration:  2273  Loss:  0.46288592   Accuracy:  0.859375\n",
      "Iteration:  2274  Loss:  0.23696029   Accuracy:  0.9296875\n",
      "Iteration:  2275  Loss:  0.27502304   Accuracy:  0.9375\n",
      "Iteration:  2276  Loss:  0.34398112   Accuracy:  0.890625\n",
      "Iteration:  2277  Loss:  0.52072537   Accuracy:  0.8671875\n",
      "Iteration:  2278  Loss:  0.5875749   Accuracy:  0.859375\n",
      "Iteration:  2279  Loss:  0.7204645   Accuracy:  0.8671875\n",
      "Iteration:  2280  Loss:  0.43341452   Accuracy:  0.859375\n",
      "Iteration:  2281  Loss:  0.2666226   Accuracy:  0.921875\n",
      "Iteration:  2282  Loss:  0.5393392   Accuracy:  0.859375\n",
      "Iteration:  2283  Loss:  0.4873741   Accuracy:  0.859375\n",
      "Iteration:  2284  Loss:  0.3476861   Accuracy:  0.8671875\n",
      "Iteration:  2285  Loss:  0.5546742   Accuracy:  0.90625\n",
      "Iteration:  2286  Loss:  0.33363795   Accuracy:  0.921875\n",
      "Iteration:  2287  Loss:  0.7694217   Accuracy:  0.859375\n",
      "Iteration:  2288  Loss:  0.4305635   Accuracy:  0.875\n",
      "Iteration:  2289  Loss:  0.41637933   Accuracy:  0.90625\n",
      "Iteration:  2290  Loss:  0.19643982   Accuracy:  0.90625\n",
      "Iteration:  2291  Loss:  0.59735984   Accuracy:  0.875\n",
      "Iteration:  2292  Loss:  0.5255269   Accuracy:  0.8828125\n",
      "Iteration:  2293  Loss:  0.49669537   Accuracy:  0.875\n",
      "Iteration:  2294  Loss:  0.63879526   Accuracy:  0.8203125\n",
      "Iteration:  2295  Loss:  0.46024704   Accuracy:  0.921875\n",
      "Iteration:  2296  Loss:  0.4191225   Accuracy:  0.890625\n",
      "Iteration:  2297  Loss:  0.5044316   Accuracy:  0.8671875\n",
      "Iteration:  2298  Loss:  0.22615355   Accuracy:  0.9296875\n",
      "Iteration:  2299  Loss:  0.34711456   Accuracy:  0.90625\n",
      "Iteration:  2300  Loss:  0.4954613   Accuracy:  0.875\n",
      "Iteration:  2301  Loss:  0.5436886   Accuracy:  0.84375\n",
      "Iteration:  2302  Loss:  0.507113   Accuracy:  0.859375\n",
      "Iteration:  2303  Loss:  0.33300287   Accuracy:  0.875\n",
      "Iteration:  2304  Loss:  0.28705782   Accuracy:  0.9140625\n",
      "Iteration:  2305  Loss:  0.47207963   Accuracy:  0.90625\n",
      "Iteration:  2306  Loss:  0.44276586   Accuracy:  0.8828125\n",
      "Iteration:  2307  Loss:  0.5661292   Accuracy:  0.8984375\n",
      "Iteration:  2308  Loss:  0.46671453   Accuracy:  0.90625\n",
      "Iteration:  2309  Loss:  0.33341756   Accuracy:  0.875\n",
      "Iteration:  2310  Loss:  0.4098905   Accuracy:  0.875\n",
      "Iteration:  2311  Loss:  0.3050542   Accuracy:  0.90625\n",
      "Iteration:  2312  Loss:  0.3904057   Accuracy:  0.90625\n",
      "Iteration:  2313  Loss:  0.37203085   Accuracy:  0.921875\n",
      "Iteration:  2314  Loss:  0.37366825   Accuracy:  0.9296875\n",
      "Iteration:  2315  Loss:  0.59644186   Accuracy:  0.875\n",
      "Iteration:  2316  Loss:  0.39508134   Accuracy:  0.921875\n",
      "Iteration:  2317  Loss:  0.27180827   Accuracy:  0.8984375\n",
      "Iteration:  2318  Loss:  0.21077694   Accuracy:  0.9296875\n",
      "Iteration:  2319  Loss:  0.3423571   Accuracy:  0.90625\n",
      "Iteration:  2320  Loss:  0.369721   Accuracy:  0.921875\n",
      "Iteration:  2321  Loss:  0.5584838   Accuracy:  0.890625\n",
      "Iteration:  2322  Loss:  0.3420755   Accuracy:  0.90625\n",
      "Iteration:  2323  Loss:  0.34738344   Accuracy:  0.9375\n",
      "Iteration:  2324  Loss:  0.7270656   Accuracy:  0.875\n",
      "Iteration:  2325  Loss:  0.5612571   Accuracy:  0.8671875\n",
      "Iteration:  2326  Loss:  0.3043785   Accuracy:  0.9140625\n",
      "Iteration:  2327  Loss:  0.26318097   Accuracy:  0.9453125\n",
      "Iteration:  2328  Loss:  0.36916482   Accuracy:  0.859375\n",
      "Iteration:  2329  Loss:  0.81498194   Accuracy:  0.8671875\n",
      "Iteration:  2330  Loss:  0.58956134   Accuracy:  0.875\n",
      "Iteration:  2331  Loss:  0.36911488   Accuracy:  0.890625\n",
      "Iteration:  2332  Loss:  0.44719616   Accuracy:  0.90625\n",
      "Iteration:  2333  Loss:  0.14386787   Accuracy:  0.953125\n",
      "Iteration:  2334  Loss:  0.50846386   Accuracy:  0.90625\n",
      "Iteration:  2335  Loss:  0.52340204   Accuracy:  0.84375\n",
      "Iteration:  2336  Loss:  0.47941828   Accuracy:  0.875\n",
      "Iteration:  2337  Loss:  0.3187342   Accuracy:  0.8984375\n",
      "Iteration:  2338  Loss:  0.54121244   Accuracy:  0.8671875\n",
      "Iteration:  2339  Loss:  0.27697518   Accuracy:  0.921875\n",
      "Iteration:  2340  Loss:  0.32586932   Accuracy:  0.8984375\n",
      "Iteration:  2341  Loss:  0.35851365   Accuracy:  0.8984375\n",
      "Iteration:  2342  Loss:  0.5103542   Accuracy:  0.890625\n",
      "Iteration:  2343  Loss:  0.42095888   Accuracy:  0.8359375\n",
      "Iteration:  2344  Loss:  0.5255786   Accuracy:  0.8515625\n",
      "Iteration:  2345  Loss:  0.3720289   Accuracy:  0.8984375\n",
      "Iteration:  2346  Loss:  0.5615248   Accuracy:  0.8828125\n",
      "Iteration:  2347  Loss:  0.33446896   Accuracy:  0.90625\n",
      "Iteration:  2348  Loss:  0.424576   Accuracy:  0.9140625\n",
      "Iteration:  2349  Loss:  0.566174   Accuracy:  0.890625\n",
      "Iteration:  2350  Loss:  0.24918266   Accuracy:  0.9296875\n",
      "Iteration:  2351  Loss:  0.32736564   Accuracy:  0.90625\n",
      "Iteration:  2352  Loss:  0.5910374   Accuracy:  0.90625\n",
      "Iteration:  2353  Loss:  0.2847921   Accuracy:  0.9375\n",
      "Iteration:  2354  Loss:  0.6770475   Accuracy:  0.890625\n",
      "Iteration:  2355  Loss:  0.4862245   Accuracy:  0.890625\n",
      "Iteration:  2356  Loss:  0.73568106   Accuracy:  0.90625\n",
      "Iteration:  2357  Loss:  0.29232687   Accuracy:  0.921875\n",
      "Iteration:  2358  Loss:  0.5519272   Accuracy:  0.8671875\n",
      "Iteration:  2359  Loss:  0.45448655   Accuracy:  0.8671875\n",
      "Iteration:  2360  Loss:  0.33508155   Accuracy:  0.9375\n",
      "Iteration:  2361  Loss:  0.3832965   Accuracy:  0.90625\n",
      "Iteration:  2362  Loss:  0.27251166   Accuracy:  0.921875\n",
      "Iteration:  2363  Loss:  0.7191572   Accuracy:  0.859375\n",
      "Iteration:  2364  Loss:  0.3735066   Accuracy:  0.90625\n",
      "Iteration:  2365  Loss:  0.49432382   Accuracy:  0.875\n",
      "Iteration:  2366  Loss:  0.451232   Accuracy:  0.8984375\n",
      "Iteration:  2367  Loss:  0.9007112   Accuracy:  0.84375\n",
      "Iteration:  2368  Loss:  0.27042514   Accuracy:  0.90625\n",
      "Iteration:  2369  Loss:  0.34998834   Accuracy:  0.90625\n",
      "Iteration:  2370  Loss:  0.40495378   Accuracy:  0.875\n",
      "Iteration:  2371  Loss:  0.13399708   Accuracy:  0.9609375\n",
      "Iteration:  2372  Loss:  0.4507411   Accuracy:  0.8984375\n",
      "Iteration:  2373  Loss:  0.34445783   Accuracy:  0.90625\n",
      "Iteration:  2374  Loss:  0.29285818   Accuracy:  0.90625\n",
      "Iteration:  2375  Loss:  0.68536747   Accuracy:  0.8359375\n",
      "Iteration:  2376  Loss:  0.3945743   Accuracy:  0.90625\n",
      "Iteration:  2377  Loss:  0.4144635   Accuracy:  0.8828125\n",
      "Iteration:  2378  Loss:  0.14477551   Accuracy:  0.9296875\n",
      "Iteration:  2379  Loss:  0.15168032   Accuracy:  0.953125\n",
      "Iteration:  2380  Loss:  0.32332402   Accuracy:  0.8984375\n",
      "Iteration:  2381  Loss:  0.2969414   Accuracy:  0.9140625\n",
      "Iteration:  2382  Loss:  0.31226677   Accuracy:  0.8984375\n",
      "Iteration:  2383  Loss:  0.35968527   Accuracy:  0.8984375\n",
      "Iteration:  2384  Loss:  0.24182683   Accuracy:  0.90625\n",
      "Iteration:  2385  Loss:  0.64619714   Accuracy:  0.875\n",
      "Iteration:  2386  Loss:  0.3314895   Accuracy:  0.890625\n",
      "Iteration:  2387  Loss:  0.2523955   Accuracy:  0.9296875\n",
      "Iteration:  2388  Loss:  0.34180403   Accuracy:  0.9140625\n",
      "Iteration:  2389  Loss:  0.2772228   Accuracy:  0.8828125\n",
      "Iteration:  2390  Loss:  0.4211883   Accuracy:  0.890625\n",
      "Iteration:  2391  Loss:  0.437751   Accuracy:  0.8828125\n",
      "Iteration:  2392  Loss:  0.2645686   Accuracy:  0.8984375\n",
      "Iteration:  2393  Loss:  0.4061829   Accuracy:  0.90625\n",
      "Iteration:  2394  Loss:  0.386159   Accuracy:  0.9296875\n",
      "Iteration:  2395  Loss:  0.186569   Accuracy:  0.9375\n",
      "Iteration:  2396  Loss:  0.4249208   Accuracy:  0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2397  Loss:  0.36911273   Accuracy:  0.8671875\n",
      "Iteration:  2398  Loss:  0.55826485   Accuracy:  0.859375\n",
      "Iteration:  2399  Loss:  0.3726619   Accuracy:  0.8984375\n",
      "Iteration:  2400  Loss:  0.33811644   Accuracy:  0.90625\n",
      "Iteration:  2401  Loss:  0.6226644   Accuracy:  0.875\n",
      "Iteration:  2402  Loss:  0.6459597   Accuracy:  0.828125\n",
      "Iteration:  2403  Loss:  0.54466414   Accuracy:  0.8828125\n",
      "Iteration:  2404  Loss:  0.5359559   Accuracy:  0.8671875\n",
      "Iteration:  2405  Loss:  0.28681   Accuracy:  0.9140625\n",
      "Iteration:  2406  Loss:  0.40993202   Accuracy:  0.890625\n",
      "Iteration:  2407  Loss:  0.52677184   Accuracy:  0.9140625\n",
      "Iteration:  2408  Loss:  0.5903425   Accuracy:  0.8515625\n",
      "Iteration:  2409  Loss:  0.3483274   Accuracy:  0.90625\n",
      "Iteration:  2410  Loss:  0.17691065   Accuracy:  0.9453125\n",
      "Iteration:  2411  Loss:  0.42135975   Accuracy:  0.859375\n",
      "Iteration:  2412  Loss:  0.31842545   Accuracy:  0.9296875\n",
      "Iteration:  2413  Loss:  0.50421023   Accuracy:  0.90625\n",
      "Iteration:  2414  Loss:  0.31179565   Accuracy:  0.9140625\n",
      "Iteration:  2415  Loss:  0.40468872   Accuracy:  0.8984375\n",
      "Iteration:  2416  Loss:  0.351187   Accuracy:  0.890625\n",
      "Iteration:  2417  Loss:  0.1558426   Accuracy:  0.9453125\n",
      "Iteration:  2418  Loss:  0.30919173   Accuracy:  0.9296875\n",
      "Iteration:  2419  Loss:  0.5794096   Accuracy:  0.8515625\n",
      "Iteration:  2420  Loss:  0.30011982   Accuracy:  0.890625\n",
      "Iteration:  2421  Loss:  0.19223216   Accuracy:  0.9140625\n",
      "Iteration:  2422  Loss:  0.4896525   Accuracy:  0.8671875\n",
      "Iteration:  2423  Loss:  0.27835447   Accuracy:  0.9140625\n",
      "Iteration:  2424  Loss:  0.5978771   Accuracy:  0.890625\n",
      "Iteration:  2425  Loss:  0.24745777   Accuracy:  0.9296875\n",
      "Iteration:  2426  Loss:  0.42643565   Accuracy:  0.9296875\n",
      "Iteration:  2427  Loss:  0.67432153   Accuracy:  0.8828125\n",
      "Iteration:  2428  Loss:  0.1397988   Accuracy:  0.953125\n",
      "Iteration:  2429  Loss:  0.74252653   Accuracy:  0.875\n",
      "Iteration:  2430  Loss:  0.47232386   Accuracy:  0.890625\n",
      "Iteration:  2431  Loss:  0.56958866   Accuracy:  0.8828125\n",
      "Iteration:  2432  Loss:  0.50404346   Accuracy:  0.8515625\n",
      "Iteration:  2433  Loss:  0.1593429   Accuracy:  0.9375\n",
      "Iteration:  2434  Loss:  0.49176228   Accuracy:  0.8671875\n",
      "Iteration:  2435  Loss:  0.5517568   Accuracy:  0.8984375\n",
      "Iteration:  2436  Loss:  0.24132383   Accuracy:  0.9296875\n",
      "Iteration:  2437  Loss:  0.49263382   Accuracy:  0.890625\n",
      "Iteration:  2438  Loss:  0.29550856   Accuracy:  0.90625\n",
      "Iteration:  2439  Loss:  0.34840515   Accuracy:  0.875\n",
      "Iteration:  2440  Loss:  0.23016764   Accuracy:  0.921875\n",
      "Iteration:  2441  Loss:  0.32808727   Accuracy:  0.90625\n",
      "Iteration:  2442  Loss:  0.33962232   Accuracy:  0.9140625\n",
      "Iteration:  2443  Loss:  0.41790378   Accuracy:  0.90625\n",
      "Iteration:  2444  Loss:  0.46612543   Accuracy:  0.8671875\n",
      "Iteration:  2445  Loss:  0.38988507   Accuracy:  0.8984375\n",
      "Iteration:  2446  Loss:  0.47048855   Accuracy:  0.8984375\n",
      "Iteration:  2447  Loss:  0.35393202   Accuracy:  0.875\n",
      "Iteration:  2448  Loss:  0.38516527   Accuracy:  0.8984375\n",
      "Iteration:  2449  Loss:  0.59303164   Accuracy:  0.8515625\n",
      "Iteration:  2450  Loss:  0.23770085   Accuracy:  0.9296875\n",
      "Iteration:  2451  Loss:  0.32042545   Accuracy:  0.9375\n",
      "Iteration:  2452  Loss:  0.7522332   Accuracy:  0.859375\n",
      "Iteration:  2453  Loss:  0.4418271   Accuracy:  0.890625\n",
      "Iteration:  2454  Loss:  0.27205038   Accuracy:  0.9296875\n",
      "Iteration:  2455  Loss:  0.36947325   Accuracy:  0.8515625\n",
      "Iteration:  2456  Loss:  0.63369673   Accuracy:  0.890625\n",
      "Iteration:  2457  Loss:  0.49268547   Accuracy:  0.875\n",
      "Iteration:  2458  Loss:  0.49723536   Accuracy:  0.8671875\n",
      "Iteration:  2459  Loss:  0.7096681   Accuracy:  0.8671875\n",
      "Iteration:  2460  Loss:  0.15606819   Accuracy:  0.9609375\n",
      "Iteration:  2461  Loss:  0.4773447   Accuracy:  0.90625\n",
      "Iteration:  2462  Loss:  0.20122227   Accuracy:  0.9296875\n",
      "Iteration:  2463  Loss:  0.44057113   Accuracy:  0.8828125\n",
      "Iteration:  2464  Loss:  0.41601062   Accuracy:  0.9140625\n",
      "Iteration:  2465  Loss:  0.29004568   Accuracy:  0.9140625\n",
      "Iteration:  2466  Loss:  0.3037847   Accuracy:  0.8984375\n",
      "Iteration:  2467  Loss:  0.2385491   Accuracy:  0.9296875\n",
      "Iteration:  2468  Loss:  0.48137808   Accuracy:  0.890625\n",
      "Iteration:  2469  Loss:  0.41517717   Accuracy:  0.8984375\n",
      "Iteration:  2470  Loss:  0.35447067   Accuracy:  0.90625\n",
      "Iteration:  2471  Loss:  0.37683365   Accuracy:  0.9296875\n",
      "Iteration:  2472  Loss:  0.6891064   Accuracy:  0.8828125\n",
      "Iteration:  2473  Loss:  0.4564494   Accuracy:  0.890625\n",
      "Iteration:  2474  Loss:  0.69603145   Accuracy:  0.8515625\n",
      "Iteration:  2475  Loss:  0.31726858   Accuracy:  0.8828125\n",
      "Iteration:  2476  Loss:  0.3799273   Accuracy:  0.8671875\n",
      "Iteration:  2477  Loss:  0.4195162   Accuracy:  0.8984375\n",
      "Iteration:  2478  Loss:  0.34287694   Accuracy:  0.9296875\n",
      "Iteration:  2479  Loss:  0.4133932   Accuracy:  0.8671875\n",
      "Iteration:  2480  Loss:  0.415331   Accuracy:  0.890625\n",
      "Iteration:  2481  Loss:  0.45432198   Accuracy:  0.8828125\n",
      "Iteration:  2482  Loss:  0.41802782   Accuracy:  0.890625\n",
      "Iteration:  2483  Loss:  0.46154588   Accuracy:  0.84375\n",
      "Iteration:  2484  Loss:  0.36332148   Accuracy:  0.8984375\n",
      "Iteration:  2485  Loss:  0.4488578   Accuracy:  0.890625\n",
      "Iteration:  2486  Loss:  0.58072   Accuracy:  0.8671875\n",
      "Iteration:  2487  Loss:  0.38027263   Accuracy:  0.9140625\n",
      "Iteration:  2488  Loss:  0.39407504   Accuracy:  0.8828125\n",
      "Iteration:  2489  Loss:  0.14324191   Accuracy:  0.9453125\n",
      "Iteration:  2490  Loss:  0.5630631   Accuracy:  0.875\n",
      "Iteration:  2491  Loss:  0.23929575   Accuracy:  0.9453125\n",
      "Iteration:  2492  Loss:  0.3100385   Accuracy:  0.9140625\n",
      "Iteration:  2493  Loss:  0.28155383   Accuracy:  0.9375\n",
      "Iteration:  2494  Loss:  0.4853888   Accuracy:  0.859375\n",
      "Iteration:  2495  Loss:  0.45127314   Accuracy:  0.890625\n",
      "Iteration:  2496  Loss:  0.39699033   Accuracy:  0.8671875\n",
      "Iteration:  2497  Loss:  0.6701052   Accuracy:  0.8828125\n",
      "Iteration:  2498  Loss:  0.568197   Accuracy:  0.8671875\n",
      "Iteration:  2499  Loss:  0.5411253   Accuracy:  0.8828125\n",
      "Iteration:  2500  Loss:  0.65339875   Accuracy:  0.8671875\n",
      "Iteration:  2501  Loss:  0.44043553   Accuracy:  0.90625\n",
      "Iteration:  2502  Loss:  0.6690867   Accuracy:  0.8515625\n",
      "Iteration:  2503  Loss:  0.41519037   Accuracy:  0.890625\n",
      "Iteration:  2504  Loss:  0.28823927   Accuracy:  0.8828125\n",
      "Iteration:  2505  Loss:  0.35345316   Accuracy:  0.890625\n",
      "Iteration:  2506  Loss:  0.35534608   Accuracy:  0.8984375\n",
      "Iteration:  2507  Loss:  0.73663706   Accuracy:  0.8359375\n",
      "Iteration:  2508  Loss:  0.34724784   Accuracy:  0.9296875\n",
      "Iteration:  2509  Loss:  0.29814798   Accuracy:  0.9296875\n",
      "Iteration:  2510  Loss:  0.3221039   Accuracy:  0.8984375\n",
      "Iteration:  2511  Loss:  0.42705852   Accuracy:  0.90625\n",
      "Iteration:  2512  Loss:  0.38022843   Accuracy:  0.8984375\n",
      "Iteration:  2513  Loss:  0.47480914   Accuracy:  0.8984375\n",
      "Iteration:  2514  Loss:  0.42500186   Accuracy:  0.875\n",
      "Iteration:  2515  Loss:  0.41587412   Accuracy:  0.8984375\n",
      "Iteration:  2516  Loss:  0.56285834   Accuracy:  0.84375\n",
      "Iteration:  2517  Loss:  0.44254923   Accuracy:  0.890625\n",
      "Iteration:  2518  Loss:  0.6228851   Accuracy:  0.859375\n",
      "Iteration:  2519  Loss:  0.23748507   Accuracy:  0.90625\n",
      "Iteration:  2520  Loss:  0.52658796   Accuracy:  0.875\n",
      "Iteration:  2521  Loss:  0.5194477   Accuracy:  0.890625\n",
      "Iteration:  2522  Loss:  0.37395766   Accuracy:  0.8828125\n",
      "Iteration:  2523  Loss:  0.38922137   Accuracy:  0.875\n",
      "Iteration:  2524  Loss:  0.54769605   Accuracy:  0.8671875\n",
      "Iteration:  2525  Loss:  0.45317242   Accuracy:  0.859375\n",
      "Iteration:  2526  Loss:  0.529654   Accuracy:  0.8828125\n",
      "Iteration:  2527  Loss:  0.3118182   Accuracy:  0.8984375\n",
      "Iteration:  2528  Loss:  0.38399646   Accuracy:  0.9140625\n",
      "Iteration:  2529  Loss:  0.32311586   Accuracy:  0.9140625\n",
      "Iteration:  2530  Loss:  0.5457021   Accuracy:  0.890625\n",
      "Iteration:  2531  Loss:  0.3572305   Accuracy:  0.890625\n",
      "Iteration:  2532  Loss:  0.529084   Accuracy:  0.859375\n",
      "Iteration:  2533  Loss:  0.36544552   Accuracy:  0.8984375\n",
      "Iteration:  2534  Loss:  0.19960509   Accuracy:  0.921875\n",
      "Iteration:  2535  Loss:  0.5616225   Accuracy:  0.8828125\n",
      "Iteration:  2536  Loss:  0.469425   Accuracy:  0.8828125\n",
      "Iteration:  2537  Loss:  0.36199182   Accuracy:  0.921875\n",
      "Iteration:  2538  Loss:  0.21408862   Accuracy:  0.9140625\n",
      "Iteration:  2539  Loss:  0.37957165   Accuracy:  0.9140625\n",
      "Iteration:  2540  Loss:  0.46765405   Accuracy:  0.875\n",
      "Iteration:  2541  Loss:  0.29600883   Accuracy:  0.9140625\n",
      "Iteration:  2542  Loss:  0.6347778   Accuracy:  0.828125\n",
      "Iteration:  2543  Loss:  0.67746145   Accuracy:  0.859375\n",
      "Iteration:  2544  Loss:  0.2171639   Accuracy:  0.9375\n",
      "Iteration:  2545  Loss:  0.42117083   Accuracy:  0.921875\n",
      "Iteration:  2546  Loss:  0.26112613   Accuracy:  0.9296875\n",
      "Iteration:  2547  Loss:  0.4036575   Accuracy:  0.9140625\n",
      "Iteration:  2548  Loss:  0.23287646   Accuracy:  0.9609375\n",
      "Iteration:  2549  Loss:  0.4256859   Accuracy:  0.890625\n",
      "Iteration:  2550  Loss:  0.42227945   Accuracy:  0.875\n",
      "Iteration:  2551  Loss:  0.5484636   Accuracy:  0.84375\n",
      "Iteration:  2552  Loss:  0.25896746   Accuracy:  0.921875\n",
      "Iteration:  2553  Loss:  0.6987457   Accuracy:  0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2554  Loss:  0.4985719   Accuracy:  0.90625\n",
      "Iteration:  2555  Loss:  0.34552768   Accuracy:  0.921875\n",
      "Iteration:  2556  Loss:  0.47869864   Accuracy:  0.8828125\n",
      "Iteration:  2557  Loss:  0.32604086   Accuracy:  0.9140625\n",
      "Iteration:  2558  Loss:  0.31067678   Accuracy:  0.9140625\n",
      "Iteration:  2559  Loss:  0.19993296   Accuracy:  0.9296875\n",
      "Iteration:  2560  Loss:  0.36616895   Accuracy:  0.90625\n",
      "Iteration:  2561  Loss:  0.4825252   Accuracy:  0.8984375\n",
      "Iteration:  2562  Loss:  0.53601366   Accuracy:  0.875\n",
      "Iteration:  2563  Loss:  0.46609682   Accuracy:  0.875\n",
      "Iteration:  2564  Loss:  0.529164   Accuracy:  0.8828125\n",
      "Iteration:  2565  Loss:  0.6529537   Accuracy:  0.90625\n",
      "Iteration:  2566  Loss:  0.64453906   Accuracy:  0.8671875\n",
      "Iteration:  2567  Loss:  0.32468987   Accuracy:  0.9140625\n",
      "Iteration:  2568  Loss:  0.1824305   Accuracy:  0.9375\n",
      "Iteration:  2569  Loss:  0.34213534   Accuracy:  0.921875\n",
      "Iteration:  2570  Loss:  0.25566095   Accuracy:  0.9140625\n",
      "Iteration:  2571  Loss:  0.6286054   Accuracy:  0.875\n",
      "Iteration:  2572  Loss:  0.3676418   Accuracy:  0.890625\n",
      "Iteration:  2573  Loss:  0.501765   Accuracy:  0.921875\n",
      "Iteration:  2574  Loss:  0.3966908   Accuracy:  0.890625\n",
      "Iteration:  2575  Loss:  0.3918152   Accuracy:  0.8828125\n",
      "Iteration:  2576  Loss:  0.3622508   Accuracy:  0.890625\n",
      "Iteration:  2577  Loss:  0.2726606   Accuracy:  0.9296875\n",
      "Iteration:  2578  Loss:  0.31616426   Accuracy:  0.921875\n",
      "Iteration:  2579  Loss:  0.40919733   Accuracy:  0.8984375\n",
      "Iteration:  2580  Loss:  0.5567769   Accuracy:  0.8671875\n",
      "Iteration:  2581  Loss:  0.4276337   Accuracy:  0.8984375\n",
      "Iteration:  2582  Loss:  0.49914998   Accuracy:  0.8671875\n",
      "Iteration:  2583  Loss:  0.34317398   Accuracy:  0.875\n",
      "Iteration:  2584  Loss:  0.21170026   Accuracy:  0.921875\n",
      "Iteration:  2585  Loss:  0.6542042   Accuracy:  0.859375\n",
      "Iteration:  2586  Loss:  0.5781678   Accuracy:  0.890625\n",
      "Iteration:  2587  Loss:  0.55619013   Accuracy:  0.875\n",
      "Iteration:  2588  Loss:  0.22444853   Accuracy:  0.9375\n",
      "Iteration:  2589  Loss:  0.42207056   Accuracy:  0.921875\n",
      "Iteration:  2590  Loss:  0.33116376   Accuracy:  0.921875\n",
      "Iteration:  2591  Loss:  0.37994725   Accuracy:  0.8984375\n",
      "Iteration:  2592  Loss:  0.5848961   Accuracy:  0.890625\n",
      "Iteration:  2593  Loss:  0.35590994   Accuracy:  0.8828125\n",
      "Iteration:  2594  Loss:  0.4767192   Accuracy:  0.890625\n",
      "Iteration:  2595  Loss:  0.32782826   Accuracy:  0.90625\n",
      "Iteration:  2596  Loss:  0.25436497   Accuracy:  0.8984375\n",
      "Iteration:  2597  Loss:  0.28884512   Accuracy:  0.9375\n",
      "Iteration:  2598  Loss:  0.47142333   Accuracy:  0.90625\n",
      "Iteration:  2599  Loss:  0.33809885   Accuracy:  0.953125\n",
      "Iteration:  2600  Loss:  0.42351785   Accuracy:  0.875\n",
      "Iteration:  2601  Loss:  0.6260847   Accuracy:  0.8984375\n",
      "Iteration:  2602  Loss:  0.25178707   Accuracy:  0.9453125\n",
      "Iteration:  2603  Loss:  0.4004228   Accuracy:  0.875\n",
      "Iteration:  2604  Loss:  0.48350483   Accuracy:  0.84375\n",
      "Iteration:  2605  Loss:  0.40949824   Accuracy:  0.8984375\n",
      "Iteration:  2606  Loss:  0.36885846   Accuracy:  0.8984375\n",
      "Iteration:  2607  Loss:  0.42668653   Accuracy:  0.8828125\n",
      "Iteration:  2608  Loss:  0.37693226   Accuracy:  0.921875\n",
      "Iteration:  2609  Loss:  0.32545155   Accuracy:  0.90625\n",
      "Iteration:  2610  Loss:  0.3624687   Accuracy:  0.8984375\n",
      "Iteration:  2611  Loss:  0.49872956   Accuracy:  0.8515625\n",
      "Iteration:  2612  Loss:  0.4240977   Accuracy:  0.859375\n",
      "Iteration:  2613  Loss:  0.61063737   Accuracy:  0.8828125\n",
      "Iteration:  2614  Loss:  0.32153612   Accuracy:  0.8828125\n",
      "Iteration:  2615  Loss:  0.27739486   Accuracy:  0.921875\n",
      "Iteration:  2616  Loss:  0.23960961   Accuracy:  0.890625\n",
      "Iteration:  2617  Loss:  0.2928856   Accuracy:  0.9140625\n",
      "Iteration:  2618  Loss:  0.19952478   Accuracy:  0.9375\n",
      "Iteration:  2619  Loss:  0.3012346   Accuracy:  0.90625\n",
      "Iteration:  2620  Loss:  0.30465925   Accuracy:  0.921875\n",
      "Iteration:  2621  Loss:  0.28026226   Accuracy:  0.9296875\n",
      "Iteration:  2622  Loss:  0.44380742   Accuracy:  0.8828125\n",
      "Iteration:  2623  Loss:  0.5554025   Accuracy:  0.859375\n",
      "Iteration:  2624  Loss:  0.39847094   Accuracy:  0.9140625\n",
      "Iteration:  2625  Loss:  0.41704503   Accuracy:  0.8828125\n",
      "Iteration:  2626  Loss:  0.36640456   Accuracy:  0.890625\n",
      "Iteration:  2627  Loss:  0.36442122   Accuracy:  0.859375\n",
      "Iteration:  2628  Loss:  0.39760515   Accuracy:  0.8984375\n",
      "Iteration:  2629  Loss:  0.23155689   Accuracy:  0.953125\n",
      "Iteration:  2630  Loss:  0.28389338   Accuracy:  0.921875\n",
      "Iteration:  2631  Loss:  0.5484253   Accuracy:  0.8984375\n",
      "Iteration:  2632  Loss:  0.39938408   Accuracy:  0.8984375\n",
      "Iteration:  2633  Loss:  0.6443758   Accuracy:  0.875\n",
      "Iteration:  2634  Loss:  0.37173408   Accuracy:  0.875\n",
      "Iteration:  2635  Loss:  0.68520373   Accuracy:  0.890625\n",
      "Iteration:  2636  Loss:  0.34091526   Accuracy:  0.8828125\n",
      "Iteration:  2637  Loss:  0.16351864   Accuracy:  0.9296875\n",
      "Iteration:  2638  Loss:  0.39793587   Accuracy:  0.8828125\n",
      "Iteration:  2639  Loss:  0.39986163   Accuracy:  0.8828125\n",
      "Iteration:  2640  Loss:  0.45244086   Accuracy:  0.9140625\n",
      "Iteration:  2641  Loss:  0.54522276   Accuracy:  0.890625\n",
      "Iteration:  2642  Loss:  0.49768162   Accuracy:  0.8671875\n",
      "Iteration:  2643  Loss:  0.3678158   Accuracy:  0.921875\n",
      "Iteration:  2644  Loss:  0.27731025   Accuracy:  0.9453125\n",
      "Iteration:  2645  Loss:  0.40251005   Accuracy:  0.890625\n",
      "Iteration:  2646  Loss:  0.35728988   Accuracy:  0.875\n",
      "Iteration:  2647  Loss:  0.5178051   Accuracy:  0.875\n",
      "Iteration:  2648  Loss:  0.2493366   Accuracy:  0.9453125\n",
      "Iteration:  2649  Loss:  0.36054313   Accuracy:  0.8828125\n",
      "Iteration:  2650  Loss:  0.50296485   Accuracy:  0.8984375\n",
      "Iteration:  2651  Loss:  0.28436   Accuracy:  0.90625\n",
      "Iteration:  2652  Loss:  0.5199669   Accuracy:  0.890625\n",
      "Iteration:  2653  Loss:  0.5946916   Accuracy:  0.8828125\n",
      "Iteration:  2654  Loss:  0.49945277   Accuracy:  0.875\n",
      "Iteration:  2655  Loss:  0.41484153   Accuracy:  0.921875\n",
      "Iteration:  2656  Loss:  0.58671844   Accuracy:  0.859375\n",
      "Iteration:  2657  Loss:  0.28663418   Accuracy:  0.9375\n",
      "Iteration:  2658  Loss:  0.54738396   Accuracy:  0.8515625\n",
      "Iteration:  2659  Loss:  0.51539624   Accuracy:  0.8671875\n",
      "Iteration:  2660  Loss:  0.306948   Accuracy:  0.90625\n",
      "Iteration:  2661  Loss:  0.36717644   Accuracy:  0.921875\n",
      "Iteration:  2662  Loss:  0.43808046   Accuracy:  0.8828125\n",
      "Iteration:  2663  Loss:  0.28510493   Accuracy:  0.8984375\n",
      "Iteration:  2664  Loss:  0.36048922   Accuracy:  0.90625\n",
      "Iteration:  2665  Loss:  0.42018604   Accuracy:  0.8828125\n",
      "Iteration:  2666  Loss:  0.1582934   Accuracy:  0.9453125\n",
      "Iteration:  2667  Loss:  0.42553422   Accuracy:  0.875\n",
      "Iteration:  2668  Loss:  0.5191419   Accuracy:  0.8828125\n",
      "Iteration:  2669  Loss:  0.4103443   Accuracy:  0.9375\n",
      "Iteration:  2670  Loss:  0.26476836   Accuracy:  0.9296875\n",
      "Iteration:  2671  Loss:  0.33623356   Accuracy:  0.9140625\n",
      "Iteration:  2672  Loss:  0.21169573   Accuracy:  0.9453125\n",
      "Iteration:  2673  Loss:  0.31687492   Accuracy:  0.9453125\n",
      "Iteration:  2674  Loss:  0.50458765   Accuracy:  0.8828125\n",
      "Iteration:  2675  Loss:  0.22092745   Accuracy:  0.9296875\n",
      "Iteration:  2676  Loss:  0.5390191   Accuracy:  0.875\n",
      "Iteration:  2677  Loss:  0.5464507   Accuracy:  0.8515625\n",
      "Iteration:  2678  Loss:  0.52181333   Accuracy:  0.890625\n",
      "Iteration:  2679  Loss:  0.46396956   Accuracy:  0.859375\n",
      "Iteration:  2680  Loss:  0.23828675   Accuracy:  0.8984375\n",
      "Iteration:  2681  Loss:  0.5765862   Accuracy:  0.875\n",
      "Iteration:  2682  Loss:  0.5473522   Accuracy:  0.8984375\n",
      "Iteration:  2683  Loss:  0.49965814   Accuracy:  0.90625\n",
      "Iteration:  2684  Loss:  0.5416843   Accuracy:  0.8984375\n",
      "Iteration:  2685  Loss:  0.26579562   Accuracy:  0.9296875\n",
      "Iteration:  2686  Loss:  0.28876925   Accuracy:  0.90625\n",
      "Iteration:  2687  Loss:  0.64027345   Accuracy:  0.8828125\n",
      "Iteration:  2688  Loss:  0.41936615   Accuracy:  0.8984375\n",
      "Iteration:  2689  Loss:  0.45994264   Accuracy:  0.9140625\n",
      "Iteration:  2690  Loss:  0.37866586   Accuracy:  0.90625\n",
      "Iteration:  2691  Loss:  0.48769724   Accuracy:  0.859375\n",
      "Iteration:  2692  Loss:  0.45853555   Accuracy:  0.8984375\n",
      "Iteration:  2693  Loss:  0.27133888   Accuracy:  0.921875\n",
      "Iteration:  2694  Loss:  0.423541   Accuracy:  0.8984375\n",
      "Iteration:  2695  Loss:  0.36277774   Accuracy:  0.8984375\n",
      "Iteration:  2696  Loss:  0.5383081   Accuracy:  0.8671875\n",
      "Iteration:  2697  Loss:  0.39880213   Accuracy:  0.8671875\n",
      "Iteration:  2698  Loss:  0.5725834   Accuracy:  0.8359375\n",
      "Iteration:  2699  Loss:  0.54825366   Accuracy:  0.8984375\n",
      "Iteration:  2700  Loss:  0.42012262   Accuracy:  0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2701  Loss:  0.2931909   Accuracy:  0.9296875\n",
      "Iteration:  2702  Loss:  0.22491209   Accuracy:  0.921875\n",
      "Iteration:  2703  Loss:  0.46034035   Accuracy:  0.890625\n",
      "Iteration:  2704  Loss:  0.24819729   Accuracy:  0.9296875\n",
      "Iteration:  2705  Loss:  0.4841984   Accuracy:  0.8671875\n",
      "Iteration:  2706  Loss:  0.2949175   Accuracy:  0.921875\n",
      "Iteration:  2707  Loss:  0.3864773   Accuracy:  0.8984375\n",
      "Iteration:  2708  Loss:  0.32832998   Accuracy:  0.90625\n",
      "Iteration:  2709  Loss:  0.49271494   Accuracy:  0.890625\n",
      "Iteration:  2710  Loss:  0.35306   Accuracy:  0.9140625\n",
      "Iteration:  2711  Loss:  0.31714585   Accuracy:  0.9140625\n",
      "Iteration:  2712  Loss:  0.36998406   Accuracy:  0.90625\n",
      "Iteration:  2713  Loss:  0.7281851   Accuracy:  0.8671875\n",
      "Iteration:  2714  Loss:  0.15010598   Accuracy:  0.9375\n",
      "Iteration:  2715  Loss:  0.39649504   Accuracy:  0.875\n",
      "Iteration:  2716  Loss:  0.45705205   Accuracy:  0.875\n",
      "Iteration:  2717  Loss:  0.29261148   Accuracy:  0.9140625\n",
      "Iteration:  2718  Loss:  0.38427508   Accuracy:  0.9453125\n",
      "Iteration:  2719  Loss:  0.44059056   Accuracy:  0.8828125\n",
      "Iteration:  2720  Loss:  0.28381515   Accuracy:  0.9140625\n",
      "Iteration:  2721  Loss:  0.47775197   Accuracy:  0.921875\n",
      "Iteration:  2722  Loss:  0.27600685   Accuracy:  0.9296875\n",
      "Iteration:  2723  Loss:  0.33713818   Accuracy:  0.921875\n",
      "Iteration:  2724  Loss:  0.4567257   Accuracy:  0.875\n",
      "Iteration:  2725  Loss:  0.37023246   Accuracy:  0.859375\n",
      "Iteration:  2726  Loss:  0.32123864   Accuracy:  0.8828125\n",
      "Iteration:  2727  Loss:  0.24238555   Accuracy:  0.921875\n",
      "Iteration:  2728  Loss:  0.2088299   Accuracy:  0.921875\n",
      "Iteration:  2729  Loss:  0.47021905   Accuracy:  0.8828125\n",
      "Iteration:  2730  Loss:  0.37211847   Accuracy:  0.8984375\n",
      "Iteration:  2731  Loss:  0.43774056   Accuracy:  0.9296875\n",
      "Iteration:  2732  Loss:  0.44538754   Accuracy:  0.8984375\n",
      "Iteration:  2733  Loss:  0.7821175   Accuracy:  0.8515625\n",
      "Iteration:  2734  Loss:  0.41148245   Accuracy:  0.8984375\n",
      "Iteration:  2735  Loss:  0.40819234   Accuracy:  0.9140625\n",
      "Iteration:  2736  Loss:  0.23770586   Accuracy:  0.9140625\n",
      "Iteration:  2737  Loss:  0.33537218   Accuracy:  0.890625\n",
      "Iteration:  2738  Loss:  0.24470899   Accuracy:  0.9296875\n",
      "Iteration:  2739  Loss:  0.3656929   Accuracy:  0.875\n",
      "Iteration:  2740  Loss:  0.30458727   Accuracy:  0.8828125\n",
      "Iteration:  2741  Loss:  0.44811982   Accuracy:  0.859375\n",
      "Iteration:  2742  Loss:  0.6223594   Accuracy:  0.8828125\n",
      "Iteration:  2743  Loss:  0.46919757   Accuracy:  0.875\n",
      "Iteration:  2744  Loss:  0.27649075   Accuracy:  0.921875\n",
      "Iteration:  2745  Loss:  0.43283176   Accuracy:  0.8828125\n",
      "Iteration:  2746  Loss:  0.39833644   Accuracy:  0.890625\n",
      "Iteration:  2747  Loss:  0.4118506   Accuracy:  0.84375\n",
      "Iteration:  2748  Loss:  0.2753624   Accuracy:  0.9296875\n",
      "Iteration:  2749  Loss:  0.40571418   Accuracy:  0.8984375\n",
      "Iteration:  2750  Loss:  0.38672432   Accuracy:  0.8671875\n",
      "Iteration:  2751  Loss:  0.31386456   Accuracy:  0.9140625\n",
      "Iteration:  2752  Loss:  0.46469072   Accuracy:  0.890625\n",
      "Iteration:  2753  Loss:  0.6738473   Accuracy:  0.8515625\n",
      "Iteration:  2754  Loss:  0.5011425   Accuracy:  0.8671875\n",
      "Iteration:  2755  Loss:  0.53950125   Accuracy:  0.828125\n",
      "Iteration:  2756  Loss:  0.58759874   Accuracy:  0.875\n",
      "Iteration:  2757  Loss:  0.23623487   Accuracy:  0.9375\n",
      "Iteration:  2758  Loss:  0.40490168   Accuracy:  0.90625\n",
      "Iteration:  2759  Loss:  0.5169594   Accuracy:  0.875\n",
      "Iteration:  2760  Loss:  0.37313366   Accuracy:  0.8984375\n",
      "Iteration:  2761  Loss:  0.23701602   Accuracy:  0.9296875\n",
      "Iteration:  2762  Loss:  0.35773635   Accuracy:  0.8828125\n",
      "Iteration:  2763  Loss:  0.28999186   Accuracy:  0.90625\n",
      "Iteration:  2764  Loss:  0.42630532   Accuracy:  0.9140625\n",
      "Iteration:  2765  Loss:  0.539019   Accuracy:  0.890625\n",
      "Iteration:  2766  Loss:  0.46603304   Accuracy:  0.84375\n",
      "Iteration:  2767  Loss:  0.50920904   Accuracy:  0.8828125\n",
      "Iteration:  2768  Loss:  0.31927478   Accuracy:  0.8984375\n",
      "Iteration:  2769  Loss:  0.49191535   Accuracy:  0.921875\n",
      "Iteration:  2770  Loss:  0.54900527   Accuracy:  0.90625\n",
      "Iteration:  2771  Loss:  0.29670504   Accuracy:  0.921875\n",
      "Iteration:  2772  Loss:  0.5716535   Accuracy:  0.875\n",
      "Iteration:  2773  Loss:  0.69801456   Accuracy:  0.8359375\n",
      "Iteration:  2774  Loss:  0.4831544   Accuracy:  0.875\n",
      "Iteration:  2775  Loss:  0.66643417   Accuracy:  0.84375\n",
      "Iteration:  2776  Loss:  0.27016336   Accuracy:  0.9140625\n",
      "Iteration:  2777  Loss:  0.33200648   Accuracy:  0.90625\n",
      "Iteration:  2778  Loss:  0.51695436   Accuracy:  0.8984375\n",
      "Iteration:  2779  Loss:  0.51993895   Accuracy:  0.8671875\n",
      "Iteration:  2780  Loss:  0.36078256   Accuracy:  0.8828125\n",
      "Iteration:  2781  Loss:  0.56084305   Accuracy:  0.90625\n",
      "Iteration:  2782  Loss:  0.31548572   Accuracy:  0.921875\n",
      "Iteration:  2783  Loss:  0.51727295   Accuracy:  0.8828125\n",
      "Iteration:  2784  Loss:  0.41451657   Accuracy:  0.921875\n",
      "Iteration:  2785  Loss:  0.22485395   Accuracy:  0.90625\n",
      "Iteration:  2786  Loss:  0.53964007   Accuracy:  0.859375\n",
      "Iteration:  2787  Loss:  0.36160752   Accuracy:  0.9140625\n",
      "Iteration:  2788  Loss:  0.36488783   Accuracy:  0.8828125\n",
      "Iteration:  2789  Loss:  0.6580057   Accuracy:  0.875\n",
      "Iteration:  2790  Loss:  0.41766557   Accuracy:  0.9140625\n",
      "Iteration:  2791  Loss:  0.28565258   Accuracy:  0.9140625\n",
      "Iteration:  2792  Loss:  0.28873911   Accuracy:  0.9140625\n",
      "Iteration:  2793  Loss:  0.16627933   Accuracy:  0.9609375\n",
      "Iteration:  2794  Loss:  0.35402197   Accuracy:  0.9453125\n",
      "Iteration:  2795  Loss:  0.39291477   Accuracy:  0.890625\n",
      "Iteration:  2796  Loss:  0.3268689   Accuracy:  0.953125\n",
      "Iteration:  2797  Loss:  0.38229036   Accuracy:  0.8828125\n",
      "Iteration:  2798  Loss:  0.27702993   Accuracy:  0.9296875\n",
      "Iteration:  2799  Loss:  0.2953995   Accuracy:  0.9375\n",
      "Iteration:  2800  Loss:  0.3480331   Accuracy:  0.90625\n",
      "Iteration:  2801  Loss:  0.36278543   Accuracy:  0.875\n",
      "Iteration:  2802  Loss:  0.28037256   Accuracy:  0.8984375\n",
      "Iteration:  2803  Loss:  0.6546491   Accuracy:  0.8203125\n",
      "Iteration:  2804  Loss:  0.34853244   Accuracy:  0.890625\n",
      "Iteration:  2805  Loss:  0.3665514   Accuracy:  0.8828125\n",
      "Iteration:  2806  Loss:  0.28721598   Accuracy:  0.90625\n",
      "Iteration:  2807  Loss:  0.47948757   Accuracy:  0.875\n",
      "Iteration:  2808  Loss:  0.35524508   Accuracy:  0.890625\n",
      "Iteration:  2809  Loss:  0.27247053   Accuracy:  0.921875\n",
      "Iteration:  2810  Loss:  0.38809073   Accuracy:  0.8828125\n",
      "Iteration:  2811  Loss:  0.33644205   Accuracy:  0.8984375\n",
      "Iteration:  2812  Loss:  0.44839758   Accuracy:  0.890625\n",
      "Iteration:  2813  Loss:  0.4673213   Accuracy:  0.9140625\n",
      "Iteration:  2814  Loss:  0.4413815   Accuracy:  0.875\n",
      "Iteration:  2815  Loss:  0.58002865   Accuracy:  0.84375\n",
      "Iteration:  2816  Loss:  0.29636192   Accuracy:  0.859375\n",
      "Iteration:  2817  Loss:  0.36911806   Accuracy:  0.8828125\n",
      "Iteration:  2818  Loss:  0.22592275   Accuracy:  0.921875\n",
      "Iteration:  2819  Loss:  0.12628977   Accuracy:  0.9609375\n",
      "Iteration:  2820  Loss:  0.34484926   Accuracy:  0.9140625\n",
      "Iteration:  2821  Loss:  0.44787827   Accuracy:  0.890625\n",
      "Iteration:  2822  Loss:  0.37871107   Accuracy:  0.90625\n",
      "Iteration:  2823  Loss:  0.33032048   Accuracy:  0.921875\n",
      "Iteration:  2824  Loss:  0.42010185   Accuracy:  0.890625\n",
      "Iteration:  2825  Loss:  0.48517025   Accuracy:  0.8828125\n",
      "Iteration:  2826  Loss:  0.5542431   Accuracy:  0.9140625\n",
      "Iteration:  2827  Loss:  0.47826815   Accuracy:  0.875\n",
      "Iteration:  2828  Loss:  0.5390377   Accuracy:  0.8515625\n",
      "Iteration:  2829  Loss:  0.41482607   Accuracy:  0.8984375\n",
      "Iteration:  2830  Loss:  0.29053006   Accuracy:  0.8984375\n",
      "Iteration:  2831  Loss:  0.46120107   Accuracy:  0.890625\n",
      "Iteration:  2832  Loss:  0.64027613   Accuracy:  0.8203125\n",
      "Iteration:  2833  Loss:  0.5813339   Accuracy:  0.859375\n",
      "Iteration:  2834  Loss:  0.16680123   Accuracy:  0.9375\n",
      "Iteration:  2835  Loss:  0.50583386   Accuracy:  0.8984375\n",
      "Iteration:  2836  Loss:  0.4936298   Accuracy:  0.8671875\n",
      "Iteration:  2837  Loss:  0.3296517   Accuracy:  0.921875\n",
      "Iteration:  2838  Loss:  0.4760702   Accuracy:  0.890625\n",
      "Iteration:  2839  Loss:  0.50415325   Accuracy:  0.890625\n",
      "Iteration:  2840  Loss:  0.65799344   Accuracy:  0.8671875\n",
      "Iteration:  2841  Loss:  0.31939864   Accuracy:  0.9140625\n",
      "Iteration:  2842  Loss:  0.3792227   Accuracy:  0.8984375\n",
      "Iteration:  2843  Loss:  0.63245565   Accuracy:  0.8828125\n",
      "Iteration:  2844  Loss:  0.24957544   Accuracy:  0.9375\n",
      "Iteration:  2845  Loss:  0.3636956   Accuracy:  0.8984375\n",
      "Iteration:  2846  Loss:  0.41437495   Accuracy:  0.8828125\n",
      "Iteration:  2847  Loss:  0.44490048   Accuracy:  0.8671875\n",
      "Iteration:  2848  Loss:  0.38810715   Accuracy:  0.8828125\n",
      "Iteration:  2849  Loss:  0.5053487   Accuracy:  0.859375\n",
      "Iteration:  2850  Loss:  0.5152941   Accuracy:  0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2851  Loss:  0.32029933   Accuracy:  0.9296875\n",
      "Iteration:  2852  Loss:  0.31993306   Accuracy:  0.8828125\n",
      "Iteration:  2853  Loss:  0.49902046   Accuracy:  0.921875\n",
      "Iteration:  2854  Loss:  0.27528244   Accuracy:  0.90625\n",
      "Iteration:  2855  Loss:  0.12256184   Accuracy:  0.9453125\n",
      "Iteration:  2856  Loss:  0.3634717   Accuracy:  0.9375\n",
      "Iteration:  2857  Loss:  0.5927897   Accuracy:  0.8671875\n",
      "Iteration:  2858  Loss:  0.49636573   Accuracy:  0.859375\n",
      "Iteration:  2859  Loss:  0.33730355   Accuracy:  0.8984375\n",
      "Iteration:  2860  Loss:  0.40809736   Accuracy:  0.9296875\n",
      "Iteration:  2861  Loss:  0.4749969   Accuracy:  0.90625\n",
      "Iteration:  2862  Loss:  0.5650627   Accuracy:  0.921875\n",
      "Iteration:  2863  Loss:  0.32564354   Accuracy:  0.8984375\n",
      "Iteration:  2864  Loss:  0.5974647   Accuracy:  0.8828125\n",
      "Iteration:  2865  Loss:  0.61534774   Accuracy:  0.890625\n",
      "Iteration:  2866  Loss:  0.32234073   Accuracy:  0.9140625\n",
      "Iteration:  2867  Loss:  0.40157914   Accuracy:  0.8984375\n",
      "Iteration:  2868  Loss:  0.35061955   Accuracy:  0.921875\n",
      "Iteration:  2869  Loss:  0.24539223   Accuracy:  0.9296875\n",
      "Iteration:  2870  Loss:  0.29030117   Accuracy:  0.90625\n",
      "Iteration:  2871  Loss:  0.63976055   Accuracy:  0.90625\n",
      "Iteration:  2872  Loss:  0.27466998   Accuracy:  0.9375\n",
      "Iteration:  2873  Loss:  0.3419932   Accuracy:  0.90625\n",
      "Iteration:  2874  Loss:  0.44792104   Accuracy:  0.890625\n",
      "Iteration:  2875  Loss:  0.22898655   Accuracy:  0.921875\n",
      "Iteration:  2876  Loss:  0.2750824   Accuracy:  0.9375\n",
      "Iteration:  2877  Loss:  0.4328201   Accuracy:  0.8984375\n",
      "Iteration:  2878  Loss:  0.16210952   Accuracy:  0.953125\n",
      "Iteration:  2879  Loss:  0.3227558   Accuracy:  0.921875\n",
      "Iteration:  2880  Loss:  0.3338787   Accuracy:  0.90625\n",
      "Iteration:  2881  Loss:  0.51608634   Accuracy:  0.84375\n",
      "Iteration:  2882  Loss:  0.14329804   Accuracy:  0.9609375\n",
      "Iteration:  2883  Loss:  0.538556   Accuracy:  0.875\n",
      "Iteration:  2884  Loss:  0.28869805   Accuracy:  0.8984375\n",
      "Iteration:  2885  Loss:  0.45642036   Accuracy:  0.9375\n",
      "Iteration:  2886  Loss:  0.38828832   Accuracy:  0.890625\n",
      "Iteration:  2887  Loss:  0.4707724   Accuracy:  0.8984375\n",
      "Iteration:  2888  Loss:  0.7103034   Accuracy:  0.8671875\n",
      "Iteration:  2889  Loss:  0.36470047   Accuracy:  0.9296875\n",
      "Iteration:  2890  Loss:  0.27920192   Accuracy:  0.8984375\n",
      "Iteration:  2891  Loss:  0.2702383   Accuracy:  0.8828125\n",
      "Iteration:  2892  Loss:  0.4706902   Accuracy:  0.890625\n",
      "Iteration:  2893  Loss:  0.33632106   Accuracy:  0.890625\n",
      "Iteration:  2894  Loss:  0.47144908   Accuracy:  0.90625\n",
      "Iteration:  2895  Loss:  0.5266322   Accuracy:  0.8984375\n",
      "Iteration:  2896  Loss:  0.30209303   Accuracy:  0.90625\n",
      "Iteration:  2897  Loss:  0.39432153   Accuracy:  0.890625\n",
      "Iteration:  2898  Loss:  0.27695173   Accuracy:  0.9453125\n",
      "Iteration:  2899  Loss:  0.4730518   Accuracy:  0.890625\n",
      "Iteration:  2900  Loss:  0.23112041   Accuracy:  0.9453125\n",
      "Iteration:  2901  Loss:  0.43605664   Accuracy:  0.8828125\n",
      "Iteration:  2902  Loss:  0.45835826   Accuracy:  0.875\n",
      "Iteration:  2903  Loss:  0.36931473   Accuracy:  0.875\n",
      "Iteration:  2904  Loss:  0.29586402   Accuracy:  0.921875\n",
      "Iteration:  2905  Loss:  0.6338082   Accuracy:  0.890625\n",
      "Iteration:  2906  Loss:  0.7181528   Accuracy:  0.8515625\n",
      "Iteration:  2907  Loss:  0.63769615   Accuracy:  0.8828125\n",
      "Iteration:  2908  Loss:  0.48410922   Accuracy:  0.875\n",
      "Iteration:  2909  Loss:  0.3676598   Accuracy:  0.8828125\n",
      "Iteration:  2910  Loss:  0.33514225   Accuracy:  0.9375\n",
      "Iteration:  2911  Loss:  0.34563142   Accuracy:  0.875\n",
      "Iteration:  2912  Loss:  0.39985698   Accuracy:  0.890625\n",
      "Iteration:  2913  Loss:  0.5874149   Accuracy:  0.875\n",
      "Iteration:  2914  Loss:  0.38287663   Accuracy:  0.890625\n",
      "Iteration:  2915  Loss:  0.33284622   Accuracy:  0.8984375\n",
      "Iteration:  2916  Loss:  0.34329784   Accuracy:  0.90625\n",
      "Iteration:  2917  Loss:  0.46743977   Accuracy:  0.875\n",
      "Iteration:  2918  Loss:  0.2542234   Accuracy:  0.9140625\n",
      "Iteration:  2919  Loss:  0.3332099   Accuracy:  0.921875\n",
      "Iteration:  2920  Loss:  0.45774466   Accuracy:  0.8828125\n",
      "Iteration:  2921  Loss:  0.31764972   Accuracy:  0.90625\n",
      "Iteration:  2922  Loss:  0.58362734   Accuracy:  0.84375\n",
      "Iteration:  2923  Loss:  0.5111289   Accuracy:  0.9453125\n",
      "Iteration:  2924  Loss:  0.27742466   Accuracy:  0.90625\n",
      "Iteration:  2925  Loss:  0.36092532   Accuracy:  0.953125\n",
      "Iteration:  2926  Loss:  0.25027263   Accuracy:  0.890625\n",
      "Iteration:  2927  Loss:  0.36796206   Accuracy:  0.90625\n",
      "Iteration:  2928  Loss:  0.43802518   Accuracy:  0.8671875\n",
      "Iteration:  2929  Loss:  0.29371333   Accuracy:  0.921875\n",
      "Iteration:  2930  Loss:  0.5106517   Accuracy:  0.8984375\n",
      "Iteration:  2931  Loss:  0.55344105   Accuracy:  0.828125\n",
      "Iteration:  2932  Loss:  0.49612054   Accuracy:  0.8828125\n",
      "Iteration:  2933  Loss:  0.56890345   Accuracy:  0.859375\n",
      "Iteration:  2934  Loss:  0.36191058   Accuracy:  0.875\n",
      "Iteration:  2935  Loss:  0.44211   Accuracy:  0.8984375\n",
      "Iteration:  2936  Loss:  0.34891695   Accuracy:  0.90625\n",
      "Iteration:  2937  Loss:  0.31882563   Accuracy:  0.90625\n",
      "Iteration:  2938  Loss:  0.36667943   Accuracy:  0.859375\n",
      "Iteration:  2939  Loss:  0.25785857   Accuracy:  0.9453125\n",
      "Iteration:  2940  Loss:  0.23168871   Accuracy:  0.8984375\n",
      "Iteration:  2941  Loss:  0.38779652   Accuracy:  0.8984375\n",
      "Iteration:  2942  Loss:  0.34831697   Accuracy:  0.8984375\n",
      "Iteration:  2943  Loss:  0.113069944   Accuracy:  0.9609375\n",
      "Iteration:  2944  Loss:  0.50022954   Accuracy:  0.8984375\n",
      "Iteration:  2945  Loss:  0.7166647   Accuracy:  0.859375\n",
      "Iteration:  2946  Loss:  0.42643708   Accuracy:  0.8515625\n",
      "Iteration:  2947  Loss:  0.47014764   Accuracy:  0.875\n",
      "Iteration:  2948  Loss:  0.37948012   Accuracy:  0.875\n",
      "Iteration:  2949  Loss:  0.46410674   Accuracy:  0.8984375\n",
      "Iteration:  2950  Loss:  0.5320863   Accuracy:  0.8828125\n",
      "Iteration:  2951  Loss:  0.463795   Accuracy:  0.859375\n",
      "Iteration:  2952  Loss:  0.43487555   Accuracy:  0.875\n",
      "Iteration:  2953  Loss:  0.44494057   Accuracy:  0.8671875\n",
      "Iteration:  2954  Loss:  0.37460655   Accuracy:  0.90625\n",
      "Iteration:  2955  Loss:  0.36457172   Accuracy:  0.921875\n",
      "Iteration:  2956  Loss:  0.23991528   Accuracy:  0.921875\n",
      "Iteration:  2957  Loss:  0.5738997   Accuracy:  0.8828125\n",
      "Iteration:  2958  Loss:  0.5775469   Accuracy:  0.859375\n",
      "Iteration:  2959  Loss:  0.32666874   Accuracy:  0.9296875\n",
      "Iteration:  2960  Loss:  0.19102663   Accuracy:  0.9375\n",
      "Iteration:  2961  Loss:  0.2015282   Accuracy:  0.921875\n",
      "Iteration:  2962  Loss:  0.20742276   Accuracy:  0.9296875\n",
      "Iteration:  2963  Loss:  0.5849544   Accuracy:  0.8671875\n",
      "Iteration:  2964  Loss:  0.375219   Accuracy:  0.8828125\n",
      "Iteration:  2965  Loss:  0.6464651   Accuracy:  0.890625\n",
      "Iteration:  2966  Loss:  0.52533114   Accuracy:  0.890625\n",
      "Iteration:  2967  Loss:  0.4436833   Accuracy:  0.875\n",
      "Iteration:  2968  Loss:  0.4897553   Accuracy:  0.90625\n",
      "Iteration:  2969  Loss:  0.36689478   Accuracy:  0.9296875\n",
      "Iteration:  2970  Loss:  0.36184478   Accuracy:  0.90625\n",
      "Iteration:  2971  Loss:  0.33814776   Accuracy:  0.8828125\n",
      "Iteration:  2972  Loss:  0.30503917   Accuracy:  0.90625\n",
      "Iteration:  2973  Loss:  0.26243907   Accuracy:  0.8984375\n",
      "Iteration:  2974  Loss:  0.20634149   Accuracy:  0.921875\n",
      "Iteration:  2975  Loss:  0.25013286   Accuracy:  0.90625\n",
      "Iteration:  2976  Loss:  0.21970333   Accuracy:  0.9296875\n",
      "Iteration:  2977  Loss:  0.420817   Accuracy:  0.890625\n",
      "Iteration:  2978  Loss:  0.4769143   Accuracy:  0.8828125\n",
      "Iteration:  2979  Loss:  0.39400092   Accuracy:  0.8828125\n",
      "Iteration:  2980  Loss:  0.5349605   Accuracy:  0.8359375\n",
      "Iteration:  2981  Loss:  0.35818404   Accuracy:  0.8828125\n",
      "Iteration:  2982  Loss:  0.31475592   Accuracy:  0.9140625\n",
      "Iteration:  2983  Loss:  0.35709667   Accuracy:  0.921875\n",
      "Iteration:  2984  Loss:  0.5167849   Accuracy:  0.90625\n",
      "Iteration:  2985  Loss:  0.60349417   Accuracy:  0.8828125\n",
      "Iteration:  2986  Loss:  0.3630031   Accuracy:  0.8828125\n",
      "Iteration:  2987  Loss:  0.22708604   Accuracy:  0.9375\n",
      "Iteration:  2988  Loss:  0.3333465   Accuracy:  0.8984375\n",
      "Iteration:  2989  Loss:  0.51032066   Accuracy:  0.90625\n",
      "Iteration:  2990  Loss:  0.3831827   Accuracy:  0.9375\n",
      "Iteration:  2991  Loss:  0.20385207   Accuracy:  0.921875\n",
      "Iteration:  2992  Loss:  0.37657934   Accuracy:  0.921875\n",
      "Iteration:  2993  Loss:  0.74020493   Accuracy:  0.8671875\n",
      "Iteration:  2994  Loss:  0.34320226   Accuracy:  0.875\n",
      "Iteration:  2995  Loss:  0.22106397   Accuracy:  0.9140625\n",
      "Iteration:  2996  Loss:  0.37352228   Accuracy:  0.8984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2997  Loss:  0.3951866   Accuracy:  0.859375\n",
      "Iteration:  2998  Loss:  0.33719188   Accuracy:  0.90625\n",
      "Iteration:  2999  Loss:  0.31611493   Accuracy:  0.9375\n",
      "Iteration:  3000  Loss:  0.43546343   Accuracy:  0.8671875\n",
      "Iteration:  3001  Loss:  0.3293457   Accuracy:  0.921875\n",
      "Iteration:  3002  Loss:  0.5708073   Accuracy:  0.8671875\n",
      "Iteration:  3003  Loss:  0.59707844   Accuracy:  0.8515625\n",
      "Iteration:  3004  Loss:  0.38539553   Accuracy:  0.921875\n",
      "Iteration:  3005  Loss:  0.37525162   Accuracy:  0.8984375\n",
      "Iteration:  3006  Loss:  0.6193323   Accuracy:  0.9140625\n",
      "Iteration:  3007  Loss:  0.23666981   Accuracy:  0.8984375\n",
      "Iteration:  3008  Loss:  0.5799966   Accuracy:  0.8828125\n",
      "Iteration:  3009  Loss:  0.41552657   Accuracy:  0.9140625\n",
      "Iteration:  3010  Loss:  0.36128274   Accuracy:  0.8828125\n",
      "Iteration:  3011  Loss:  0.5971811   Accuracy:  0.90625\n",
      "Iteration:  3012  Loss:  0.38488436   Accuracy:  0.8984375\n",
      "Iteration:  3013  Loss:  0.40234113   Accuracy:  0.890625\n",
      "Iteration:  3014  Loss:  0.41968971   Accuracy:  0.90625\n",
      "Iteration:  3015  Loss:  0.42527065   Accuracy:  0.8828125\n",
      "Iteration:  3016  Loss:  0.42968178   Accuracy:  0.9140625\n",
      "Iteration:  3017  Loss:  0.20286785   Accuracy:  0.9296875\n",
      "Iteration:  3018  Loss:  0.6278513   Accuracy:  0.859375\n",
      "Iteration:  3019  Loss:  0.29833594   Accuracy:  0.9140625\n",
      "Iteration:  3020  Loss:  0.31848088   Accuracy:  0.921875\n",
      "Iteration:  3021  Loss:  0.4912631   Accuracy:  0.8984375\n",
      "Iteration:  3022  Loss:  0.5987254   Accuracy:  0.8515625\n",
      "Iteration:  3023  Loss:  0.39361954   Accuracy:  0.8828125\n",
      "Iteration:  3024  Loss:  0.18947405   Accuracy:  0.9453125\n",
      "Iteration:  3025  Loss:  0.26880783   Accuracy:  0.9140625\n",
      "Iteration:  3026  Loss:  0.54393697   Accuracy:  0.875\n",
      "Iteration:  3027  Loss:  0.34335595   Accuracy:  0.890625\n",
      "Iteration:  3028  Loss:  0.5245876   Accuracy:  0.9140625\n",
      "Iteration:  3029  Loss:  0.14569563   Accuracy:  0.953125\n",
      "Iteration:  3030  Loss:  0.17399463   Accuracy:  0.9453125\n",
      "Iteration:  3031  Loss:  0.46575588   Accuracy:  0.8828125\n",
      "Iteration:  3032  Loss:  0.5001896   Accuracy:  0.90625\n",
      "Iteration:  3033  Loss:  0.31002346   Accuracy:  0.921875\n",
      "Iteration:  3034  Loss:  0.4469831   Accuracy:  0.9140625\n",
      "Iteration:  3035  Loss:  0.34410053   Accuracy:  0.9140625\n",
      "Iteration:  3036  Loss:  0.5992237   Accuracy:  0.828125\n",
      "Iteration:  3037  Loss:  0.27931538   Accuracy:  0.9296875\n",
      "Iteration:  3038  Loss:  0.48434922   Accuracy:  0.8984375\n",
      "Iteration:  3039  Loss:  0.46971697   Accuracy:  0.8984375\n",
      "Iteration:  3040  Loss:  0.40685004   Accuracy:  0.921875\n",
      "Iteration:  3041  Loss:  0.22458763   Accuracy:  0.9375\n",
      "Iteration:  3042  Loss:  0.37656903   Accuracy:  0.8671875\n",
      "Iteration:  3043  Loss:  0.37653306   Accuracy:  0.8984375\n",
      "Iteration:  3044  Loss:  0.200344   Accuracy:  0.9453125\n",
      "Iteration:  3045  Loss:  0.42824036   Accuracy:  0.8984375\n",
      "Iteration:  3046  Loss:  0.65413195   Accuracy:  0.90625\n",
      "Iteration:  3047  Loss:  0.40971798   Accuracy:  0.8671875\n",
      "Iteration:  3048  Loss:  0.4359741   Accuracy:  0.890625\n",
      "Iteration:  3049  Loss:  0.45210904   Accuracy:  0.875\n",
      "Iteration:  3050  Loss:  0.27530688   Accuracy:  0.921875\n",
      "Iteration:  3051  Loss:  0.22343127   Accuracy:  0.953125\n",
      "Iteration:  3052  Loss:  0.5371908   Accuracy:  0.8828125\n",
      "Iteration:  3053  Loss:  0.4432783   Accuracy:  0.859375\n",
      "Iteration:  3054  Loss:  0.18151826   Accuracy:  0.9296875\n",
      "Iteration:  3055  Loss:  0.44324952   Accuracy:  0.8828125\n",
      "Iteration:  3056  Loss:  0.30662185   Accuracy:  0.9140625\n",
      "Iteration:  3057  Loss:  0.36815748   Accuracy:  0.875\n",
      "Iteration:  3058  Loss:  0.5954846   Accuracy:  0.8984375\n",
      "Iteration:  3059  Loss:  0.44337702   Accuracy:  0.8984375\n",
      "Iteration:  3060  Loss:  0.6022749   Accuracy:  0.8515625\n",
      "Iteration:  3061  Loss:  0.38743272   Accuracy:  0.8828125\n",
      "Iteration:  3062  Loss:  0.57877296   Accuracy:  0.8515625\n",
      "Iteration:  3063  Loss:  0.31200808   Accuracy:  0.90625\n",
      "Iteration:  3064  Loss:  0.31109747   Accuracy:  0.8984375\n",
      "Iteration:  3065  Loss:  0.31661594   Accuracy:  0.890625\n",
      "Iteration:  3066  Loss:  0.62274075   Accuracy:  0.828125\n",
      "Iteration:  3067  Loss:  0.401114   Accuracy:  0.890625\n",
      "Iteration:  3068  Loss:  0.37976143   Accuracy:  0.921875\n",
      "Iteration:  3069  Loss:  0.3238601   Accuracy:  0.9140625\n",
      "Iteration:  3070  Loss:  0.35680562   Accuracy:  0.890625\n",
      "Iteration:  3071  Loss:  0.35248452   Accuracy:  0.8984375\n",
      "Iteration:  3072  Loss:  0.45376432   Accuracy:  0.8828125\n",
      "Iteration:  3073  Loss:  0.34261942   Accuracy:  0.90625\n",
      "Iteration:  3074  Loss:  0.30494243   Accuracy:  0.9140625\n",
      "Iteration:  3075  Loss:  0.24057092   Accuracy:  0.921875\n",
      "Iteration:  3076  Loss:  0.30159792   Accuracy:  0.9140625\n",
      "Iteration:  3077  Loss:  0.43642724   Accuracy:  0.9375\n",
      "Iteration:  3078  Loss:  0.5346997   Accuracy:  0.890625\n",
      "Iteration:  3079  Loss:  0.273381   Accuracy:  0.8984375\n",
      "Iteration:  3080  Loss:  0.24494165   Accuracy:  0.890625\n",
      "Iteration:  3081  Loss:  0.34872103   Accuracy:  0.859375\n",
      "Iteration:  3082  Loss:  0.3747735   Accuracy:  0.9140625\n",
      "Iteration:  3083  Loss:  0.31410426   Accuracy:  0.890625\n",
      "Iteration:  3084  Loss:  0.5535619   Accuracy:  0.8671875\n",
      "Iteration:  3085  Loss:  0.38523367   Accuracy:  0.890625\n",
      "Iteration:  3086  Loss:  0.39732516   Accuracy:  0.8671875\n",
      "Iteration:  3087  Loss:  0.41687462   Accuracy:  0.8984375\n",
      "Iteration:  3088  Loss:  0.3895771   Accuracy:  0.8984375\n",
      "Iteration:  3089  Loss:  0.4960066   Accuracy:  0.921875\n",
      "Iteration:  3090  Loss:  0.22593352   Accuracy:  0.9140625\n",
      "Iteration:  3091  Loss:  0.31774276   Accuracy:  0.9140625\n",
      "Iteration:  3092  Loss:  0.42695516   Accuracy:  0.8671875\n",
      "Iteration:  3093  Loss:  0.393292   Accuracy:  0.8828125\n",
      "Iteration:  3094  Loss:  0.7293208   Accuracy:  0.8671875\n",
      "Iteration:  3095  Loss:  0.09041588   Accuracy:  0.96875\n",
      "Iteration:  3096  Loss:  0.62611836   Accuracy:  0.9140625\n",
      "Iteration:  3097  Loss:  0.2765084   Accuracy:  0.953125\n",
      "Iteration:  3098  Loss:  0.34989828   Accuracy:  0.875\n",
      "Iteration:  3099  Loss:  0.38197017   Accuracy:  0.890625\n",
      "Iteration:  3100  Loss:  0.3214506   Accuracy:  0.890625\n",
      "Iteration:  3101  Loss:  0.54852617   Accuracy:  0.8359375\n",
      "Iteration:  3102  Loss:  0.29658395   Accuracy:  0.8984375\n",
      "Iteration:  3103  Loss:  0.42411426   Accuracy:  0.890625\n",
      "Iteration:  3104  Loss:  0.34117696   Accuracy:  0.9140625\n",
      "Iteration:  3105  Loss:  0.41821134   Accuracy:  0.8828125\n",
      "Iteration:  3106  Loss:  0.3779093   Accuracy:  0.9296875\n",
      "Iteration:  3107  Loss:  0.33460554   Accuracy:  0.9140625\n",
      "Iteration:  3108  Loss:  0.37858278   Accuracy:  0.890625\n",
      "Iteration:  3109  Loss:  0.24978156   Accuracy:  0.9296875\n",
      "Iteration:  3110  Loss:  0.39077717   Accuracy:  0.921875\n",
      "Iteration:  3111  Loss:  0.40204325   Accuracy:  0.875\n",
      "Iteration:  3112  Loss:  0.44676757   Accuracy:  0.890625\n",
      "Iteration:  3113  Loss:  0.14946412   Accuracy:  0.953125\n",
      "Iteration:  3114  Loss:  0.3389849   Accuracy:  0.890625\n",
      "Iteration:  3115  Loss:  0.30441493   Accuracy:  0.921875\n",
      "Iteration:  3116  Loss:  0.5237935   Accuracy:  0.890625\n",
      "Iteration:  3117  Loss:  0.24999171   Accuracy:  0.890625\n",
      "Iteration:  3118  Loss:  0.45653474   Accuracy:  0.875\n",
      "Iteration:  3119  Loss:  0.28500858   Accuracy:  0.9140625\n",
      "Iteration:  3120  Loss:  0.3202419   Accuracy:  0.921875\n",
      "Iteration:  3121  Loss:  0.54616827   Accuracy:  0.859375\n",
      "Iteration:  3122  Loss:  0.52492714   Accuracy:  0.890625\n",
      "Iteration:  3123  Loss:  0.2470552   Accuracy:  0.90625\n",
      "Iteration:  3124  Loss:  0.2799013   Accuracy:  0.9375\n",
      "Iteration:  3125  Loss:  0.46105373   Accuracy:  0.8828125\n",
      "Iteration:  3126  Loss:  0.2359575   Accuracy:  0.9453125\n",
      "Iteration:  3127  Loss:  0.2780637   Accuracy:  0.9375\n",
      "Iteration:  3128  Loss:  0.36977965   Accuracy:  0.890625\n",
      "Iteration:  3129  Loss:  0.8161875   Accuracy:  0.796875\n",
      "Iteration:  3130  Loss:  0.48689955   Accuracy:  0.8984375\n",
      "Iteration:  3131  Loss:  0.2518203   Accuracy:  0.9140625\n",
      "Iteration:  3132  Loss:  0.37368405   Accuracy:  0.890625\n",
      "Iteration:  3133  Loss:  0.3083345   Accuracy:  0.9140625\n",
      "Iteration:  3134  Loss:  0.3846957   Accuracy:  0.9296875\n",
      "Iteration:  3135  Loss:  0.38684082   Accuracy:  0.8828125\n",
      "Iteration:  3136  Loss:  0.27982235   Accuracy:  0.9140625\n",
      "Iteration:  3137  Loss:  0.35083044   Accuracy:  0.9140625\n",
      "Iteration:  3138  Loss:  0.4754165   Accuracy:  0.875\n",
      "Iteration:  3139  Loss:  0.28343546   Accuracy:  0.921875\n",
      "Iteration:  3140  Loss:  0.7771551   Accuracy:  0.875\n",
      "Iteration:  3141  Loss:  0.24902476   Accuracy:  0.921875\n",
      "Iteration:  3142  Loss:  0.47213113   Accuracy:  0.8984375\n",
      "Iteration:  3143  Loss:  0.2834977   Accuracy:  0.9140625\n",
      "Iteration:  3144  Loss:  0.6478383   Accuracy:  0.8515625\n",
      "Iteration:  3145  Loss:  0.22843748   Accuracy:  0.9296875\n",
      "Iteration:  3146  Loss:  0.36626887   Accuracy:  0.9140625\n",
      "Iteration:  3147  Loss:  0.2582981   Accuracy:  0.90625\n",
      "Iteration:  3148  Loss:  0.2676777   Accuracy:  0.8984375\n",
      "Iteration:  3149  Loss:  0.5715082   Accuracy:  0.9296875\n",
      "Iteration:  3150  Loss:  0.32596517   Accuracy:  0.9140625\n",
      "Iteration:  3151  Loss:  0.19517252   Accuracy:  0.9453125\n",
      "Iteration:  3152  Loss:  0.40791056   Accuracy:  0.8984375\n",
      "Iteration:  3153  Loss:  0.44034073   Accuracy:  0.8828125\n",
      "Iteration:  3154  Loss:  0.3556726   Accuracy:  0.9140625\n",
      "Iteration:  3155  Loss:  0.28033084   Accuracy:  0.8984375\n",
      "Iteration:  3156  Loss:  0.37192655   Accuracy:  0.921875\n",
      "Iteration:  3157  Loss:  0.30182806   Accuracy:  0.9140625\n",
      "Iteration:  3158  Loss:  0.42033878   Accuracy:  0.875\n",
      "Iteration:  3159  Loss:  0.278648   Accuracy:  0.9296875\n",
      "Iteration:  3160  Loss:  0.61492205   Accuracy:  0.875\n",
      "Iteration:  3161  Loss:  0.62094545   Accuracy:  0.8828125\n",
      "Iteration:  3162  Loss:  0.37415624   Accuracy:  0.921875\n",
      "Iteration:  3163  Loss:  0.29858518   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3164  Loss:  0.4120413   Accuracy:  0.890625\n",
      "Iteration:  3165  Loss:  0.53251266   Accuracy:  0.875\n",
      "Iteration:  3166  Loss:  0.23664206   Accuracy:  0.9140625\n",
      "Iteration:  3167  Loss:  0.36785093   Accuracy:  0.8671875\n",
      "Iteration:  3168  Loss:  0.25959978   Accuracy:  0.9296875\n",
      "Iteration:  3169  Loss:  0.35546094   Accuracy:  0.90625\n",
      "Iteration:  3170  Loss:  0.46018577   Accuracy:  0.9140625\n",
      "Iteration:  3171  Loss:  0.3145637   Accuracy:  0.890625\n",
      "Iteration:  3172  Loss:  0.18121526   Accuracy:  0.9453125\n",
      "Iteration:  3173  Loss:  0.29081008   Accuracy:  0.8984375\n",
      "Iteration:  3174  Loss:  0.18599747   Accuracy:  0.9375\n",
      "Iteration:  3175  Loss:  0.3930306   Accuracy:  0.8828125\n",
      "Iteration:  3176  Loss:  0.4969756   Accuracy:  0.9140625\n",
      "Iteration:  3177  Loss:  0.4486593   Accuracy:  0.890625\n",
      "Iteration:  3178  Loss:  0.31705907   Accuracy:  0.9375\n",
      "Iteration:  3179  Loss:  0.23234367   Accuracy:  0.9375\n",
      "Iteration:  3180  Loss:  0.35476506   Accuracy:  0.9375\n",
      "Iteration:  3181  Loss:  0.2404612   Accuracy:  0.9609375\n",
      "Iteration:  3182  Loss:  0.2725435   Accuracy:  0.90625\n",
      "Iteration:  3183  Loss:  0.23842037   Accuracy:  0.921875\n",
      "Iteration:  3184  Loss:  0.5974606   Accuracy:  0.8984375\n",
      "Iteration:  3185  Loss:  0.5053475   Accuracy:  0.8515625\n",
      "Iteration:  3186  Loss:  0.23930056   Accuracy:  0.9296875\n",
      "Iteration:  3187  Loss:  0.3140062   Accuracy:  0.9140625\n",
      "Iteration:  3188  Loss:  0.23035155   Accuracy:  0.8984375\n",
      "Iteration:  3189  Loss:  0.36963084   Accuracy:  0.9453125\n",
      "Iteration:  3190  Loss:  0.5346408   Accuracy:  0.890625\n",
      "Iteration:  3191  Loss:  0.23278657   Accuracy:  0.9375\n",
      "Iteration:  3192  Loss:  0.46904   Accuracy:  0.9140625\n",
      "Iteration:  3193  Loss:  0.61525536   Accuracy:  0.859375\n",
      "Iteration:  3194  Loss:  0.19835244   Accuracy:  0.9296875\n",
      "Iteration:  3195  Loss:  0.36139604   Accuracy:  0.890625\n",
      "Iteration:  3196  Loss:  0.28232354   Accuracy:  0.8984375\n",
      "Iteration:  3197  Loss:  0.4051228   Accuracy:  0.8984375\n",
      "Iteration:  3198  Loss:  0.7378066   Accuracy:  0.859375\n",
      "Iteration:  3199  Loss:  0.25537443   Accuracy:  0.9140625\n",
      "Iteration:  3200  Loss:  0.3587193   Accuracy:  0.9140625\n",
      "Iteration:  3201  Loss:  0.5474138   Accuracy:  0.890625\n",
      "Iteration:  3202  Loss:  0.27678576   Accuracy:  0.8984375\n",
      "Iteration:  3203  Loss:  0.5687293   Accuracy:  0.8828125\n",
      "Iteration:  3204  Loss:  0.78512806   Accuracy:  0.8359375\n",
      "Iteration:  3205  Loss:  0.5155795   Accuracy:  0.9140625\n",
      "Iteration:  3206  Loss:  0.325998   Accuracy:  0.890625\n",
      "Iteration:  3207  Loss:  0.38308233   Accuracy:  0.859375\n",
      "Iteration:  3208  Loss:  0.18855105   Accuracy:  0.9296875\n",
      "Iteration:  3209  Loss:  0.48331875   Accuracy:  0.84375\n",
      "Iteration:  3210  Loss:  0.4058906   Accuracy:  0.8828125\n",
      "Iteration:  3211  Loss:  0.5309191   Accuracy:  0.8671875\n",
      "Iteration:  3212  Loss:  0.27564263   Accuracy:  0.953125\n",
      "Iteration:  3213  Loss:  0.31585482   Accuracy:  0.90625\n",
      "Iteration:  3214  Loss:  0.27748725   Accuracy:  0.9296875\n",
      "Iteration:  3215  Loss:  0.29349375   Accuracy:  0.8828125\n",
      "Iteration:  3216  Loss:  0.45103094   Accuracy:  0.890625\n",
      "Iteration:  3217  Loss:  0.47649255   Accuracy:  0.890625\n",
      "Iteration:  3218  Loss:  0.6399033   Accuracy:  0.8828125\n",
      "Iteration:  3219  Loss:  0.2962222   Accuracy:  0.90625\n",
      "Iteration:  3220  Loss:  0.46711397   Accuracy:  0.875\n",
      "Iteration:  3221  Loss:  0.3267808   Accuracy:  0.921875\n",
      "Iteration:  3222  Loss:  0.3636386   Accuracy:  0.90625\n",
      "Iteration:  3223  Loss:  0.51109755   Accuracy:  0.8671875\n",
      "Iteration:  3224  Loss:  0.5028169   Accuracy:  0.8671875\n",
      "Iteration:  3225  Loss:  0.37992308   Accuracy:  0.859375\n",
      "Iteration:  3226  Loss:  0.34316054   Accuracy:  0.8984375\n",
      "Iteration:  3227  Loss:  0.3088798   Accuracy:  0.9140625\n",
      "Iteration:  3228  Loss:  0.68766534   Accuracy:  0.8671875\n",
      "Iteration:  3229  Loss:  0.36107123   Accuracy:  0.9296875\n",
      "Iteration:  3230  Loss:  0.3719737   Accuracy:  0.90625\n",
      "Iteration:  3231  Loss:  0.4652288   Accuracy:  0.8671875\n",
      "Iteration:  3232  Loss:  0.2649555   Accuracy:  0.9140625\n",
      "Iteration:  3233  Loss:  0.39763117   Accuracy:  0.9140625\n",
      "Iteration:  3234  Loss:  0.34192264   Accuracy:  0.875\n",
      "Iteration:  3235  Loss:  0.3901243   Accuracy:  0.8984375\n",
      "Iteration:  3236  Loss:  0.23261721   Accuracy:  0.9453125\n",
      "Iteration:  3237  Loss:  0.3010372   Accuracy:  0.90625\n",
      "Iteration:  3238  Loss:  0.21106899   Accuracy:  0.921875\n",
      "Iteration:  3239  Loss:  0.52467024   Accuracy:  0.8515625\n",
      "Iteration:  3240  Loss:  0.5328028   Accuracy:  0.8828125\n",
      "Iteration:  3241  Loss:  0.32064125   Accuracy:  0.890625\n",
      "Iteration:  3242  Loss:  0.4556722   Accuracy:  0.9140625\n",
      "Iteration:  3243  Loss:  0.359491   Accuracy:  0.9140625\n",
      "Iteration:  3244  Loss:  0.3395428   Accuracy:  0.9140625\n",
      "Iteration:  3245  Loss:  0.33036086   Accuracy:  0.9296875\n",
      "Iteration:  3246  Loss:  0.34688872   Accuracy:  0.8984375\n",
      "Iteration:  3247  Loss:  0.27282137   Accuracy:  0.9296875\n",
      "Iteration:  3248  Loss:  0.52192765   Accuracy:  0.890625\n",
      "Iteration:  3249  Loss:  0.59178257   Accuracy:  0.859375\n",
      "Iteration:  3250  Loss:  0.29690167   Accuracy:  0.90625\n",
      "Iteration:  3251  Loss:  0.5044323   Accuracy:  0.859375\n",
      "Iteration:  3252  Loss:  0.29073477   Accuracy:  0.9140625\n",
      "Iteration:  3253  Loss:  0.25222218   Accuracy:  0.921875\n",
      "Iteration:  3254  Loss:  0.35123497   Accuracy:  0.8984375\n",
      "Iteration:  3255  Loss:  0.4715813   Accuracy:  0.8671875\n",
      "Iteration:  3256  Loss:  0.42547598   Accuracy:  0.9296875\n",
      "Iteration:  3257  Loss:  0.2565828   Accuracy:  0.90625\n",
      "Iteration:  3258  Loss:  0.5807164   Accuracy:  0.8671875\n",
      "Iteration:  3259  Loss:  0.45197314   Accuracy:  0.890625\n",
      "Iteration:  3260  Loss:  0.4479252   Accuracy:  0.8515625\n",
      "Iteration:  3261  Loss:  0.415398   Accuracy:  0.875\n",
      "Iteration:  3262  Loss:  0.5208055   Accuracy:  0.8828125\n",
      "Iteration:  3263  Loss:  0.25264502   Accuracy:  0.921875\n",
      "Iteration:  3264  Loss:  0.34005016   Accuracy:  0.890625\n",
      "Iteration:  3265  Loss:  0.27604198   Accuracy:  0.9453125\n",
      "Iteration:  3266  Loss:  0.37826747   Accuracy:  0.921875\n",
      "Iteration:  3267  Loss:  0.41521108   Accuracy:  0.8828125\n",
      "Iteration:  3268  Loss:  0.25325853   Accuracy:  0.9453125\n",
      "Iteration:  3269  Loss:  0.44664353   Accuracy:  0.8984375\n",
      "Iteration:  3270  Loss:  0.4753276   Accuracy:  0.90625\n",
      "Iteration:  3271  Loss:  0.41543669   Accuracy:  0.8671875\n",
      "Iteration:  3272  Loss:  0.28405198   Accuracy:  0.90625\n",
      "Iteration:  3273  Loss:  0.5253634   Accuracy:  0.875\n",
      "Iteration:  3274  Loss:  0.67798305   Accuracy:  0.828125\n",
      "Iteration:  3275  Loss:  0.62001455   Accuracy:  0.890625\n",
      "Iteration:  3276  Loss:  0.49037927   Accuracy:  0.8984375\n",
      "Iteration:  3277  Loss:  0.60649776   Accuracy:  0.8828125\n",
      "Iteration:  3278  Loss:  0.4179998   Accuracy:  0.859375\n",
      "Iteration:  3279  Loss:  0.4148039   Accuracy:  0.875\n",
      "Iteration:  3280  Loss:  0.42370558   Accuracy:  0.8984375\n",
      "Iteration:  3281  Loss:  0.43466017   Accuracy:  0.9140625\n",
      "Iteration:  3282  Loss:  0.566245   Accuracy:  0.8515625\n",
      "Iteration:  3283  Loss:  0.32610846   Accuracy:  0.90625\n",
      "Iteration:  3284  Loss:  0.3284217   Accuracy:  0.8984375\n",
      "Iteration:  3285  Loss:  0.4868621   Accuracy:  0.890625\n",
      "Iteration:  3286  Loss:  0.35458064   Accuracy:  0.890625\n",
      "Iteration:  3287  Loss:  0.51732033   Accuracy:  0.8671875\n",
      "Iteration:  3288  Loss:  0.37156692   Accuracy:  0.921875\n",
      "Iteration:  3289  Loss:  0.55429745   Accuracy:  0.859375\n",
      "Iteration:  3290  Loss:  0.3432874   Accuracy:  0.8828125\n",
      "Iteration:  3291  Loss:  0.2795178   Accuracy:  0.921875\n",
      "Iteration:  3292  Loss:  0.3801842   Accuracy:  0.875\n",
      "Iteration:  3293  Loss:  0.2962981   Accuracy:  0.9296875\n",
      "Iteration:  3294  Loss:  0.4141782   Accuracy:  0.8984375\n",
      "Iteration:  3295  Loss:  0.5442861   Accuracy:  0.875\n",
      "Iteration:  3296  Loss:  0.16400668   Accuracy:  0.9453125\n",
      "Iteration:  3297  Loss:  0.3668748   Accuracy:  0.9140625\n",
      "Iteration:  3298  Loss:  0.3533098   Accuracy:  0.90625\n",
      "Iteration:  3299  Loss:  0.41390124   Accuracy:  0.890625\n",
      "Iteration:  3300  Loss:  0.30433977   Accuracy:  0.921875\n",
      "Iteration:  3301  Loss:  0.20076507   Accuracy:  0.9609375\n",
      "Iteration:  3302  Loss:  0.58946645   Accuracy:  0.8671875\n",
      "Iteration:  3303  Loss:  0.23887445   Accuracy:  0.9375\n",
      "Iteration:  3304  Loss:  0.99169016   Accuracy:  0.8125\n",
      "Iteration:  3305  Loss:  0.29389378   Accuracy:  0.9296875\n",
      "Iteration:  3306  Loss:  0.24518622   Accuracy:  0.953125\n",
      "Iteration:  3307  Loss:  0.37157917   Accuracy:  0.859375\n",
      "Iteration:  3308  Loss:  0.28883988   Accuracy:  0.90625\n",
      "Iteration:  3309  Loss:  0.5653917   Accuracy:  0.875\n",
      "Iteration:  3310  Loss:  0.349034   Accuracy:  0.921875\n",
      "Iteration:  3311  Loss:  0.29142308   Accuracy:  0.90625\n",
      "Iteration:  3312  Loss:  0.41373152   Accuracy:  0.890625\n",
      "Iteration:  3313  Loss:  0.2607411   Accuracy:  0.9375\n",
      "Iteration:  3314  Loss:  0.22524863   Accuracy:  0.9453125\n",
      "Iteration:  3315  Loss:  0.2805598   Accuracy:  0.9296875\n",
      "Iteration:  3316  Loss:  0.1891369   Accuracy:  0.9375\n",
      "Iteration:  3317  Loss:  0.75710344   Accuracy:  0.859375\n",
      "Iteration:  3318  Loss:  0.22360419   Accuracy:  0.921875\n",
      "Iteration:  3319  Loss:  0.53256327   Accuracy:  0.8828125\n",
      "Iteration:  3320  Loss:  0.20841143   Accuracy:  0.9296875\n",
      "Iteration:  3321  Loss:  0.4527424   Accuracy:  0.890625\n",
      "Iteration:  3322  Loss:  0.38679552   Accuracy:  0.9140625\n",
      "Iteration:  3323  Loss:  0.34625316   Accuracy:  0.90625\n",
      "Iteration:  3324  Loss:  0.31742796   Accuracy:  0.890625\n",
      "Iteration:  3325  Loss:  0.46346223   Accuracy:  0.8828125\n",
      "Iteration:  3326  Loss:  0.462537   Accuracy:  0.8671875\n",
      "Iteration:  3327  Loss:  0.40158805   Accuracy:  0.875\n",
      "Iteration:  3328  Loss:  0.51013434   Accuracy:  0.8671875\n",
      "Iteration:  3329  Loss:  0.49922383   Accuracy:  0.8828125\n",
      "Iteration:  3330  Loss:  0.29590955   Accuracy:  0.921875\n",
      "Iteration:  3331  Loss:  0.3217471   Accuracy:  0.9296875\n",
      "Iteration:  3332  Loss:  0.33528125   Accuracy:  0.8828125\n",
      "Iteration:  3333  Loss:  0.3232769   Accuracy:  0.9296875\n",
      "Iteration:  3334  Loss:  0.19549191   Accuracy:  0.9296875\n",
      "Iteration:  3335  Loss:  0.5706096   Accuracy:  0.8671875\n",
      "Iteration:  3336  Loss:  0.39895767   Accuracy:  0.921875\n",
      "Iteration:  3337  Loss:  0.3644963   Accuracy:  0.890625\n",
      "Iteration:  3338  Loss:  0.39494908   Accuracy:  0.90625\n",
      "Iteration:  3339  Loss:  0.22769797   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3340  Loss:  0.39710122   Accuracy:  0.921875\n",
      "Iteration:  3341  Loss:  0.24894354   Accuracy:  0.90625\n",
      "Iteration:  3342  Loss:  0.36607328   Accuracy:  0.8984375\n",
      "Iteration:  3343  Loss:  0.4126017   Accuracy:  0.8828125\n",
      "Iteration:  3344  Loss:  0.34269333   Accuracy:  0.84375\n",
      "Iteration:  3345  Loss:  0.33543602   Accuracy:  0.921875\n",
      "Iteration:  3346  Loss:  0.49043673   Accuracy:  0.875\n",
      "Iteration:  3347  Loss:  0.13526036   Accuracy:  0.9296875\n",
      "Iteration:  3348  Loss:  0.3495321   Accuracy:  0.8828125\n",
      "Iteration:  3349  Loss:  0.259942   Accuracy:  0.9375\n",
      "Iteration:  3350  Loss:  0.3258947   Accuracy:  0.8984375\n",
      "Iteration:  3351  Loss:  0.34139442   Accuracy:  0.9140625\n",
      "Iteration:  3352  Loss:  0.25732356   Accuracy:  0.9296875\n",
      "Iteration:  3353  Loss:  0.54937315   Accuracy:  0.875\n",
      "Iteration:  3354  Loss:  0.3764814   Accuracy:  0.875\n",
      "Iteration:  3355  Loss:  0.59000564   Accuracy:  0.890625\n",
      "Iteration:  3356  Loss:  0.60076946   Accuracy:  0.84375\n",
      "Iteration:  3357  Loss:  0.39312655   Accuracy:  0.9140625\n",
      "Iteration:  3358  Loss:  0.14447518   Accuracy:  0.9375\n",
      "Iteration:  3359  Loss:  0.2829823   Accuracy:  0.921875\n",
      "Iteration:  3360  Loss:  0.3699261   Accuracy:  0.890625\n",
      "Iteration:  3361  Loss:  0.41821772   Accuracy:  0.8984375\n",
      "Iteration:  3362  Loss:  0.48058802   Accuracy:  0.8828125\n",
      "Iteration:  3363  Loss:  0.27940142   Accuracy:  0.90625\n",
      "Iteration:  3364  Loss:  0.5285149   Accuracy:  0.859375\n",
      "Iteration:  3365  Loss:  0.34073547   Accuracy:  0.8984375\n",
      "Iteration:  3366  Loss:  0.25830904   Accuracy:  0.9296875\n",
      "Iteration:  3367  Loss:  0.1623468   Accuracy:  0.953125\n",
      "Iteration:  3368  Loss:  0.29050186   Accuracy:  0.90625\n",
      "Iteration:  3369  Loss:  0.2982326   Accuracy:  0.8984375\n",
      "Iteration:  3370  Loss:  0.5120564   Accuracy:  0.8828125\n",
      "Iteration:  3371  Loss:  0.48204607   Accuracy:  0.890625\n",
      "Iteration:  3372  Loss:  0.22179972   Accuracy:  0.9296875\n",
      "Iteration:  3373  Loss:  0.42500967   Accuracy:  0.8828125\n",
      "Iteration:  3374  Loss:  0.41008726   Accuracy:  0.8828125\n",
      "Iteration:  3375  Loss:  0.236061   Accuracy:  0.921875\n",
      "Iteration:  3376  Loss:  0.3038854   Accuracy:  0.9140625\n",
      "Iteration:  3377  Loss:  0.4841084   Accuracy:  0.8828125\n",
      "Iteration:  3378  Loss:  0.23294078   Accuracy:  0.9140625\n",
      "Iteration:  3379  Loss:  0.34694532   Accuracy:  0.9296875\n",
      "Iteration:  3380  Loss:  0.38390583   Accuracy:  0.8671875\n",
      "Iteration:  3381  Loss:  0.30686218   Accuracy:  0.9140625\n",
      "Iteration:  3382  Loss:  0.33809215   Accuracy:  0.921875\n",
      "Iteration:  3383  Loss:  0.4798895   Accuracy:  0.8984375\n",
      "Iteration:  3384  Loss:  0.38898808   Accuracy:  0.921875\n",
      "Iteration:  3385  Loss:  0.34780785   Accuracy:  0.875\n",
      "Iteration:  3386  Loss:  0.3267464   Accuracy:  0.8984375\n",
      "Iteration:  3387  Loss:  0.39380285   Accuracy:  0.8828125\n",
      "Iteration:  3388  Loss:  0.28307986   Accuracy:  0.90625\n",
      "Iteration:  3389  Loss:  0.39042556   Accuracy:  0.9140625\n",
      "Iteration:  3390  Loss:  0.39869213   Accuracy:  0.921875\n",
      "Iteration:  3391  Loss:  0.4942701   Accuracy:  0.9140625\n",
      "Iteration:  3392  Loss:  0.26584977   Accuracy:  0.921875\n",
      "Iteration:  3393  Loss:  0.34903604   Accuracy:  0.9453125\n",
      "Iteration:  3394  Loss:  0.28488752   Accuracy:  0.9140625\n",
      "Iteration:  3395  Loss:  0.6040764   Accuracy:  0.8984375\n",
      "Iteration:  3396  Loss:  0.30786917   Accuracy:  0.9140625\n",
      "Iteration:  3397  Loss:  0.41085088   Accuracy:  0.890625\n",
      "Iteration:  3398  Loss:  0.14882343   Accuracy:  0.953125\n",
      "Iteration:  3399  Loss:  0.607804   Accuracy:  0.8828125\n",
      "Iteration:  3400  Loss:  0.5136126   Accuracy:  0.8671875\n",
      "Iteration:  3401  Loss:  0.29197168   Accuracy:  0.921875\n",
      "Iteration:  3402  Loss:  0.2113955   Accuracy:  0.9375\n",
      "Iteration:  3403  Loss:  0.30184454   Accuracy:  0.9140625\n",
      "Iteration:  3404  Loss:  0.43778938   Accuracy:  0.8984375\n",
      "Iteration:  3405  Loss:  0.41084617   Accuracy:  0.875\n",
      "Iteration:  3406  Loss:  0.34913906   Accuracy:  0.8671875\n",
      "Iteration:  3407  Loss:  0.6798229   Accuracy:  0.875\n",
      "Iteration:  3408  Loss:  0.4272125   Accuracy:  0.8984375\n",
      "Iteration:  3409  Loss:  0.24801093   Accuracy:  0.9453125\n",
      "Iteration:  3410  Loss:  0.5721178   Accuracy:  0.90625\n",
      "Iteration:  3411  Loss:  0.22235548   Accuracy:  0.9453125\n",
      "Iteration:  3412  Loss:  0.34739542   Accuracy:  0.9296875\n",
      "Iteration:  3413  Loss:  0.31453377   Accuracy:  0.9140625\n",
      "Iteration:  3414  Loss:  0.45548886   Accuracy:  0.890625\n",
      "Iteration:  3415  Loss:  0.3906612   Accuracy:  0.8984375\n",
      "Iteration:  3416  Loss:  0.46205848   Accuracy:  0.90625\n",
      "Iteration:  3417  Loss:  0.56638956   Accuracy:  0.8828125\n",
      "Iteration:  3418  Loss:  0.34174913   Accuracy:  0.8984375\n",
      "Iteration:  3419  Loss:  0.41810593   Accuracy:  0.8671875\n",
      "Iteration:  3420  Loss:  0.28716514   Accuracy:  0.9296875\n",
      "Iteration:  3421  Loss:  0.50593746   Accuracy:  0.8515625\n",
      "Iteration:  3422  Loss:  0.3292186   Accuracy:  0.890625\n",
      "Iteration:  3423  Loss:  0.39283645   Accuracy:  0.8984375\n",
      "Iteration:  3424  Loss:  0.73075247   Accuracy:  0.90625\n",
      "Iteration:  3425  Loss:  0.56263673   Accuracy:  0.8828125\n",
      "Iteration:  3426  Loss:  0.5951706   Accuracy:  0.875\n",
      "Iteration:  3427  Loss:  0.5197649   Accuracy:  0.90625\n",
      "Iteration:  3428  Loss:  0.23028806   Accuracy:  0.9296875\n",
      "Iteration:  3429  Loss:  0.22292653   Accuracy:  0.9375\n",
      "Iteration:  3430  Loss:  0.44914266   Accuracy:  0.875\n",
      "Iteration:  3431  Loss:  0.30868378   Accuracy:  0.8984375\n",
      "Iteration:  3432  Loss:  0.17967096   Accuracy:  0.9609375\n",
      "Iteration:  3433  Loss:  0.54340214   Accuracy:  0.8515625\n",
      "Iteration:  3434  Loss:  0.37964734   Accuracy:  0.9296875\n",
      "Iteration:  3435  Loss:  0.50006443   Accuracy:  0.9140625\n",
      "Iteration:  3436  Loss:  0.5695625   Accuracy:  0.8828125\n",
      "Iteration:  3437  Loss:  0.48348254   Accuracy:  0.875\n",
      "Iteration:  3438  Loss:  0.4614224   Accuracy:  0.8828125\n",
      "Iteration:  3439  Loss:  0.28074992   Accuracy:  0.90625\n",
      "Iteration:  3440  Loss:  0.36922786   Accuracy:  0.921875\n",
      "Iteration:  3441  Loss:  0.36542138   Accuracy:  0.921875\n",
      "Iteration:  3442  Loss:  0.4415899   Accuracy:  0.8671875\n",
      "Iteration:  3443  Loss:  0.36715138   Accuracy:  0.890625\n",
      "Iteration:  3444  Loss:  0.31260738   Accuracy:  0.8984375\n",
      "Iteration:  3445  Loss:  0.36682144   Accuracy:  0.9140625\n",
      "Iteration:  3446  Loss:  0.27196157   Accuracy:  0.921875\n",
      "Iteration:  3447  Loss:  0.26534992   Accuracy:  0.90625\n",
      "Iteration:  3448  Loss:  0.5581667   Accuracy:  0.859375\n",
      "Iteration:  3449  Loss:  0.20801955   Accuracy:  0.921875\n",
      "Iteration:  3450  Loss:  0.42850167   Accuracy:  0.875\n",
      "Iteration:  3451  Loss:  0.44194466   Accuracy:  0.890625\n",
      "Iteration:  3452  Loss:  0.35716894   Accuracy:  0.875\n",
      "Iteration:  3453  Loss:  0.6178911   Accuracy:  0.8828125\n",
      "Iteration:  3454  Loss:  0.33827788   Accuracy:  0.875\n",
      "Iteration:  3455  Loss:  0.22262686   Accuracy:  0.90625\n",
      "Iteration:  3456  Loss:  0.2628904   Accuracy:  0.90625\n",
      "Iteration:  3457  Loss:  0.36774516   Accuracy:  0.9375\n",
      "Iteration:  3458  Loss:  0.23106518   Accuracy:  0.9375\n",
      "Iteration:  3459  Loss:  0.7188113   Accuracy:  0.8671875\n",
      "Iteration:  3460  Loss:  0.4618642   Accuracy:  0.9140625\n",
      "Iteration:  3461  Loss:  0.3758789   Accuracy:  0.890625\n",
      "Iteration:  3462  Loss:  0.30591303   Accuracy:  0.9140625\n",
      "Iteration:  3463  Loss:  0.6017218   Accuracy:  0.8515625\n",
      "Iteration:  3464  Loss:  0.5672409   Accuracy:  0.890625\n",
      "Iteration:  3465  Loss:  0.48388267   Accuracy:  0.890625\n",
      "Iteration:  3466  Loss:  0.32803848   Accuracy:  0.9296875\n",
      "Iteration:  3467  Loss:  0.30601168   Accuracy:  0.8828125\n",
      "Iteration:  3468  Loss:  0.31973726   Accuracy:  0.890625\n",
      "Iteration:  3469  Loss:  0.20187306   Accuracy:  0.921875\n",
      "Iteration:  3470  Loss:  0.3746184   Accuracy:  0.9140625\n",
      "Iteration:  3471  Loss:  0.68845457   Accuracy:  0.8515625\n",
      "Iteration:  3472  Loss:  0.21434335   Accuracy:  0.9296875\n",
      "Iteration:  3473  Loss:  0.40698367   Accuracy:  0.921875\n",
      "Iteration:  3474  Loss:  0.18615013   Accuracy:  0.9453125\n",
      "Iteration:  3475  Loss:  0.3422586   Accuracy:  0.921875\n",
      "Iteration:  3476  Loss:  0.78903794   Accuracy:  0.8203125\n",
      "Iteration:  3477  Loss:  0.37481403   Accuracy:  0.9296875\n",
      "Iteration:  3478  Loss:  0.5223613   Accuracy:  0.875\n",
      "Iteration:  3479  Loss:  0.3686288   Accuracy:  0.9296875\n",
      "Iteration:  3480  Loss:  0.43104264   Accuracy:  0.90625\n",
      "Iteration:  3481  Loss:  0.36469054   Accuracy:  0.9140625\n",
      "Iteration:  3482  Loss:  0.24742213   Accuracy:  0.9296875\n",
      "Iteration:  3483  Loss:  0.4126222   Accuracy:  0.921875\n",
      "Iteration:  3484  Loss:  0.37664413   Accuracy:  0.9140625\n",
      "Iteration:  3485  Loss:  0.2237874   Accuracy:  0.9296875\n",
      "Iteration:  3486  Loss:  0.45757395   Accuracy:  0.8984375\n",
      "Iteration:  3487  Loss:  0.41436136   Accuracy:  0.90625\n",
      "Iteration:  3488  Loss:  0.5012468   Accuracy:  0.890625\n",
      "Iteration:  3489  Loss:  0.5212592   Accuracy:  0.8359375\n",
      "Iteration:  3490  Loss:  0.40643072   Accuracy:  0.8984375\n",
      "Iteration:  3491  Loss:  0.48118454   Accuracy:  0.84375\n",
      "Iteration:  3492  Loss:  0.400609   Accuracy:  0.90625\n",
      "Iteration:  3493  Loss:  0.17361313   Accuracy:  0.9453125\n",
      "Iteration:  3494  Loss:  0.2992962   Accuracy:  0.9140625\n",
      "Iteration:  3495  Loss:  0.10538278   Accuracy:  0.953125\n",
      "Iteration:  3496  Loss:  0.15244302   Accuracy:  0.9375\n",
      "Iteration:  3497  Loss:  0.48748043   Accuracy:  0.8984375\n",
      "Iteration:  3498  Loss:  0.4810843   Accuracy:  0.8984375\n",
      "Iteration:  3499  Loss:  0.48928785   Accuracy:  0.890625\n",
      "Iteration:  3500  Loss:  0.16589768   Accuracy:  0.9453125\n",
      "Iteration:  3501  Loss:  0.48037767   Accuracy:  0.90625\n",
      "Iteration:  3502  Loss:  0.1910661   Accuracy:  0.90625\n",
      "Iteration:  3503  Loss:  0.36034924   Accuracy:  0.9296875\n",
      "Iteration:  3504  Loss:  0.33161247   Accuracy:  0.921875\n",
      "Iteration:  3505  Loss:  0.5528569   Accuracy:  0.8671875\n",
      "Iteration:  3506  Loss:  0.3519185   Accuracy:  0.9140625\n",
      "Iteration:  3507  Loss:  0.5892376   Accuracy:  0.921875\n",
      "Iteration:  3508  Loss:  0.37262   Accuracy:  0.890625\n",
      "Iteration:  3509  Loss:  0.36985514   Accuracy:  0.9140625\n",
      "Iteration:  3510  Loss:  0.45593387   Accuracy:  0.90625\n",
      "Iteration:  3511  Loss:  0.33561006   Accuracy:  0.890625\n",
      "Iteration:  3512  Loss:  0.35389653   Accuracy:  0.9140625\n",
      "Iteration:  3513  Loss:  0.27504382   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3514  Loss:  0.26533863   Accuracy:  0.9453125\n",
      "Iteration:  3515  Loss:  0.29540652   Accuracy:  0.9140625\n",
      "Iteration:  3516  Loss:  0.34545332   Accuracy:  0.8671875\n",
      "Iteration:  3517  Loss:  0.36029795   Accuracy:  0.9296875\n",
      "Iteration:  3518  Loss:  0.25385985   Accuracy:  0.921875\n",
      "Iteration:  3519  Loss:  0.40420473   Accuracy:  0.90625\n",
      "Iteration:  3520  Loss:  0.4049378   Accuracy:  0.890625\n",
      "Iteration:  3521  Loss:  0.33713007   Accuracy:  0.921875\n",
      "Iteration:  3522  Loss:  0.29147452   Accuracy:  0.921875\n",
      "Iteration:  3523  Loss:  0.25509036   Accuracy:  0.9375\n",
      "Iteration:  3524  Loss:  0.3700301   Accuracy:  0.921875\n",
      "Iteration:  3525  Loss:  0.23694102   Accuracy:  0.953125\n",
      "Iteration:  3526  Loss:  0.30267194   Accuracy:  0.8984375\n",
      "Iteration:  3527  Loss:  0.47492075   Accuracy:  0.875\n",
      "Iteration:  3528  Loss:  0.40369052   Accuracy:  0.90625\n",
      "Iteration:  3529  Loss:  0.37878057   Accuracy:  0.9140625\n",
      "Iteration:  3530  Loss:  0.187913   Accuracy:  0.953125\n",
      "Iteration:  3531  Loss:  0.38638824   Accuracy:  0.875\n",
      "Iteration:  3532  Loss:  0.45463482   Accuracy:  0.8984375\n",
      "Iteration:  3533  Loss:  0.289121   Accuracy:  0.9375\n",
      "Iteration:  3534  Loss:  0.43784294   Accuracy:  0.875\n",
      "Iteration:  3535  Loss:  0.4504788   Accuracy:  0.875\n",
      "Iteration:  3536  Loss:  0.42561567   Accuracy:  0.921875\n",
      "Iteration:  3537  Loss:  0.4508922   Accuracy:  0.90625\n",
      "Iteration:  3538  Loss:  0.50839585   Accuracy:  0.84375\n",
      "Iteration:  3539  Loss:  0.30216038   Accuracy:  0.921875\n",
      "Iteration:  3540  Loss:  0.37922674   Accuracy:  0.875\n",
      "Iteration:  3541  Loss:  0.32910776   Accuracy:  0.9140625\n",
      "Iteration:  3542  Loss:  0.3780436   Accuracy:  0.9140625\n",
      "Iteration:  3543  Loss:  0.43246967   Accuracy:  0.8671875\n",
      "Iteration:  3544  Loss:  0.47111335   Accuracy:  0.90625\n",
      "Iteration:  3545  Loss:  0.358125   Accuracy:  0.890625\n",
      "Iteration:  3546  Loss:  0.3755529   Accuracy:  0.9296875\n",
      "Iteration:  3547  Loss:  0.4209944   Accuracy:  0.8984375\n",
      "Iteration:  3548  Loss:  0.49778503   Accuracy:  0.8828125\n",
      "Iteration:  3549  Loss:  0.6207377   Accuracy:  0.8359375\n",
      "Iteration:  3550  Loss:  0.4112331   Accuracy:  0.890625\n",
      "Iteration:  3551  Loss:  0.4864117   Accuracy:  0.8515625\n",
      "Iteration:  3552  Loss:  0.54065555   Accuracy:  0.921875\n",
      "Iteration:  3553  Loss:  0.4121492   Accuracy:  0.8984375\n",
      "Iteration:  3554  Loss:  0.4331322   Accuracy:  0.875\n",
      "Iteration:  3555  Loss:  0.4982994   Accuracy:  0.84375\n",
      "Iteration:  3556  Loss:  0.27951175   Accuracy:  0.9453125\n",
      "Iteration:  3557  Loss:  0.28316358   Accuracy:  0.8984375\n",
      "Iteration:  3558  Loss:  0.27041394   Accuracy:  0.921875\n",
      "Iteration:  3559  Loss:  0.47142842   Accuracy:  0.875\n",
      "Iteration:  3560  Loss:  0.39458156   Accuracy:  0.890625\n",
      "Iteration:  3561  Loss:  0.21978635   Accuracy:  0.921875\n",
      "Iteration:  3562  Loss:  0.19948983   Accuracy:  0.921875\n",
      "Iteration:  3563  Loss:  0.31314465   Accuracy:  0.8984375\n",
      "Iteration:  3564  Loss:  0.33610886   Accuracy:  0.921875\n",
      "Iteration:  3565  Loss:  0.4759486   Accuracy:  0.8671875\n",
      "Iteration:  3566  Loss:  0.35843602   Accuracy:  0.9140625\n",
      "Iteration:  3567  Loss:  0.22490329   Accuracy:  0.9296875\n",
      "Iteration:  3568  Loss:  0.37953028   Accuracy:  0.890625\n",
      "Iteration:  3569  Loss:  0.5013122   Accuracy:  0.921875\n",
      "Iteration:  3570  Loss:  0.43630704   Accuracy:  0.890625\n",
      "Iteration:  3571  Loss:  0.3467921   Accuracy:  0.921875\n",
      "Iteration:  3572  Loss:  0.38497812   Accuracy:  0.890625\n",
      "Iteration:  3573  Loss:  0.53130805   Accuracy:  0.84375\n",
      "Iteration:  3574  Loss:  0.41957098   Accuracy:  0.9140625\n",
      "Iteration:  3575  Loss:  0.18640842   Accuracy:  0.9296875\n",
      "Iteration:  3576  Loss:  0.39137375   Accuracy:  0.90625\n",
      "Iteration:  3577  Loss:  0.26635265   Accuracy:  0.9140625\n",
      "Iteration:  3578  Loss:  0.33238485   Accuracy:  0.890625\n",
      "Iteration:  3579  Loss:  0.5647253   Accuracy:  0.890625\n",
      "Iteration:  3580  Loss:  0.36824208   Accuracy:  0.9375\n",
      "Iteration:  3581  Loss:  0.2985261   Accuracy:  0.9140625\n",
      "Iteration:  3582  Loss:  0.41159573   Accuracy:  0.8828125\n",
      "Iteration:  3583  Loss:  0.35391465   Accuracy:  0.9375\n",
      "Iteration:  3584  Loss:  0.20722128   Accuracy:  0.9296875\n",
      "Iteration:  3585  Loss:  0.36905807   Accuracy:  0.8984375\n",
      "Iteration:  3586  Loss:  0.24584113   Accuracy:  0.9296875\n",
      "Iteration:  3587  Loss:  0.5600724   Accuracy:  0.859375\n",
      "Iteration:  3588  Loss:  0.33709183   Accuracy:  0.8984375\n",
      "Iteration:  3589  Loss:  0.3558823   Accuracy:  0.8984375\n",
      "Iteration:  3590  Loss:  0.3465237   Accuracy:  0.8828125\n",
      "Iteration:  3591  Loss:  0.26582313   Accuracy:  0.9140625\n",
      "Iteration:  3592  Loss:  0.48169136   Accuracy:  0.890625\n",
      "Iteration:  3593  Loss:  0.4320757   Accuracy:  0.8984375\n",
      "Iteration:  3594  Loss:  0.2688276   Accuracy:  0.9140625\n",
      "Iteration:  3595  Loss:  0.56833667   Accuracy:  0.921875\n",
      "Iteration:  3596  Loss:  0.26956856   Accuracy:  0.9296875\n",
      "Iteration:  3597  Loss:  0.44253471   Accuracy:  0.84375\n",
      "Iteration:  3598  Loss:  0.36642393   Accuracy:  0.875\n",
      "Iteration:  3599  Loss:  0.33672374   Accuracy:  0.90625\n",
      "Iteration:  3600  Loss:  0.3124592   Accuracy:  0.921875\n",
      "Iteration:  3601  Loss:  0.1820128   Accuracy:  0.9453125\n",
      "Iteration:  3602  Loss:  0.3239753   Accuracy:  0.9296875\n",
      "Iteration:  3603  Loss:  0.40901494   Accuracy:  0.8828125\n",
      "Iteration:  3604  Loss:  0.37442818   Accuracy:  0.8984375\n",
      "Iteration:  3605  Loss:  0.1785661   Accuracy:  0.9375\n",
      "Iteration:  3606  Loss:  0.14403528   Accuracy:  0.9453125\n",
      "Iteration:  3607  Loss:  0.32399744   Accuracy:  0.9453125\n",
      "Iteration:  3608  Loss:  0.30566037   Accuracy:  0.921875\n",
      "Iteration:  3609  Loss:  0.34502566   Accuracy:  0.921875\n",
      "Iteration:  3610  Loss:  0.36105365   Accuracy:  0.90625\n",
      "Iteration:  3611  Loss:  0.34580818   Accuracy:  0.875\n",
      "Iteration:  3612  Loss:  0.2168493   Accuracy:  0.8984375\n",
      "Iteration:  3613  Loss:  0.19522084   Accuracy:  0.953125\n",
      "Iteration:  3614  Loss:  0.09728074   Accuracy:  0.96875\n",
      "Iteration:  3615  Loss:  0.43034288   Accuracy:  0.9140625\n",
      "Iteration:  3616  Loss:  0.3499011   Accuracy:  0.890625\n",
      "Iteration:  3617  Loss:  0.6067616   Accuracy:  0.890625\n",
      "Iteration:  3618  Loss:  0.4445731   Accuracy:  0.875\n",
      "Iteration:  3619  Loss:  0.32108635   Accuracy:  0.8828125\n",
      "Iteration:  3620  Loss:  0.36037415   Accuracy:  0.9296875\n",
      "Iteration:  3621  Loss:  0.42308253   Accuracy:  0.90625\n",
      "Iteration:  3622  Loss:  0.6134083   Accuracy:  0.8515625\n",
      "Iteration:  3623  Loss:  0.25593308   Accuracy:  0.921875\n",
      "Iteration:  3624  Loss:  0.5459952   Accuracy:  0.8515625\n",
      "Iteration:  3625  Loss:  0.46071485   Accuracy:  0.890625\n",
      "Iteration:  3626  Loss:  0.26260826   Accuracy:  0.9140625\n",
      "Iteration:  3627  Loss:  0.5016753   Accuracy:  0.875\n",
      "Iteration:  3628  Loss:  0.39476833   Accuracy:  0.890625\n",
      "Iteration:  3629  Loss:  0.45354897   Accuracy:  0.890625\n",
      "Iteration:  3630  Loss:  0.34535497   Accuracy:  0.921875\n",
      "Iteration:  3631  Loss:  0.5321769   Accuracy:  0.8984375\n",
      "Iteration:  3632  Loss:  0.42929918   Accuracy:  0.8984375\n",
      "Iteration:  3633  Loss:  0.33675128   Accuracy:  0.875\n",
      "Iteration:  3634  Loss:  0.24884409   Accuracy:  0.9140625\n",
      "Iteration:  3635  Loss:  0.36449558   Accuracy:  0.8828125\n",
      "Iteration:  3636  Loss:  0.626029   Accuracy:  0.859375\n",
      "Iteration:  3637  Loss:  0.387598   Accuracy:  0.890625\n",
      "Iteration:  3638  Loss:  0.47224727   Accuracy:  0.890625\n",
      "Iteration:  3639  Loss:  0.3561143   Accuracy:  0.9140625\n",
      "Iteration:  3640  Loss:  0.4323942   Accuracy:  0.859375\n",
      "Iteration:  3641  Loss:  0.33639228   Accuracy:  0.9296875\n",
      "Iteration:  3642  Loss:  0.543366   Accuracy:  0.8515625\n",
      "Iteration:  3643  Loss:  0.41230124   Accuracy:  0.890625\n",
      "Iteration:  3644  Loss:  0.3954717   Accuracy:  0.890625\n",
      "Iteration:  3645  Loss:  0.5591917   Accuracy:  0.875\n",
      "Iteration:  3646  Loss:  0.21091422   Accuracy:  0.9375\n",
      "Iteration:  3647  Loss:  0.4307797   Accuracy:  0.890625\n",
      "Iteration:  3648  Loss:  0.38173568   Accuracy:  0.921875\n",
      "Iteration:  3649  Loss:  0.2329406   Accuracy:  0.9375\n",
      "Iteration:  3650  Loss:  0.428489   Accuracy:  0.8828125\n",
      "Iteration:  3651  Loss:  0.28663245   Accuracy:  0.921875\n",
      "Iteration:  3652  Loss:  0.3104569   Accuracy:  0.8828125\n",
      "Iteration:  3653  Loss:  0.44391403   Accuracy:  0.921875\n",
      "Iteration:  3654  Loss:  0.50072604   Accuracy:  0.8671875\n",
      "Iteration:  3655  Loss:  0.44191316   Accuracy:  0.8984375\n",
      "Iteration:  3656  Loss:  0.31982297   Accuracy:  0.8828125\n",
      "Iteration:  3657  Loss:  0.22792593   Accuracy:  0.9375\n",
      "Iteration:  3658  Loss:  0.26068258   Accuracy:  0.9296875\n",
      "Iteration:  3659  Loss:  0.17404547   Accuracy:  0.9453125\n",
      "Iteration:  3660  Loss:  0.17336452   Accuracy:  0.9453125\n",
      "Iteration:  3661  Loss:  0.55579793   Accuracy:  0.8125\n",
      "Iteration:  3662  Loss:  0.3752584   Accuracy:  0.90625\n",
      "Iteration:  3663  Loss:  0.30859786   Accuracy:  0.8671875\n",
      "Iteration:  3664  Loss:  0.10908089   Accuracy:  0.96875\n",
      "Iteration:  3665  Loss:  0.49720305   Accuracy:  0.8828125\n",
      "Iteration:  3666  Loss:  0.31845823   Accuracy:  0.8828125\n",
      "Iteration:  3667  Loss:  0.29508862   Accuracy:  0.9375\n",
      "Iteration:  3668  Loss:  0.18212321   Accuracy:  0.9296875\n",
      "Iteration:  3669  Loss:  0.32369336   Accuracy:  0.90625\n",
      "Iteration:  3670  Loss:  0.472135   Accuracy:  0.9375\n",
      "Iteration:  3671  Loss:  0.2749923   Accuracy:  0.9375\n",
      "Iteration:  3672  Loss:  0.38070473   Accuracy:  0.8984375\n",
      "Iteration:  3673  Loss:  0.25752604   Accuracy:  0.8828125\n",
      "Iteration:  3674  Loss:  0.34993842   Accuracy:  0.90625\n",
      "Iteration:  3675  Loss:  0.25914854   Accuracy:  0.953125\n",
      "Iteration:  3676  Loss:  0.37612897   Accuracy:  0.90625\n",
      "Iteration:  3677  Loss:  0.46849495   Accuracy:  0.8984375\n",
      "Iteration:  3678  Loss:  0.29057413   Accuracy:  0.90625\n",
      "Iteration:  3679  Loss:  0.428582   Accuracy:  0.8671875\n",
      "Iteration:  3680  Loss:  0.27908146   Accuracy:  0.9296875\n",
      "Iteration:  3681  Loss:  0.46462342   Accuracy:  0.8671875\n",
      "Iteration:  3682  Loss:  0.51238596   Accuracy:  0.8984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3683  Loss:  0.54503065   Accuracy:  0.8828125\n",
      "Iteration:  3684  Loss:  0.21320343   Accuracy:  0.9296875\n",
      "Iteration:  3685  Loss:  0.11758526   Accuracy:  0.953125\n",
      "Iteration:  3686  Loss:  0.4378777   Accuracy:  0.8828125\n",
      "Iteration:  3687  Loss:  0.39025477   Accuracy:  0.9140625\n",
      "Iteration:  3688  Loss:  0.32353616   Accuracy:  0.9140625\n",
      "Iteration:  3689  Loss:  0.4663048   Accuracy:  0.8515625\n",
      "Iteration:  3690  Loss:  0.4041773   Accuracy:  0.9140625\n",
      "Iteration:  3691  Loss:  0.215422   Accuracy:  0.9453125\n",
      "Iteration:  3692  Loss:  0.20238829   Accuracy:  0.9375\n",
      "Iteration:  3693  Loss:  0.21231614   Accuracy:  0.96875\n",
      "Iteration:  3694  Loss:  0.36146367   Accuracy:  0.8828125\n",
      "Iteration:  3695  Loss:  0.2298893   Accuracy:  0.9140625\n",
      "Iteration:  3696  Loss:  0.5485693   Accuracy:  0.875\n",
      "Iteration:  3697  Loss:  0.37437117   Accuracy:  0.9140625\n",
      "Iteration:  3698  Loss:  0.39295244   Accuracy:  0.890625\n",
      "Iteration:  3699  Loss:  0.32072774   Accuracy:  0.9140625\n",
      "Iteration:  3700  Loss:  0.39808238   Accuracy:  0.890625\n",
      "Iteration:  3701  Loss:  0.26622733   Accuracy:  0.921875\n",
      "Iteration:  3702  Loss:  0.4378873   Accuracy:  0.859375\n",
      "Iteration:  3703  Loss:  0.27686024   Accuracy:  0.921875\n",
      "Iteration:  3704  Loss:  0.3584459   Accuracy:  0.90625\n",
      "Iteration:  3705  Loss:  0.29572222   Accuracy:  0.90625\n",
      "Iteration:  3706  Loss:  0.3834669   Accuracy:  0.8984375\n",
      "Iteration:  3707  Loss:  0.382563   Accuracy:  0.8984375\n",
      "Iteration:  3708  Loss:  0.2441738   Accuracy:  0.9296875\n",
      "Iteration:  3709  Loss:  0.3766868   Accuracy:  0.9140625\n",
      "Iteration:  3710  Loss:  0.3121877   Accuracy:  0.921875\n",
      "Iteration:  3711  Loss:  0.31627607   Accuracy:  0.9140625\n",
      "Iteration:  3712  Loss:  0.34728312   Accuracy:  0.8984375\n",
      "Iteration:  3713  Loss:  0.6673513   Accuracy:  0.8515625\n",
      "Iteration:  3714  Loss:  0.21264373   Accuracy:  0.9375\n",
      "Iteration:  3715  Loss:  0.41313282   Accuracy:  0.890625\n",
      "Iteration:  3716  Loss:  0.26841426   Accuracy:  0.921875\n",
      "Iteration:  3717  Loss:  0.30579117   Accuracy:  0.90625\n",
      "Iteration:  3718  Loss:  0.20444214   Accuracy:  0.9375\n",
      "Iteration:  3719  Loss:  0.44168186   Accuracy:  0.90625\n",
      "Iteration:  3720  Loss:  0.37588215   Accuracy:  0.859375\n",
      "Iteration:  3721  Loss:  0.50542367   Accuracy:  0.8828125\n",
      "Iteration:  3722  Loss:  0.51016843   Accuracy:  0.859375\n",
      "Iteration:  3723  Loss:  0.51824605   Accuracy:  0.8671875\n",
      "Iteration:  3724  Loss:  0.4067253   Accuracy:  0.875\n",
      "Iteration:  3725  Loss:  0.31958532   Accuracy:  0.921875\n",
      "Iteration:  3726  Loss:  0.49969897   Accuracy:  0.90625\n",
      "Iteration:  3727  Loss:  0.52131283   Accuracy:  0.84375\n",
      "Iteration:  3728  Loss:  0.31590948   Accuracy:  0.90625\n",
      "Iteration:  3729  Loss:  0.38770056   Accuracy:  0.890625\n",
      "Iteration:  3730  Loss:  0.27554053   Accuracy:  0.90625\n",
      "Iteration:  3731  Loss:  0.123701915   Accuracy:  0.9453125\n",
      "Iteration:  3732  Loss:  0.311872   Accuracy:  0.8984375\n",
      "Iteration:  3733  Loss:  0.42786676   Accuracy:  0.8984375\n",
      "Iteration:  3734  Loss:  0.44437486   Accuracy:  0.8671875\n",
      "Iteration:  3735  Loss:  0.34613413   Accuracy:  0.90625\n",
      "Iteration:  3736  Loss:  0.3569885   Accuracy:  0.9140625\n",
      "Iteration:  3737  Loss:  0.55385417   Accuracy:  0.859375\n",
      "Iteration:  3738  Loss:  0.22583282   Accuracy:  0.953125\n",
      "Iteration:  3739  Loss:  0.4549819   Accuracy:  0.921875\n",
      "Iteration:  3740  Loss:  0.4960695   Accuracy:  0.8828125\n",
      "Iteration:  3741  Loss:  0.6299813   Accuracy:  0.8671875\n",
      "Iteration:  3742  Loss:  0.24362831   Accuracy:  0.9296875\n",
      "Iteration:  3743  Loss:  0.41454646   Accuracy:  0.890625\n",
      "Iteration:  3744  Loss:  0.39477718   Accuracy:  0.90625\n",
      "Iteration:  3745  Loss:  0.4054548   Accuracy:  0.8984375\n",
      "Iteration:  3746  Loss:  0.24878986   Accuracy:  0.90625\n",
      "Iteration:  3747  Loss:  0.5091975   Accuracy:  0.8671875\n",
      "Iteration:  3748  Loss:  0.47900563   Accuracy:  0.8984375\n",
      "Iteration:  3749  Loss:  0.41946647   Accuracy:  0.921875\n",
      "Iteration:  3750  Loss:  0.226066   Accuracy:  0.9140625\n",
      "Iteration:  3751  Loss:  0.30514455   Accuracy:  0.9453125\n",
      "Iteration:  3752  Loss:  0.7959761   Accuracy:  0.890625\n",
      "Iteration:  3753  Loss:  0.37291136   Accuracy:  0.921875\n",
      "Iteration:  3754  Loss:  0.48025164   Accuracy:  0.921875\n",
      "Iteration:  3755  Loss:  0.33072677   Accuracy:  0.90625\n",
      "Iteration:  3756  Loss:  0.26630056   Accuracy:  0.9140625\n",
      "Iteration:  3757  Loss:  0.5114781   Accuracy:  0.859375\n",
      "Iteration:  3758  Loss:  0.3450291   Accuracy:  0.8984375\n",
      "Iteration:  3759  Loss:  0.32755277   Accuracy:  0.8828125\n",
      "Iteration:  3760  Loss:  0.38290668   Accuracy:  0.8984375\n",
      "Iteration:  3761  Loss:  0.2681279   Accuracy:  0.953125\n",
      "Iteration:  3762  Loss:  0.2621629   Accuracy:  0.921875\n",
      "Iteration:  3763  Loss:  0.4723376   Accuracy:  0.890625\n",
      "Iteration:  3764  Loss:  0.31489527   Accuracy:  0.9140625\n",
      "Iteration:  3765  Loss:  0.42205933   Accuracy:  0.8828125\n",
      "Iteration:  3766  Loss:  0.4827681   Accuracy:  0.859375\n",
      "Iteration:  3767  Loss:  0.34856778   Accuracy:  0.8984375\n",
      "Iteration:  3768  Loss:  0.2606234   Accuracy:  0.9140625\n",
      "Iteration:  3769  Loss:  0.29689294   Accuracy:  0.9296875\n",
      "Iteration:  3770  Loss:  0.15693626   Accuracy:  0.9375\n",
      "Iteration:  3771  Loss:  0.39230722   Accuracy:  0.921875\n",
      "Iteration:  3772  Loss:  0.23843716   Accuracy:  0.9140625\n",
      "Iteration:  3773  Loss:  0.77697587   Accuracy:  0.84375\n",
      "Iteration:  3774  Loss:  0.3087775   Accuracy:  0.8828125\n",
      "Iteration:  3775  Loss:  0.3785256   Accuracy:  0.9296875\n",
      "Iteration:  3776  Loss:  0.4590733   Accuracy:  0.8984375\n",
      "Iteration:  3777  Loss:  0.44604522   Accuracy:  0.875\n",
      "Iteration:  3778  Loss:  0.25504595   Accuracy:  0.921875\n",
      "Iteration:  3779  Loss:  0.4013803   Accuracy:  0.8671875\n",
      "Iteration:  3780  Loss:  0.45114726   Accuracy:  0.8671875\n",
      "Iteration:  3781  Loss:  0.32252997   Accuracy:  0.90625\n",
      "Iteration:  3782  Loss:  0.3118544   Accuracy:  0.8984375\n",
      "Iteration:  3783  Loss:  0.26681742   Accuracy:  0.9375\n",
      "Iteration:  3784  Loss:  0.44118792   Accuracy:  0.890625\n",
      "Iteration:  3785  Loss:  0.24394575   Accuracy:  0.90625\n",
      "Iteration:  3786  Loss:  0.24270695   Accuracy:  0.921875\n",
      "Iteration:  3787  Loss:  0.3195679   Accuracy:  0.953125\n",
      "Iteration:  3788  Loss:  0.31392455   Accuracy:  0.9453125\n",
      "Iteration:  3789  Loss:  0.52300525   Accuracy:  0.8984375\n",
      "Iteration:  3790  Loss:  0.43395457   Accuracy:  0.875\n",
      "Iteration:  3791  Loss:  0.44136178   Accuracy:  0.8828125\n",
      "Iteration:  3792  Loss:  0.47477704   Accuracy:  0.8828125\n",
      "Iteration:  3793  Loss:  0.23687975   Accuracy:  0.9375\n",
      "Iteration:  3794  Loss:  0.50540453   Accuracy:  0.9140625\n",
      "Iteration:  3795  Loss:  0.49111196   Accuracy:  0.8828125\n",
      "Iteration:  3796  Loss:  0.47925854   Accuracy:  0.8671875\n",
      "Iteration:  3797  Loss:  0.5395745   Accuracy:  0.921875\n",
      "Iteration:  3798  Loss:  0.40623727   Accuracy:  0.8984375\n",
      "Iteration:  3799  Loss:  0.26490492   Accuracy:  0.890625\n",
      "Iteration:  3800  Loss:  0.27846497   Accuracy:  0.921875\n",
      "Iteration:  3801  Loss:  0.39701757   Accuracy:  0.875\n",
      "Iteration:  3802  Loss:  0.36577886   Accuracy:  0.890625\n",
      "Iteration:  3803  Loss:  0.46530917   Accuracy:  0.8828125\n",
      "Iteration:  3804  Loss:  0.627771   Accuracy:  0.8359375\n",
      "Iteration:  3805  Loss:  0.527571   Accuracy:  0.8984375\n",
      "Iteration:  3806  Loss:  0.37785247   Accuracy:  0.90625\n",
      "Iteration:  3807  Loss:  0.16145551   Accuracy:  0.9453125\n",
      "Iteration:  3808  Loss:  0.25793028   Accuracy:  0.921875\n",
      "Iteration:  3809  Loss:  0.5213061   Accuracy:  0.8828125\n",
      "Iteration:  3810  Loss:  0.30821308   Accuracy:  0.8984375\n",
      "Iteration:  3811  Loss:  0.34713507   Accuracy:  0.90625\n",
      "Iteration:  3812  Loss:  0.37163776   Accuracy:  0.921875\n",
      "Iteration:  3813  Loss:  0.31532222   Accuracy:  0.9296875\n",
      "Iteration:  3814  Loss:  0.54294676   Accuracy:  0.8828125\n",
      "Iteration:  3815  Loss:  0.46213073   Accuracy:  0.8515625\n",
      "Iteration:  3816  Loss:  0.34500462   Accuracy:  0.90625\n",
      "Iteration:  3817  Loss:  0.28422385   Accuracy:  0.9296875\n",
      "Iteration:  3818  Loss:  0.26518178   Accuracy:  0.9296875\n",
      "Iteration:  3819  Loss:  0.43958452   Accuracy:  0.90625\n",
      "Iteration:  3820  Loss:  0.29828307   Accuracy:  0.90625\n",
      "Iteration:  3821  Loss:  0.4625476   Accuracy:  0.859375\n",
      "Iteration:  3822  Loss:  0.43667826   Accuracy:  0.8828125\n",
      "Iteration:  3823  Loss:  0.5821473   Accuracy:  0.8984375\n",
      "Iteration:  3824  Loss:  0.38336575   Accuracy:  0.8671875\n",
      "Iteration:  3825  Loss:  0.20789863   Accuracy:  0.953125\n",
      "Iteration:  3826  Loss:  0.4717986   Accuracy:  0.890625\n",
      "Iteration:  3827  Loss:  0.554539   Accuracy:  0.921875\n",
      "Iteration:  3828  Loss:  0.36345357   Accuracy:  0.90625\n",
      "Iteration:  3829  Loss:  0.3052396   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3830  Loss:  0.6818149   Accuracy:  0.859375\n",
      "Iteration:  3831  Loss:  0.08856194   Accuracy:  0.9765625\n",
      "Iteration:  3832  Loss:  0.24436125   Accuracy:  0.9453125\n",
      "Iteration:  3833  Loss:  0.27645463   Accuracy:  0.921875\n",
      "Iteration:  3834  Loss:  0.41027874   Accuracy:  0.8984375\n",
      "Iteration:  3835  Loss:  0.41509137   Accuracy:  0.84375\n",
      "Iteration:  3836  Loss:  0.26275504   Accuracy:  0.9296875\n",
      "Iteration:  3837  Loss:  0.24489905   Accuracy:  0.9140625\n",
      "Iteration:  3838  Loss:  0.22740825   Accuracy:  0.921875\n",
      "Iteration:  3839  Loss:  0.6976762   Accuracy:  0.875\n",
      "Iteration:  3840  Loss:  0.5558684   Accuracy:  0.890625\n",
      "Iteration:  3841  Loss:  0.43249223   Accuracy:  0.90625\n",
      "Iteration:  3842  Loss:  0.2291431   Accuracy:  0.9140625\n",
      "Iteration:  3843  Loss:  0.47053537   Accuracy:  0.9140625\n",
      "Iteration:  3844  Loss:  0.21688312   Accuracy:  0.9296875\n",
      "Iteration:  3845  Loss:  0.50036263   Accuracy:  0.90625\n",
      "Iteration:  3846  Loss:  0.1799508   Accuracy:  0.953125\n",
      "Iteration:  3847  Loss:  0.32248503   Accuracy:  0.8828125\n",
      "Iteration:  3848  Loss:  0.6812187   Accuracy:  0.8671875\n",
      "Iteration:  3849  Loss:  0.38733125   Accuracy:  0.9296875\n",
      "Iteration:  3850  Loss:  0.25957707   Accuracy:  0.921875\n",
      "Iteration:  3851  Loss:  0.5559139   Accuracy:  0.8671875\n",
      "Iteration:  3852  Loss:  0.5177857   Accuracy:  0.8671875\n",
      "Iteration:  3853  Loss:  0.285142   Accuracy:  0.921875\n",
      "Iteration:  3854  Loss:  0.44446057   Accuracy:  0.890625\n",
      "Iteration:  3855  Loss:  0.42013392   Accuracy:  0.9296875\n",
      "Iteration:  3856  Loss:  0.27084422   Accuracy:  0.9296875\n",
      "Iteration:  3857  Loss:  0.3971604   Accuracy:  0.859375\n",
      "Iteration:  3858  Loss:  0.42429325   Accuracy:  0.921875\n",
      "Iteration:  3859  Loss:  0.58981377   Accuracy:  0.8828125\n",
      "Iteration:  3860  Loss:  0.32548165   Accuracy:  0.8828125\n",
      "Iteration:  3861  Loss:  0.5786049   Accuracy:  0.84375\n",
      "Iteration:  3862  Loss:  0.69143134   Accuracy:  0.859375\n",
      "Iteration:  3863  Loss:  0.42360628   Accuracy:  0.9140625\n",
      "Iteration:  3864  Loss:  0.30699044   Accuracy:  0.9296875\n",
      "Iteration:  3865  Loss:  0.23764515   Accuracy:  0.9375\n",
      "Iteration:  3866  Loss:  0.31948316   Accuracy:  0.90625\n",
      "Iteration:  3867  Loss:  0.38618976   Accuracy:  0.875\n",
      "Iteration:  3868  Loss:  0.39780912   Accuracy:  0.8671875\n",
      "Iteration:  3869  Loss:  0.34476608   Accuracy:  0.9140625\n",
      "Iteration:  3870  Loss:  0.2216568   Accuracy:  0.9453125\n",
      "Iteration:  3871  Loss:  0.29600617   Accuracy:  0.875\n",
      "Iteration:  3872  Loss:  0.36244577   Accuracy:  0.8828125\n",
      "Iteration:  3873  Loss:  0.3815711   Accuracy:  0.921875\n",
      "Iteration:  3874  Loss:  0.46665394   Accuracy:  0.8671875\n",
      "Iteration:  3875  Loss:  0.43761918   Accuracy:  0.8828125\n",
      "Iteration:  3876  Loss:  0.41893542   Accuracy:  0.8828125\n",
      "Iteration:  3877  Loss:  0.36832407   Accuracy:  0.9140625\n",
      "Iteration:  3878  Loss:  0.46182108   Accuracy:  0.90625\n",
      "Iteration:  3879  Loss:  0.2859557   Accuracy:  0.9296875\n",
      "Iteration:  3880  Loss:  0.53132546   Accuracy:  0.8671875\n",
      "Iteration:  3881  Loss:  0.41455373   Accuracy:  0.875\n",
      "Iteration:  3882  Loss:  0.5547292   Accuracy:  0.875\n",
      "Iteration:  3883  Loss:  0.5326653   Accuracy:  0.875\n",
      "Iteration:  3884  Loss:  0.34515122   Accuracy:  0.921875\n",
      "Iteration:  3885  Loss:  0.33346856   Accuracy:  0.9296875\n",
      "Iteration:  3886  Loss:  0.29684418   Accuracy:  0.90625\n",
      "Iteration:  3887  Loss:  0.41329136   Accuracy:  0.8828125\n",
      "Iteration:  3888  Loss:  0.30549783   Accuracy:  0.90625\n",
      "Iteration:  3889  Loss:  0.49609295   Accuracy:  0.8828125\n",
      "Iteration:  3890  Loss:  0.5237691   Accuracy:  0.9140625\n",
      "Iteration:  3891  Loss:  0.6592534   Accuracy:  0.90625\n",
      "Iteration:  3892  Loss:  0.65946186   Accuracy:  0.875\n",
      "Iteration:  3893  Loss:  0.15510532   Accuracy:  0.9453125\n",
      "Iteration:  3894  Loss:  0.3940644   Accuracy:  0.890625\n",
      "Iteration:  3895  Loss:  0.31994808   Accuracy:  0.8828125\n",
      "Iteration:  3896  Loss:  0.30932248   Accuracy:  0.921875\n",
      "Iteration:  3897  Loss:  0.4854531   Accuracy:  0.9375\n",
      "Iteration:  3898  Loss:  0.5497124   Accuracy:  0.8671875\n",
      "Iteration:  3899  Loss:  0.51329386   Accuracy:  0.859375\n",
      "Iteration:  3900  Loss:  0.39993602   Accuracy:  0.890625\n",
      "Iteration:  3901  Loss:  0.437474   Accuracy:  0.8515625\n",
      "Iteration:  3902  Loss:  0.40990672   Accuracy:  0.8671875\n",
      "Iteration:  3903  Loss:  0.4840542   Accuracy:  0.8984375\n",
      "Iteration:  3904  Loss:  0.2606346   Accuracy:  0.9296875\n",
      "Iteration:  3905  Loss:  0.3536136   Accuracy:  0.90625\n",
      "Iteration:  3906  Loss:  0.71636415   Accuracy:  0.84375\n",
      "Iteration:  3907  Loss:  0.31331432   Accuracy:  0.9296875\n",
      "Iteration:  3908  Loss:  0.26433152   Accuracy:  0.8984375\n",
      "Iteration:  3909  Loss:  0.6325331   Accuracy:  0.875\n",
      "Iteration:  3910  Loss:  0.2771797   Accuracy:  0.9296875\n",
      "Iteration:  3911  Loss:  0.40932557   Accuracy:  0.8671875\n",
      "Iteration:  3912  Loss:  0.392631   Accuracy:  0.8984375\n",
      "Iteration:  3913  Loss:  0.2756145   Accuracy:  0.8984375\n",
      "Iteration:  3914  Loss:  0.52491784   Accuracy:  0.90625\n",
      "Iteration:  3915  Loss:  0.3704591   Accuracy:  0.9140625\n",
      "Iteration:  3916  Loss:  0.38069186   Accuracy:  0.90625\n",
      "Iteration:  3917  Loss:  0.22605062   Accuracy:  0.921875\n",
      "Iteration:  3918  Loss:  0.39179108   Accuracy:  0.890625\n",
      "Iteration:  3919  Loss:  0.38160825   Accuracy:  0.8828125\n",
      "Iteration:  3920  Loss:  0.38822657   Accuracy:  0.8984375\n",
      "Iteration:  3921  Loss:  0.2308562   Accuracy:  0.9453125\n",
      "Iteration:  3922  Loss:  0.28096998   Accuracy:  0.9140625\n",
      "Iteration:  3923  Loss:  0.30344313   Accuracy:  0.921875\n",
      "Iteration:  3924  Loss:  0.4570943   Accuracy:  0.875\n",
      "Iteration:  3925  Loss:  0.14102371   Accuracy:  0.96875\n",
      "Iteration:  3926  Loss:  0.37609184   Accuracy:  0.859375\n",
      "Iteration:  3927  Loss:  0.3943379   Accuracy:  0.8828125\n",
      "Iteration:  3928  Loss:  0.43763912   Accuracy:  0.9296875\n",
      "Iteration:  3929  Loss:  0.47477427   Accuracy:  0.921875\n",
      "Iteration:  3930  Loss:  0.34249708   Accuracy:  0.8984375\n",
      "Iteration:  3931  Loss:  0.31296194   Accuracy:  0.921875\n",
      "Iteration:  3932  Loss:  0.3845357   Accuracy:  0.9140625\n",
      "Iteration:  3933  Loss:  0.4932257   Accuracy:  0.921875\n",
      "Iteration:  3934  Loss:  0.4927005   Accuracy:  0.8671875\n",
      "Iteration:  3935  Loss:  0.41902605   Accuracy:  0.890625\n",
      "Iteration:  3936  Loss:  0.25249702   Accuracy:  0.9296875\n",
      "Iteration:  3937  Loss:  0.5108974   Accuracy:  0.859375\n",
      "Iteration:  3938  Loss:  0.23938078   Accuracy:  0.9140625\n",
      "Iteration:  3939  Loss:  0.20645548   Accuracy:  0.9375\n",
      "Iteration:  3940  Loss:  0.2795221   Accuracy:  0.8984375\n",
      "Iteration:  3941  Loss:  0.27366146   Accuracy:  0.9140625\n",
      "Iteration:  3942  Loss:  0.35369802   Accuracy:  0.8515625\n",
      "Iteration:  3943  Loss:  0.27292213   Accuracy:  0.875\n",
      "Iteration:  3944  Loss:  0.47813714   Accuracy:  0.8359375\n",
      "Iteration:  3945  Loss:  0.25536647   Accuracy:  0.90625\n",
      "Iteration:  3946  Loss:  0.32085595   Accuracy:  0.90625\n",
      "Iteration:  3947  Loss:  0.17023747   Accuracy:  0.953125\n",
      "Iteration:  3948  Loss:  0.5337504   Accuracy:  0.8984375\n",
      "Iteration:  3949  Loss:  0.40857837   Accuracy:  0.90625\n",
      "Iteration:  3950  Loss:  0.3907688   Accuracy:  0.9140625\n",
      "Iteration:  3951  Loss:  0.43090478   Accuracy:  0.9296875\n",
      "Iteration:  3952  Loss:  0.14191106   Accuracy:  0.96875\n",
      "Iteration:  3953  Loss:  0.437805   Accuracy:  0.875\n",
      "Iteration:  3954  Loss:  0.3770427   Accuracy:  0.9140625\n",
      "Iteration:  3955  Loss:  0.5066813   Accuracy:  0.8984375\n",
      "Iteration:  3956  Loss:  0.4206042   Accuracy:  0.90625\n",
      "Iteration:  3957  Loss:  0.2808982   Accuracy:  0.90625\n",
      "Iteration:  3958  Loss:  0.5452968   Accuracy:  0.890625\n",
      "Iteration:  3959  Loss:  0.3149336   Accuracy:  0.8984375\n",
      "Iteration:  3960  Loss:  0.5349856   Accuracy:  0.8671875\n",
      "Iteration:  3961  Loss:  0.25021476   Accuracy:  0.9375\n",
      "Iteration:  3962  Loss:  0.28857198   Accuracy:  0.9140625\n",
      "Iteration:  3963  Loss:  0.31559688   Accuracy:  0.9296875\n",
      "Iteration:  3964  Loss:  0.3759345   Accuracy:  0.90625\n",
      "Iteration:  3965  Loss:  0.42255425   Accuracy:  0.8671875\n",
      "Iteration:  3966  Loss:  0.2856198   Accuracy:  0.9140625\n",
      "Iteration:  3967  Loss:  0.30699906   Accuracy:  0.9140625\n",
      "Iteration:  3968  Loss:  0.2778419   Accuracy:  0.921875\n",
      "Iteration:  3969  Loss:  0.5893701   Accuracy:  0.9140625\n",
      "Iteration:  3970  Loss:  0.24586937   Accuracy:  0.90625\n",
      "Iteration:  3971  Loss:  0.29314044   Accuracy:  0.90625\n",
      "Iteration:  3972  Loss:  0.22450444   Accuracy:  0.9296875\n",
      "Iteration:  3973  Loss:  0.35051388   Accuracy:  0.8984375\n",
      "Iteration:  3974  Loss:  0.19290878   Accuracy:  0.953125\n",
      "Iteration:  3975  Loss:  0.30374438   Accuracy:  0.953125\n",
      "Iteration:  3976  Loss:  0.41194558   Accuracy:  0.9140625\n",
      "Iteration:  3977  Loss:  0.30429363   Accuracy:  0.890625\n",
      "Iteration:  3978  Loss:  0.3737449   Accuracy:  0.9140625\n",
      "Iteration:  3979  Loss:  0.32406527   Accuracy:  0.9140625\n",
      "Iteration:  3980  Loss:  0.54039776   Accuracy:  0.8671875\n",
      "Iteration:  3981  Loss:  0.38046587   Accuracy:  0.875\n",
      "Iteration:  3982  Loss:  0.48951986   Accuracy:  0.90625\n",
      "Iteration:  3983  Loss:  0.25825697   Accuracy:  0.9140625\n",
      "Iteration:  3984  Loss:  0.49886307   Accuracy:  0.8515625\n",
      "Iteration:  3985  Loss:  0.29894382   Accuracy:  0.9296875\n",
      "Iteration:  3986  Loss:  0.27086565   Accuracy:  0.9453125\n",
      "Iteration:  3987  Loss:  0.19662908   Accuracy:  0.9375\n",
      "Iteration:  3988  Loss:  0.54270273   Accuracy:  0.8984375\n",
      "Iteration:  3989  Loss:  0.35976598   Accuracy:  0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3990  Loss:  0.20836872   Accuracy:  0.953125\n",
      "Iteration:  3991  Loss:  0.46967304   Accuracy:  0.8984375\n",
      "Iteration:  3992  Loss:  0.28979164   Accuracy:  0.90625\n",
      "Iteration:  3993  Loss:  0.33228508   Accuracy:  0.875\n",
      "Iteration:  3994  Loss:  0.56564176   Accuracy:  0.90625\n",
      "Iteration:  3995  Loss:  0.4512139   Accuracy:  0.890625\n",
      "Iteration:  3996  Loss:  0.32690802   Accuracy:  0.9296875\n",
      "Iteration:  3997  Loss:  0.24304096   Accuracy:  0.921875\n",
      "Iteration:  3998  Loss:  0.33677328   Accuracy:  0.9296875\n",
      "Iteration:  3999  Loss:  0.42150164   Accuracy:  0.90625\n",
      "Iteration:  4000  Loss:  0.14728728   Accuracy:  0.9453125\n",
      "Iteration:  4001  Loss:  0.31817806   Accuracy:  0.9140625\n",
      "Iteration:  4002  Loss:  0.5324019   Accuracy:  0.8515625\n",
      "Iteration:  4003  Loss:  0.18552579   Accuracy:  0.9453125\n",
      "Iteration:  4004  Loss:  0.5833849   Accuracy:  0.8984375\n",
      "Iteration:  4005  Loss:  0.25556722   Accuracy:  0.921875\n",
      "Iteration:  4006  Loss:  0.31256843   Accuracy:  0.9453125\n",
      "Iteration:  4007  Loss:  0.2867356   Accuracy:  0.8828125\n",
      "Iteration:  4008  Loss:  0.33489916   Accuracy:  0.9140625\n",
      "Iteration:  4009  Loss:  0.35405532   Accuracy:  0.9375\n",
      "Iteration:  4010  Loss:  0.2960475   Accuracy:  0.9296875\n",
      "Iteration:  4011  Loss:  0.45310247   Accuracy:  0.890625\n",
      "Iteration:  4012  Loss:  0.36253405   Accuracy:  0.921875\n",
      "Iteration:  4013  Loss:  0.23075283   Accuracy:  0.9140625\n",
      "Iteration:  4014  Loss:  0.6769593   Accuracy:  0.8671875\n",
      "Iteration:  4015  Loss:  0.19682896   Accuracy:  0.9375\n",
      "Iteration:  4016  Loss:  0.26248556   Accuracy:  0.921875\n",
      "Iteration:  4017  Loss:  0.3174157   Accuracy:  0.8828125\n",
      "Iteration:  4018  Loss:  0.36154708   Accuracy:  0.9140625\n",
      "Iteration:  4019  Loss:  0.40460834   Accuracy:  0.8515625\n",
      "Iteration:  4020  Loss:  0.31326178   Accuracy:  0.9296875\n",
      "Iteration:  4021  Loss:  0.379313   Accuracy:  0.890625\n",
      "Iteration:  4022  Loss:  0.44189525   Accuracy:  0.875\n",
      "Iteration:  4023  Loss:  0.24692616   Accuracy:  0.9140625\n",
      "Iteration:  4024  Loss:  0.24779698   Accuracy:  0.90625\n",
      "Iteration:  4025  Loss:  0.24812168   Accuracy:  0.90625\n",
      "Iteration:  4026  Loss:  0.33474   Accuracy:  0.8828125\n",
      "Iteration:  4027  Loss:  0.3429793   Accuracy:  0.9453125\n",
      "Iteration:  4028  Loss:  0.43555632   Accuracy:  0.8828125\n",
      "Iteration:  4029  Loss:  0.19068204   Accuracy:  0.9296875\n",
      "Iteration:  4030  Loss:  0.32241935   Accuracy:  0.890625\n",
      "Iteration:  4031  Loss:  0.3778673   Accuracy:  0.9296875\n",
      "Iteration:  4032  Loss:  0.25636187   Accuracy:  0.9296875\n",
      "Iteration:  4033  Loss:  0.3531741   Accuracy:  0.8828125\n",
      "Iteration:  4034  Loss:  0.26605445   Accuracy:  0.9140625\n",
      "Iteration:  4035  Loss:  0.42632934   Accuracy:  0.890625\n",
      "Iteration:  4036  Loss:  0.387385   Accuracy:  0.90625\n",
      "Iteration:  4037  Loss:  0.38858953   Accuracy:  0.90625\n",
      "Iteration:  4038  Loss:  0.62643623   Accuracy:  0.828125\n",
      "Iteration:  4039  Loss:  0.47622243   Accuracy:  0.875\n",
      "Iteration:  4040  Loss:  0.37901515   Accuracy:  0.90625\n",
      "Iteration:  4041  Loss:  0.36913916   Accuracy:  0.9375\n",
      "Iteration:  4042  Loss:  0.21722688   Accuracy:  0.9375\n",
      "Iteration:  4043  Loss:  0.21907721   Accuracy:  0.921875\n",
      "Iteration:  4044  Loss:  0.34198183   Accuracy:  0.890625\n",
      "Iteration:  4045  Loss:  0.42689925   Accuracy:  0.90625\n",
      "Iteration:  4046  Loss:  0.23786458   Accuracy:  0.9140625\n",
      "Iteration:  4047  Loss:  0.50610703   Accuracy:  0.8515625\n",
      "Iteration:  4048  Loss:  0.30104005   Accuracy:  0.8984375\n",
      "Iteration:  4049  Loss:  0.2775912   Accuracy:  0.921875\n",
      "Iteration:  4050  Loss:  0.3365026   Accuracy:  0.875\n",
      "Iteration:  4051  Loss:  0.2716916   Accuracy:  0.8984375\n",
      "Iteration:  4052  Loss:  0.29523596   Accuracy:  0.9296875\n",
      "Iteration:  4053  Loss:  0.2550425   Accuracy:  0.921875\n",
      "Iteration:  4054  Loss:  0.18133749   Accuracy:  0.9375\n",
      "Iteration:  4055  Loss:  0.36024815   Accuracy:  0.9375\n",
      "Iteration:  4056  Loss:  0.40107447   Accuracy:  0.90625\n",
      "Iteration:  4057  Loss:  0.58107275   Accuracy:  0.859375\n",
      "Iteration:  4058  Loss:  0.41399702   Accuracy:  0.8828125\n",
      "Iteration:  4059  Loss:  0.35829815   Accuracy:  0.9140625\n",
      "Iteration:  4060  Loss:  0.24077094   Accuracy:  0.9375\n",
      "Iteration:  4061  Loss:  0.41442963   Accuracy:  0.890625\n",
      "Iteration:  4062  Loss:  0.46918792   Accuracy:  0.90625\n",
      "Iteration:  4063  Loss:  0.3538086   Accuracy:  0.8828125\n",
      "Iteration:  4064  Loss:  0.30330318   Accuracy:  0.921875\n",
      "Iteration:  4065  Loss:  0.23069179   Accuracy:  0.9140625\n",
      "Iteration:  4066  Loss:  0.41677648   Accuracy:  0.8828125\n",
      "Iteration:  4067  Loss:  0.27541998   Accuracy:  0.9375\n",
      "Iteration:  4068  Loss:  0.30567378   Accuracy:  0.921875\n",
      "Iteration:  4069  Loss:  0.36380324   Accuracy:  0.8984375\n",
      "Iteration:  4070  Loss:  0.5495763   Accuracy:  0.8359375\n",
      "Iteration:  4071  Loss:  0.31361845   Accuracy:  0.875\n",
      "Iteration:  4072  Loss:  0.29285973   Accuracy:  0.9375\n",
      "Iteration:  4073  Loss:  0.2372487   Accuracy:  0.9296875\n",
      "Iteration:  4074  Loss:  0.41488054   Accuracy:  0.9140625\n",
      "Iteration:  4075  Loss:  0.36592934   Accuracy:  0.8828125\n",
      "Iteration:  4076  Loss:  0.5248324   Accuracy:  0.828125\n",
      "Iteration:  4077  Loss:  0.36360514   Accuracy:  0.8671875\n",
      "Iteration:  4078  Loss:  0.21775347   Accuracy:  0.921875\n",
      "Iteration:  4079  Loss:  0.41587818   Accuracy:  0.890625\n",
      "Iteration:  4080  Loss:  0.52922046   Accuracy:  0.9140625\n",
      "Iteration:  4081  Loss:  0.2448696   Accuracy:  0.9140625\n",
      "Iteration:  4082  Loss:  0.534343   Accuracy:  0.859375\n",
      "Iteration:  4083  Loss:  0.3729094   Accuracy:  0.9140625\n",
      "Iteration:  4084  Loss:  0.57972646   Accuracy:  0.890625\n",
      "Iteration:  4085  Loss:  0.16514917   Accuracy:  0.9375\n",
      "Iteration:  4086  Loss:  0.3130259   Accuracy:  0.890625\n",
      "Iteration:  4087  Loss:  0.3450153   Accuracy:  0.8984375\n",
      "Iteration:  4088  Loss:  0.31715855   Accuracy:  0.90625\n",
      "Iteration:  4089  Loss:  0.2645107   Accuracy:  0.9140625\n",
      "Iteration:  4090  Loss:  0.35100648   Accuracy:  0.9296875\n",
      "Iteration:  4091  Loss:  0.48281273   Accuracy:  0.875\n",
      "Iteration:  4092  Loss:  0.39571196   Accuracy:  0.8984375\n",
      "Iteration:  4093  Loss:  0.1889967   Accuracy:  0.9296875\n",
      "Iteration:  4094  Loss:  0.27415657   Accuracy:  0.9140625\n",
      "Iteration:  4095  Loss:  0.3455624   Accuracy:  0.90625\n",
      "Iteration:  4096  Loss:  0.46016476   Accuracy:  0.875\n",
      "Iteration:  4097  Loss:  0.3203049   Accuracy:  0.90625\n",
      "Iteration:  4098  Loss:  0.54174346   Accuracy:  0.9140625\n",
      "Iteration:  4099  Loss:  0.31746125   Accuracy:  0.9296875\n",
      "Iteration:  4100  Loss:  0.61125517   Accuracy:  0.890625\n",
      "Iteration:  4101  Loss:  0.28138408   Accuracy:  0.90625\n",
      "Iteration:  4102  Loss:  0.21470106   Accuracy:  0.953125\n",
      "Iteration:  4103  Loss:  0.21066195   Accuracy:  0.9375\n",
      "Iteration:  4104  Loss:  0.48904383   Accuracy:  0.90625\n",
      "Iteration:  4105  Loss:  0.114639595   Accuracy:  0.9765625\n",
      "Iteration:  4106  Loss:  0.24212974   Accuracy:  0.90625\n",
      "Iteration:  4107  Loss:  0.32058358   Accuracy:  0.8984375\n",
      "Iteration:  4108  Loss:  0.22177681   Accuracy:  0.9140625\n",
      "Iteration:  4109  Loss:  0.28694195   Accuracy:  0.9609375\n",
      "Iteration:  4110  Loss:  0.36797482   Accuracy:  0.921875\n",
      "Iteration:  4111  Loss:  0.58818305   Accuracy:  0.8515625\n",
      "Iteration:  4112  Loss:  0.34861672   Accuracy:  0.9140625\n",
      "Iteration:  4113  Loss:  0.23065127   Accuracy:  0.921875\n",
      "Iteration:  4114  Loss:  0.31019074   Accuracy:  0.8828125\n",
      "Iteration:  4115  Loss:  0.1743827   Accuracy:  0.9375\n",
      "Iteration:  4116  Loss:  0.48274118   Accuracy:  0.8828125\n",
      "Iteration:  4117  Loss:  0.3320629   Accuracy:  0.8984375\n",
      "Iteration:  4118  Loss:  0.2204631   Accuracy:  0.90625\n",
      "Iteration:  4119  Loss:  0.30904078   Accuracy:  0.90625\n",
      "Iteration:  4120  Loss:  0.335209   Accuracy:  0.921875\n",
      "Iteration:  4121  Loss:  0.3705036   Accuracy:  0.8984375\n",
      "Iteration:  4122  Loss:  0.33449134   Accuracy:  0.90625\n",
      "Iteration:  4123  Loss:  0.31983113   Accuracy:  0.921875\n",
      "Iteration:  4124  Loss:  0.45468408   Accuracy:  0.8984375\n",
      "Iteration:  4125  Loss:  0.42224708   Accuracy:  0.8671875\n",
      "Iteration:  4126  Loss:  0.5116112   Accuracy:  0.8828125\n",
      "Iteration:  4127  Loss:  0.2313205   Accuracy:  0.9453125\n",
      "Iteration:  4128  Loss:  0.3273342   Accuracy:  0.90625\n",
      "Iteration:  4129  Loss:  0.37610084   Accuracy:  0.90625\n",
      "Iteration:  4130  Loss:  0.3377499   Accuracy:  0.9296875\n",
      "Iteration:  4131  Loss:  0.23733139   Accuracy:  0.921875\n",
      "Iteration:  4132  Loss:  0.20623234   Accuracy:  0.921875\n",
      "Iteration:  4133  Loss:  0.35215622   Accuracy:  0.9140625\n",
      "Iteration:  4134  Loss:  0.30867183   Accuracy:  0.90625\n",
      "Iteration:  4135  Loss:  0.3946168   Accuracy:  0.921875\n",
      "Iteration:  4136  Loss:  0.5029802   Accuracy:  0.9140625\n",
      "Iteration:  4137  Loss:  0.3254826   Accuracy:  0.90625\n",
      "Iteration:  4138  Loss:  0.40483272   Accuracy:  0.8671875\n",
      "Iteration:  4139  Loss:  0.42716473   Accuracy:  0.9140625\n",
      "Iteration:  4140  Loss:  0.27559224   Accuracy:  0.9453125\n",
      "Iteration:  4141  Loss:  0.35073918   Accuracy:  0.9140625\n",
      "Iteration:  4142  Loss:  0.5640409   Accuracy:  0.8515625\n",
      "Iteration:  4143  Loss:  0.40923953   Accuracy:  0.890625\n",
      "Iteration:  4144  Loss:  0.419653   Accuracy:  0.8984375\n",
      "Iteration:  4145  Loss:  0.3852502   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4146  Loss:  0.42039853   Accuracy:  0.890625\n",
      "Iteration:  4147  Loss:  0.35076517   Accuracy:  0.9140625\n",
      "Iteration:  4148  Loss:  0.4164973   Accuracy:  0.875\n",
      "Iteration:  4149  Loss:  0.55255985   Accuracy:  0.875\n",
      "Iteration:  4150  Loss:  0.34453857   Accuracy:  0.890625\n",
      "Iteration:  4151  Loss:  0.36364302   Accuracy:  0.8984375\n",
      "Iteration:  4152  Loss:  0.4148523   Accuracy:  0.9296875\n",
      "Iteration:  4153  Loss:  0.5889176   Accuracy:  0.875\n",
      "Iteration:  4154  Loss:  0.24768235   Accuracy:  0.921875\n",
      "Iteration:  4155  Loss:  0.6267258   Accuracy:  0.875\n",
      "Iteration:  4156  Loss:  0.5052314   Accuracy:  0.90625\n",
      "Iteration:  4157  Loss:  0.36215138   Accuracy:  0.890625\n",
      "Iteration:  4158  Loss:  0.30896723   Accuracy:  0.90625\n",
      "Iteration:  4159  Loss:  0.2543993   Accuracy:  0.9296875\n",
      "Iteration:  4160  Loss:  0.33101755   Accuracy:  0.875\n",
      "Iteration:  4161  Loss:  0.4185703   Accuracy:  0.890625\n",
      "Iteration:  4162  Loss:  0.26317573   Accuracy:  0.9453125\n",
      "Iteration:  4163  Loss:  0.20367032   Accuracy:  0.921875\n",
      "Iteration:  4164  Loss:  0.3184353   Accuracy:  0.8828125\n",
      "Iteration:  4165  Loss:  0.21064475   Accuracy:  0.9375\n",
      "Iteration:  4166  Loss:  0.62037426   Accuracy:  0.8828125\n",
      "Iteration:  4167  Loss:  0.40138754   Accuracy:  0.875\n",
      "Iteration:  4168  Loss:  0.31072438   Accuracy:  0.921875\n",
      "Iteration:  4169  Loss:  0.4119449   Accuracy:  0.875\n",
      "Iteration:  4170  Loss:  0.21813112   Accuracy:  0.96875\n",
      "Iteration:  4171  Loss:  0.29361802   Accuracy:  0.9140625\n",
      "Iteration:  4172  Loss:  0.5887773   Accuracy:  0.859375\n",
      "Iteration:  4173  Loss:  0.36474445   Accuracy:  0.890625\n",
      "Iteration:  4174  Loss:  0.61900413   Accuracy:  0.859375\n",
      "Iteration:  4175  Loss:  0.44693378   Accuracy:  0.890625\n",
      "Iteration:  4176  Loss:  0.215091   Accuracy:  0.9375\n",
      "Iteration:  4177  Loss:  0.17094739   Accuracy:  0.9453125\n",
      "Iteration:  4178  Loss:  0.3602554   Accuracy:  0.9296875\n",
      "Iteration:  4179  Loss:  0.3085763   Accuracy:  0.8984375\n",
      "Iteration:  4180  Loss:  0.45638973   Accuracy:  0.890625\n",
      "Iteration:  4181  Loss:  0.21628402   Accuracy:  0.9453125\n",
      "Iteration:  4182  Loss:  0.28027934   Accuracy:  0.9140625\n",
      "Iteration:  4183  Loss:  0.26600423   Accuracy:  0.9140625\n",
      "Iteration:  4184  Loss:  0.47746536   Accuracy:  0.90625\n",
      "Iteration:  4185  Loss:  0.25006607   Accuracy:  0.9375\n",
      "Iteration:  4186  Loss:  0.27197862   Accuracy:  0.921875\n",
      "Iteration:  4187  Loss:  0.50050133   Accuracy:  0.8828125\n",
      "Iteration:  4188  Loss:  0.33507335   Accuracy:  0.9296875\n",
      "Iteration:  4189  Loss:  0.36189598   Accuracy:  0.8828125\n",
      "Iteration:  4190  Loss:  0.39184803   Accuracy:  0.921875\n",
      "Iteration:  4191  Loss:  0.4250397   Accuracy:  0.8984375\n",
      "Iteration:  4192  Loss:  0.30100423   Accuracy:  0.8828125\n",
      "Iteration:  4193  Loss:  0.45334277   Accuracy:  0.8984375\n",
      "Iteration:  4194  Loss:  0.48469737   Accuracy:  0.8828125\n",
      "Iteration:  4195  Loss:  0.76067764   Accuracy:  0.8671875\n",
      "Iteration:  4196  Loss:  0.3423398   Accuracy:  0.90625\n",
      "Iteration:  4197  Loss:  0.32913566   Accuracy:  0.9296875\n",
      "Iteration:  4198  Loss:  0.58258295   Accuracy:  0.8984375\n",
      "Iteration:  4199  Loss:  0.31830966   Accuracy:  0.8984375\n",
      "Iteration:  4200  Loss:  0.29085708   Accuracy:  0.90625\n",
      "Iteration:  4201  Loss:  0.24960062   Accuracy:  0.921875\n",
      "Iteration:  4202  Loss:  0.30660605   Accuracy:  0.921875\n",
      "Iteration:  4203  Loss:  0.40462142   Accuracy:  0.890625\n",
      "Iteration:  4204  Loss:  0.3182155   Accuracy:  0.90625\n",
      "Iteration:  4205  Loss:  0.38474846   Accuracy:  0.9140625\n",
      "Iteration:  4206  Loss:  0.5939283   Accuracy:  0.8671875\n",
      "Iteration:  4207  Loss:  0.30558223   Accuracy:  0.921875\n",
      "Iteration:  4208  Loss:  0.41685584   Accuracy:  0.8671875\n",
      "Iteration:  4209  Loss:  0.45567024   Accuracy:  0.90625\n",
      "Iteration:  4210  Loss:  0.37515035   Accuracy:  0.890625\n",
      "Iteration:  4211  Loss:  0.56174314   Accuracy:  0.8828125\n",
      "Iteration:  4212  Loss:  0.41824865   Accuracy:  0.8671875\n",
      "Iteration:  4213  Loss:  0.5296747   Accuracy:  0.8984375\n",
      "Iteration:  4214  Loss:  0.4915852   Accuracy:  0.8671875\n",
      "Iteration:  4215  Loss:  0.2650186   Accuracy:  0.90625\n",
      "Iteration:  4216  Loss:  0.23796839   Accuracy:  0.9140625\n",
      "Iteration:  4217  Loss:  0.51115394   Accuracy:  0.8515625\n",
      "Iteration:  4218  Loss:  0.28690732   Accuracy:  0.90625\n",
      "Iteration:  4219  Loss:  0.34439078   Accuracy:  0.90625\n",
      "Iteration:  4220  Loss:  0.42333725   Accuracy:  0.90625\n",
      "Iteration:  4221  Loss:  0.41734552   Accuracy:  0.90625\n",
      "Iteration:  4222  Loss:  0.20789684   Accuracy:  0.9453125\n",
      "Iteration:  4223  Loss:  0.4767394   Accuracy:  0.890625\n",
      "Iteration:  4224  Loss:  0.43352336   Accuracy:  0.90625\n",
      "Iteration:  4225  Loss:  0.19039689   Accuracy:  0.9375\n",
      "Iteration:  4226  Loss:  0.3806887   Accuracy:  0.90625\n",
      "Iteration:  4227  Loss:  0.17764366   Accuracy:  0.921875\n",
      "Iteration:  4228  Loss:  0.46174422   Accuracy:  0.875\n",
      "Iteration:  4229  Loss:  0.27413613   Accuracy:  0.921875\n",
      "Iteration:  4230  Loss:  0.6624967   Accuracy:  0.8671875\n",
      "Iteration:  4231  Loss:  0.27191177   Accuracy:  0.9296875\n",
      "Iteration:  4232  Loss:  0.29633468   Accuracy:  0.890625\n",
      "Iteration:  4233  Loss:  0.33662778   Accuracy:  0.9140625\n",
      "Iteration:  4234  Loss:  0.46844736   Accuracy:  0.8671875\n",
      "Iteration:  4235  Loss:  0.48525143   Accuracy:  0.890625\n",
      "Iteration:  4236  Loss:  0.19743344   Accuracy:  0.921875\n",
      "Iteration:  4237  Loss:  0.57546246   Accuracy:  0.8671875\n",
      "Iteration:  4238  Loss:  0.39973605   Accuracy:  0.90625\n",
      "Iteration:  4239  Loss:  0.28008252   Accuracy:  0.90625\n",
      "Iteration:  4240  Loss:  0.21381962   Accuracy:  0.90625\n",
      "Iteration:  4241  Loss:  0.392413   Accuracy:  0.8515625\n",
      "Iteration:  4242  Loss:  0.28518283   Accuracy:  0.921875\n",
      "Iteration:  4243  Loss:  0.34240198   Accuracy:  0.90625\n",
      "Iteration:  4244  Loss:  0.31618208   Accuracy:  0.890625\n",
      "Iteration:  4245  Loss:  0.20877609   Accuracy:  0.9453125\n",
      "Iteration:  4246  Loss:  0.36524007   Accuracy:  0.890625\n",
      "Iteration:  4247  Loss:  0.3575374   Accuracy:  0.9140625\n",
      "Iteration:  4248  Loss:  0.33146694   Accuracy:  0.90625\n",
      "Iteration:  4249  Loss:  0.22387594   Accuracy:  0.9375\n",
      "Iteration:  4250  Loss:  0.20970789   Accuracy:  0.9609375\n",
      "Iteration:  4251  Loss:  0.2213193   Accuracy:  0.921875\n",
      "Iteration:  4252  Loss:  0.25152165   Accuracy:  0.90625\n",
      "Iteration:  4253  Loss:  0.27289099   Accuracy:  0.9140625\n",
      "Iteration:  4254  Loss:  0.37483132   Accuracy:  0.90625\n",
      "Iteration:  4255  Loss:  0.2053512   Accuracy:  0.9140625\n",
      "Iteration:  4256  Loss:  0.6844156   Accuracy:  0.8515625\n",
      "Iteration:  4257  Loss:  0.5796444   Accuracy:  0.8515625\n",
      "Iteration:  4258  Loss:  0.25664905   Accuracy:  0.9140625\n",
      "Iteration:  4259  Loss:  0.2936985   Accuracy:  0.90625\n",
      "Iteration:  4260  Loss:  0.43133265   Accuracy:  0.875\n",
      "Iteration:  4261  Loss:  0.6385745   Accuracy:  0.8984375\n",
      "Iteration:  4262  Loss:  0.38742673   Accuracy:  0.8828125\n",
      "Iteration:  4263  Loss:  0.24365202   Accuracy:  0.921875\n",
      "Iteration:  4264  Loss:  0.29279867   Accuracy:  0.90625\n",
      "Iteration:  4265  Loss:  0.23306996   Accuracy:  0.953125\n",
      "Iteration:  4266  Loss:  0.28843266   Accuracy:  0.9296875\n",
      "Iteration:  4267  Loss:  0.22274175   Accuracy:  0.9296875\n",
      "Iteration:  4268  Loss:  0.5093814   Accuracy:  0.8671875\n",
      "Iteration:  4269  Loss:  0.4442131   Accuracy:  0.859375\n",
      "Iteration:  4270  Loss:  0.28836232   Accuracy:  0.9453125\n",
      "Iteration:  4271  Loss:  0.33192056   Accuracy:  0.921875\n",
      "Iteration:  4272  Loss:  0.62165093   Accuracy:  0.859375\n",
      "Iteration:  4273  Loss:  0.31817794   Accuracy:  0.9375\n",
      "Iteration:  4274  Loss:  0.31502765   Accuracy:  0.890625\n",
      "Iteration:  4275  Loss:  0.23466508   Accuracy:  0.9453125\n",
      "Iteration:  4276  Loss:  0.32243437   Accuracy:  0.9375\n",
      "Iteration:  4277  Loss:  0.3757226   Accuracy:  0.890625\n",
      "Iteration:  4278  Loss:  0.36158752   Accuracy:  0.90625\n",
      "Iteration:  4279  Loss:  0.38624793   Accuracy:  0.90625\n",
      "Iteration:  4280  Loss:  0.34848893   Accuracy:  0.875\n",
      "Iteration:  4281  Loss:  0.28821427   Accuracy:  0.8984375\n",
      "Iteration:  4282  Loss:  0.5429078   Accuracy:  0.890625\n",
      "Iteration:  4283  Loss:  0.43466872   Accuracy:  0.8984375\n",
      "Iteration:  4284  Loss:  0.32191923   Accuracy:  0.921875\n",
      "Iteration:  4285  Loss:  0.12342556   Accuracy:  0.96875\n",
      "Iteration:  4286  Loss:  0.5439096   Accuracy:  0.8671875\n",
      "Iteration:  4287  Loss:  0.3566732   Accuracy:  0.8984375\n",
      "Iteration:  4288  Loss:  0.67113   Accuracy:  0.890625\n",
      "Iteration:  4289  Loss:  0.6290562   Accuracy:  0.890625\n",
      "Iteration:  4290  Loss:  0.30767435   Accuracy:  0.9375\n",
      "Iteration:  4291  Loss:  0.36711293   Accuracy:  0.890625\n",
      "Iteration:  4292  Loss:  0.39958107   Accuracy:  0.9140625\n",
      "Iteration:  4293  Loss:  0.32118544   Accuracy:  0.921875\n",
      "Iteration:  4294  Loss:  0.28730696   Accuracy:  0.9296875\n",
      "Iteration:  4295  Loss:  0.45477834   Accuracy:  0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4296  Loss:  0.38049358   Accuracy:  0.8984375\n",
      "Iteration:  4297  Loss:  0.7897848   Accuracy:  0.84375\n",
      "Iteration:  4298  Loss:  0.4389185   Accuracy:  0.9140625\n",
      "Iteration:  4299  Loss:  0.3697546   Accuracy:  0.9296875\n",
      "Iteration:  4300  Loss:  0.4237914   Accuracy:  0.8984375\n",
      "Iteration:  4301  Loss:  0.4856398   Accuracy:  0.8828125\n",
      "Iteration:  4302  Loss:  0.2508712   Accuracy:  0.9140625\n",
      "Iteration:  4303  Loss:  0.40223   Accuracy:  0.8828125\n",
      "Iteration:  4304  Loss:  0.46281832   Accuracy:  0.9140625\n",
      "Iteration:  4305  Loss:  0.3821079   Accuracy:  0.9375\n",
      "Iteration:  4306  Loss:  0.48185888   Accuracy:  0.90625\n",
      "Iteration:  4307  Loss:  0.33847216   Accuracy:  0.9140625\n",
      "Iteration:  4308  Loss:  0.37639827   Accuracy:  0.8984375\n",
      "Iteration:  4309  Loss:  0.22670677   Accuracy:  0.9375\n",
      "Iteration:  4310  Loss:  0.17475896   Accuracy:  0.9296875\n",
      "Iteration:  4311  Loss:  0.2997704   Accuracy:  0.890625\n",
      "Iteration:  4312  Loss:  0.21269503   Accuracy:  0.9140625\n",
      "Iteration:  4313  Loss:  0.3601188   Accuracy:  0.90625\n",
      "Iteration:  4314  Loss:  0.3205698   Accuracy:  0.921875\n",
      "Iteration:  4315  Loss:  0.48982733   Accuracy:  0.859375\n",
      "Iteration:  4316  Loss:  0.2809467   Accuracy:  0.90625\n",
      "Iteration:  4317  Loss:  0.40328395   Accuracy:  0.90625\n",
      "Iteration:  4318  Loss:  0.2666642   Accuracy:  0.9140625\n",
      "Iteration:  4319  Loss:  0.40221524   Accuracy:  0.9296875\n",
      "Iteration:  4320  Loss:  0.302094   Accuracy:  0.8828125\n",
      "Iteration:  4321  Loss:  0.32589793   Accuracy:  0.9375\n",
      "Iteration:  4322  Loss:  0.30153805   Accuracy:  0.9453125\n",
      "Iteration:  4323  Loss:  0.51612127   Accuracy:  0.875\n",
      "Iteration:  4324  Loss:  0.36415142   Accuracy:  0.90625\n",
      "Iteration:  4325  Loss:  0.31069636   Accuracy:  0.9296875\n",
      "Iteration:  4326  Loss:  0.4417106   Accuracy:  0.8828125\n",
      "Iteration:  4327  Loss:  0.15574133   Accuracy:  0.9453125\n",
      "Iteration:  4328  Loss:  0.21077672   Accuracy:  0.9296875\n",
      "Iteration:  4329  Loss:  0.18184704   Accuracy:  0.953125\n",
      "Iteration:  4330  Loss:  0.28993735   Accuracy:  0.9609375\n",
      "Iteration:  4331  Loss:  0.41159812   Accuracy:  0.8984375\n",
      "Iteration:  4332  Loss:  0.2735223   Accuracy:  0.921875\n",
      "Iteration:  4333  Loss:  0.30419934   Accuracy:  0.890625\n",
      "Iteration:  4334  Loss:  0.40641704   Accuracy:  0.9296875\n",
      "Iteration:  4335  Loss:  0.5140339   Accuracy:  0.875\n",
      "Iteration:  4336  Loss:  0.20446774   Accuracy:  0.953125\n",
      "Iteration:  4337  Loss:  0.30017588   Accuracy:  0.8828125\n",
      "Iteration:  4338  Loss:  0.41760397   Accuracy:  0.921875\n",
      "Iteration:  4339  Loss:  0.3460867   Accuracy:  0.9140625\n",
      "Iteration:  4340  Loss:  0.5771132   Accuracy:  0.8125\n",
      "Iteration:  4341  Loss:  0.358479   Accuracy:  0.890625\n",
      "Iteration:  4342  Loss:  0.254825   Accuracy:  0.921875\n",
      "Iteration:  4343  Loss:  0.34921047   Accuracy:  0.8984375\n",
      "Iteration:  4344  Loss:  0.31250143   Accuracy:  0.9140625\n",
      "Iteration:  4345  Loss:  0.2598598   Accuracy:  0.921875\n",
      "Iteration:  4346  Loss:  0.32513496   Accuracy:  0.8984375\n",
      "Iteration:  4347  Loss:  0.16835359   Accuracy:  0.9296875\n",
      "Iteration:  4348  Loss:  0.51056004   Accuracy:  0.875\n",
      "Iteration:  4349  Loss:  0.2604587   Accuracy:  0.9140625\n",
      "Iteration:  4350  Loss:  0.43043032   Accuracy:  0.8828125\n",
      "Iteration:  4351  Loss:  0.1966724   Accuracy:  0.9140625\n",
      "Iteration:  4352  Loss:  0.44656324   Accuracy:  0.9296875\n",
      "Iteration:  4353  Loss:  0.24249178   Accuracy:  0.9375\n",
      "Iteration:  4354  Loss:  0.46148846   Accuracy:  0.8671875\n",
      "Iteration:  4355  Loss:  0.40300658   Accuracy:  0.9140625\n",
      "Iteration:  4356  Loss:  0.25410384   Accuracy:  0.9296875\n",
      "Iteration:  4357  Loss:  0.34572932   Accuracy:  0.890625\n",
      "Iteration:  4358  Loss:  0.34908962   Accuracy:  0.9296875\n",
      "Iteration:  4359  Loss:  0.41946965   Accuracy:  0.875\n",
      "Iteration:  4360  Loss:  0.32572445   Accuracy:  0.90625\n",
      "Iteration:  4361  Loss:  0.29436532   Accuracy:  0.9375\n",
      "Iteration:  4362  Loss:  0.36424842   Accuracy:  0.8984375\n",
      "Iteration:  4363  Loss:  0.54824424   Accuracy:  0.8515625\n",
      "Iteration:  4364  Loss:  0.25071013   Accuracy:  0.9296875\n",
      "Iteration:  4365  Loss:  0.21815671   Accuracy:  0.9375\n",
      "Iteration:  4366  Loss:  0.31270084   Accuracy:  0.921875\n",
      "Iteration:  4367  Loss:  0.30468544   Accuracy:  0.890625\n",
      "Iteration:  4368  Loss:  0.28920913   Accuracy:  0.921875\n",
      "Iteration:  4369  Loss:  0.14125514   Accuracy:  0.953125\n",
      "Iteration:  4370  Loss:  0.37892377   Accuracy:  0.890625\n",
      "Iteration:  4371  Loss:  0.21346352   Accuracy:  0.9453125\n",
      "Iteration:  4372  Loss:  0.24134126   Accuracy:  0.9453125\n",
      "Iteration:  4373  Loss:  0.2850911   Accuracy:  0.8984375\n",
      "Iteration:  4374  Loss:  0.18519703   Accuracy:  0.9453125\n",
      "Iteration:  4375  Loss:  0.35594085   Accuracy:  0.90625\n",
      "Iteration:  4376  Loss:  0.19069207   Accuracy:  0.9453125\n",
      "Iteration:  4377  Loss:  0.2567864   Accuracy:  0.9140625\n",
      "Iteration:  4378  Loss:  0.25519395   Accuracy:  0.9140625\n",
      "Iteration:  4379  Loss:  0.2804981   Accuracy:  0.890625\n",
      "Iteration:  4380  Loss:  0.42096668   Accuracy:  0.9296875\n",
      "Iteration:  4381  Loss:  0.23232421   Accuracy:  0.921875\n",
      "Iteration:  4382  Loss:  0.4323549   Accuracy:  0.921875\n",
      "Iteration:  4383  Loss:  0.3757196   Accuracy:  0.890625\n",
      "Iteration:  4384  Loss:  0.4746003   Accuracy:  0.859375\n",
      "Iteration:  4385  Loss:  0.17915478   Accuracy:  0.9453125\n",
      "Iteration:  4386  Loss:  0.38825294   Accuracy:  0.8984375\n",
      "Iteration:  4387  Loss:  0.11098579   Accuracy:  0.953125\n",
      "Iteration:  4388  Loss:  0.3158265   Accuracy:  0.9375\n",
      "Iteration:  4389  Loss:  0.16872355   Accuracy:  0.9375\n",
      "Iteration:  4390  Loss:  0.2510075   Accuracy:  0.921875\n",
      "Iteration:  4391  Loss:  0.37015563   Accuracy:  0.8984375\n",
      "Iteration:  4392  Loss:  0.31248653   Accuracy:  0.8828125\n",
      "Iteration:  4393  Loss:  0.26204932   Accuracy:  0.9296875\n",
      "Iteration:  4394  Loss:  0.5212533   Accuracy:  0.875\n",
      "Iteration:  4395  Loss:  0.4291416   Accuracy:  0.8984375\n",
      "Iteration:  4396  Loss:  0.5895713   Accuracy:  0.8828125\n",
      "Iteration:  4397  Loss:  0.224983   Accuracy:  0.9375\n",
      "Iteration:  4398  Loss:  0.39382234   Accuracy:  0.8828125\n",
      "Iteration:  4399  Loss:  0.39875263   Accuracy:  0.890625\n",
      "Iteration:  4400  Loss:  0.13110653   Accuracy:  0.9609375\n",
      "Iteration:  4401  Loss:  0.49489403   Accuracy:  0.890625\n",
      "Iteration:  4402  Loss:  0.22911072   Accuracy:  0.921875\n",
      "Iteration:  4403  Loss:  0.38589376   Accuracy:  0.890625\n",
      "Iteration:  4404  Loss:  0.41557264   Accuracy:  0.84375\n",
      "Iteration:  4405  Loss:  0.14807877   Accuracy:  0.9453125\n",
      "Iteration:  4406  Loss:  0.41980067   Accuracy:  0.890625\n",
      "Iteration:  4407  Loss:  0.18296802   Accuracy:  0.9609375\n",
      "Iteration:  4408  Loss:  0.3768791   Accuracy:  0.8828125\n",
      "Iteration:  4409  Loss:  0.40819764   Accuracy:  0.8984375\n",
      "Iteration:  4410  Loss:  0.41263422   Accuracy:  0.8828125\n",
      "Iteration:  4411  Loss:  0.29508784   Accuracy:  0.9296875\n",
      "Iteration:  4412  Loss:  0.5529597   Accuracy:  0.8828125\n",
      "Iteration:  4413  Loss:  0.37375864   Accuracy:  0.890625\n",
      "Iteration:  4414  Loss:  0.5618398   Accuracy:  0.890625\n",
      "Iteration:  4415  Loss:  0.4271133   Accuracy:  0.90625\n",
      "Iteration:  4416  Loss:  0.23923004   Accuracy:  0.921875\n",
      "Iteration:  4417  Loss:  0.37851793   Accuracy:  0.9140625\n",
      "Iteration:  4418  Loss:  0.52834827   Accuracy:  0.8984375\n",
      "Iteration:  4419  Loss:  0.24902633   Accuracy:  0.9296875\n",
      "Iteration:  4420  Loss:  0.30663294   Accuracy:  0.9140625\n",
      "Iteration:  4421  Loss:  0.2196734   Accuracy:  0.9453125\n",
      "Iteration:  4422  Loss:  0.36791134   Accuracy:  0.859375\n",
      "Iteration:  4423  Loss:  0.3160491   Accuracy:  0.890625\n",
      "Iteration:  4424  Loss:  0.34961253   Accuracy:  0.90625\n",
      "Iteration:  4425  Loss:  0.29978466   Accuracy:  0.9140625\n",
      "Iteration:  4426  Loss:  0.19978625   Accuracy:  0.921875\n",
      "Iteration:  4427  Loss:  0.27933654   Accuracy:  0.921875\n",
      "Iteration:  4428  Loss:  0.33543777   Accuracy:  0.9296875\n",
      "Iteration:  4429  Loss:  0.4241039   Accuracy:  0.8984375\n",
      "Iteration:  4430  Loss:  0.26715523   Accuracy:  0.90625\n",
      "Iteration:  4431  Loss:  0.28696036   Accuracy:  0.8984375\n",
      "Iteration:  4432  Loss:  0.23905614   Accuracy:  0.9375\n",
      "Iteration:  4433  Loss:  0.15994799   Accuracy:  0.9453125\n",
      "Iteration:  4434  Loss:  0.6547446   Accuracy:  0.859375\n",
      "Iteration:  4435  Loss:  0.30407044   Accuracy:  0.9453125\n",
      "Iteration:  4436  Loss:  0.51390207   Accuracy:  0.875\n",
      "Iteration:  4437  Loss:  0.24182078   Accuracy:  0.9296875\n",
      "Iteration:  4438  Loss:  0.3874001   Accuracy:  0.8984375\n",
      "Iteration:  4439  Loss:  0.35262564   Accuracy:  0.8671875\n",
      "Iteration:  4440  Loss:  0.21340832   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4441  Loss:  0.4720219   Accuracy:  0.8984375\n",
      "Iteration:  4442  Loss:  0.26793873   Accuracy:  0.9140625\n",
      "Iteration:  4443  Loss:  0.4208261   Accuracy:  0.890625\n",
      "Iteration:  4444  Loss:  0.2793288   Accuracy:  0.9140625\n",
      "Iteration:  4445  Loss:  0.38003898   Accuracy:  0.8984375\n",
      "Iteration:  4446  Loss:  0.37294632   Accuracy:  0.875\n",
      "Iteration:  4447  Loss:  0.3845082   Accuracy:  0.921875\n",
      "Iteration:  4448  Loss:  0.44157493   Accuracy:  0.8828125\n",
      "Iteration:  4449  Loss:  0.4540136   Accuracy:  0.8671875\n",
      "Iteration:  4450  Loss:  0.18849488   Accuracy:  0.90625\n",
      "Iteration:  4451  Loss:  0.6107981   Accuracy:  0.8828125\n",
      "Iteration:  4452  Loss:  0.41144022   Accuracy:  0.9140625\n",
      "Iteration:  4453  Loss:  0.7325033   Accuracy:  0.828125\n",
      "Iteration:  4454  Loss:  0.40324336   Accuracy:  0.8984375\n",
      "Iteration:  4455  Loss:  0.44495413   Accuracy:  0.890625\n",
      "Iteration:  4456  Loss:  0.30368695   Accuracy:  0.90625\n",
      "Iteration:  4457  Loss:  0.2821332   Accuracy:  0.9375\n",
      "Iteration:  4458  Loss:  0.3931463   Accuracy:  0.875\n",
      "Iteration:  4459  Loss:  0.38288963   Accuracy:  0.890625\n",
      "Iteration:  4460  Loss:  0.5182164   Accuracy:  0.8828125\n",
      "Iteration:  4461  Loss:  0.3670393   Accuracy:  0.8984375\n",
      "Iteration:  4462  Loss:  0.33607846   Accuracy:  0.921875\n",
      "Iteration:  4463  Loss:  0.28360304   Accuracy:  0.9140625\n",
      "Iteration:  4464  Loss:  0.19915013   Accuracy:  0.9609375\n",
      "Iteration:  4465  Loss:  0.5669418   Accuracy:  0.859375\n",
      "Iteration:  4466  Loss:  0.32894605   Accuracy:  0.90625\n",
      "Iteration:  4467  Loss:  0.24921334   Accuracy:  0.9140625\n",
      "Iteration:  4468  Loss:  0.3226995   Accuracy:  0.8984375\n",
      "Iteration:  4469  Loss:  0.26222163   Accuracy:  0.921875\n",
      "Iteration:  4470  Loss:  0.26962155   Accuracy:  0.8984375\n",
      "Iteration:  4471  Loss:  0.44518143   Accuracy:  0.890625\n",
      "Iteration:  4472  Loss:  0.46848404   Accuracy:  0.8671875\n",
      "Iteration:  4473  Loss:  0.3947064   Accuracy:  0.8984375\n",
      "Iteration:  4474  Loss:  0.5899228   Accuracy:  0.8984375\n",
      "Iteration:  4475  Loss:  0.39798325   Accuracy:  0.9140625\n",
      "Iteration:  4476  Loss:  0.24804497   Accuracy:  0.9375\n",
      "Iteration:  4477  Loss:  0.34660694   Accuracy:  0.890625\n",
      "Iteration:  4478  Loss:  0.19074064   Accuracy:  0.9296875\n",
      "Iteration:  4479  Loss:  0.46651506   Accuracy:  0.875\n",
      "Iteration:  4480  Loss:  0.21556693   Accuracy:  0.953125\n",
      "Iteration:  4481  Loss:  0.19857256   Accuracy:  0.9375\n",
      "Iteration:  4482  Loss:  0.34587646   Accuracy:  0.90625\n",
      "Iteration:  4483  Loss:  0.44515935   Accuracy:  0.8984375\n",
      "Iteration:  4484  Loss:  0.37961715   Accuracy:  0.8828125\n",
      "Iteration:  4485  Loss:  0.32750964   Accuracy:  0.890625\n",
      "Iteration:  4486  Loss:  0.55220056   Accuracy:  0.8828125\n",
      "Iteration:  4487  Loss:  0.21905503   Accuracy:  0.9453125\n",
      "Iteration:  4488  Loss:  0.24321064   Accuracy:  0.8984375\n",
      "Iteration:  4489  Loss:  0.25954682   Accuracy:  0.8984375\n",
      "Iteration:  4490  Loss:  0.29552305   Accuracy:  0.9375\n",
      "Iteration:  4491  Loss:  0.21866956   Accuracy:  0.9453125\n",
      "Iteration:  4492  Loss:  0.32797354   Accuracy:  0.921875\n",
      "Iteration:  4493  Loss:  0.4561136   Accuracy:  0.8671875\n",
      "Iteration:  4494  Loss:  0.5673302   Accuracy:  0.890625\n",
      "Iteration:  4495  Loss:  0.3150983   Accuracy:  0.8984375\n",
      "Iteration:  4496  Loss:  0.54106826   Accuracy:  0.9140625\n",
      "Iteration:  4497  Loss:  0.423984   Accuracy:  0.84375\n",
      "Iteration:  4498  Loss:  0.2894287   Accuracy:  0.9296875\n",
      "Iteration:  4499  Loss:  0.30566522   Accuracy:  0.921875\n",
      "Iteration:  4500  Loss:  0.30536115   Accuracy:  0.9140625\n",
      "Iteration:  4501  Loss:  0.26802343   Accuracy:  0.9140625\n",
      "Iteration:  4502  Loss:  0.24929944   Accuracy:  0.921875\n",
      "Iteration:  4503  Loss:  0.26746368   Accuracy:  0.9375\n",
      "Iteration:  4504  Loss:  0.3370971   Accuracy:  0.9296875\n",
      "Iteration:  4505  Loss:  0.27525172   Accuracy:  0.8984375\n",
      "Iteration:  4506  Loss:  0.1941539   Accuracy:  0.9140625\n",
      "Iteration:  4507  Loss:  0.12161731   Accuracy:  0.953125\n",
      "Iteration:  4508  Loss:  0.41932866   Accuracy:  0.8984375\n",
      "Iteration:  4509  Loss:  0.33273536   Accuracy:  0.9375\n",
      "Iteration:  4510  Loss:  0.7299315   Accuracy:  0.8671875\n",
      "Iteration:  4511  Loss:  0.27058738   Accuracy:  0.921875\n",
      "Iteration:  4512  Loss:  0.2830237   Accuracy:  0.921875\n",
      "Iteration:  4513  Loss:  0.40922487   Accuracy:  0.921875\n",
      "Iteration:  4514  Loss:  0.33011147   Accuracy:  0.9140625\n",
      "Iteration:  4515  Loss:  0.4597664   Accuracy:  0.90625\n",
      "Iteration:  4516  Loss:  0.23600523   Accuracy:  0.921875\n",
      "Iteration:  4517  Loss:  0.20338869   Accuracy:  0.9296875\n",
      "Iteration:  4518  Loss:  0.5830127   Accuracy:  0.890625\n",
      "Iteration:  4519  Loss:  0.48100963   Accuracy:  0.875\n",
      "Iteration:  4520  Loss:  0.24909094   Accuracy:  0.9296875\n",
      "Iteration:  4521  Loss:  0.52640325   Accuracy:  0.8671875\n",
      "Iteration:  4522  Loss:  0.6889829   Accuracy:  0.859375\n",
      "Iteration:  4523  Loss:  0.1860487   Accuracy:  0.921875\n",
      "Iteration:  4524  Loss:  0.5383062   Accuracy:  0.90625\n",
      "Iteration:  4525  Loss:  0.15886313   Accuracy:  0.9296875\n",
      "Iteration:  4526  Loss:  0.4469544   Accuracy:  0.8984375\n",
      "Iteration:  4527  Loss:  0.26142758   Accuracy:  0.9453125\n",
      "Iteration:  4528  Loss:  0.38983816   Accuracy:  0.90625\n",
      "Iteration:  4529  Loss:  0.56448406   Accuracy:  0.8671875\n",
      "Iteration:  4530  Loss:  0.30739623   Accuracy:  0.8984375\n",
      "Iteration:  4531  Loss:  0.31714582   Accuracy:  0.921875\n",
      "Iteration:  4532  Loss:  0.26640728   Accuracy:  0.890625\n",
      "Iteration:  4533  Loss:  0.74182516   Accuracy:  0.890625\n",
      "Iteration:  4534  Loss:  0.44821405   Accuracy:  0.8984375\n",
      "Iteration:  4535  Loss:  0.2291461   Accuracy:  0.9296875\n",
      "Iteration:  4536  Loss:  0.23804583   Accuracy:  0.90625\n",
      "Iteration:  4537  Loss:  0.32008117   Accuracy:  0.8984375\n",
      "Iteration:  4538  Loss:  0.4812861   Accuracy:  0.8671875\n",
      "Iteration:  4539  Loss:  0.32111233   Accuracy:  0.8984375\n",
      "Iteration:  4540  Loss:  0.20422366   Accuracy:  0.921875\n",
      "Iteration:  4541  Loss:  0.35684556   Accuracy:  0.90625\n",
      "Iteration:  4542  Loss:  0.3294207   Accuracy:  0.9140625\n",
      "Iteration:  4543  Loss:  0.4342004   Accuracy:  0.8984375\n",
      "Iteration:  4544  Loss:  0.49542296   Accuracy:  0.8515625\n",
      "Iteration:  4545  Loss:  0.26099873   Accuracy:  0.9375\n",
      "Iteration:  4546  Loss:  0.26043966   Accuracy:  0.890625\n",
      "Iteration:  4547  Loss:  0.33942872   Accuracy:  0.890625\n",
      "Iteration:  4548  Loss:  0.309324   Accuracy:  0.90625\n",
      "Iteration:  4549  Loss:  0.43779096   Accuracy:  0.859375\n",
      "Iteration:  4550  Loss:  0.5288268   Accuracy:  0.9140625\n",
      "Iteration:  4551  Loss:  0.46520936   Accuracy:  0.84375\n",
      "Iteration:  4552  Loss:  0.32671523   Accuracy:  0.9140625\n",
      "Iteration:  4553  Loss:  0.14879188   Accuracy:  0.9609375\n",
      "Iteration:  4554  Loss:  0.47047478   Accuracy:  0.8515625\n",
      "Iteration:  4555  Loss:  0.40375063   Accuracy:  0.890625\n",
      "Iteration:  4556  Loss:  0.33633867   Accuracy:  0.90625\n",
      "Iteration:  4557  Loss:  0.24271643   Accuracy:  0.921875\n",
      "Iteration:  4558  Loss:  0.41361868   Accuracy:  0.8828125\n",
      "Iteration:  4559  Loss:  0.36650142   Accuracy:  0.8515625\n",
      "Iteration:  4560  Loss:  0.45587516   Accuracy:  0.875\n",
      "Iteration:  4561  Loss:  0.22533178   Accuracy:  0.90625\n",
      "Iteration:  4562  Loss:  0.37602448   Accuracy:  0.921875\n",
      "Iteration:  4563  Loss:  0.58550787   Accuracy:  0.8671875\n",
      "Iteration:  4564  Loss:  0.39223474   Accuracy:  0.8359375\n",
      "Iteration:  4565  Loss:  0.24151722   Accuracy:  0.90625\n",
      "Iteration:  4566  Loss:  0.18111   Accuracy:  0.953125\n",
      "Iteration:  4567  Loss:  0.29104865   Accuracy:  0.8984375\n",
      "Iteration:  4568  Loss:  0.4767977   Accuracy:  0.859375\n",
      "Iteration:  4569  Loss:  0.46028113   Accuracy:  0.8671875\n",
      "Iteration:  4570  Loss:  0.33393788   Accuracy:  0.9140625\n",
      "Iteration:  4571  Loss:  0.4567362   Accuracy:  0.8828125\n",
      "Iteration:  4572  Loss:  0.42532027   Accuracy:  0.859375\n",
      "Iteration:  4573  Loss:  0.31345564   Accuracy:  0.9140625\n",
      "Iteration:  4574  Loss:  0.35284   Accuracy:  0.890625\n",
      "Iteration:  4575  Loss:  0.26012826   Accuracy:  0.90625\n",
      "Iteration:  4576  Loss:  0.44399196   Accuracy:  0.8828125\n",
      "Iteration:  4577  Loss:  0.5968356   Accuracy:  0.8828125\n",
      "Iteration:  4578  Loss:  0.33665782   Accuracy:  0.8671875\n",
      "Iteration:  4579  Loss:  0.23348644   Accuracy:  0.9375\n",
      "Iteration:  4580  Loss:  0.19220772   Accuracy:  0.9140625\n",
      "Iteration:  4581  Loss:  0.31023362   Accuracy:  0.9296875\n",
      "Iteration:  4582  Loss:  0.3056187   Accuracy:  0.9296875\n",
      "Iteration:  4583  Loss:  0.17885323   Accuracy:  0.9296875\n",
      "Iteration:  4584  Loss:  0.23484896   Accuracy:  0.9140625\n",
      "Iteration:  4585  Loss:  0.33255318   Accuracy:  0.890625\n",
      "Iteration:  4586  Loss:  0.5326001   Accuracy:  0.875\n",
      "Iteration:  4587  Loss:  0.3255583   Accuracy:  0.9140625\n",
      "Iteration:  4588  Loss:  0.33028695   Accuracy:  0.8984375\n",
      "Iteration:  4589  Loss:  0.24582204   Accuracy:  0.9296875\n",
      "Iteration:  4590  Loss:  0.3043648   Accuracy:  0.9375\n",
      "Iteration:  4591  Loss:  0.7909484   Accuracy:  0.84375\n",
      "Iteration:  4592  Loss:  0.40293896   Accuracy:  0.8828125\n",
      "Iteration:  4593  Loss:  0.17642698   Accuracy:  0.9296875\n",
      "Iteration:  4594  Loss:  0.317015   Accuracy:  0.921875\n",
      "Iteration:  4595  Loss:  0.16753024   Accuracy:  0.9609375\n",
      "Iteration:  4596  Loss:  0.4362575   Accuracy:  0.90625\n",
      "Iteration:  4597  Loss:  0.56153935   Accuracy:  0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4598  Loss:  0.3377108   Accuracy:  0.890625\n",
      "Iteration:  4599  Loss:  0.35507858   Accuracy:  0.90625\n",
      "Iteration:  4600  Loss:  0.42055964   Accuracy:  0.8984375\n",
      "Iteration:  4601  Loss:  0.24282438   Accuracy:  0.9296875\n",
      "Iteration:  4602  Loss:  0.4307713   Accuracy:  0.8828125\n",
      "Iteration:  4603  Loss:  0.3520944   Accuracy:  0.9140625\n",
      "Iteration:  4604  Loss:  0.61022794   Accuracy:  0.875\n",
      "Iteration:  4605  Loss:  0.24545422   Accuracy:  0.9140625\n",
      "Iteration:  4606  Loss:  0.5291946   Accuracy:  0.8671875\n",
      "Iteration:  4607  Loss:  0.32971656   Accuracy:  0.9375\n",
      "Iteration:  4608  Loss:  0.20876938   Accuracy:  0.9453125\n",
      "Iteration:  4609  Loss:  0.32433218   Accuracy:  0.9140625\n",
      "Iteration:  4610  Loss:  0.49047956   Accuracy:  0.8984375\n",
      "Iteration:  4611  Loss:  0.58434093   Accuracy:  0.8671875\n",
      "Iteration:  4612  Loss:  0.39882863   Accuracy:  0.921875\n",
      "Iteration:  4613  Loss:  0.26604605   Accuracy:  0.953125\n",
      "Iteration:  4614  Loss:  0.47714934   Accuracy:  0.875\n",
      "Iteration:  4615  Loss:  0.28495198   Accuracy:  0.90625\n",
      "Iteration:  4616  Loss:  0.24724656   Accuracy:  0.90625\n",
      "Iteration:  4617  Loss:  0.25266752   Accuracy:  0.9140625\n",
      "Iteration:  4618  Loss:  0.63900805   Accuracy:  0.859375\n",
      "Iteration:  4619  Loss:  0.2772298   Accuracy:  0.8984375\n",
      "Iteration:  4620  Loss:  0.24101555   Accuracy:  0.90625\n",
      "Iteration:  4621  Loss:  0.25470525   Accuracy:  0.9296875\n",
      "Iteration:  4622  Loss:  0.6057013   Accuracy:  0.875\n",
      "Iteration:  4623  Loss:  0.35135978   Accuracy:  0.8984375\n",
      "Iteration:  4624  Loss:  0.20835775   Accuracy:  0.9375\n",
      "Iteration:  4625  Loss:  0.51794016   Accuracy:  0.8828125\n",
      "Iteration:  4626  Loss:  0.36148888   Accuracy:  0.8828125\n",
      "Iteration:  4627  Loss:  0.2765175   Accuracy:  0.9375\n",
      "Iteration:  4628  Loss:  0.39062178   Accuracy:  0.9140625\n",
      "Iteration:  4629  Loss:  0.4353731   Accuracy:  0.875\n",
      "Iteration:  4630  Loss:  0.27963266   Accuracy:  0.9140625\n",
      "Iteration:  4631  Loss:  0.39267272   Accuracy:  0.9140625\n",
      "Iteration:  4632  Loss:  0.3244003   Accuracy:  0.921875\n",
      "Iteration:  4633  Loss:  0.26376748   Accuracy:  0.921875\n",
      "Iteration:  4634  Loss:  0.35969764   Accuracy:  0.875\n",
      "Iteration:  4635  Loss:  0.43207157   Accuracy:  0.8671875\n",
      "Iteration:  4636  Loss:  0.42319092   Accuracy:  0.8984375\n",
      "Iteration:  4637  Loss:  0.33335736   Accuracy:  0.953125\n",
      "Iteration:  4638  Loss:  0.35246876   Accuracy:  0.890625\n",
      "Iteration:  4639  Loss:  0.33068866   Accuracy:  0.90625\n",
      "Iteration:  4640  Loss:  0.27735138   Accuracy:  0.9296875\n",
      "Iteration:  4641  Loss:  0.37059385   Accuracy:  0.8984375\n",
      "Iteration:  4642  Loss:  0.22121762   Accuracy:  0.921875\n",
      "Iteration:  4643  Loss:  0.494024   Accuracy:  0.8984375\n",
      "Iteration:  4644  Loss:  0.38591218   Accuracy:  0.8984375\n",
      "Iteration:  4645  Loss:  0.33772412   Accuracy:  0.9140625\n",
      "Iteration:  4646  Loss:  0.4581579   Accuracy:  0.921875\n",
      "Iteration:  4647  Loss:  0.28705317   Accuracy:  0.921875\n",
      "Iteration:  4648  Loss:  0.33079153   Accuracy:  0.9140625\n",
      "Iteration:  4649  Loss:  0.29447073   Accuracy:  0.9140625\n",
      "Iteration:  4650  Loss:  0.39545935   Accuracy:  0.953125\n",
      "Iteration:  4651  Loss:  0.6399717   Accuracy:  0.9140625\n",
      "Iteration:  4652  Loss:  0.28995177   Accuracy:  0.953125\n",
      "Iteration:  4653  Loss:  0.39946797   Accuracy:  0.90625\n",
      "Iteration:  4654  Loss:  0.28233737   Accuracy:  0.921875\n",
      "Iteration:  4655  Loss:  0.42421424   Accuracy:  0.8671875\n",
      "Iteration:  4656  Loss:  0.4575458   Accuracy:  0.859375\n",
      "Iteration:  4657  Loss:  0.5004807   Accuracy:  0.875\n",
      "Iteration:  4658  Loss:  0.35688788   Accuracy:  0.890625\n",
      "Iteration:  4659  Loss:  0.3746218   Accuracy:  0.8828125\n",
      "Iteration:  4660  Loss:  0.22033504   Accuracy:  0.953125\n",
      "Iteration:  4661  Loss:  0.15382728   Accuracy:  0.96875\n",
      "Iteration:  4662  Loss:  0.30733907   Accuracy:  0.90625\n",
      "Iteration:  4663  Loss:  0.35063812   Accuracy:  0.890625\n",
      "Iteration:  4664  Loss:  0.28695944   Accuracy:  0.90625\n",
      "Iteration:  4665  Loss:  0.3542713   Accuracy:  0.9140625\n",
      "Iteration:  4666  Loss:  0.558498   Accuracy:  0.859375\n",
      "Iteration:  4667  Loss:  0.42210397   Accuracy:  0.890625\n",
      "Iteration:  4668  Loss:  0.4567919   Accuracy:  0.875\n",
      "Iteration:  4669  Loss:  0.3476497   Accuracy:  0.9296875\n",
      "Iteration:  4670  Loss:  0.33933562   Accuracy:  0.921875\n",
      "Iteration:  4671  Loss:  0.37976456   Accuracy:  0.90625\n",
      "Iteration:  4672  Loss:  0.4802263   Accuracy:  0.90625\n",
      "Iteration:  4673  Loss:  0.18073052   Accuracy:  0.9453125\n",
      "Iteration:  4674  Loss:  0.4005204   Accuracy:  0.8671875\n",
      "Iteration:  4675  Loss:  0.2977076   Accuracy:  0.921875\n",
      "Iteration:  4676  Loss:  0.14973539   Accuracy:  0.9453125\n",
      "Iteration:  4677  Loss:  0.47332907   Accuracy:  0.921875\n",
      "Iteration:  4678  Loss:  0.26978573   Accuracy:  0.9375\n",
      "Iteration:  4679  Loss:  0.64119595   Accuracy:  0.8515625\n",
      "Iteration:  4680  Loss:  0.2118915   Accuracy:  0.9296875\n",
      "Iteration:  4681  Loss:  0.3596388   Accuracy:  0.890625\n",
      "Iteration:  4682  Loss:  0.4474244   Accuracy:  0.890625\n",
      "Iteration:  4683  Loss:  0.35399637   Accuracy:  0.921875\n",
      "Iteration:  4684  Loss:  0.28452373   Accuracy:  0.9375\n",
      "Iteration:  4685  Loss:  0.21243502   Accuracy:  0.9296875\n",
      "Iteration:  4686  Loss:  0.40486223   Accuracy:  0.921875\n",
      "Iteration:  4687  Loss:  0.5376537   Accuracy:  0.8828125\n",
      "Iteration:  4688  Loss:  0.27114353   Accuracy:  0.90625\n",
      "Iteration:  4689  Loss:  0.39051023   Accuracy:  0.9140625\n",
      "Iteration:  4690  Loss:  0.48222083   Accuracy:  0.890625\n",
      "Iteration:  4691  Loss:  0.40025827   Accuracy:  0.8828125\n",
      "Iteration:  4692  Loss:  0.4419533   Accuracy:  0.8984375\n",
      "Iteration:  4693  Loss:  0.29766017   Accuracy:  0.8984375\n",
      "Iteration:  4694  Loss:  0.15670632   Accuracy:  0.9453125\n",
      "Iteration:  4695  Loss:  0.31491295   Accuracy:  0.9296875\n",
      "Iteration:  4696  Loss:  0.34747615   Accuracy:  0.9140625\n",
      "Iteration:  4697  Loss:  0.40440685   Accuracy:  0.9140625\n",
      "Iteration:  4698  Loss:  0.2416395   Accuracy:  0.9296875\n",
      "Iteration:  4699  Loss:  0.18249746   Accuracy:  0.9453125\n",
      "Iteration:  4700  Loss:  0.3603998   Accuracy:  0.921875\n",
      "Iteration:  4701  Loss:  0.43437123   Accuracy:  0.8828125\n",
      "Iteration:  4702  Loss:  0.4238268   Accuracy:  0.9296875\n",
      "Iteration:  4703  Loss:  0.47900087   Accuracy:  0.8828125\n",
      "Iteration:  4704  Loss:  0.45093524   Accuracy:  0.890625\n",
      "Iteration:  4705  Loss:  0.23505157   Accuracy:  0.921875\n",
      "Iteration:  4706  Loss:  0.722258   Accuracy:  0.859375\n",
      "Iteration:  4707  Loss:  0.3278056   Accuracy:  0.890625\n",
      "Iteration:  4708  Loss:  0.27315316   Accuracy:  0.921875\n",
      "Iteration:  4709  Loss:  0.3125712   Accuracy:  0.9140625\n",
      "Iteration:  4710  Loss:  0.48954403   Accuracy:  0.875\n",
      "Iteration:  4711  Loss:  0.27533656   Accuracy:  0.9375\n",
      "Iteration:  4712  Loss:  0.4576893   Accuracy:  0.8671875\n",
      "Iteration:  4713  Loss:  0.34751692   Accuracy:  0.921875\n",
      "Iteration:  4714  Loss:  0.35597348   Accuracy:  0.8984375\n",
      "Iteration:  4715  Loss:  0.39767468   Accuracy:  0.921875\n",
      "Iteration:  4716  Loss:  0.34905136   Accuracy:  0.8828125\n",
      "Iteration:  4717  Loss:  0.37594143   Accuracy:  0.921875\n",
      "Iteration:  4718  Loss:  0.23166135   Accuracy:  0.9375\n",
      "Iteration:  4719  Loss:  0.31574467   Accuracy:  0.890625\n",
      "Iteration:  4720  Loss:  0.2705334   Accuracy:  0.9140625\n",
      "Iteration:  4721  Loss:  0.40351468   Accuracy:  0.8984375\n",
      "Iteration:  4722  Loss:  0.36548686   Accuracy:  0.8828125\n",
      "Iteration:  4723  Loss:  0.4342643   Accuracy:  0.8828125\n",
      "Iteration:  4724  Loss:  0.3908225   Accuracy:  0.90625\n",
      "Iteration:  4725  Loss:  0.47741398   Accuracy:  0.8828125\n",
      "Iteration:  4726  Loss:  0.37570384   Accuracy:  0.90625\n",
      "Iteration:  4727  Loss:  0.20811035   Accuracy:  0.9375\n",
      "Iteration:  4728  Loss:  0.22158825   Accuracy:  0.953125\n",
      "Iteration:  4729  Loss:  0.28405595   Accuracy:  0.90625\n",
      "Iteration:  4730  Loss:  0.39923146   Accuracy:  0.8828125\n",
      "Iteration:  4731  Loss:  0.5060829   Accuracy:  0.890625\n",
      "Iteration:  4732  Loss:  0.35329652   Accuracy:  0.90625\n",
      "Iteration:  4733  Loss:  0.47994804   Accuracy:  0.8828125\n",
      "Iteration:  4734  Loss:  0.4470743   Accuracy:  0.890625\n",
      "Iteration:  4735  Loss:  0.28757298   Accuracy:  0.9375\n",
      "Iteration:  4736  Loss:  0.49377972   Accuracy:  0.8515625\n",
      "Iteration:  4737  Loss:  0.18290077   Accuracy:  0.9453125\n",
      "Iteration:  4738  Loss:  0.115335315   Accuracy:  0.9609375\n",
      "Iteration:  4739  Loss:  0.46571282   Accuracy:  0.8984375\n",
      "Iteration:  4740  Loss:  0.31262293   Accuracy:  0.9140625\n",
      "Iteration:  4741  Loss:  0.42836407   Accuracy:  0.8984375\n",
      "Iteration:  4742  Loss:  0.45677316   Accuracy:  0.8984375\n",
      "Iteration:  4743  Loss:  0.41252145   Accuracy:  0.8984375\n",
      "Iteration:  4744  Loss:  0.32869512   Accuracy:  0.90625\n",
      "Iteration:  4745  Loss:  0.61784583   Accuracy:  0.90625\n",
      "Iteration:  4746  Loss:  0.2177206   Accuracy:  0.9296875\n",
      "Iteration:  4747  Loss:  0.7253299   Accuracy:  0.8984375\n",
      "Iteration:  4748  Loss:  0.29643223   Accuracy:  0.9453125\n",
      "Iteration:  4749  Loss:  0.21029034   Accuracy:  0.9296875\n",
      "Iteration:  4750  Loss:  0.23919049   Accuracy:  0.90625\n",
      "Iteration:  4751  Loss:  0.48370832   Accuracy:  0.8984375\n",
      "Iteration:  4752  Loss:  0.26770732   Accuracy:  0.921875\n",
      "Iteration:  4753  Loss:  0.41999286   Accuracy:  0.9375\n",
      "Iteration:  4754  Loss:  0.24988699   Accuracy:  0.8984375\n",
      "Iteration:  4755  Loss:  0.2997083   Accuracy:  0.9453125\n",
      "Iteration:  4756  Loss:  0.21479765   Accuracy:  0.921875\n",
      "Iteration:  4757  Loss:  0.38623694   Accuracy:  0.8984375\n",
      "Iteration:  4758  Loss:  0.3170906   Accuracy:  0.921875\n",
      "Iteration:  4759  Loss:  0.19422525   Accuracy:  0.9296875\n",
      "Iteration:  4760  Loss:  0.30309206   Accuracy:  0.9296875\n",
      "Iteration:  4761  Loss:  0.32134894   Accuracy:  0.921875\n",
      "Iteration:  4762  Loss:  0.27428585   Accuracy:  0.9140625\n",
      "Iteration:  4763  Loss:  0.35237062   Accuracy:  0.9140625\n",
      "Iteration:  4764  Loss:  0.2624771   Accuracy:  0.921875\n",
      "Iteration:  4765  Loss:  0.408766   Accuracy:  0.875\n",
      "Iteration:  4766  Loss:  0.38268152   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4767  Loss:  0.31009072   Accuracy:  0.9296875\n",
      "Iteration:  4768  Loss:  0.36109835   Accuracy:  0.8671875\n",
      "Iteration:  4769  Loss:  0.3096755   Accuracy:  0.8828125\n",
      "Iteration:  4770  Loss:  0.24114168   Accuracy:  0.921875\n",
      "Iteration:  4771  Loss:  0.37034017   Accuracy:  0.8984375\n",
      "Iteration:  4772  Loss:  0.41692543   Accuracy:  0.8671875\n",
      "Iteration:  4773  Loss:  0.346358   Accuracy:  0.9140625\n",
      "Iteration:  4774  Loss:  0.3463825   Accuracy:  0.90625\n",
      "Iteration:  4775  Loss:  0.30214116   Accuracy:  0.9375\n",
      "Iteration:  4776  Loss:  0.20613663   Accuracy:  0.9375\n",
      "Iteration:  4777  Loss:  0.3860753   Accuracy:  0.90625\n",
      "Iteration:  4778  Loss:  0.36891067   Accuracy:  0.8828125\n",
      "Iteration:  4779  Loss:  0.18348429   Accuracy:  0.9375\n",
      "Iteration:  4780  Loss:  0.1327372   Accuracy:  0.96875\n",
      "Iteration:  4781  Loss:  0.4874282   Accuracy:  0.8515625\n",
      "Iteration:  4782  Loss:  0.49635464   Accuracy:  0.890625\n",
      "Iteration:  4783  Loss:  0.5022862   Accuracy:  0.8515625\n",
      "Iteration:  4784  Loss:  0.34457773   Accuracy:  0.90625\n",
      "Iteration:  4785  Loss:  0.20543434   Accuracy:  0.9140625\n",
      "Iteration:  4786  Loss:  0.26190823   Accuracy:  0.9453125\n",
      "Iteration:  4787  Loss:  0.2417098   Accuracy:  0.9375\n",
      "Iteration:  4788  Loss:  0.35755894   Accuracy:  0.90625\n",
      "Iteration:  4789  Loss:  0.45380998   Accuracy:  0.8984375\n",
      "Iteration:  4790  Loss:  0.16191977   Accuracy:  0.9453125\n",
      "Iteration:  4791  Loss:  0.24655172   Accuracy:  0.9375\n",
      "Iteration:  4792  Loss:  0.3837753   Accuracy:  0.8984375\n",
      "Iteration:  4793  Loss:  0.32818997   Accuracy:  0.90625\n",
      "Iteration:  4794  Loss:  0.1817613   Accuracy:  0.953125\n",
      "Iteration:  4795  Loss:  0.31553903   Accuracy:  0.8984375\n",
      "Iteration:  4796  Loss:  0.30194452   Accuracy:  0.8984375\n",
      "Iteration:  4797  Loss:  0.22346425   Accuracy:  0.9453125\n",
      "Iteration:  4798  Loss:  0.2758321   Accuracy:  0.9296875\n",
      "Iteration:  4799  Loss:  0.48481986   Accuracy:  0.8671875\n",
      "Iteration:  4800  Loss:  0.39330414   Accuracy:  0.90625\n",
      "Iteration:  4801  Loss:  0.40386882   Accuracy:  0.90625\n",
      "Iteration:  4802  Loss:  0.22989893   Accuracy:  0.9140625\n",
      "Iteration:  4803  Loss:  0.35348958   Accuracy:  0.875\n",
      "Iteration:  4804  Loss:  0.13152489   Accuracy:  0.953125\n",
      "Iteration:  4805  Loss:  0.36613515   Accuracy:  0.90625\n",
      "Iteration:  4806  Loss:  0.3685423   Accuracy:  0.890625\n",
      "Iteration:  4807  Loss:  0.24986145   Accuracy:  0.9375\n",
      "Iteration:  4808  Loss:  0.46490213   Accuracy:  0.8828125\n",
      "Iteration:  4809  Loss:  0.33463123   Accuracy:  0.90625\n",
      "Iteration:  4810  Loss:  0.41033125   Accuracy:  0.890625\n",
      "Iteration:  4811  Loss:  0.3844447   Accuracy:  0.8984375\n",
      "Iteration:  4812  Loss:  0.3077211   Accuracy:  0.890625\n",
      "Iteration:  4813  Loss:  0.17128046   Accuracy:  0.953125\n",
      "Iteration:  4814  Loss:  0.49827376   Accuracy:  0.8984375\n",
      "Iteration:  4815  Loss:  0.22981621   Accuracy:  0.921875\n",
      "Iteration:  4816  Loss:  0.44159308   Accuracy:  0.9140625\n",
      "Iteration:  4817  Loss:  0.26054773   Accuracy:  0.9296875\n",
      "Iteration:  4818  Loss:  0.28541487   Accuracy:  0.90625\n",
      "Iteration:  4819  Loss:  0.34214807   Accuracy:  0.9140625\n",
      "Iteration:  4820  Loss:  0.36969322   Accuracy:  0.890625\n",
      "Iteration:  4821  Loss:  0.16709462   Accuracy:  0.9453125\n",
      "Iteration:  4822  Loss:  0.28227338   Accuracy:  0.9140625\n",
      "Iteration:  4823  Loss:  0.34139305   Accuracy:  0.90625\n",
      "Iteration:  4824  Loss:  0.18190996   Accuracy:  0.9375\n",
      "Iteration:  4825  Loss:  0.2510305   Accuracy:  0.9453125\n",
      "Iteration:  4826  Loss:  0.23396932   Accuracy:  0.9453125\n",
      "Iteration:  4827  Loss:  0.35227388   Accuracy:  0.890625\n",
      "Iteration:  4828  Loss:  0.37452716   Accuracy:  0.9296875\n",
      "Iteration:  4829  Loss:  0.42232537   Accuracy:  0.8828125\n",
      "Iteration:  4830  Loss:  0.38745123   Accuracy:  0.84375\n",
      "Iteration:  4831  Loss:  0.56280345   Accuracy:  0.921875\n",
      "Iteration:  4832  Loss:  0.5471495   Accuracy:  0.890625\n",
      "Iteration:  4833  Loss:  0.43724334   Accuracy:  0.9140625\n",
      "Iteration:  4834  Loss:  0.21398017   Accuracy:  0.9453125\n",
      "Iteration:  4835  Loss:  0.3942263   Accuracy:  0.890625\n",
      "Iteration:  4836  Loss:  0.28821814   Accuracy:  0.9453125\n",
      "Iteration:  4837  Loss:  0.40042537   Accuracy:  0.8828125\n",
      "Iteration:  4838  Loss:  0.29974866   Accuracy:  0.9140625\n",
      "Iteration:  4839  Loss:  0.30800095   Accuracy:  0.90625\n",
      "Iteration:  4840  Loss:  0.48984006   Accuracy:  0.859375\n",
      "Iteration:  4841  Loss:  0.53268874   Accuracy:  0.9140625\n",
      "Iteration:  4842  Loss:  0.3606058   Accuracy:  0.921875\n",
      "Iteration:  4843  Loss:  0.34534964   Accuracy:  0.8984375\n",
      "Iteration:  4844  Loss:  0.302436   Accuracy:  0.8984375\n",
      "Iteration:  4845  Loss:  0.23619239   Accuracy:  0.921875\n",
      "Iteration:  4846  Loss:  0.3304221   Accuracy:  0.90625\n",
      "Iteration:  4847  Loss:  0.26368928   Accuracy:  0.8984375\n",
      "Iteration:  4848  Loss:  0.31415436   Accuracy:  0.9375\n",
      "Iteration:  4849  Loss:  0.45674914   Accuracy:  0.890625\n",
      "Iteration:  4850  Loss:  0.19931576   Accuracy:  0.9375\n",
      "Iteration:  4851  Loss:  0.25272918   Accuracy:  0.8828125\n",
      "Iteration:  4852  Loss:  0.52868205   Accuracy:  0.8828125\n",
      "Iteration:  4853  Loss:  0.36524922   Accuracy:  0.890625\n",
      "Iteration:  4854  Loss:  0.28021696   Accuracy:  0.9140625\n",
      "Iteration:  4855  Loss:  0.4164182   Accuracy:  0.875\n",
      "Iteration:  4856  Loss:  0.42875594   Accuracy:  0.8984375\n",
      "Iteration:  4857  Loss:  0.5114463   Accuracy:  0.90625\n",
      "Iteration:  4858  Loss:  0.37605804   Accuracy:  0.859375\n",
      "Iteration:  4859  Loss:  0.25622514   Accuracy:  0.90625\n",
      "Iteration:  4860  Loss:  0.25961956   Accuracy:  0.9453125\n",
      "Iteration:  4861  Loss:  0.2679368   Accuracy:  0.921875\n",
      "Iteration:  4862  Loss:  0.2705644   Accuracy:  0.90625\n",
      "Iteration:  4863  Loss:  0.3288554   Accuracy:  0.875\n",
      "Iteration:  4864  Loss:  0.37315983   Accuracy:  0.890625\n",
      "Iteration:  4865  Loss:  0.33429608   Accuracy:  0.9296875\n",
      "Iteration:  4866  Loss:  0.40617216   Accuracy:  0.8671875\n",
      "Iteration:  4867  Loss:  0.45051998   Accuracy:  0.875\n",
      "Iteration:  4868  Loss:  0.36828658   Accuracy:  0.90625\n",
      "Iteration:  4869  Loss:  0.35090545   Accuracy:  0.875\n",
      "Iteration:  4870  Loss:  0.35840008   Accuracy:  0.90625\n",
      "Iteration:  4871  Loss:  0.30858344   Accuracy:  0.9375\n",
      "Iteration:  4872  Loss:  0.39949065   Accuracy:  0.8828125\n",
      "Iteration:  4873  Loss:  0.56581867   Accuracy:  0.875\n",
      "Iteration:  4874  Loss:  0.39950812   Accuracy:  0.890625\n",
      "Iteration:  4875  Loss:  0.39875615   Accuracy:  0.9140625\n",
      "Iteration:  4876  Loss:  0.14645886   Accuracy:  0.9453125\n",
      "Iteration:  4877  Loss:  0.21354815   Accuracy:  0.9375\n",
      "Iteration:  4878  Loss:  0.29172844   Accuracy:  0.8828125\n",
      "Iteration:  4879  Loss:  0.2942288   Accuracy:  0.8984375\n",
      "Iteration:  4880  Loss:  0.49286324   Accuracy:  0.875\n",
      "Iteration:  4881  Loss:  0.33704773   Accuracy:  0.921875\n",
      "Iteration:  4882  Loss:  0.38959396   Accuracy:  0.8828125\n",
      "Iteration:  4883  Loss:  0.21305832   Accuracy:  0.9140625\n",
      "Iteration:  4884  Loss:  0.29275772   Accuracy:  0.890625\n",
      "Iteration:  4885  Loss:  0.23509037   Accuracy:  0.9296875\n",
      "Iteration:  4886  Loss:  0.36787796   Accuracy:  0.9140625\n",
      "Iteration:  4887  Loss:  0.29603586   Accuracy:  0.890625\n",
      "Iteration:  4888  Loss:  0.28564292   Accuracy:  0.9453125\n",
      "Iteration:  4889  Loss:  0.31475988   Accuracy:  0.890625\n",
      "Iteration:  4890  Loss:  0.503605   Accuracy:  0.875\n",
      "Iteration:  4891  Loss:  0.43326926   Accuracy:  0.921875\n",
      "Iteration:  4892  Loss:  0.27683866   Accuracy:  0.9140625\n",
      "Iteration:  4893  Loss:  0.3673519   Accuracy:  0.8671875\n",
      "Iteration:  4894  Loss:  0.3644217   Accuracy:  0.90625\n",
      "Iteration:  4895  Loss:  0.29194573   Accuracy:  0.9375\n",
      "Iteration:  4896  Loss:  0.23421803   Accuracy:  0.921875\n",
      "Iteration:  4897  Loss:  0.2869628   Accuracy:  0.890625\n",
      "Iteration:  4898  Loss:  0.43526858   Accuracy:  0.8984375\n",
      "Iteration:  4899  Loss:  0.43388525   Accuracy:  0.9140625\n",
      "Iteration:  4900  Loss:  0.21837348   Accuracy:  0.9375\n",
      "Iteration:  4901  Loss:  0.3052482   Accuracy:  0.921875\n",
      "Iteration:  4902  Loss:  0.40042365   Accuracy:  0.9296875\n",
      "Iteration:  4903  Loss:  0.6382999   Accuracy:  0.8671875\n",
      "Iteration:  4904  Loss:  0.2822322   Accuracy:  0.9375\n",
      "Iteration:  4905  Loss:  0.33170587   Accuracy:  0.90625\n",
      "Iteration:  4906  Loss:  0.36988324   Accuracy:  0.890625\n",
      "Iteration:  4907  Loss:  0.21893449   Accuracy:  0.9453125\n",
      "Iteration:  4908  Loss:  0.274315   Accuracy:  0.9140625\n",
      "Iteration:  4909  Loss:  0.15756923   Accuracy:  0.9453125\n",
      "Iteration:  4910  Loss:  0.3964045   Accuracy:  0.9296875\n",
      "Iteration:  4911  Loss:  0.36911243   Accuracy:  0.9296875\n",
      "Iteration:  4912  Loss:  0.34042728   Accuracy:  0.8828125\n",
      "Iteration:  4913  Loss:  0.50011635   Accuracy:  0.8984375\n",
      "Iteration:  4914  Loss:  0.35859638   Accuracy:  0.9296875\n",
      "Iteration:  4915  Loss:  0.27698267   Accuracy:  0.8984375\n",
      "Iteration:  4916  Loss:  0.48109335   Accuracy:  0.8671875\n",
      "Iteration:  4917  Loss:  0.32996985   Accuracy:  0.890625\n",
      "Iteration:  4918  Loss:  0.4272473   Accuracy:  0.859375\n",
      "Iteration:  4919  Loss:  0.1777655   Accuracy:  0.9453125\n",
      "Iteration:  4920  Loss:  0.2570359   Accuracy:  0.921875\n",
      "Iteration:  4921  Loss:  0.40472925   Accuracy:  0.8828125\n",
      "Iteration:  4922  Loss:  0.39099136   Accuracy:  0.9140625\n",
      "Iteration:  4923  Loss:  0.43666616   Accuracy:  0.8671875\n",
      "Iteration:  4924  Loss:  0.36206692   Accuracy:  0.875\n",
      "Iteration:  4925  Loss:  0.449302   Accuracy:  0.90625\n",
      "Iteration:  4926  Loss:  0.21199074   Accuracy:  0.9296875\n",
      "Iteration:  4927  Loss:  0.3230457   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4928  Loss:  0.41441265   Accuracy:  0.8984375\n",
      "Iteration:  4929  Loss:  0.23082408   Accuracy:  0.921875\n",
      "Iteration:  4930  Loss:  0.41099986   Accuracy:  0.8984375\n",
      "Iteration:  4931  Loss:  0.28734255   Accuracy:  0.921875\n",
      "Iteration:  4932  Loss:  0.29125586   Accuracy:  0.90625\n",
      "Iteration:  4933  Loss:  0.43473804   Accuracy:  0.90625\n",
      "Iteration:  4934  Loss:  0.36799002   Accuracy:  0.9140625\n",
      "Iteration:  4935  Loss:  0.48575863   Accuracy:  0.8984375\n",
      "Iteration:  4936  Loss:  0.18490699   Accuracy:  0.953125\n",
      "Iteration:  4937  Loss:  0.30799344   Accuracy:  0.9140625\n",
      "Iteration:  4938  Loss:  0.48368242   Accuracy:  0.8828125\n",
      "Iteration:  4939  Loss:  0.32321623   Accuracy:  0.890625\n",
      "Iteration:  4940  Loss:  0.3427233   Accuracy:  0.8984375\n",
      "Iteration:  4941  Loss:  0.20437083   Accuracy:  0.9375\n",
      "Iteration:  4942  Loss:  0.42756498   Accuracy:  0.890625\n",
      "Iteration:  4943  Loss:  0.21992098   Accuracy:  0.9296875\n",
      "Iteration:  4944  Loss:  0.25612274   Accuracy:  0.9375\n",
      "Iteration:  4945  Loss:  0.29626015   Accuracy:  0.9296875\n",
      "Iteration:  4946  Loss:  0.49807873   Accuracy:  0.84375\n",
      "Iteration:  4947  Loss:  0.34303674   Accuracy:  0.921875\n",
      "Iteration:  4948  Loss:  0.35327977   Accuracy:  0.9296875\n",
      "Iteration:  4949  Loss:  0.45648468   Accuracy:  0.90625\n",
      "Iteration:  4950  Loss:  0.19859308   Accuracy:  0.9375\n",
      "Iteration:  4951  Loss:  0.41227815   Accuracy:  0.8984375\n",
      "Iteration:  4952  Loss:  0.4169314   Accuracy:  0.8671875\n",
      "Iteration:  4953  Loss:  0.41090685   Accuracy:  0.890625\n",
      "Iteration:  4954  Loss:  0.31171548   Accuracy:  0.90625\n",
      "Iteration:  4955  Loss:  0.32485023   Accuracy:  0.9296875\n",
      "Iteration:  4956  Loss:  0.35160768   Accuracy:  0.890625\n",
      "Iteration:  4957  Loss:  0.6259403   Accuracy:  0.8828125\n",
      "Iteration:  4958  Loss:  0.23978439   Accuracy:  0.9453125\n",
      "Iteration:  4959  Loss:  0.3917448   Accuracy:  0.90625\n",
      "Iteration:  4960  Loss:  0.25497103   Accuracy:  0.9453125\n",
      "Iteration:  4961  Loss:  0.44092932   Accuracy:  0.890625\n",
      "Iteration:  4962  Loss:  0.30195573   Accuracy:  0.8984375\n",
      "Iteration:  4963  Loss:  0.25039303   Accuracy:  0.9296875\n",
      "Iteration:  4964  Loss:  0.20147064   Accuracy:  0.9453125\n",
      "Iteration:  4965  Loss:  0.17540082   Accuracy:  0.9375\n",
      "Iteration:  4966  Loss:  0.6778848   Accuracy:  0.8671875\n",
      "Iteration:  4967  Loss:  0.35915312   Accuracy:  0.9140625\n",
      "Iteration:  4968  Loss:  0.31242922   Accuracy:  0.921875\n",
      "Iteration:  4969  Loss:  0.26625118   Accuracy:  0.9140625\n",
      "Iteration:  4970  Loss:  0.19957083   Accuracy:  0.953125\n",
      "Iteration:  4971  Loss:  0.25091523   Accuracy:  0.9140625\n",
      "Iteration:  4972  Loss:  0.3687468   Accuracy:  0.9296875\n",
      "Iteration:  4973  Loss:  0.62838256   Accuracy:  0.8984375\n",
      "Iteration:  4974  Loss:  0.29476973   Accuracy:  0.9140625\n",
      "Iteration:  4975  Loss:  0.5074062   Accuracy:  0.8984375\n",
      "Iteration:  4976  Loss:  0.37249196   Accuracy:  0.921875\n",
      "Iteration:  4977  Loss:  0.31576616   Accuracy:  0.9140625\n",
      "Iteration:  4978  Loss:  0.22396342   Accuracy:  0.9375\n",
      "Iteration:  4979  Loss:  0.42868197   Accuracy:  0.875\n",
      "Iteration:  4980  Loss:  0.26763108   Accuracy:  0.9296875\n",
      "Iteration:  4981  Loss:  0.512753   Accuracy:  0.9140625\n",
      "Iteration:  4982  Loss:  0.27751476   Accuracy:  0.8984375\n",
      "Iteration:  4983  Loss:  0.46070242   Accuracy:  0.8984375\n",
      "Iteration:  4984  Loss:  0.3032686   Accuracy:  0.921875\n",
      "Iteration:  4985  Loss:  0.20809829   Accuracy:  0.9375\n",
      "Iteration:  4986  Loss:  0.41221926   Accuracy:  0.90625\n",
      "Iteration:  4987  Loss:  0.29093936   Accuracy:  0.921875\n",
      "Iteration:  4988  Loss:  0.30711478   Accuracy:  0.9296875\n",
      "Iteration:  4989  Loss:  0.26583186   Accuracy:  0.9453125\n",
      "Iteration:  4990  Loss:  0.30829212   Accuracy:  0.890625\n",
      "Iteration:  4991  Loss:  0.24857517   Accuracy:  0.96875\n",
      "Iteration:  4992  Loss:  0.69570917   Accuracy:  0.8984375\n",
      "Iteration:  4993  Loss:  0.32135677   Accuracy:  0.8671875\n",
      "Iteration:  4994  Loss:  0.3811128   Accuracy:  0.8828125\n",
      "Iteration:  4995  Loss:  0.47705728   Accuracy:  0.8828125\n",
      "Iteration:  4996  Loss:  0.24557361   Accuracy:  0.90625\n",
      "Iteration:  4997  Loss:  0.44017184   Accuracy:  0.9140625\n",
      "Iteration:  4998  Loss:  0.23029238   Accuracy:  0.9375\n",
      "Iteration:  4999  Loss:  0.59312576   Accuracy:  0.8984375\n"
     ]
    }
   ],
   "source": [
    "## This will find loss using Gredient Descent Algorithm\n",
    "\n",
    "loss_dir = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(5000):\n",
    "        \n",
    "        batch_x, batch_y = data.train.next_batch(128)\n",
    "        loss_val, accuracy_val, gd = sess.run([loss, accuracy, gd_step], feed_dict = {x: batch_x, y_true: batch_y})\n",
    "        loss_dir.append(loss_val)\n",
    "        print ('Iteration: ', _, ' Loss: ' , loss_val, '  Accuracy: ', accuracy_val)\n",
    "    accuracy_val = sess.run(accuracy, feed_dict = {x: data.test.images, y_true: data.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss ---->')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_dir, 'green')\n",
    "plt.xlabel('Iteration ---->')\n",
    "plt.ylabel('Loss ---->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing data:  90.41000008583069\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy on Testing data: ' , accuracy_val * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_step = tf.train.AdamOptimizer(0.5).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Loss:  2.649598   Accuracy:  0.0859375\n",
      "Iteration:  1  Loss:  2.2906597   Accuracy:  0.15625\n",
      "Iteration:  2  Loss:  2.2143373   Accuracy:  0.234375\n",
      "Iteration:  3  Loss:  2.1838093   Accuracy:  0.4453125\n",
      "Iteration:  4  Loss:  2.1120343   Accuracy:  0.3828125\n",
      "Iteration:  5  Loss:  2.1639323   Accuracy:  0.3671875\n",
      "Iteration:  6  Loss:  2.0785856   Accuracy:  0.375\n",
      "Iteration:  7  Loss:  1.8327861   Accuracy:  0.5546875\n",
      "Iteration:  8  Loss:  1.9311208   Accuracy:  0.4375\n",
      "Iteration:  9  Loss:  1.7867395   Accuracy:  0.5\n",
      "Iteration:  10  Loss:  1.7709935   Accuracy:  0.5546875\n",
      "Iteration:  11  Loss:  1.6331091   Accuracy:  0.6640625\n",
      "Iteration:  12  Loss:  1.6987326   Accuracy:  0.46875\n",
      "Iteration:  13  Loss:  1.495245   Accuracy:  0.609375\n",
      "Iteration:  14  Loss:  1.6160635   Accuracy:  0.6015625\n",
      "Iteration:  15  Loss:  1.5024636   Accuracy:  0.6328125\n",
      "Iteration:  16  Loss:  1.4466805   Accuracy:  0.6640625\n",
      "Iteration:  17  Loss:  1.4330363   Accuracy:  0.6796875\n",
      "Iteration:  18  Loss:  1.4094237   Accuracy:  0.71875\n",
      "Iteration:  19  Loss:  1.3976631   Accuracy:  0.6640625\n",
      "Iteration:  20  Loss:  1.2647119   Accuracy:  0.7265625\n",
      "Iteration:  21  Loss:  1.2433486   Accuracy:  0.6953125\n",
      "Iteration:  22  Loss:  1.2839537   Accuracy:  0.6796875\n",
      "Iteration:  23  Loss:  1.1694534   Accuracy:  0.71875\n",
      "Iteration:  24  Loss:  1.1854   Accuracy:  0.703125\n",
      "Iteration:  25  Loss:  1.1346933   Accuracy:  0.6953125\n",
      "Iteration:  26  Loss:  1.0938513   Accuracy:  0.765625\n",
      "Iteration:  27  Loss:  1.163736   Accuracy:  0.75\n",
      "Iteration:  28  Loss:  1.0657051   Accuracy:  0.8515625\n",
      "Iteration:  29  Loss:  1.1132739   Accuracy:  0.75\n",
      "Iteration:  30  Loss:  1.0371788   Accuracy:  0.796875\n",
      "Iteration:  31  Loss:  1.1246203   Accuracy:  0.7421875\n",
      "Iteration:  32  Loss:  0.9419134   Accuracy:  0.8125\n",
      "Iteration:  33  Loss:  0.9329949   Accuracy:  0.8203125\n",
      "Iteration:  34  Loss:  0.86201644   Accuracy:  0.8203125\n",
      "Iteration:  35  Loss:  0.832289   Accuracy:  0.875\n",
      "Iteration:  36  Loss:  0.9325301   Accuracy:  0.7578125\n",
      "Iteration:  37  Loss:  0.8487181   Accuracy:  0.8125\n",
      "Iteration:  38  Loss:  0.9079888   Accuracy:  0.78125\n",
      "Iteration:  39  Loss:  0.9095317   Accuracy:  0.7890625\n",
      "Iteration:  40  Loss:  0.8391594   Accuracy:  0.7890625\n",
      "Iteration:  41  Loss:  0.8481728   Accuracy:  0.796875\n",
      "Iteration:  42  Loss:  0.95173967   Accuracy:  0.78125\n",
      "Iteration:  43  Loss:  0.8341999   Accuracy:  0.8125\n",
      "Iteration:  44  Loss:  0.8078333   Accuracy:  0.828125\n",
      "Iteration:  45  Loss:  0.7317305   Accuracy:  0.890625\n",
      "Iteration:  46  Loss:  0.86234343   Accuracy:  0.796875\n",
      "Iteration:  47  Loss:  0.8687837   Accuracy:  0.7734375\n",
      "Iteration:  48  Loss:  0.763615   Accuracy:  0.796875\n",
      "Iteration:  49  Loss:  0.7882194   Accuracy:  0.8515625\n",
      "Iteration:  50  Loss:  0.7191381   Accuracy:  0.84375\n",
      "Iteration:  51  Loss:  0.7578223   Accuracy:  0.8359375\n",
      "Iteration:  52  Loss:  0.8036436   Accuracy:  0.828125\n",
      "Iteration:  53  Loss:  0.8448214   Accuracy:  0.7734375\n",
      "Iteration:  54  Loss:  0.75881153   Accuracy:  0.84375\n",
      "Iteration:  55  Loss:  0.7297684   Accuracy:  0.8203125\n",
      "Iteration:  56  Loss:  0.73138225   Accuracy:  0.8203125\n",
      "Iteration:  57  Loss:  0.78901607   Accuracy:  0.8125\n",
      "Iteration:  58  Loss:  0.75068504   Accuracy:  0.828125\n",
      "Iteration:  59  Loss:  0.84596354   Accuracy:  0.796875\n",
      "Iteration:  60  Loss:  0.74843276   Accuracy:  0.796875\n",
      "Iteration:  61  Loss:  0.8487425   Accuracy:  0.78125\n",
      "Iteration:  62  Loss:  0.67242944   Accuracy:  0.84375\n",
      "Iteration:  63  Loss:  0.6832786   Accuracy:  0.8671875\n",
      "Iteration:  64  Loss:  0.63372904   Accuracy:  0.875\n",
      "Iteration:  65  Loss:  0.674935   Accuracy:  0.828125\n",
      "Iteration:  66  Loss:  0.65547526   Accuracy:  0.8515625\n",
      "Iteration:  67  Loss:  0.6450496   Accuracy:  0.8203125\n",
      "Iteration:  68  Loss:  0.62640476   Accuracy:  0.859375\n",
      "Iteration:  69  Loss:  0.5918442   Accuracy:  0.84375\n",
      "Iteration:  70  Loss:  0.67313457   Accuracy:  0.859375\n",
      "Iteration:  71  Loss:  0.6062454   Accuracy:  0.8671875\n",
      "Iteration:  72  Loss:  0.70811445   Accuracy:  0.859375\n",
      "Iteration:  73  Loss:  0.53105485   Accuracy:  0.859375\n",
      "Iteration:  74  Loss:  0.66977584   Accuracy:  0.828125\n",
      "Iteration:  75  Loss:  0.5432656   Accuracy:  0.875\n",
      "Iteration:  76  Loss:  0.6320185   Accuracy:  0.84375\n",
      "Iteration:  77  Loss:  0.7509544   Accuracy:  0.7890625\n",
      "Iteration:  78  Loss:  0.6713269   Accuracy:  0.84375\n",
      "Iteration:  79  Loss:  0.5983175   Accuracy:  0.875\n",
      "Iteration:  80  Loss:  0.6858554   Accuracy:  0.84375\n",
      "Iteration:  81  Loss:  0.56280744   Accuracy:  0.921875\n",
      "Iteration:  82  Loss:  0.71419096   Accuracy:  0.8203125\n",
      "Iteration:  83  Loss:  0.5781765   Accuracy:  0.875\n",
      "Iteration:  84  Loss:  0.5387696   Accuracy:  0.875\n",
      "Iteration:  85  Loss:  0.5524433   Accuracy:  0.84375\n",
      "Iteration:  86  Loss:  0.56435376   Accuracy:  0.859375\n",
      "Iteration:  87  Loss:  0.5365496   Accuracy:  0.890625\n",
      "Iteration:  88  Loss:  0.73184866   Accuracy:  0.78125\n",
      "Iteration:  89  Loss:  0.5687553   Accuracy:  0.859375\n",
      "Iteration:  90  Loss:  0.61394536   Accuracy:  0.8359375\n",
      "Iteration:  91  Loss:  0.57079035   Accuracy:  0.8828125\n",
      "Iteration:  92  Loss:  0.6252215   Accuracy:  0.828125\n",
      "Iteration:  93  Loss:  0.45030713   Accuracy:  0.921875\n",
      "Iteration:  94  Loss:  0.6072339   Accuracy:  0.8359375\n",
      "Iteration:  95  Loss:  0.5196849   Accuracy:  0.8984375\n",
      "Iteration:  96  Loss:  0.6298293   Accuracy:  0.828125\n",
      "Iteration:  97  Loss:  0.57313573   Accuracy:  0.859375\n",
      "Iteration:  98  Loss:  0.6520662   Accuracy:  0.7890625\n",
      "Iteration:  99  Loss:  0.5897035   Accuracy:  0.8671875\n",
      "Iteration:  100  Loss:  0.5140531   Accuracy:  0.875\n",
      "Iteration:  101  Loss:  0.5641092   Accuracy:  0.859375\n",
      "Iteration:  102  Loss:  0.6558907   Accuracy:  0.859375\n",
      "Iteration:  103  Loss:  0.45412534   Accuracy:  0.8828125\n",
      "Iteration:  104  Loss:  0.48334032   Accuracy:  0.890625\n",
      "Iteration:  105  Loss:  0.5605196   Accuracy:  0.84375\n",
      "Iteration:  106  Loss:  0.63368106   Accuracy:  0.859375\n",
      "Iteration:  107  Loss:  0.4578941   Accuracy:  0.90625\n",
      "Iteration:  108  Loss:  0.40167695   Accuracy:  0.9453125\n",
      "Iteration:  109  Loss:  0.5042167   Accuracy:  0.8828125\n",
      "Iteration:  110  Loss:  0.5942335   Accuracy:  0.8671875\n",
      "Iteration:  111  Loss:  0.46559078   Accuracy:  0.8828125\n",
      "Iteration:  112  Loss:  0.57804257   Accuracy:  0.859375\n",
      "Iteration:  113  Loss:  0.5081495   Accuracy:  0.8671875\n",
      "Iteration:  114  Loss:  0.55762947   Accuracy:  0.8359375\n",
      "Iteration:  115  Loss:  0.46439034   Accuracy:  0.8828125\n",
      "Iteration:  116  Loss:  0.6160634   Accuracy:  0.8515625\n",
      "Iteration:  117  Loss:  0.4661429   Accuracy:  0.84375\n",
      "Iteration:  118  Loss:  0.5502761   Accuracy:  0.859375\n",
      "Iteration:  119  Loss:  0.53123623   Accuracy:  0.8671875\n",
      "Iteration:  120  Loss:  0.4313338   Accuracy:  0.859375\n",
      "Iteration:  121  Loss:  0.5675684   Accuracy:  0.875\n",
      "Iteration:  122  Loss:  0.41733366   Accuracy:  0.9375\n",
      "Iteration:  123  Loss:  0.6142366   Accuracy:  0.8515625\n",
      "Iteration:  124  Loss:  0.46054724   Accuracy:  0.921875\n",
      "Iteration:  125  Loss:  0.5900339   Accuracy:  0.84375\n",
      "Iteration:  126  Loss:  0.5049672   Accuracy:  0.890625\n",
      "Iteration:  127  Loss:  0.45199427   Accuracy:  0.8828125\n",
      "Iteration:  128  Loss:  0.5166234   Accuracy:  0.8984375\n",
      "Iteration:  129  Loss:  0.5512873   Accuracy:  0.8359375\n",
      "Iteration:  130  Loss:  0.4202544   Accuracy:  0.8984375\n",
      "Iteration:  131  Loss:  0.5285114   Accuracy:  0.8515625\n",
      "Iteration:  132  Loss:  0.558563   Accuracy:  0.8515625\n",
      "Iteration:  133  Loss:  0.47141683   Accuracy:  0.90625\n",
      "Iteration:  134  Loss:  0.5476395   Accuracy:  0.8828125\n",
      "Iteration:  135  Loss:  0.40199983   Accuracy:  0.9140625\n",
      "Iteration:  136  Loss:  0.51229066   Accuracy:  0.890625\n",
      "Iteration:  137  Loss:  0.4693579   Accuracy:  0.875\n",
      "Iteration:  138  Loss:  0.42296836   Accuracy:  0.9140625\n",
      "Iteration:  139  Loss:  0.56281096   Accuracy:  0.84375\n",
      "Iteration:  140  Loss:  0.41361648   Accuracy:  0.8828125\n",
      "Iteration:  141  Loss:  0.4198749   Accuracy:  0.90625\n",
      "Iteration:  142  Loss:  0.55612373   Accuracy:  0.8671875\n",
      "Iteration:  143  Loss:  0.63529956   Accuracy:  0.8515625\n",
      "Iteration:  144  Loss:  0.50247896   Accuracy:  0.8515625\n",
      "Iteration:  145  Loss:  0.53483725   Accuracy:  0.8515625\n",
      "Iteration:  146  Loss:  0.5000057   Accuracy:  0.859375\n",
      "Iteration:  147  Loss:  0.41555962   Accuracy:  0.890625\n",
      "Iteration:  148  Loss:  0.5038216   Accuracy:  0.90625\n",
      "Iteration:  149  Loss:  0.52947927   Accuracy:  0.8671875\n",
      "Iteration:  150  Loss:  0.43475193   Accuracy:  0.8828125\n",
      "Iteration:  151  Loss:  0.44941086   Accuracy:  0.875\n",
      "Iteration:  152  Loss:  0.63497883   Accuracy:  0.8671875\n",
      "Iteration:  153  Loss:  0.49911502   Accuracy:  0.890625\n",
      "Iteration:  154  Loss:  0.5751947   Accuracy:  0.8046875\n",
      "Iteration:  155  Loss:  0.39916223   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  156  Loss:  0.42281836   Accuracy:  0.8984375\n",
      "Iteration:  157  Loss:  0.44445312   Accuracy:  0.90625\n",
      "Iteration:  158  Loss:  0.59836555   Accuracy:  0.84375\n",
      "Iteration:  159  Loss:  0.40266842   Accuracy:  0.9140625\n",
      "Iteration:  160  Loss:  0.38966456   Accuracy:  0.9375\n",
      "Iteration:  161  Loss:  0.5026897   Accuracy:  0.84375\n",
      "Iteration:  162  Loss:  0.33858997   Accuracy:  0.9375\n",
      "Iteration:  163  Loss:  0.39287028   Accuracy:  0.890625\n",
      "Iteration:  164  Loss:  0.5205877   Accuracy:  0.8671875\n",
      "Iteration:  165  Loss:  0.42163187   Accuracy:  0.9140625\n",
      "Iteration:  166  Loss:  0.5534123   Accuracy:  0.8203125\n",
      "Iteration:  167  Loss:  0.52260447   Accuracy:  0.859375\n",
      "Iteration:  168  Loss:  0.44954395   Accuracy:  0.8828125\n",
      "Iteration:  169  Loss:  0.27284116   Accuracy:  0.9296875\n",
      "Iteration:  170  Loss:  0.46164274   Accuracy:  0.859375\n",
      "Iteration:  171  Loss:  0.41116905   Accuracy:  0.921875\n",
      "Iteration:  172  Loss:  0.42703134   Accuracy:  0.8671875\n",
      "Iteration:  173  Loss:  0.47325188   Accuracy:  0.890625\n",
      "Iteration:  174  Loss:  0.3705849   Accuracy:  0.90625\n",
      "Iteration:  175  Loss:  0.4292915   Accuracy:  0.8828125\n",
      "Iteration:  176  Loss:  0.57624465   Accuracy:  0.828125\n",
      "Iteration:  177  Loss:  0.44998288   Accuracy:  0.890625\n",
      "Iteration:  178  Loss:  0.48274618   Accuracy:  0.8671875\n",
      "Iteration:  179  Loss:  0.46312594   Accuracy:  0.875\n",
      "Iteration:  180  Loss:  0.4291815   Accuracy:  0.8984375\n",
      "Iteration:  181  Loss:  0.43590432   Accuracy:  0.90625\n",
      "Iteration:  182  Loss:  0.39502472   Accuracy:  0.90625\n",
      "Iteration:  183  Loss:  0.4566508   Accuracy:  0.8828125\n",
      "Iteration:  184  Loss:  0.44143048   Accuracy:  0.8828125\n",
      "Iteration:  185  Loss:  0.42823893   Accuracy:  0.8828125\n",
      "Iteration:  186  Loss:  0.39319324   Accuracy:  0.9140625\n",
      "Iteration:  187  Loss:  0.43807185   Accuracy:  0.890625\n",
      "Iteration:  188  Loss:  0.46361884   Accuracy:  0.890625\n",
      "Iteration:  189  Loss:  0.5785984   Accuracy:  0.828125\n",
      "Iteration:  190  Loss:  0.4090681   Accuracy:  0.890625\n",
      "Iteration:  191  Loss:  0.5046917   Accuracy:  0.8671875\n",
      "Iteration:  192  Loss:  0.3899111   Accuracy:  0.8984375\n",
      "Iteration:  193  Loss:  0.41762927   Accuracy:  0.890625\n",
      "Iteration:  194  Loss:  0.4168481   Accuracy:  0.875\n",
      "Iteration:  195  Loss:  0.3269547   Accuracy:  0.9296875\n",
      "Iteration:  196  Loss:  0.4519218   Accuracy:  0.90625\n",
      "Iteration:  197  Loss:  0.5827215   Accuracy:  0.8515625\n",
      "Iteration:  198  Loss:  0.38716766   Accuracy:  0.890625\n",
      "Iteration:  199  Loss:  0.38699698   Accuracy:  0.8828125\n",
      "Iteration:  200  Loss:  0.3918401   Accuracy:  0.8984375\n",
      "Iteration:  201  Loss:  0.4133042   Accuracy:  0.890625\n",
      "Iteration:  202  Loss:  0.4293182   Accuracy:  0.8828125\n",
      "Iteration:  203  Loss:  0.6358427   Accuracy:  0.828125\n",
      "Iteration:  204  Loss:  0.45885485   Accuracy:  0.8671875\n",
      "Iteration:  205  Loss:  0.4102516   Accuracy:  0.875\n",
      "Iteration:  206  Loss:  0.42917153   Accuracy:  0.8984375\n",
      "Iteration:  207  Loss:  0.49661106   Accuracy:  0.8125\n",
      "Iteration:  208  Loss:  0.45457953   Accuracy:  0.8828125\n",
      "Iteration:  209  Loss:  0.3150413   Accuracy:  0.9140625\n",
      "Iteration:  210  Loss:  0.32108867   Accuracy:  0.9296875\n",
      "Iteration:  211  Loss:  0.46630192   Accuracy:  0.8984375\n",
      "Iteration:  212  Loss:  0.33021584   Accuracy:  0.9296875\n",
      "Iteration:  213  Loss:  0.3604735   Accuracy:  0.90625\n",
      "Iteration:  214  Loss:  0.39689246   Accuracy:  0.90625\n",
      "Iteration:  215  Loss:  0.46592274   Accuracy:  0.84375\n",
      "Iteration:  216  Loss:  0.3861702   Accuracy:  0.890625\n",
      "Iteration:  217  Loss:  0.41500968   Accuracy:  0.8828125\n",
      "Iteration:  218  Loss:  0.4496107   Accuracy:  0.8203125\n",
      "Iteration:  219  Loss:  0.35039523   Accuracy:  0.9140625\n",
      "Iteration:  220  Loss:  0.42987025   Accuracy:  0.8828125\n",
      "Iteration:  221  Loss:  0.384739   Accuracy:  0.8828125\n",
      "Iteration:  222  Loss:  0.34586585   Accuracy:  0.9296875\n",
      "Iteration:  223  Loss:  0.39881203   Accuracy:  0.90625\n",
      "Iteration:  224  Loss:  0.3661825   Accuracy:  0.90625\n",
      "Iteration:  225  Loss:  0.53150207   Accuracy:  0.8046875\n",
      "Iteration:  226  Loss:  0.5194684   Accuracy:  0.859375\n",
      "Iteration:  227  Loss:  0.37783578   Accuracy:  0.90625\n",
      "Iteration:  228  Loss:  0.37662792   Accuracy:  0.8828125\n",
      "Iteration:  229  Loss:  0.43327618   Accuracy:  0.875\n",
      "Iteration:  230  Loss:  0.38997066   Accuracy:  0.890625\n",
      "Iteration:  231  Loss:  0.37150398   Accuracy:  0.890625\n",
      "Iteration:  232  Loss:  0.36479527   Accuracy:  0.9140625\n",
      "Iteration:  233  Loss:  0.38453874   Accuracy:  0.921875\n",
      "Iteration:  234  Loss:  0.58796257   Accuracy:  0.8203125\n",
      "Iteration:  235  Loss:  0.4505067   Accuracy:  0.8671875\n",
      "Iteration:  236  Loss:  0.5164677   Accuracy:  0.875\n",
      "Iteration:  237  Loss:  0.31063336   Accuracy:  0.921875\n",
      "Iteration:  238  Loss:  0.27049738   Accuracy:  0.9375\n",
      "Iteration:  239  Loss:  0.31301206   Accuracy:  0.9296875\n",
      "Iteration:  240  Loss:  0.5899035   Accuracy:  0.8515625\n",
      "Iteration:  241  Loss:  0.42909116   Accuracy:  0.890625\n",
      "Iteration:  242  Loss:  0.35687146   Accuracy:  0.9140625\n",
      "Iteration:  243  Loss:  0.49760604   Accuracy:  0.828125\n",
      "Iteration:  244  Loss:  0.35540897   Accuracy:  0.9140625\n",
      "Iteration:  245  Loss:  0.4321392   Accuracy:  0.875\n",
      "Iteration:  246  Loss:  0.4330842   Accuracy:  0.8828125\n",
      "Iteration:  247  Loss:  0.37514383   Accuracy:  0.9140625\n",
      "Iteration:  248  Loss:  0.38696098   Accuracy:  0.8984375\n",
      "Iteration:  249  Loss:  0.3153133   Accuracy:  0.8984375\n",
      "Iteration:  250  Loss:  0.40682054   Accuracy:  0.859375\n",
      "Iteration:  251  Loss:  0.35369936   Accuracy:  0.90625\n",
      "Iteration:  252  Loss:  0.32145306   Accuracy:  0.921875\n",
      "Iteration:  253  Loss:  0.43315822   Accuracy:  0.8828125\n",
      "Iteration:  254  Loss:  0.31643334   Accuracy:  0.9140625\n",
      "Iteration:  255  Loss:  0.48234445   Accuracy:  0.84375\n",
      "Iteration:  256  Loss:  0.40152183   Accuracy:  0.859375\n",
      "Iteration:  257  Loss:  0.41918004   Accuracy:  0.921875\n",
      "Iteration:  258  Loss:  0.38469684   Accuracy:  0.90625\n",
      "Iteration:  259  Loss:  0.34138447   Accuracy:  0.90625\n",
      "Iteration:  260  Loss:  0.3373698   Accuracy:  0.90625\n",
      "Iteration:  261  Loss:  0.48821738   Accuracy:  0.8671875\n",
      "Iteration:  262  Loss:  0.537007   Accuracy:  0.875\n",
      "Iteration:  263  Loss:  0.5221179   Accuracy:  0.84375\n",
      "Iteration:  264  Loss:  0.3565249   Accuracy:  0.8984375\n",
      "Iteration:  265  Loss:  0.45316905   Accuracy:  0.8828125\n",
      "Iteration:  266  Loss:  0.3584662   Accuracy:  0.8984375\n",
      "Iteration:  267  Loss:  0.35797584   Accuracy:  0.90625\n",
      "Iteration:  268  Loss:  0.43950486   Accuracy:  0.859375\n",
      "Iteration:  269  Loss:  0.44123435   Accuracy:  0.8671875\n",
      "Iteration:  270  Loss:  0.49870998   Accuracy:  0.828125\n",
      "Iteration:  271  Loss:  0.3079584   Accuracy:  0.9140625\n",
      "Iteration:  272  Loss:  0.37838504   Accuracy:  0.8828125\n",
      "Iteration:  273  Loss:  0.42646053   Accuracy:  0.90625\n",
      "Iteration:  274  Loss:  0.4007107   Accuracy:  0.890625\n",
      "Iteration:  275  Loss:  0.38742223   Accuracy:  0.875\n",
      "Iteration:  276  Loss:  0.33809882   Accuracy:  0.9140625\n",
      "Iteration:  277  Loss:  0.30307186   Accuracy:  0.9140625\n",
      "Iteration:  278  Loss:  0.5159568   Accuracy:  0.8671875\n",
      "Iteration:  279  Loss:  0.53604424   Accuracy:  0.859375\n",
      "Iteration:  280  Loss:  0.32908174   Accuracy:  0.9140625\n",
      "Iteration:  281  Loss:  0.5347812   Accuracy:  0.875\n",
      "Iteration:  282  Loss:  0.381333   Accuracy:  0.9140625\n",
      "Iteration:  283  Loss:  0.32770547   Accuracy:  0.9296875\n",
      "Iteration:  284  Loss:  0.29048494   Accuracy:  0.9375\n",
      "Iteration:  285  Loss:  0.35496774   Accuracy:  0.8984375\n",
      "Iteration:  286  Loss:  0.31596655   Accuracy:  0.890625\n",
      "Iteration:  287  Loss:  0.34134766   Accuracy:  0.875\n",
      "Iteration:  288  Loss:  0.39478934   Accuracy:  0.8828125\n",
      "Iteration:  289  Loss:  0.41860095   Accuracy:  0.8671875\n",
      "Iteration:  290  Loss:  0.4551408   Accuracy:  0.890625\n",
      "Iteration:  291  Loss:  0.3346411   Accuracy:  0.890625\n",
      "Iteration:  292  Loss:  0.29686254   Accuracy:  0.9375\n",
      "Iteration:  293  Loss:  0.33233294   Accuracy:  0.9140625\n",
      "Iteration:  294  Loss:  0.36822745   Accuracy:  0.890625\n",
      "Iteration:  295  Loss:  0.35637587   Accuracy:  0.921875\n",
      "Iteration:  296  Loss:  0.3920388   Accuracy:  0.875\n",
      "Iteration:  297  Loss:  0.24439192   Accuracy:  0.96875\n",
      "Iteration:  298  Loss:  0.42326248   Accuracy:  0.8828125\n",
      "Iteration:  299  Loss:  0.35104302   Accuracy:  0.90625\n",
      "Iteration:  300  Loss:  0.3488633   Accuracy:  0.90625\n",
      "Iteration:  301  Loss:  0.42640275   Accuracy:  0.890625\n",
      "Iteration:  302  Loss:  0.32265145   Accuracy:  0.9140625\n",
      "Iteration:  303  Loss:  0.37226927   Accuracy:  0.8515625\n",
      "Iteration:  304  Loss:  0.34342897   Accuracy:  0.921875\n",
      "Iteration:  305  Loss:  0.42446834   Accuracy:  0.890625\n",
      "Iteration:  306  Loss:  0.36932713   Accuracy:  0.8828125\n",
      "Iteration:  307  Loss:  0.42296588   Accuracy:  0.890625\n",
      "Iteration:  308  Loss:  0.37507102   Accuracy:  0.921875\n",
      "Iteration:  309  Loss:  0.46418905   Accuracy:  0.8671875\n",
      "Iteration:  310  Loss:  0.2444836   Accuracy:  0.9453125\n",
      "Iteration:  311  Loss:  0.33921885   Accuracy:  0.890625\n",
      "Iteration:  312  Loss:  0.42460698   Accuracy:  0.890625\n",
      "Iteration:  313  Loss:  0.42297706   Accuracy:  0.8828125\n",
      "Iteration:  314  Loss:  0.44006717   Accuracy:  0.8828125\n",
      "Iteration:  315  Loss:  0.35223293   Accuracy:  0.8984375\n",
      "Iteration:  316  Loss:  0.24510637   Accuracy:  0.9609375\n",
      "Iteration:  317  Loss:  0.3327036   Accuracy:  0.9140625\n",
      "Iteration:  318  Loss:  0.37625432   Accuracy:  0.8828125\n",
      "Iteration:  319  Loss:  0.4322195   Accuracy:  0.8671875\n",
      "Iteration:  320  Loss:  0.40971443   Accuracy:  0.8828125\n",
      "Iteration:  321  Loss:  0.27652603   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  322  Loss:  0.40663886   Accuracy:  0.890625\n",
      "Iteration:  323  Loss:  0.41592836   Accuracy:  0.8671875\n",
      "Iteration:  324  Loss:  0.33055463   Accuracy:  0.921875\n",
      "Iteration:  325  Loss:  0.38042715   Accuracy:  0.9140625\n",
      "Iteration:  326  Loss:  0.41961443   Accuracy:  0.890625\n",
      "Iteration:  327  Loss:  0.38243097   Accuracy:  0.8671875\n",
      "Iteration:  328  Loss:  0.29620636   Accuracy:  0.9296875\n",
      "Iteration:  329  Loss:  0.39435738   Accuracy:  0.8984375\n",
      "Iteration:  330  Loss:  0.24019603   Accuracy:  0.953125\n",
      "Iteration:  331  Loss:  0.485554   Accuracy:  0.84375\n",
      "Iteration:  332  Loss:  0.38726363   Accuracy:  0.875\n",
      "Iteration:  333  Loss:  0.39013356   Accuracy:  0.890625\n",
      "Iteration:  334  Loss:  0.32548535   Accuracy:  0.9140625\n",
      "Iteration:  335  Loss:  0.38645196   Accuracy:  0.921875\n",
      "Iteration:  336  Loss:  0.36754656   Accuracy:  0.8828125\n",
      "Iteration:  337  Loss:  0.30732885   Accuracy:  0.9296875\n",
      "Iteration:  338  Loss:  0.4064174   Accuracy:  0.921875\n",
      "Iteration:  339  Loss:  0.42638856   Accuracy:  0.875\n",
      "Iteration:  340  Loss:  0.3488434   Accuracy:  0.8828125\n",
      "Iteration:  341  Loss:  0.351856   Accuracy:  0.9140625\n",
      "Iteration:  342  Loss:  0.33304706   Accuracy:  0.8984375\n",
      "Iteration:  343  Loss:  0.39716163   Accuracy:  0.90625\n",
      "Iteration:  344  Loss:  0.44870213   Accuracy:  0.84375\n",
      "Iteration:  345  Loss:  0.26266176   Accuracy:  0.9453125\n",
      "Iteration:  346  Loss:  0.33149737   Accuracy:  0.90625\n",
      "Iteration:  347  Loss:  0.44606188   Accuracy:  0.859375\n",
      "Iteration:  348  Loss:  0.41825423   Accuracy:  0.8828125\n",
      "Iteration:  349  Loss:  0.3165313   Accuracy:  0.90625\n",
      "Iteration:  350  Loss:  0.49087286   Accuracy:  0.875\n",
      "Iteration:  351  Loss:  0.41799405   Accuracy:  0.875\n",
      "Iteration:  352  Loss:  0.32241917   Accuracy:  0.8984375\n",
      "Iteration:  353  Loss:  0.33937097   Accuracy:  0.8828125\n",
      "Iteration:  354  Loss:  0.26592734   Accuracy:  0.921875\n",
      "Iteration:  355  Loss:  0.41341186   Accuracy:  0.8984375\n",
      "Iteration:  356  Loss:  0.433421   Accuracy:  0.8984375\n",
      "Iteration:  357  Loss:  0.40127856   Accuracy:  0.890625\n",
      "Iteration:  358  Loss:  0.47205022   Accuracy:  0.890625\n",
      "Iteration:  359  Loss:  0.41613442   Accuracy:  0.875\n",
      "Iteration:  360  Loss:  0.25273928   Accuracy:  0.9296875\n",
      "Iteration:  361  Loss:  0.30946845   Accuracy:  0.9140625\n",
      "Iteration:  362  Loss:  0.29686058   Accuracy:  0.9140625\n",
      "Iteration:  363  Loss:  0.3949501   Accuracy:  0.8671875\n",
      "Iteration:  364  Loss:  0.39814016   Accuracy:  0.8984375\n",
      "Iteration:  365  Loss:  0.46324712   Accuracy:  0.859375\n",
      "Iteration:  366  Loss:  0.46360213   Accuracy:  0.8671875\n",
      "Iteration:  367  Loss:  0.381895   Accuracy:  0.890625\n",
      "Iteration:  368  Loss:  0.43338603   Accuracy:  0.8828125\n",
      "Iteration:  369  Loss:  0.34631798   Accuracy:  0.9296875\n",
      "Iteration:  370  Loss:  0.36851865   Accuracy:  0.90625\n",
      "Iteration:  371  Loss:  0.40565738   Accuracy:  0.8984375\n",
      "Iteration:  372  Loss:  0.40799278   Accuracy:  0.859375\n",
      "Iteration:  373  Loss:  0.43381917   Accuracy:  0.859375\n",
      "Iteration:  374  Loss:  0.6414764   Accuracy:  0.828125\n",
      "Iteration:  375  Loss:  0.32153577   Accuracy:  0.9375\n",
      "Iteration:  376  Loss:  0.34657797   Accuracy:  0.9140625\n",
      "Iteration:  377  Loss:  0.38742006   Accuracy:  0.875\n",
      "Iteration:  378  Loss:  0.36494473   Accuracy:  0.8984375\n",
      "Iteration:  379  Loss:  0.24624878   Accuracy:  0.9765625\n",
      "Iteration:  380  Loss:  0.35595036   Accuracy:  0.875\n",
      "Iteration:  381  Loss:  0.4379811   Accuracy:  0.875\n",
      "Iteration:  382  Loss:  0.28889775   Accuracy:  0.9140625\n",
      "Iteration:  383  Loss:  0.40157548   Accuracy:  0.890625\n",
      "Iteration:  384  Loss:  0.26955837   Accuracy:  0.8984375\n",
      "Iteration:  385  Loss:  0.32743374   Accuracy:  0.8984375\n",
      "Iteration:  386  Loss:  0.45556447   Accuracy:  0.8515625\n",
      "Iteration:  387  Loss:  0.27131265   Accuracy:  0.921875\n",
      "Iteration:  388  Loss:  0.35846302   Accuracy:  0.90625\n",
      "Iteration:  389  Loss:  0.3791694   Accuracy:  0.890625\n",
      "Iteration:  390  Loss:  0.22701633   Accuracy:  0.9609375\n",
      "Iteration:  391  Loss:  0.30600935   Accuracy:  0.921875\n",
      "Iteration:  392  Loss:  0.33579648   Accuracy:  0.8984375\n",
      "Iteration:  393  Loss:  0.23102082   Accuracy:  0.953125\n",
      "Iteration:  394  Loss:  0.3732979   Accuracy:  0.90625\n",
      "Iteration:  395  Loss:  0.24790195   Accuracy:  0.9375\n",
      "Iteration:  396  Loss:  0.40611306   Accuracy:  0.90625\n",
      "Iteration:  397  Loss:  0.39759576   Accuracy:  0.8828125\n",
      "Iteration:  398  Loss:  0.35888368   Accuracy:  0.9140625\n",
      "Iteration:  399  Loss:  0.4022249   Accuracy:  0.8671875\n",
      "Iteration:  400  Loss:  0.6040722   Accuracy:  0.84375\n",
      "Iteration:  401  Loss:  0.26459834   Accuracy:  0.9296875\n",
      "Iteration:  402  Loss:  0.3444277   Accuracy:  0.8984375\n",
      "Iteration:  403  Loss:  0.3972426   Accuracy:  0.8828125\n",
      "Iteration:  404  Loss:  0.33999005   Accuracy:  0.9140625\n",
      "Iteration:  405  Loss:  0.37343162   Accuracy:  0.90625\n",
      "Iteration:  406  Loss:  0.3239504   Accuracy:  0.9140625\n",
      "Iteration:  407  Loss:  0.39459294   Accuracy:  0.8984375\n",
      "Iteration:  408  Loss:  0.40842426   Accuracy:  0.8984375\n",
      "Iteration:  409  Loss:  0.30199912   Accuracy:  0.9140625\n",
      "Iteration:  410  Loss:  0.31579933   Accuracy:  0.921875\n",
      "Iteration:  411  Loss:  0.38240197   Accuracy:  0.90625\n",
      "Iteration:  412  Loss:  0.35073954   Accuracy:  0.921875\n",
      "Iteration:  413  Loss:  0.32634753   Accuracy:  0.8984375\n",
      "Iteration:  414  Loss:  0.32158682   Accuracy:  0.90625\n",
      "Iteration:  415  Loss:  0.35759413   Accuracy:  0.9140625\n",
      "Iteration:  416  Loss:  0.428529   Accuracy:  0.8671875\n",
      "Iteration:  417  Loss:  0.5444708   Accuracy:  0.8671875\n",
      "Iteration:  418  Loss:  0.29207647   Accuracy:  0.9140625\n",
      "Iteration:  419  Loss:  0.41982   Accuracy:  0.875\n",
      "Iteration:  420  Loss:  0.4178091   Accuracy:  0.8828125\n",
      "Iteration:  421  Loss:  0.19222   Accuracy:  0.953125\n",
      "Iteration:  422  Loss:  0.25031763   Accuracy:  0.9296875\n",
      "Iteration:  423  Loss:  0.4364607   Accuracy:  0.8828125\n",
      "Iteration:  424  Loss:  0.34234628   Accuracy:  0.8984375\n",
      "Iteration:  425  Loss:  0.31680045   Accuracy:  0.9140625\n",
      "Iteration:  426  Loss:  0.27141348   Accuracy:  0.9453125\n",
      "Iteration:  427  Loss:  0.36152062   Accuracy:  0.890625\n",
      "Iteration:  428  Loss:  0.39963374   Accuracy:  0.8984375\n",
      "Iteration:  429  Loss:  0.31263036   Accuracy:  0.8984375\n",
      "Iteration:  430  Loss:  0.2648875   Accuracy:  0.9453125\n",
      "Iteration:  431  Loss:  0.3229575   Accuracy:  0.9140625\n",
      "Iteration:  432  Loss:  0.31804883   Accuracy:  0.921875\n",
      "Iteration:  433  Loss:  0.2809704   Accuracy:  0.90625\n",
      "Iteration:  434  Loss:  0.25978363   Accuracy:  0.9453125\n",
      "Iteration:  435  Loss:  0.4011547   Accuracy:  0.8828125\n",
      "Iteration:  436  Loss:  0.2485111   Accuracy:  0.9453125\n",
      "Iteration:  437  Loss:  0.28864378   Accuracy:  0.90625\n",
      "Iteration:  438  Loss:  0.44140285   Accuracy:  0.890625\n",
      "Iteration:  439  Loss:  0.27893513   Accuracy:  0.9140625\n",
      "Iteration:  440  Loss:  0.30827314   Accuracy:  0.9140625\n",
      "Iteration:  441  Loss:  0.49168426   Accuracy:  0.875\n",
      "Iteration:  442  Loss:  0.36542434   Accuracy:  0.921875\n",
      "Iteration:  443  Loss:  0.3202331   Accuracy:  0.90625\n",
      "Iteration:  444  Loss:  0.30902806   Accuracy:  0.9296875\n",
      "Iteration:  445  Loss:  0.408608   Accuracy:  0.8359375\n",
      "Iteration:  446  Loss:  0.35155064   Accuracy:  0.890625\n",
      "Iteration:  447  Loss:  0.30733547   Accuracy:  0.8984375\n",
      "Iteration:  448  Loss:  0.3320635   Accuracy:  0.890625\n",
      "Iteration:  449  Loss:  0.34472603   Accuracy:  0.9140625\n",
      "Iteration:  450  Loss:  0.37958103   Accuracy:  0.8828125\n",
      "Iteration:  451  Loss:  0.35443816   Accuracy:  0.8671875\n",
      "Iteration:  452  Loss:  0.28990623   Accuracy:  0.8984375\n",
      "Iteration:  453  Loss:  0.31695634   Accuracy:  0.90625\n",
      "Iteration:  454  Loss:  0.39399272   Accuracy:  0.8828125\n",
      "Iteration:  455  Loss:  0.26813844   Accuracy:  0.90625\n",
      "Iteration:  456  Loss:  0.23194462   Accuracy:  0.9375\n",
      "Iteration:  457  Loss:  0.2595297   Accuracy:  0.9140625\n",
      "Iteration:  458  Loss:  0.27847868   Accuracy:  0.9296875\n",
      "Iteration:  459  Loss:  0.28349423   Accuracy:  0.921875\n",
      "Iteration:  460  Loss:  0.28430426   Accuracy:  0.9296875\n",
      "Iteration:  461  Loss:  0.30456248   Accuracy:  0.9140625\n",
      "Iteration:  462  Loss:  0.26892596   Accuracy:  0.921875\n",
      "Iteration:  463  Loss:  0.4411553   Accuracy:  0.8515625\n",
      "Iteration:  464  Loss:  0.23532039   Accuracy:  0.9375\n",
      "Iteration:  465  Loss:  0.29301804   Accuracy:  0.8984375\n",
      "Iteration:  466  Loss:  0.42255592   Accuracy:  0.9140625\n",
      "Iteration:  467  Loss:  0.36645618   Accuracy:  0.890625\n",
      "Iteration:  468  Loss:  0.36767197   Accuracy:  0.8984375\n",
      "Iteration:  469  Loss:  0.28473258   Accuracy:  0.9375\n",
      "Iteration:  470  Loss:  0.3499198   Accuracy:  0.90625\n",
      "Iteration:  471  Loss:  0.32090637   Accuracy:  0.9140625\n",
      "Iteration:  472  Loss:  0.4044101   Accuracy:  0.9140625\n",
      "Iteration:  473  Loss:  0.3598253   Accuracy:  0.8984375\n",
      "Iteration:  474  Loss:  0.32095152   Accuracy:  0.9375\n",
      "Iteration:  475  Loss:  0.33727077   Accuracy:  0.90625\n",
      "Iteration:  476  Loss:  0.51277524   Accuracy:  0.8515625\n",
      "Iteration:  477  Loss:  0.28014433   Accuracy:  0.90625\n",
      "Iteration:  478  Loss:  0.42243314   Accuracy:  0.8203125\n",
      "Iteration:  479  Loss:  0.3120197   Accuracy:  0.90625\n",
      "Iteration:  480  Loss:  0.3719695   Accuracy:  0.8984375\n",
      "Iteration:  481  Loss:  0.37041515   Accuracy:  0.90625\n",
      "Iteration:  482  Loss:  0.3594446   Accuracy:  0.921875\n",
      "Iteration:  483  Loss:  0.26657772   Accuracy:  0.8828125\n",
      "Iteration:  484  Loss:  0.29154456   Accuracy:  0.90625\n",
      "Iteration:  485  Loss:  0.34906262   Accuracy:  0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  486  Loss:  0.44451827   Accuracy:  0.8984375\n",
      "Iteration:  487  Loss:  0.2910177   Accuracy:  0.890625\n",
      "Iteration:  488  Loss:  0.34072858   Accuracy:  0.8828125\n",
      "Iteration:  489  Loss:  0.21660003   Accuracy:  0.9609375\n",
      "Iteration:  490  Loss:  0.37162912   Accuracy:  0.8984375\n",
      "Iteration:  491  Loss:  0.3503614   Accuracy:  0.9140625\n",
      "Iteration:  492  Loss:  0.31161824   Accuracy:  0.9296875\n",
      "Iteration:  493  Loss:  0.27663547   Accuracy:  0.9296875\n",
      "Iteration:  494  Loss:  0.41201246   Accuracy:  0.90625\n",
      "Iteration:  495  Loss:  0.32497454   Accuracy:  0.8984375\n",
      "Iteration:  496  Loss:  0.33870122   Accuracy:  0.90625\n",
      "Iteration:  497  Loss:  0.43291414   Accuracy:  0.859375\n",
      "Iteration:  498  Loss:  0.42356503   Accuracy:  0.8828125\n",
      "Iteration:  499  Loss:  0.28109062   Accuracy:  0.9296875\n",
      "Iteration:  500  Loss:  0.34050798   Accuracy:  0.8984375\n",
      "Iteration:  501  Loss:  0.30763486   Accuracy:  0.90625\n",
      "Iteration:  502  Loss:  0.30723396   Accuracy:  0.9375\n",
      "Iteration:  503  Loss:  0.41207826   Accuracy:  0.8671875\n",
      "Iteration:  504  Loss:  0.33764726   Accuracy:  0.90625\n",
      "Iteration:  505  Loss:  0.26945174   Accuracy:  0.921875\n",
      "Iteration:  506  Loss:  0.32956898   Accuracy:  0.921875\n",
      "Iteration:  507  Loss:  0.32242218   Accuracy:  0.8984375\n",
      "Iteration:  508  Loss:  0.48931277   Accuracy:  0.8515625\n",
      "Iteration:  509  Loss:  0.29658046   Accuracy:  0.8984375\n",
      "Iteration:  510  Loss:  0.30905887   Accuracy:  0.8984375\n",
      "Iteration:  511  Loss:  0.3367445   Accuracy:  0.921875\n",
      "Iteration:  512  Loss:  0.24382341   Accuracy:  0.9375\n",
      "Iteration:  513  Loss:  0.4200307   Accuracy:  0.8828125\n",
      "Iteration:  514  Loss:  0.26757473   Accuracy:  0.9140625\n",
      "Iteration:  515  Loss:  0.2970959   Accuracy:  0.9140625\n",
      "Iteration:  516  Loss:  0.41591623   Accuracy:  0.8515625\n",
      "Iteration:  517  Loss:  0.3106806   Accuracy:  0.9140625\n",
      "Iteration:  518  Loss:  0.4404542   Accuracy:  0.8984375\n",
      "Iteration:  519  Loss:  0.27443582   Accuracy:  0.9375\n",
      "Iteration:  520  Loss:  0.29653996   Accuracy:  0.890625\n",
      "Iteration:  521  Loss:  0.23008437   Accuracy:  0.9375\n",
      "Iteration:  522  Loss:  0.27141562   Accuracy:  0.9140625\n",
      "Iteration:  523  Loss:  0.18787342   Accuracy:  0.953125\n",
      "Iteration:  524  Loss:  0.35235795   Accuracy:  0.8984375\n",
      "Iteration:  525  Loss:  0.357153   Accuracy:  0.8671875\n",
      "Iteration:  526  Loss:  0.2859921   Accuracy:  0.890625\n",
      "Iteration:  527  Loss:  0.26134187   Accuracy:  0.9375\n",
      "Iteration:  528  Loss:  0.40250695   Accuracy:  0.875\n",
      "Iteration:  529  Loss:  0.3571661   Accuracy:  0.8984375\n",
      "Iteration:  530  Loss:  0.26095235   Accuracy:  0.953125\n",
      "Iteration:  531  Loss:  0.2806211   Accuracy:  0.9140625\n",
      "Iteration:  532  Loss:  0.21194595   Accuracy:  0.9453125\n",
      "Iteration:  533  Loss:  0.35562074   Accuracy:  0.875\n",
      "Iteration:  534  Loss:  0.24125609   Accuracy:  0.921875\n",
      "Iteration:  535  Loss:  0.33385062   Accuracy:  0.8984375\n",
      "Iteration:  536  Loss:  0.4473189   Accuracy:  0.84375\n",
      "Iteration:  537  Loss:  0.27544868   Accuracy:  0.921875\n",
      "Iteration:  538  Loss:  0.33443576   Accuracy:  0.90625\n",
      "Iteration:  539  Loss:  0.27856994   Accuracy:  0.90625\n",
      "Iteration:  540  Loss:  0.3189909   Accuracy:  0.9296875\n",
      "Iteration:  541  Loss:  0.4927159   Accuracy:  0.859375\n",
      "Iteration:  542  Loss:  0.31110683   Accuracy:  0.90625\n",
      "Iteration:  543  Loss:  0.36628756   Accuracy:  0.8984375\n",
      "Iteration:  544  Loss:  0.4455936   Accuracy:  0.8671875\n",
      "Iteration:  545  Loss:  0.40781328   Accuracy:  0.8828125\n",
      "Iteration:  546  Loss:  0.37197062   Accuracy:  0.859375\n",
      "Iteration:  547  Loss:  0.2750946   Accuracy:  0.90625\n",
      "Iteration:  548  Loss:  0.38024932   Accuracy:  0.8984375\n",
      "Iteration:  549  Loss:  0.2589226   Accuracy:  0.90625\n",
      "Iteration:  550  Loss:  0.2831038   Accuracy:  0.9296875\n",
      "Iteration:  551  Loss:  0.35158497   Accuracy:  0.890625\n",
      "Iteration:  552  Loss:  0.28007385   Accuracy:  0.9296875\n",
      "Iteration:  553  Loss:  0.27972758   Accuracy:  0.8984375\n",
      "Iteration:  554  Loss:  0.40478748   Accuracy:  0.8515625\n",
      "Iteration:  555  Loss:  0.37290043   Accuracy:  0.921875\n",
      "Iteration:  556  Loss:  0.33677268   Accuracy:  0.875\n",
      "Iteration:  557  Loss:  0.3184712   Accuracy:  0.90625\n",
      "Iteration:  558  Loss:  0.3070444   Accuracy:  0.921875\n",
      "Iteration:  559  Loss:  0.31478152   Accuracy:  0.8984375\n",
      "Iteration:  560  Loss:  0.50888705   Accuracy:  0.8671875\n",
      "Iteration:  561  Loss:  0.42788443   Accuracy:  0.8671875\n",
      "Iteration:  562  Loss:  0.31609178   Accuracy:  0.9375\n",
      "Iteration:  563  Loss:  0.19202155   Accuracy:  0.953125\n",
      "Iteration:  564  Loss:  0.30393875   Accuracy:  0.90625\n",
      "Iteration:  565  Loss:  0.29102015   Accuracy:  0.90625\n",
      "Iteration:  566  Loss:  0.3758941   Accuracy:  0.8984375\n",
      "Iteration:  567  Loss:  0.30627444   Accuracy:  0.9140625\n",
      "Iteration:  568  Loss:  0.3663112   Accuracy:  0.8671875\n",
      "Iteration:  569  Loss:  0.31568128   Accuracy:  0.8671875\n",
      "Iteration:  570  Loss:  0.446172   Accuracy:  0.8984375\n",
      "Iteration:  571  Loss:  0.29334152   Accuracy:  0.8984375\n",
      "Iteration:  572  Loss:  0.4023632   Accuracy:  0.90625\n",
      "Iteration:  573  Loss:  0.31960315   Accuracy:  0.8984375\n",
      "Iteration:  574  Loss:  0.25871438   Accuracy:  0.921875\n",
      "Iteration:  575  Loss:  0.36493778   Accuracy:  0.875\n",
      "Iteration:  576  Loss:  0.41714257   Accuracy:  0.875\n",
      "Iteration:  577  Loss:  0.34219974   Accuracy:  0.9375\n",
      "Iteration:  578  Loss:  0.2755851   Accuracy:  0.90625\n",
      "Iteration:  579  Loss:  0.4509924   Accuracy:  0.8984375\n",
      "Iteration:  580  Loss:  0.38926262   Accuracy:  0.8984375\n",
      "Iteration:  581  Loss:  0.50169593   Accuracy:  0.8359375\n",
      "Iteration:  582  Loss:  0.33515018   Accuracy:  0.90625\n",
      "Iteration:  583  Loss:  0.4023527   Accuracy:  0.875\n",
      "Iteration:  584  Loss:  0.29447693   Accuracy:  0.90625\n",
      "Iteration:  585  Loss:  0.39920458   Accuracy:  0.8671875\n",
      "Iteration:  586  Loss:  0.32407802   Accuracy:  0.90625\n",
      "Iteration:  587  Loss:  0.28502238   Accuracy:  0.9296875\n",
      "Iteration:  588  Loss:  0.56124973   Accuracy:  0.875\n",
      "Iteration:  589  Loss:  0.2658774   Accuracy:  0.9453125\n",
      "Iteration:  590  Loss:  0.23234428   Accuracy:  0.921875\n",
      "Iteration:  591  Loss:  0.2751094   Accuracy:  0.921875\n",
      "Iteration:  592  Loss:  0.4017555   Accuracy:  0.890625\n",
      "Iteration:  593  Loss:  0.23413542   Accuracy:  0.9296875\n",
      "Iteration:  594  Loss:  0.25563553   Accuracy:  0.9140625\n",
      "Iteration:  595  Loss:  0.39287636   Accuracy:  0.8828125\n",
      "Iteration:  596  Loss:  0.29849222   Accuracy:  0.921875\n",
      "Iteration:  597  Loss:  0.38300902   Accuracy:  0.8828125\n",
      "Iteration:  598  Loss:  0.2588128   Accuracy:  0.9140625\n",
      "Iteration:  599  Loss:  0.3909893   Accuracy:  0.875\n",
      "Iteration:  600  Loss:  0.43848825   Accuracy:  0.9140625\n",
      "Iteration:  601  Loss:  0.37792313   Accuracy:  0.90625\n",
      "Iteration:  602  Loss:  0.29709548   Accuracy:  0.9296875\n",
      "Iteration:  603  Loss:  0.27102447   Accuracy:  0.921875\n",
      "Iteration:  604  Loss:  0.31398022   Accuracy:  0.921875\n",
      "Iteration:  605  Loss:  0.24164343   Accuracy:  0.9375\n",
      "Iteration:  606  Loss:  0.34756118   Accuracy:  0.90625\n",
      "Iteration:  607  Loss:  0.27097303   Accuracy:  0.9140625\n",
      "Iteration:  608  Loss:  0.21425885   Accuracy:  0.9453125\n",
      "Iteration:  609  Loss:  0.41063315   Accuracy:  0.8984375\n",
      "Iteration:  610  Loss:  0.29141623   Accuracy:  0.9375\n",
      "Iteration:  611  Loss:  0.32380465   Accuracy:  0.890625\n",
      "Iteration:  612  Loss:  0.48061937   Accuracy:  0.8671875\n",
      "Iteration:  613  Loss:  0.1985877   Accuracy:  0.9453125\n",
      "Iteration:  614  Loss:  0.3157152   Accuracy:  0.90625\n",
      "Iteration:  615  Loss:  0.272195   Accuracy:  0.90625\n",
      "Iteration:  616  Loss:  0.4396088   Accuracy:  0.8671875\n",
      "Iteration:  617  Loss:  0.36842763   Accuracy:  0.8828125\n",
      "Iteration:  618  Loss:  0.27208567   Accuracy:  0.921875\n",
      "Iteration:  619  Loss:  0.41057545   Accuracy:  0.890625\n",
      "Iteration:  620  Loss:  0.38662523   Accuracy:  0.8828125\n",
      "Iteration:  621  Loss:  0.2960145   Accuracy:  0.90625\n",
      "Iteration:  622  Loss:  0.2665947   Accuracy:  0.921875\n",
      "Iteration:  623  Loss:  0.25774714   Accuracy:  0.921875\n",
      "Iteration:  624  Loss:  0.3354146   Accuracy:  0.890625\n",
      "Iteration:  625  Loss:  0.35895354   Accuracy:  0.875\n",
      "Iteration:  626  Loss:  0.38656217   Accuracy:  0.90625\n",
      "Iteration:  627  Loss:  0.2573182   Accuracy:  0.9140625\n",
      "Iteration:  628  Loss:  0.33998996   Accuracy:  0.875\n",
      "Iteration:  629  Loss:  0.26466805   Accuracy:  0.921875\n",
      "Iteration:  630  Loss:  0.25068223   Accuracy:  0.921875\n",
      "Iteration:  631  Loss:  0.2820041   Accuracy:  0.9296875\n",
      "Iteration:  632  Loss:  0.36378306   Accuracy:  0.921875\n",
      "Iteration:  633  Loss:  0.2894397   Accuracy:  0.8984375\n",
      "Iteration:  634  Loss:  0.47315168   Accuracy:  0.8828125\n",
      "Iteration:  635  Loss:  0.29441747   Accuracy:  0.921875\n",
      "Iteration:  636  Loss:  0.35161686   Accuracy:  0.90625\n",
      "Iteration:  637  Loss:  0.24190375   Accuracy:  0.9453125\n",
      "Iteration:  638  Loss:  0.3240851   Accuracy:  0.9140625\n",
      "Iteration:  639  Loss:  0.40497163   Accuracy:  0.90625\n",
      "Iteration:  640  Loss:  0.21044497   Accuracy:  0.953125\n",
      "Iteration:  641  Loss:  0.2793125   Accuracy:  0.9140625\n",
      "Iteration:  642  Loss:  0.22838047   Accuracy:  0.9453125\n",
      "Iteration:  643  Loss:  0.3825239   Accuracy:  0.8984375\n",
      "Iteration:  644  Loss:  0.32525066   Accuracy:  0.90625\n",
      "Iteration:  645  Loss:  0.3060133   Accuracy:  0.890625\n",
      "Iteration:  646  Loss:  0.3907212   Accuracy:  0.890625\n",
      "Iteration:  647  Loss:  0.40734735   Accuracy:  0.8984375\n",
      "Iteration:  648  Loss:  0.21165545   Accuracy:  0.953125\n",
      "Iteration:  649  Loss:  0.35847098   Accuracy:  0.921875\n",
      "Iteration:  650  Loss:  0.36079654   Accuracy:  0.9140625\n",
      "Iteration:  651  Loss:  0.21752325   Accuracy:  0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  652  Loss:  0.3378772   Accuracy:  0.9375\n",
      "Iteration:  653  Loss:  0.39568725   Accuracy:  0.90625\n",
      "Iteration:  654  Loss:  0.28920916   Accuracy:  0.921875\n",
      "Iteration:  655  Loss:  0.24798079   Accuracy:  0.921875\n",
      "Iteration:  656  Loss:  0.2824325   Accuracy:  0.9296875\n",
      "Iteration:  657  Loss:  0.3598525   Accuracy:  0.9140625\n",
      "Iteration:  658  Loss:  0.2420118   Accuracy:  0.9296875\n",
      "Iteration:  659  Loss:  0.39851916   Accuracy:  0.8671875\n",
      "Iteration:  660  Loss:  0.20162669   Accuracy:  0.9296875\n",
      "Iteration:  661  Loss:  0.36502078   Accuracy:  0.90625\n",
      "Iteration:  662  Loss:  0.31229022   Accuracy:  0.9296875\n",
      "Iteration:  663  Loss:  0.4117711   Accuracy:  0.90625\n",
      "Iteration:  664  Loss:  0.31842738   Accuracy:  0.90625\n",
      "Iteration:  665  Loss:  0.33830607   Accuracy:  0.90625\n",
      "Iteration:  666  Loss:  0.28108665   Accuracy:  0.9375\n",
      "Iteration:  667  Loss:  0.42363262   Accuracy:  0.890625\n",
      "Iteration:  668  Loss:  0.40518132   Accuracy:  0.90625\n",
      "Iteration:  669  Loss:  0.31500816   Accuracy:  0.90625\n",
      "Iteration:  670  Loss:  0.32878783   Accuracy:  0.90625\n",
      "Iteration:  671  Loss:  0.29310197   Accuracy:  0.90625\n",
      "Iteration:  672  Loss:  0.39056137   Accuracy:  0.8671875\n",
      "Iteration:  673  Loss:  0.2688551   Accuracy:  0.953125\n",
      "Iteration:  674  Loss:  0.37283826   Accuracy:  0.9140625\n",
      "Iteration:  675  Loss:  0.37479687   Accuracy:  0.90625\n",
      "Iteration:  676  Loss:  0.27115577   Accuracy:  0.921875\n",
      "Iteration:  677  Loss:  0.29955485   Accuracy:  0.9140625\n",
      "Iteration:  678  Loss:  0.3034119   Accuracy:  0.9296875\n",
      "Iteration:  679  Loss:  0.30583984   Accuracy:  0.90625\n",
      "Iteration:  680  Loss:  0.32256213   Accuracy:  0.9296875\n",
      "Iteration:  681  Loss:  0.26374853   Accuracy:  0.953125\n",
      "Iteration:  682  Loss:  0.34822327   Accuracy:  0.9140625\n",
      "Iteration:  683  Loss:  0.22055602   Accuracy:  0.9609375\n",
      "Iteration:  684  Loss:  0.25189975   Accuracy:  0.9140625\n",
      "Iteration:  685  Loss:  0.23845229   Accuracy:  0.9296875\n",
      "Iteration:  686  Loss:  0.27905166   Accuracy:  0.9140625\n",
      "Iteration:  687  Loss:  0.26476154   Accuracy:  0.9453125\n",
      "Iteration:  688  Loss:  0.391968   Accuracy:  0.8828125\n",
      "Iteration:  689  Loss:  0.3034175   Accuracy:  0.90625\n",
      "Iteration:  690  Loss:  0.3193428   Accuracy:  0.921875\n",
      "Iteration:  691  Loss:  0.3278916   Accuracy:  0.90625\n",
      "Iteration:  692  Loss:  0.43830946   Accuracy:  0.84375\n",
      "Iteration:  693  Loss:  0.2378414   Accuracy:  0.8984375\n",
      "Iteration:  694  Loss:  0.36653167   Accuracy:  0.8984375\n",
      "Iteration:  695  Loss:  0.42904595   Accuracy:  0.8828125\n",
      "Iteration:  696  Loss:  0.34868595   Accuracy:  0.9140625\n",
      "Iteration:  697  Loss:  0.4155063   Accuracy:  0.921875\n",
      "Iteration:  698  Loss:  0.26111603   Accuracy:  0.890625\n",
      "Iteration:  699  Loss:  0.21230713   Accuracy:  0.9140625\n",
      "Iteration:  700  Loss:  0.30315062   Accuracy:  0.9140625\n",
      "Iteration:  701  Loss:  0.33540788   Accuracy:  0.90625\n",
      "Iteration:  702  Loss:  0.18659995   Accuracy:  0.9453125\n",
      "Iteration:  703  Loss:  0.33125442   Accuracy:  0.8828125\n",
      "Iteration:  704  Loss:  0.31866506   Accuracy:  0.90625\n",
      "Iteration:  705  Loss:  0.30907828   Accuracy:  0.921875\n",
      "Iteration:  706  Loss:  0.24787667   Accuracy:  0.9296875\n",
      "Iteration:  707  Loss:  0.2669817   Accuracy:  0.921875\n",
      "Iteration:  708  Loss:  0.2014345   Accuracy:  0.921875\n",
      "Iteration:  709  Loss:  0.34161568   Accuracy:  0.9140625\n",
      "Iteration:  710  Loss:  0.33323407   Accuracy:  0.890625\n",
      "Iteration:  711  Loss:  0.30076134   Accuracy:  0.921875\n",
      "Iteration:  712  Loss:  0.41015896   Accuracy:  0.8515625\n",
      "Iteration:  713  Loss:  0.25860688   Accuracy:  0.9296875\n",
      "Iteration:  714  Loss:  0.26693025   Accuracy:  0.9296875\n",
      "Iteration:  715  Loss:  0.22365464   Accuracy:  0.9375\n",
      "Iteration:  716  Loss:  0.25469142   Accuracy:  0.9453125\n",
      "Iteration:  717  Loss:  0.3027858   Accuracy:  0.9296875\n",
      "Iteration:  718  Loss:  0.2097991   Accuracy:  0.953125\n",
      "Iteration:  719  Loss:  0.29110545   Accuracy:  0.921875\n",
      "Iteration:  720  Loss:  0.34196454   Accuracy:  0.9296875\n",
      "Iteration:  721  Loss:  0.28920245   Accuracy:  0.9375\n",
      "Iteration:  722  Loss:  0.3897137   Accuracy:  0.90625\n",
      "Iteration:  723  Loss:  0.32989806   Accuracy:  0.90625\n",
      "Iteration:  724  Loss:  0.24822125   Accuracy:  0.9609375\n",
      "Iteration:  725  Loss:  0.24934316   Accuracy:  0.9296875\n",
      "Iteration:  726  Loss:  0.37262672   Accuracy:  0.84375\n",
      "Iteration:  727  Loss:  0.31394136   Accuracy:  0.890625\n",
      "Iteration:  728  Loss:  0.2823019   Accuracy:  0.921875\n",
      "Iteration:  729  Loss:  0.29107773   Accuracy:  0.9140625\n",
      "Iteration:  730  Loss:  0.30778152   Accuracy:  0.875\n",
      "Iteration:  731  Loss:  0.3171503   Accuracy:  0.8828125\n",
      "Iteration:  732  Loss:  0.3462362   Accuracy:  0.890625\n",
      "Iteration:  733  Loss:  0.47091484   Accuracy:  0.859375\n",
      "Iteration:  734  Loss:  0.30036575   Accuracy:  0.90625\n",
      "Iteration:  735  Loss:  0.3148542   Accuracy:  0.8984375\n",
      "Iteration:  736  Loss:  0.33514744   Accuracy:  0.859375\n",
      "Iteration:  737  Loss:  0.39321235   Accuracy:  0.8828125\n",
      "Iteration:  738  Loss:  0.23133153   Accuracy:  0.9296875\n",
      "Iteration:  739  Loss:  0.39454293   Accuracy:  0.890625\n",
      "Iteration:  740  Loss:  0.31436667   Accuracy:  0.921875\n",
      "Iteration:  741  Loss:  0.4371335   Accuracy:  0.890625\n",
      "Iteration:  742  Loss:  0.34282362   Accuracy:  0.890625\n",
      "Iteration:  743  Loss:  0.32487208   Accuracy:  0.90625\n",
      "Iteration:  744  Loss:  0.46338597   Accuracy:  0.8515625\n",
      "Iteration:  745  Loss:  0.24877083   Accuracy:  0.9140625\n",
      "Iteration:  746  Loss:  0.38056982   Accuracy:  0.890625\n",
      "Iteration:  747  Loss:  0.28552595   Accuracy:  0.9140625\n",
      "Iteration:  748  Loss:  0.3609972   Accuracy:  0.8828125\n",
      "Iteration:  749  Loss:  0.19894901   Accuracy:  0.9375\n",
      "Iteration:  750  Loss:  0.43983746   Accuracy:  0.859375\n",
      "Iteration:  751  Loss:  0.23622805   Accuracy:  0.921875\n",
      "Iteration:  752  Loss:  0.21306819   Accuracy:  0.9453125\n",
      "Iteration:  753  Loss:  0.26204717   Accuracy:  0.9140625\n",
      "Iteration:  754  Loss:  0.42868423   Accuracy:  0.8671875\n",
      "Iteration:  755  Loss:  0.32631737   Accuracy:  0.921875\n",
      "Iteration:  756  Loss:  0.38461855   Accuracy:  0.8984375\n",
      "Iteration:  757  Loss:  0.22087082   Accuracy:  0.9453125\n",
      "Iteration:  758  Loss:  0.26155633   Accuracy:  0.9296875\n",
      "Iteration:  759  Loss:  0.41336364   Accuracy:  0.90625\n",
      "Iteration:  760  Loss:  0.40365496   Accuracy:  0.8671875\n",
      "Iteration:  761  Loss:  0.37387758   Accuracy:  0.890625\n",
      "Iteration:  762  Loss:  0.19956814   Accuracy:  0.953125\n",
      "Iteration:  763  Loss:  0.273787   Accuracy:  0.90625\n",
      "Iteration:  764  Loss:  0.23433825   Accuracy:  0.9453125\n",
      "Iteration:  765  Loss:  0.373416   Accuracy:  0.8984375\n",
      "Iteration:  766  Loss:  0.21412435   Accuracy:  0.9453125\n",
      "Iteration:  767  Loss:  0.3424863   Accuracy:  0.890625\n",
      "Iteration:  768  Loss:  0.32427964   Accuracy:  0.9140625\n",
      "Iteration:  769  Loss:  0.27160686   Accuracy:  0.9140625\n",
      "Iteration:  770  Loss:  0.21021593   Accuracy:  0.9375\n",
      "Iteration:  771  Loss:  0.3800782   Accuracy:  0.90625\n",
      "Iteration:  772  Loss:  0.30651852   Accuracy:  0.8984375\n",
      "Iteration:  773  Loss:  0.20335317   Accuracy:  0.9375\n",
      "Iteration:  774  Loss:  0.3147776   Accuracy:  0.875\n",
      "Iteration:  775  Loss:  0.22590837   Accuracy:  0.9296875\n",
      "Iteration:  776  Loss:  0.32189733   Accuracy:  0.8984375\n",
      "Iteration:  777  Loss:  0.32382914   Accuracy:  0.890625\n",
      "Iteration:  778  Loss:  0.39946872   Accuracy:  0.875\n",
      "Iteration:  779  Loss:  0.30716163   Accuracy:  0.921875\n",
      "Iteration:  780  Loss:  0.5242063   Accuracy:  0.875\n",
      "Iteration:  781  Loss:  0.34949943   Accuracy:  0.8984375\n",
      "Iteration:  782  Loss:  0.2409887   Accuracy:  0.9296875\n",
      "Iteration:  783  Loss:  0.3287029   Accuracy:  0.90625\n",
      "Iteration:  784  Loss:  0.17752802   Accuracy:  0.953125\n",
      "Iteration:  785  Loss:  0.2194237   Accuracy:  0.9375\n",
      "Iteration:  786  Loss:  0.2942845   Accuracy:  0.8984375\n",
      "Iteration:  787  Loss:  0.37911898   Accuracy:  0.8828125\n",
      "Iteration:  788  Loss:  0.34041238   Accuracy:  0.8984375\n",
      "Iteration:  789  Loss:  0.29580167   Accuracy:  0.9375\n",
      "Iteration:  790  Loss:  0.2817116   Accuracy:  0.921875\n",
      "Iteration:  791  Loss:  0.37683743   Accuracy:  0.8515625\n",
      "Iteration:  792  Loss:  0.23083206   Accuracy:  0.9296875\n",
      "Iteration:  793  Loss:  0.21511036   Accuracy:  0.9296875\n",
      "Iteration:  794  Loss:  0.31481624   Accuracy:  0.9140625\n",
      "Iteration:  795  Loss:  0.4057   Accuracy:  0.8671875\n",
      "Iteration:  796  Loss:  0.20778973   Accuracy:  0.9296875\n",
      "Iteration:  797  Loss:  0.26383725   Accuracy:  0.9453125\n",
      "Iteration:  798  Loss:  0.22470045   Accuracy:  0.9375\n",
      "Iteration:  799  Loss:  0.3065777   Accuracy:  0.90625\n",
      "Iteration:  800  Loss:  0.2448066   Accuracy:  0.9296875\n",
      "Iteration:  801  Loss:  0.23427387   Accuracy:  0.9296875\n",
      "Iteration:  802  Loss:  0.2879053   Accuracy:  0.9453125\n",
      "Iteration:  803  Loss:  0.40023994   Accuracy:  0.8828125\n",
      "Iteration:  804  Loss:  0.51328385   Accuracy:  0.8515625\n",
      "Iteration:  805  Loss:  0.28421485   Accuracy:  0.9140625\n",
      "Iteration:  806  Loss:  0.2943163   Accuracy:  0.921875\n",
      "Iteration:  807  Loss:  0.25232822   Accuracy:  0.9140625\n",
      "Iteration:  808  Loss:  0.31593508   Accuracy:  0.8984375\n",
      "Iteration:  809  Loss:  0.2644664   Accuracy:  0.921875\n",
      "Iteration:  810  Loss:  0.11840893   Accuracy:  0.9921875\n",
      "Iteration:  811  Loss:  0.22890899   Accuracy:  0.9296875\n",
      "Iteration:  812  Loss:  0.36357158   Accuracy:  0.90625\n",
      "Iteration:  813  Loss:  0.22529541   Accuracy:  0.9453125\n",
      "Iteration:  814  Loss:  0.2418896   Accuracy:  0.9375\n",
      "Iteration:  815  Loss:  0.32461333   Accuracy:  0.8984375\n",
      "Iteration:  816  Loss:  0.20037657   Accuracy:  0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  817  Loss:  0.2906569   Accuracy:  0.9140625\n",
      "Iteration:  818  Loss:  0.2591138   Accuracy:  0.9140625\n",
      "Iteration:  819  Loss:  0.14507103   Accuracy:  0.953125\n",
      "Iteration:  820  Loss:  0.30561328   Accuracy:  0.9296875\n",
      "Iteration:  821  Loss:  0.31764463   Accuracy:  0.9296875\n",
      "Iteration:  822  Loss:  0.23830073   Accuracy:  0.9296875\n",
      "Iteration:  823  Loss:  0.27823326   Accuracy:  0.921875\n",
      "Iteration:  824  Loss:  0.32316566   Accuracy:  0.8984375\n",
      "Iteration:  825  Loss:  0.2722082   Accuracy:  0.90625\n",
      "Iteration:  826  Loss:  0.2644853   Accuracy:  0.90625\n",
      "Iteration:  827  Loss:  0.3239435   Accuracy:  0.890625\n",
      "Iteration:  828  Loss:  0.18212603   Accuracy:  0.953125\n",
      "Iteration:  829  Loss:  0.39131215   Accuracy:  0.921875\n",
      "Iteration:  830  Loss:  0.43495527   Accuracy:  0.890625\n",
      "Iteration:  831  Loss:  0.3542686   Accuracy:  0.90625\n",
      "Iteration:  832  Loss:  0.21568058   Accuracy:  0.953125\n",
      "Iteration:  833  Loss:  0.36059192   Accuracy:  0.875\n",
      "Iteration:  834  Loss:  0.3889734   Accuracy:  0.8984375\n",
      "Iteration:  835  Loss:  0.16126075   Accuracy:  0.9609375\n",
      "Iteration:  836  Loss:  0.46501175   Accuracy:  0.890625\n",
      "Iteration:  837  Loss:  0.3601738   Accuracy:  0.8984375\n",
      "Iteration:  838  Loss:  0.23549876   Accuracy:  0.9140625\n",
      "Iteration:  839  Loss:  0.46345353   Accuracy:  0.84375\n",
      "Iteration:  840  Loss:  0.25643033   Accuracy:  0.9453125\n",
      "Iteration:  841  Loss:  0.3748359   Accuracy:  0.890625\n",
      "Iteration:  842  Loss:  0.2589857   Accuracy:  0.9375\n",
      "Iteration:  843  Loss:  0.2089743   Accuracy:  0.9296875\n",
      "Iteration:  844  Loss:  0.28951988   Accuracy:  0.890625\n",
      "Iteration:  845  Loss:  0.23707683   Accuracy:  0.9375\n",
      "Iteration:  846  Loss:  0.22442839   Accuracy:  0.9296875\n",
      "Iteration:  847  Loss:  0.29894683   Accuracy:  0.9375\n",
      "Iteration:  848  Loss:  0.2817643   Accuracy:  0.9140625\n",
      "Iteration:  849  Loss:  0.4233472   Accuracy:  0.8671875\n",
      "Iteration:  850  Loss:  0.36586648   Accuracy:  0.8671875\n",
      "Iteration:  851  Loss:  0.35748053   Accuracy:  0.890625\n",
      "Iteration:  852  Loss:  0.16742241   Accuracy:  0.9765625\n",
      "Iteration:  853  Loss:  0.30463022   Accuracy:  0.9140625\n",
      "Iteration:  854  Loss:  0.391401   Accuracy:  0.8515625\n",
      "Iteration:  855  Loss:  0.32120746   Accuracy:  0.8984375\n",
      "Iteration:  856  Loss:  0.23035097   Accuracy:  0.9375\n",
      "Iteration:  857  Loss:  0.3288926   Accuracy:  0.890625\n",
      "Iteration:  858  Loss:  0.27637145   Accuracy:  0.921875\n",
      "Iteration:  859  Loss:  0.2929424   Accuracy:  0.9375\n",
      "Iteration:  860  Loss:  0.25879973   Accuracy:  0.9140625\n",
      "Iteration:  861  Loss:  0.43688685   Accuracy:  0.8984375\n",
      "Iteration:  862  Loss:  0.36583087   Accuracy:  0.8828125\n",
      "Iteration:  863  Loss:  0.38096416   Accuracy:  0.921875\n",
      "Iteration:  864  Loss:  0.30032995   Accuracy:  0.9375\n",
      "Iteration:  865  Loss:  0.2384151   Accuracy:  0.9375\n",
      "Iteration:  866  Loss:  0.3158902   Accuracy:  0.9140625\n",
      "Iteration:  867  Loss:  0.38537216   Accuracy:  0.9140625\n",
      "Iteration:  868  Loss:  0.27597955   Accuracy:  0.9140625\n",
      "Iteration:  869  Loss:  0.38649276   Accuracy:  0.8984375\n",
      "Iteration:  870  Loss:  0.3082366   Accuracy:  0.890625\n",
      "Iteration:  871  Loss:  0.43005222   Accuracy:  0.875\n",
      "Iteration:  872  Loss:  0.34765434   Accuracy:  0.8984375\n",
      "Iteration:  873  Loss:  0.36751217   Accuracy:  0.8984375\n",
      "Iteration:  874  Loss:  0.28298166   Accuracy:  0.8984375\n",
      "Iteration:  875  Loss:  0.24078552   Accuracy:  0.921875\n",
      "Iteration:  876  Loss:  0.30369037   Accuracy:  0.859375\n",
      "Iteration:  877  Loss:  0.2625175   Accuracy:  0.921875\n",
      "Iteration:  878  Loss:  0.2987523   Accuracy:  0.890625\n",
      "Iteration:  879  Loss:  0.2827616   Accuracy:  0.9140625\n",
      "Iteration:  880  Loss:  0.23651871   Accuracy:  0.921875\n",
      "Iteration:  881  Loss:  0.3296501   Accuracy:  0.921875\n",
      "Iteration:  882  Loss:  0.30261102   Accuracy:  0.90625\n",
      "Iteration:  883  Loss:  0.3181163   Accuracy:  0.90625\n",
      "Iteration:  884  Loss:  0.2735315   Accuracy:  0.90625\n",
      "Iteration:  885  Loss:  0.4267211   Accuracy:  0.8984375\n",
      "Iteration:  886  Loss:  0.36410064   Accuracy:  0.8984375\n",
      "Iteration:  887  Loss:  0.28345582   Accuracy:  0.8984375\n",
      "Iteration:  888  Loss:  0.29682076   Accuracy:  0.90625\n",
      "Iteration:  889  Loss:  0.32308194   Accuracy:  0.890625\n",
      "Iteration:  890  Loss:  0.2595312   Accuracy:  0.9375\n",
      "Iteration:  891  Loss:  0.33156508   Accuracy:  0.90625\n",
      "Iteration:  892  Loss:  0.43703917   Accuracy:  0.875\n",
      "Iteration:  893  Loss:  0.28842056   Accuracy:  0.9140625\n",
      "Iteration:  894  Loss:  0.26367503   Accuracy:  0.9140625\n",
      "Iteration:  895  Loss:  0.3697071   Accuracy:  0.921875\n",
      "Iteration:  896  Loss:  0.26399362   Accuracy:  0.9296875\n",
      "Iteration:  897  Loss:  0.30992293   Accuracy:  0.8828125\n",
      "Iteration:  898  Loss:  0.17888819   Accuracy:  0.953125\n",
      "Iteration:  899  Loss:  0.29676569   Accuracy:  0.9296875\n",
      "Iteration:  900  Loss:  0.44034666   Accuracy:  0.8984375\n",
      "Iteration:  901  Loss:  0.33898968   Accuracy:  0.8828125\n",
      "Iteration:  902  Loss:  0.36710447   Accuracy:  0.890625\n",
      "Iteration:  903  Loss:  0.22122107   Accuracy:  0.9296875\n",
      "Iteration:  904  Loss:  0.38141817   Accuracy:  0.890625\n",
      "Iteration:  905  Loss:  0.27436167   Accuracy:  0.890625\n",
      "Iteration:  906  Loss:  0.36880752   Accuracy:  0.8671875\n",
      "Iteration:  907  Loss:  0.29757375   Accuracy:  0.9140625\n",
      "Iteration:  908  Loss:  0.25233844   Accuracy:  0.921875\n",
      "Iteration:  909  Loss:  0.2970531   Accuracy:  0.9140625\n",
      "Iteration:  910  Loss:  0.32618433   Accuracy:  0.9140625\n",
      "Iteration:  911  Loss:  0.1568465   Accuracy:  0.9609375\n",
      "Iteration:  912  Loss:  0.26188946   Accuracy:  0.9140625\n",
      "Iteration:  913  Loss:  0.2437334   Accuracy:  0.9453125\n",
      "Iteration:  914  Loss:  0.27772623   Accuracy:  0.9296875\n",
      "Iteration:  915  Loss:  0.25463152   Accuracy:  0.921875\n",
      "Iteration:  916  Loss:  0.33039743   Accuracy:  0.8984375\n",
      "Iteration:  917  Loss:  0.33119777   Accuracy:  0.921875\n",
      "Iteration:  918  Loss:  0.3427708   Accuracy:  0.890625\n",
      "Iteration:  919  Loss:  0.21281093   Accuracy:  0.9375\n",
      "Iteration:  920  Loss:  0.26008898   Accuracy:  0.9296875\n",
      "Iteration:  921  Loss:  0.3102989   Accuracy:  0.9140625\n",
      "Iteration:  922  Loss:  0.24421667   Accuracy:  0.9296875\n",
      "Iteration:  923  Loss:  0.21721253   Accuracy:  0.9375\n",
      "Iteration:  924  Loss:  0.3612005   Accuracy:  0.90625\n",
      "Iteration:  925  Loss:  0.45290267   Accuracy:  0.8828125\n",
      "Iteration:  926  Loss:  0.27092633   Accuracy:  0.9375\n",
      "Iteration:  927  Loss:  0.22798999   Accuracy:  0.9453125\n",
      "Iteration:  928  Loss:  0.1702123   Accuracy:  0.9609375\n",
      "Iteration:  929  Loss:  0.19333515   Accuracy:  0.9609375\n",
      "Iteration:  930  Loss:  0.30187964   Accuracy:  0.921875\n",
      "Iteration:  931  Loss:  0.2553452   Accuracy:  0.9296875\n",
      "Iteration:  932  Loss:  0.3909644   Accuracy:  0.9140625\n",
      "Iteration:  933  Loss:  0.37480205   Accuracy:  0.90625\n",
      "Iteration:  934  Loss:  0.21304643   Accuracy:  0.9453125\n",
      "Iteration:  935  Loss:  0.3888656   Accuracy:  0.8515625\n",
      "Iteration:  936  Loss:  0.25044283   Accuracy:  0.921875\n",
      "Iteration:  937  Loss:  0.20042108   Accuracy:  0.921875\n",
      "Iteration:  938  Loss:  0.43963742   Accuracy:  0.859375\n",
      "Iteration:  939  Loss:  0.41217595   Accuracy:  0.8984375\n",
      "Iteration:  940  Loss:  0.31633344   Accuracy:  0.90625\n",
      "Iteration:  941  Loss:  0.2979091   Accuracy:  0.875\n",
      "Iteration:  942  Loss:  0.22880274   Accuracy:  0.921875\n",
      "Iteration:  943  Loss:  0.19512115   Accuracy:  0.9296875\n",
      "Iteration:  944  Loss:  0.3969136   Accuracy:  0.875\n",
      "Iteration:  945  Loss:  0.22893739   Accuracy:  0.9375\n",
      "Iteration:  946  Loss:  0.33784968   Accuracy:  0.90625\n",
      "Iteration:  947  Loss:  0.30581594   Accuracy:  0.890625\n",
      "Iteration:  948  Loss:  0.25162974   Accuracy:  0.9140625\n",
      "Iteration:  949  Loss:  0.30421525   Accuracy:  0.8984375\n",
      "Iteration:  950  Loss:  0.4703958   Accuracy:  0.890625\n",
      "Iteration:  951  Loss:  0.2735265   Accuracy:  0.9140625\n",
      "Iteration:  952  Loss:  0.26649055   Accuracy:  0.9140625\n",
      "Iteration:  953  Loss:  0.3475789   Accuracy:  0.9296875\n",
      "Iteration:  954  Loss:  0.28310752   Accuracy:  0.9375\n",
      "Iteration:  955  Loss:  0.27367243   Accuracy:  0.9140625\n",
      "Iteration:  956  Loss:  0.3461129   Accuracy:  0.9140625\n",
      "Iteration:  957  Loss:  0.26904556   Accuracy:  0.90625\n",
      "Iteration:  958  Loss:  0.34877995   Accuracy:  0.921875\n",
      "Iteration:  959  Loss:  0.25121418   Accuracy:  0.9453125\n",
      "Iteration:  960  Loss:  0.26227924   Accuracy:  0.90625\n",
      "Iteration:  961  Loss:  0.41918138   Accuracy:  0.8828125\n",
      "Iteration:  962  Loss:  0.25927335   Accuracy:  0.9453125\n",
      "Iteration:  963  Loss:  0.4164744   Accuracy:  0.8984375\n",
      "Iteration:  964  Loss:  0.3610134   Accuracy:  0.8828125\n",
      "Iteration:  965  Loss:  0.33989307   Accuracy:  0.90625\n",
      "Iteration:  966  Loss:  0.3295978   Accuracy:  0.921875\n",
      "Iteration:  967  Loss:  0.40690646   Accuracy:  0.90625\n",
      "Iteration:  968  Loss:  0.22019698   Accuracy:  0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  969  Loss:  0.26180616   Accuracy:  0.921875\n",
      "Iteration:  970  Loss:  0.34104335   Accuracy:  0.8984375\n",
      "Iteration:  971  Loss:  0.29711443   Accuracy:  0.8984375\n",
      "Iteration:  972  Loss:  0.28467193   Accuracy:  0.9140625\n",
      "Iteration:  973  Loss:  0.5006255   Accuracy:  0.8984375\n",
      "Iteration:  974  Loss:  0.22896403   Accuracy:  0.9296875\n",
      "Iteration:  975  Loss:  0.2524693   Accuracy:  0.9296875\n",
      "Iteration:  976  Loss:  0.26870114   Accuracy:  0.921875\n",
      "Iteration:  977  Loss:  0.38973078   Accuracy:  0.8984375\n",
      "Iteration:  978  Loss:  0.1449737   Accuracy:  0.9765625\n",
      "Iteration:  979  Loss:  0.32861048   Accuracy:  0.875\n",
      "Iteration:  980  Loss:  0.37184823   Accuracy:  0.8984375\n",
      "Iteration:  981  Loss:  0.33460537   Accuracy:  0.8828125\n",
      "Iteration:  982  Loss:  0.25296032   Accuracy:  0.9375\n",
      "Iteration:  983  Loss:  0.34107995   Accuracy:  0.875\n",
      "Iteration:  984  Loss:  0.36126196   Accuracy:  0.875\n",
      "Iteration:  985  Loss:  0.21732715   Accuracy:  0.9375\n",
      "Iteration:  986  Loss:  0.2945735   Accuracy:  0.9140625\n",
      "Iteration:  987  Loss:  0.26875645   Accuracy:  0.9140625\n",
      "Iteration:  988  Loss:  0.39535403   Accuracy:  0.8828125\n",
      "Iteration:  989  Loss:  0.3808047   Accuracy:  0.90625\n",
      "Iteration:  990  Loss:  0.2770701   Accuracy:  0.9296875\n",
      "Iteration:  991  Loss:  0.34371263   Accuracy:  0.8984375\n",
      "Iteration:  992  Loss:  0.31685022   Accuracy:  0.9140625\n",
      "Iteration:  993  Loss:  0.32316434   Accuracy:  0.921875\n",
      "Iteration:  994  Loss:  0.38221002   Accuracy:  0.890625\n",
      "Iteration:  995  Loss:  0.2264415   Accuracy:  0.90625\n",
      "Iteration:  996  Loss:  0.2777179   Accuracy:  0.9375\n",
      "Iteration:  997  Loss:  0.39567786   Accuracy:  0.8984375\n",
      "Iteration:  998  Loss:  0.357829   Accuracy:  0.90625\n",
      "Iteration:  999  Loss:  0.2092141   Accuracy:  0.921875\n",
      "Iteration:  1000  Loss:  0.4698348   Accuracy:  0.859375\n",
      "Iteration:  1001  Loss:  0.22725709   Accuracy:  0.90625\n",
      "Iteration:  1002  Loss:  0.20123535   Accuracy:  0.921875\n",
      "Iteration:  1003  Loss:  0.42454502   Accuracy:  0.859375\n",
      "Iteration:  1004  Loss:  0.36635754   Accuracy:  0.8984375\n",
      "Iteration:  1005  Loss:  0.2810468   Accuracy:  0.921875\n",
      "Iteration:  1006  Loss:  0.30069622   Accuracy:  0.8984375\n",
      "Iteration:  1007  Loss:  0.3090014   Accuracy:  0.9375\n",
      "Iteration:  1008  Loss:  0.20655088   Accuracy:  0.9296875\n",
      "Iteration:  1009  Loss:  0.388097   Accuracy:  0.8984375\n",
      "Iteration:  1010  Loss:  0.4370914   Accuracy:  0.8515625\n",
      "Iteration:  1011  Loss:  0.38440868   Accuracy:  0.875\n",
      "Iteration:  1012  Loss:  0.20346108   Accuracy:  0.953125\n",
      "Iteration:  1013  Loss:  0.39554602   Accuracy:  0.8828125\n",
      "Iteration:  1014  Loss:  0.31439632   Accuracy:  0.90625\n",
      "Iteration:  1015  Loss:  0.29514974   Accuracy:  0.921875\n",
      "Iteration:  1016  Loss:  0.25761032   Accuracy:  0.9453125\n",
      "Iteration:  1017  Loss:  0.2989505   Accuracy:  0.9140625\n",
      "Iteration:  1018  Loss:  0.43981427   Accuracy:  0.8984375\n",
      "Iteration:  1019  Loss:  0.17750978   Accuracy:  0.9453125\n",
      "Iteration:  1020  Loss:  0.31125343   Accuracy:  0.9296875\n",
      "Iteration:  1021  Loss:  0.40985867   Accuracy:  0.84375\n",
      "Iteration:  1022  Loss:  0.29225534   Accuracy:  0.90625\n",
      "Iteration:  1023  Loss:  0.22809255   Accuracy:  0.9453125\n",
      "Iteration:  1024  Loss:  0.2946693   Accuracy:  0.921875\n",
      "Iteration:  1025  Loss:  0.245546   Accuracy:  0.9140625\n",
      "Iteration:  1026  Loss:  0.3999074   Accuracy:  0.90625\n",
      "Iteration:  1027  Loss:  0.41196218   Accuracy:  0.859375\n",
      "Iteration:  1028  Loss:  0.33165514   Accuracy:  0.90625\n",
      "Iteration:  1029  Loss:  0.38991666   Accuracy:  0.875\n",
      "Iteration:  1030  Loss:  0.31386662   Accuracy:  0.9140625\n",
      "Iteration:  1031  Loss:  0.30585992   Accuracy:  0.890625\n",
      "Iteration:  1032  Loss:  0.35585764   Accuracy:  0.8984375\n",
      "Iteration:  1033  Loss:  0.3800496   Accuracy:  0.8828125\n",
      "Iteration:  1034  Loss:  0.2392738   Accuracy:  0.9296875\n",
      "Iteration:  1035  Loss:  0.25298157   Accuracy:  0.9453125\n",
      "Iteration:  1036  Loss:  0.23781145   Accuracy:  0.9296875\n",
      "Iteration:  1037  Loss:  0.273412   Accuracy:  0.9140625\n",
      "Iteration:  1038  Loss:  0.3020722   Accuracy:  0.921875\n",
      "Iteration:  1039  Loss:  0.30554065   Accuracy:  0.90625\n",
      "Iteration:  1040  Loss:  0.28471756   Accuracy:  0.8984375\n",
      "Iteration:  1041  Loss:  0.335454   Accuracy:  0.8828125\n",
      "Iteration:  1042  Loss:  0.28558075   Accuracy:  0.9140625\n",
      "Iteration:  1043  Loss:  0.40666375   Accuracy:  0.9296875\n",
      "Iteration:  1044  Loss:  0.35157058   Accuracy:  0.890625\n",
      "Iteration:  1045  Loss:  0.2842232   Accuracy:  0.9296875\n",
      "Iteration:  1046  Loss:  0.28514928   Accuracy:  0.9296875\n",
      "Iteration:  1047  Loss:  0.28036982   Accuracy:  0.953125\n",
      "Iteration:  1048  Loss:  0.21707037   Accuracy:  0.9453125\n",
      "Iteration:  1049  Loss:  0.27668566   Accuracy:  0.921875\n",
      "Iteration:  1050  Loss:  0.2711987   Accuracy:  0.921875\n",
      "Iteration:  1051  Loss:  0.24773687   Accuracy:  0.9296875\n",
      "Iteration:  1052  Loss:  0.41522825   Accuracy:  0.875\n",
      "Iteration:  1053  Loss:  0.24952596   Accuracy:  0.9453125\n",
      "Iteration:  1054  Loss:  0.24556649   Accuracy:  0.9375\n",
      "Iteration:  1055  Loss:  0.32139292   Accuracy:  0.9140625\n",
      "Iteration:  1056  Loss:  0.28207034   Accuracy:  0.9296875\n",
      "Iteration:  1057  Loss:  0.39258066   Accuracy:  0.875\n",
      "Iteration:  1058  Loss:  0.24819478   Accuracy:  0.9375\n",
      "Iteration:  1059  Loss:  0.33410528   Accuracy:  0.890625\n",
      "Iteration:  1060  Loss:  0.3157908   Accuracy:  0.9140625\n",
      "Iteration:  1061  Loss:  0.2673888   Accuracy:  0.9296875\n",
      "Iteration:  1062  Loss:  0.3765128   Accuracy:  0.8984375\n",
      "Iteration:  1063  Loss:  0.22780871   Accuracy:  0.9140625\n",
      "Iteration:  1064  Loss:  0.2410321   Accuracy:  0.9140625\n",
      "Iteration:  1065  Loss:  0.3412571   Accuracy:  0.9140625\n",
      "Iteration:  1066  Loss:  0.3426259   Accuracy:  0.90625\n",
      "Iteration:  1067  Loss:  0.42434818   Accuracy:  0.890625\n",
      "Iteration:  1068  Loss:  0.26592875   Accuracy:  0.9453125\n",
      "Iteration:  1069  Loss:  0.15544198   Accuracy:  0.9375\n",
      "Iteration:  1070  Loss:  0.34587255   Accuracy:  0.9296875\n",
      "Iteration:  1071  Loss:  0.21377666   Accuracy:  0.9375\n",
      "Iteration:  1072  Loss:  0.25412214   Accuracy:  0.9296875\n",
      "Iteration:  1073  Loss:  0.35787812   Accuracy:  0.890625\n",
      "Iteration:  1074  Loss:  0.320462   Accuracy:  0.921875\n",
      "Iteration:  1075  Loss:  0.2855459   Accuracy:  0.890625\n",
      "Iteration:  1076  Loss:  0.3151189   Accuracy:  0.8984375\n",
      "Iteration:  1077  Loss:  0.34530994   Accuracy:  0.8828125\n",
      "Iteration:  1078  Loss:  0.22342126   Accuracy:  0.9453125\n",
      "Iteration:  1079  Loss:  0.20501183   Accuracy:  0.9296875\n",
      "Iteration:  1080  Loss:  0.26794714   Accuracy:  0.9140625\n",
      "Iteration:  1081  Loss:  0.28085685   Accuracy:  0.90625\n",
      "Iteration:  1082  Loss:  0.33974612   Accuracy:  0.9140625\n",
      "Iteration:  1083  Loss:  0.24854583   Accuracy:  0.953125\n",
      "Iteration:  1084  Loss:  0.14420044   Accuracy:  0.96875\n",
      "Iteration:  1085  Loss:  0.23710522   Accuracy:  0.8984375\n",
      "Iteration:  1086  Loss:  0.26546392   Accuracy:  0.9453125\n",
      "Iteration:  1087  Loss:  0.38215268   Accuracy:  0.9140625\n",
      "Iteration:  1088  Loss:  0.34661207   Accuracy:  0.9296875\n",
      "Iteration:  1089  Loss:  0.41712543   Accuracy:  0.90625\n",
      "Iteration:  1090  Loss:  0.32113254   Accuracy:  0.8984375\n",
      "Iteration:  1091  Loss:  0.29312742   Accuracy:  0.9296875\n",
      "Iteration:  1092  Loss:  0.32127526   Accuracy:  0.921875\n",
      "Iteration:  1093  Loss:  0.28740388   Accuracy:  0.9296875\n",
      "Iteration:  1094  Loss:  0.23996362   Accuracy:  0.90625\n",
      "Iteration:  1095  Loss:  0.31160462   Accuracy:  0.90625\n",
      "Iteration:  1096  Loss:  0.34181133   Accuracy:  0.8984375\n",
      "Iteration:  1097  Loss:  0.16061905   Accuracy:  0.9609375\n",
      "Iteration:  1098  Loss:  0.22564101   Accuracy:  0.9296875\n",
      "Iteration:  1099  Loss:  0.42221045   Accuracy:  0.875\n",
      "Iteration:  1100  Loss:  0.28263137   Accuracy:  0.9375\n",
      "Iteration:  1101  Loss:  0.4496118   Accuracy:  0.8515625\n",
      "Iteration:  1102  Loss:  0.32669026   Accuracy:  0.9296875\n",
      "Iteration:  1103  Loss:  0.28552973   Accuracy:  0.9296875\n",
      "Iteration:  1104  Loss:  0.1559897   Accuracy:  0.9609375\n",
      "Iteration:  1105  Loss:  0.27332184   Accuracy:  0.921875\n",
      "Iteration:  1106  Loss:  0.28906304   Accuracy:  0.8984375\n",
      "Iteration:  1107  Loss:  0.27997488   Accuracy:  0.9140625\n",
      "Iteration:  1108  Loss:  0.28492013   Accuracy:  0.9375\n",
      "Iteration:  1109  Loss:  0.270661   Accuracy:  0.9140625\n",
      "Iteration:  1110  Loss:  0.22517522   Accuracy:  0.9375\n",
      "Iteration:  1111  Loss:  0.3004022   Accuracy:  0.921875\n",
      "Iteration:  1112  Loss:  0.27456993   Accuracy:  0.921875\n",
      "Iteration:  1113  Loss:  0.29859656   Accuracy:  0.9296875\n",
      "Iteration:  1114  Loss:  0.17679319   Accuracy:  0.9453125\n",
      "Iteration:  1115  Loss:  0.29754537   Accuracy:  0.90625\n",
      "Iteration:  1116  Loss:  0.30385777   Accuracy:  0.90625\n",
      "Iteration:  1117  Loss:  0.36506844   Accuracy:  0.890625\n",
      "Iteration:  1118  Loss:  0.23825625   Accuracy:  0.9453125\n",
      "Iteration:  1119  Loss:  0.31350738   Accuracy:  0.90625\n",
      "Iteration:  1120  Loss:  0.20893377   Accuracy:  0.921875\n",
      "Iteration:  1121  Loss:  0.23284766   Accuracy:  0.9453125\n",
      "Iteration:  1122  Loss:  0.327082   Accuracy:  0.8828125\n",
      "Iteration:  1123  Loss:  0.28279445   Accuracy:  0.921875\n",
      "Iteration:  1124  Loss:  0.36053082   Accuracy:  0.8984375\n",
      "Iteration:  1125  Loss:  0.16320588   Accuracy:  0.953125\n",
      "Iteration:  1126  Loss:  0.41353565   Accuracy:  0.8984375\n",
      "Iteration:  1127  Loss:  0.25621092   Accuracy:  0.9140625\n",
      "Iteration:  1128  Loss:  0.22214481   Accuracy:  0.953125\n",
      "Iteration:  1129  Loss:  0.38078004   Accuracy:  0.9296875\n",
      "Iteration:  1130  Loss:  0.33108184   Accuracy:  0.90625\n",
      "Iteration:  1131  Loss:  0.37329316   Accuracy:  0.8671875\n",
      "Iteration:  1132  Loss:  0.25211146   Accuracy:  0.9140625\n",
      "Iteration:  1133  Loss:  0.350481   Accuracy:  0.8515625\n",
      "Iteration:  1134  Loss:  0.2843101   Accuracy:  0.953125\n",
      "Iteration:  1135  Loss:  0.3444302   Accuracy:  0.90625\n",
      "Iteration:  1136  Loss:  0.3666594   Accuracy:  0.8984375\n",
      "Iteration:  1137  Loss:  0.41394123   Accuracy:  0.9140625\n",
      "Iteration:  1138  Loss:  0.30035406   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1139  Loss:  0.35780442   Accuracy:  0.8984375\n",
      "Iteration:  1140  Loss:  0.2147528   Accuracy:  0.9375\n",
      "Iteration:  1141  Loss:  0.35599378   Accuracy:  0.90625\n",
      "Iteration:  1142  Loss:  0.30347252   Accuracy:  0.8984375\n",
      "Iteration:  1143  Loss:  0.2590252   Accuracy:  0.90625\n",
      "Iteration:  1144  Loss:  0.30979487   Accuracy:  0.9296875\n",
      "Iteration:  1145  Loss:  0.2625303   Accuracy:  0.9140625\n",
      "Iteration:  1146  Loss:  0.34318596   Accuracy:  0.8828125\n",
      "Iteration:  1147  Loss:  0.3662266   Accuracy:  0.921875\n",
      "Iteration:  1148  Loss:  0.35531193   Accuracy:  0.8984375\n",
      "Iteration:  1149  Loss:  0.2921875   Accuracy:  0.953125\n",
      "Iteration:  1150  Loss:  0.31537297   Accuracy:  0.9140625\n",
      "Iteration:  1151  Loss:  0.17133607   Accuracy:  0.9609375\n",
      "Iteration:  1152  Loss:  0.25201514   Accuracy:  0.9296875\n",
      "Iteration:  1153  Loss:  0.3154147   Accuracy:  0.890625\n",
      "Iteration:  1154  Loss:  0.29668257   Accuracy:  0.90625\n",
      "Iteration:  1155  Loss:  0.32660428   Accuracy:  0.8828125\n",
      "Iteration:  1156  Loss:  0.18007046   Accuracy:  0.9453125\n",
      "Iteration:  1157  Loss:  0.33524004   Accuracy:  0.921875\n",
      "Iteration:  1158  Loss:  0.18140772   Accuracy:  0.9375\n",
      "Iteration:  1159  Loss:  0.29445553   Accuracy:  0.9140625\n",
      "Iteration:  1160  Loss:  0.2658915   Accuracy:  0.90625\n",
      "Iteration:  1161  Loss:  0.4422053   Accuracy:  0.859375\n",
      "Iteration:  1162  Loss:  0.3782854   Accuracy:  0.8828125\n",
      "Iteration:  1163  Loss:  0.2746725   Accuracy:  0.9296875\n",
      "Iteration:  1164  Loss:  0.31683716   Accuracy:  0.9140625\n",
      "Iteration:  1165  Loss:  0.4547543   Accuracy:  0.875\n",
      "Iteration:  1166  Loss:  0.19702934   Accuracy:  0.953125\n",
      "Iteration:  1167  Loss:  0.2564059   Accuracy:  0.9296875\n",
      "Iteration:  1168  Loss:  0.34866282   Accuracy:  0.8984375\n",
      "Iteration:  1169  Loss:  0.31382352   Accuracy:  0.9296875\n",
      "Iteration:  1170  Loss:  0.38591546   Accuracy:  0.8984375\n",
      "Iteration:  1171  Loss:  0.22791682   Accuracy:  0.9296875\n",
      "Iteration:  1172  Loss:  0.29473168   Accuracy:  0.9140625\n",
      "Iteration:  1173  Loss:  0.3146565   Accuracy:  0.9140625\n",
      "Iteration:  1174  Loss:  0.29164624   Accuracy:  0.90625\n",
      "Iteration:  1175  Loss:  0.361611   Accuracy:  0.9296875\n",
      "Iteration:  1176  Loss:  0.24031694   Accuracy:  0.9296875\n",
      "Iteration:  1177  Loss:  0.2111505   Accuracy:  0.9296875\n",
      "Iteration:  1178  Loss:  0.29301298   Accuracy:  0.921875\n",
      "Iteration:  1179  Loss:  0.23173818   Accuracy:  0.890625\n",
      "Iteration:  1180  Loss:  0.37172556   Accuracy:  0.875\n",
      "Iteration:  1181  Loss:  0.35761827   Accuracy:  0.8984375\n",
      "Iteration:  1182  Loss:  0.1828581   Accuracy:  0.9375\n",
      "Iteration:  1183  Loss:  0.2555698   Accuracy:  0.953125\n",
      "Iteration:  1184  Loss:  0.15788269   Accuracy:  0.96875\n",
      "Iteration:  1185  Loss:  0.28897867   Accuracy:  0.9140625\n",
      "Iteration:  1186  Loss:  0.15134089   Accuracy:  0.96875\n",
      "Iteration:  1187  Loss:  0.18329246   Accuracy:  0.96875\n",
      "Iteration:  1188  Loss:  0.31267   Accuracy:  0.90625\n",
      "Iteration:  1189  Loss:  0.4088897   Accuracy:  0.8828125\n",
      "Iteration:  1190  Loss:  0.21321902   Accuracy:  0.9453125\n",
      "Iteration:  1191  Loss:  0.23035324   Accuracy:  0.90625\n",
      "Iteration:  1192  Loss:  0.22945298   Accuracy:  0.9140625\n",
      "Iteration:  1193  Loss:  0.37437853   Accuracy:  0.9140625\n",
      "Iteration:  1194  Loss:  0.2663636   Accuracy:  0.9140625\n",
      "Iteration:  1195  Loss:  0.22862235   Accuracy:  0.9296875\n",
      "Iteration:  1196  Loss:  0.2996348   Accuracy:  0.921875\n",
      "Iteration:  1197  Loss:  0.18395159   Accuracy:  0.96875\n",
      "Iteration:  1198  Loss:  0.30068374   Accuracy:  0.9609375\n",
      "Iteration:  1199  Loss:  0.18810809   Accuracy:  0.9453125\n",
      "Iteration:  1200  Loss:  0.3359276   Accuracy:  0.90625\n",
      "Iteration:  1201  Loss:  0.34460682   Accuracy:  0.9140625\n",
      "Iteration:  1202  Loss:  0.20815343   Accuracy:  0.9453125\n",
      "Iteration:  1203  Loss:  0.25382513   Accuracy:  0.90625\n",
      "Iteration:  1204  Loss:  0.33100218   Accuracy:  0.9296875\n",
      "Iteration:  1205  Loss:  0.31279796   Accuracy:  0.890625\n",
      "Iteration:  1206  Loss:  0.24481076   Accuracy:  0.9375\n",
      "Iteration:  1207  Loss:  0.1604519   Accuracy:  0.96875\n",
      "Iteration:  1208  Loss:  0.3211146   Accuracy:  0.875\n",
      "Iteration:  1209  Loss:  0.23509233   Accuracy:  0.9296875\n",
      "Iteration:  1210  Loss:  0.2856502   Accuracy:  0.9140625\n",
      "Iteration:  1211  Loss:  0.20359953   Accuracy:  0.9296875\n",
      "Iteration:  1212  Loss:  0.22470184   Accuracy:  0.953125\n",
      "Iteration:  1213  Loss:  0.5640316   Accuracy:  0.8203125\n",
      "Iteration:  1214  Loss:  0.32769114   Accuracy:  0.890625\n",
      "Iteration:  1215  Loss:  0.34714365   Accuracy:  0.8984375\n",
      "Iteration:  1216  Loss:  0.25693667   Accuracy:  0.9140625\n",
      "Iteration:  1217  Loss:  0.25797024   Accuracy:  0.9296875\n",
      "Iteration:  1218  Loss:  0.16543876   Accuracy:  0.9453125\n",
      "Iteration:  1219  Loss:  0.37292275   Accuracy:  0.90625\n",
      "Iteration:  1220  Loss:  0.3276219   Accuracy:  0.9375\n",
      "Iteration:  1221  Loss:  0.4126493   Accuracy:  0.890625\n",
      "Iteration:  1222  Loss:  0.2515837   Accuracy:  0.9296875\n",
      "Iteration:  1223  Loss:  0.37330404   Accuracy:  0.890625\n",
      "Iteration:  1224  Loss:  0.18551026   Accuracy:  0.9453125\n",
      "Iteration:  1225  Loss:  0.27668503   Accuracy:  0.8828125\n",
      "Iteration:  1226  Loss:  0.21432918   Accuracy:  0.9453125\n",
      "Iteration:  1227  Loss:  0.29557687   Accuracy:  0.921875\n",
      "Iteration:  1228  Loss:  0.24487445   Accuracy:  0.9140625\n",
      "Iteration:  1229  Loss:  0.3013467   Accuracy:  0.921875\n",
      "Iteration:  1230  Loss:  0.21509048   Accuracy:  0.921875\n",
      "Iteration:  1231  Loss:  0.2731362   Accuracy:  0.921875\n",
      "Iteration:  1232  Loss:  0.24124649   Accuracy:  0.921875\n",
      "Iteration:  1233  Loss:  0.25569397   Accuracy:  0.9140625\n",
      "Iteration:  1234  Loss:  0.42587006   Accuracy:  0.8828125\n",
      "Iteration:  1235  Loss:  0.5006994   Accuracy:  0.8828125\n",
      "Iteration:  1236  Loss:  0.13902292   Accuracy:  0.953125\n",
      "Iteration:  1237  Loss:  0.27359727   Accuracy:  0.9296875\n",
      "Iteration:  1238  Loss:  0.2615785   Accuracy:  0.9296875\n",
      "Iteration:  1239  Loss:  0.38407862   Accuracy:  0.8984375\n",
      "Iteration:  1240  Loss:  0.28045547   Accuracy:  0.90625\n",
      "Iteration:  1241  Loss:  0.24437499   Accuracy:  0.9453125\n",
      "Iteration:  1242  Loss:  0.31788033   Accuracy:  0.8984375\n",
      "Iteration:  1243  Loss:  0.22926867   Accuracy:  0.9375\n",
      "Iteration:  1244  Loss:  0.27222142   Accuracy:  0.9140625\n",
      "Iteration:  1245  Loss:  0.21476501   Accuracy:  0.9375\n",
      "Iteration:  1246  Loss:  0.31190556   Accuracy:  0.921875\n",
      "Iteration:  1247  Loss:  0.21949068   Accuracy:  0.9453125\n",
      "Iteration:  1248  Loss:  0.18282719   Accuracy:  0.9375\n",
      "Iteration:  1249  Loss:  0.26169258   Accuracy:  0.9140625\n",
      "Iteration:  1250  Loss:  0.28927287   Accuracy:  0.90625\n",
      "Iteration:  1251  Loss:  0.32298398   Accuracy:  0.9140625\n",
      "Iteration:  1252  Loss:  0.32727754   Accuracy:  0.9140625\n",
      "Iteration:  1253  Loss:  0.24433541   Accuracy:  0.9296875\n",
      "Iteration:  1254  Loss:  0.2877052   Accuracy:  0.890625\n",
      "Iteration:  1255  Loss:  0.2835481   Accuracy:  0.8828125\n",
      "Iteration:  1256  Loss:  0.4650445   Accuracy:  0.8828125\n",
      "Iteration:  1257  Loss:  0.37802505   Accuracy:  0.859375\n",
      "Iteration:  1258  Loss:  0.23900034   Accuracy:  0.9296875\n",
      "Iteration:  1259  Loss:  0.30251044   Accuracy:  0.9140625\n",
      "Iteration:  1260  Loss:  0.28385615   Accuracy:  0.90625\n",
      "Iteration:  1261  Loss:  0.35436612   Accuracy:  0.890625\n",
      "Iteration:  1262  Loss:  0.38624746   Accuracy:  0.90625\n",
      "Iteration:  1263  Loss:  0.2701591   Accuracy:  0.921875\n",
      "Iteration:  1264  Loss:  0.26417887   Accuracy:  0.9296875\n",
      "Iteration:  1265  Loss:  0.18739116   Accuracy:  0.9453125\n",
      "Iteration:  1266  Loss:  0.2636478   Accuracy:  0.9140625\n",
      "Iteration:  1267  Loss:  0.28709877   Accuracy:  0.90625\n",
      "Iteration:  1268  Loss:  0.205462   Accuracy:  0.9140625\n",
      "Iteration:  1269  Loss:  0.24418332   Accuracy:  0.9296875\n",
      "Iteration:  1270  Loss:  0.22510651   Accuracy:  0.921875\n",
      "Iteration:  1271  Loss:  0.22909154   Accuracy:  0.9296875\n",
      "Iteration:  1272  Loss:  0.27167398   Accuracy:  0.9140625\n",
      "Iteration:  1273  Loss:  0.26119652   Accuracy:  0.921875\n",
      "Iteration:  1274  Loss:  0.23366815   Accuracy:  0.9375\n",
      "Iteration:  1275  Loss:  0.3357023   Accuracy:  0.875\n",
      "Iteration:  1276  Loss:  0.243893   Accuracy:  0.9375\n",
      "Iteration:  1277  Loss:  0.4070956   Accuracy:  0.8671875\n",
      "Iteration:  1278  Loss:  0.3307252   Accuracy:  0.90625\n",
      "Iteration:  1279  Loss:  0.19620782   Accuracy:  0.953125\n",
      "Iteration:  1280  Loss:  0.24878421   Accuracy:  0.953125\n",
      "Iteration:  1281  Loss:  0.16164425   Accuracy:  0.9609375\n",
      "Iteration:  1282  Loss:  0.31133884   Accuracy:  0.9375\n",
      "Iteration:  1283  Loss:  0.31084648   Accuracy:  0.9140625\n",
      "Iteration:  1284  Loss:  0.2687973   Accuracy:  0.921875\n",
      "Iteration:  1285  Loss:  0.24139826   Accuracy:  0.8984375\n",
      "Iteration:  1286  Loss:  0.2679459   Accuracy:  0.9453125\n",
      "Iteration:  1287  Loss:  0.29533333   Accuracy:  0.8984375\n",
      "Iteration:  1288  Loss:  0.3195862   Accuracy:  0.90625\n",
      "Iteration:  1289  Loss:  0.19578674   Accuracy:  0.9375\n",
      "Iteration:  1290  Loss:  0.30485678   Accuracy:  0.9140625\n",
      "Iteration:  1291  Loss:  0.30442286   Accuracy:  0.921875\n",
      "Iteration:  1292  Loss:  0.2410149   Accuracy:  0.90625\n",
      "Iteration:  1293  Loss:  0.24392788   Accuracy:  0.9296875\n",
      "Iteration:  1294  Loss:  0.3211805   Accuracy:  0.8828125\n",
      "Iteration:  1295  Loss:  0.26929823   Accuracy:  0.9140625\n",
      "Iteration:  1296  Loss:  0.23243025   Accuracy:  0.90625\n",
      "Iteration:  1297  Loss:  0.33775842   Accuracy:  0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1298  Loss:  0.2793892   Accuracy:  0.9140625\n",
      "Iteration:  1299  Loss:  0.29074043   Accuracy:  0.90625\n",
      "Iteration:  1300  Loss:  0.33249962   Accuracy:  0.8984375\n",
      "Iteration:  1301  Loss:  0.30435762   Accuracy:  0.921875\n",
      "Iteration:  1302  Loss:  0.33872855   Accuracy:  0.9140625\n",
      "Iteration:  1303  Loss:  0.26099965   Accuracy:  0.9140625\n",
      "Iteration:  1304  Loss:  0.2772196   Accuracy:  0.90625\n",
      "Iteration:  1305  Loss:  0.23176467   Accuracy:  0.9375\n",
      "Iteration:  1306  Loss:  0.239992   Accuracy:  0.9453125\n",
      "Iteration:  1307  Loss:  0.3138659   Accuracy:  0.8984375\n",
      "Iteration:  1308  Loss:  0.38390636   Accuracy:  0.8671875\n",
      "Iteration:  1309  Loss:  0.21594635   Accuracy:  0.9140625\n",
      "Iteration:  1310  Loss:  0.29729235   Accuracy:  0.9375\n",
      "Iteration:  1311  Loss:  0.3546928   Accuracy:  0.890625\n",
      "Iteration:  1312  Loss:  0.40941685   Accuracy:  0.890625\n",
      "Iteration:  1313  Loss:  0.3713391   Accuracy:  0.890625\n",
      "Iteration:  1314  Loss:  0.23238158   Accuracy:  0.9375\n",
      "Iteration:  1315  Loss:  0.3639428   Accuracy:  0.8828125\n",
      "Iteration:  1316  Loss:  0.21497566   Accuracy:  0.90625\n",
      "Iteration:  1317  Loss:  0.37039852   Accuracy:  0.8984375\n",
      "Iteration:  1318  Loss:  0.34822783   Accuracy:  0.9296875\n",
      "Iteration:  1319  Loss:  0.19339463   Accuracy:  0.9375\n",
      "Iteration:  1320  Loss:  0.31076965   Accuracy:  0.9140625\n",
      "Iteration:  1321  Loss:  0.3707075   Accuracy:  0.890625\n",
      "Iteration:  1322  Loss:  0.38549525   Accuracy:  0.9140625\n",
      "Iteration:  1323  Loss:  0.16707768   Accuracy:  0.9609375\n",
      "Iteration:  1324  Loss:  0.30042627   Accuracy:  0.9140625\n",
      "Iteration:  1325  Loss:  0.23861778   Accuracy:  0.9375\n",
      "Iteration:  1326  Loss:  0.13360977   Accuracy:  0.9609375\n",
      "Iteration:  1327  Loss:  0.37187392   Accuracy:  0.8671875\n",
      "Iteration:  1328  Loss:  0.23820603   Accuracy:  0.890625\n",
      "Iteration:  1329  Loss:  0.27056333   Accuracy:  0.8984375\n",
      "Iteration:  1330  Loss:  0.3367443   Accuracy:  0.921875\n",
      "Iteration:  1331  Loss:  0.27370054   Accuracy:  0.921875\n",
      "Iteration:  1332  Loss:  0.35693234   Accuracy:  0.9140625\n",
      "Iteration:  1333  Loss:  0.34391013   Accuracy:  0.890625\n",
      "Iteration:  1334  Loss:  0.3209254   Accuracy:  0.9296875\n",
      "Iteration:  1335  Loss:  0.2649796   Accuracy:  0.9296875\n",
      "Iteration:  1336  Loss:  0.36542052   Accuracy:  0.9140625\n",
      "Iteration:  1337  Loss:  0.24280512   Accuracy:  0.9296875\n",
      "Iteration:  1338  Loss:  0.30125764   Accuracy:  0.8828125\n",
      "Iteration:  1339  Loss:  0.2134293   Accuracy:  0.953125\n",
      "Iteration:  1340  Loss:  0.23825997   Accuracy:  0.9140625\n",
      "Iteration:  1341  Loss:  0.23261936   Accuracy:  0.9296875\n",
      "Iteration:  1342  Loss:  0.3578117   Accuracy:  0.8984375\n",
      "Iteration:  1343  Loss:  0.1939641   Accuracy:  0.9296875\n",
      "Iteration:  1344  Loss:  0.22221142   Accuracy:  0.9453125\n",
      "Iteration:  1345  Loss:  0.31931216   Accuracy:  0.8984375\n",
      "Iteration:  1346  Loss:  0.34477425   Accuracy:  0.890625\n",
      "Iteration:  1347  Loss:  0.2724506   Accuracy:  0.9375\n",
      "Iteration:  1348  Loss:  0.37931138   Accuracy:  0.90625\n",
      "Iteration:  1349  Loss:  0.2317823   Accuracy:  0.921875\n",
      "Iteration:  1350  Loss:  0.39382088   Accuracy:  0.8828125\n",
      "Iteration:  1351  Loss:  0.48961067   Accuracy:  0.8671875\n",
      "Iteration:  1352  Loss:  0.2706255   Accuracy:  0.9296875\n",
      "Iteration:  1353  Loss:  0.25130498   Accuracy:  0.9140625\n",
      "Iteration:  1354  Loss:  0.38770795   Accuracy:  0.8671875\n",
      "Iteration:  1355  Loss:  0.18453643   Accuracy:  0.9609375\n",
      "Iteration:  1356  Loss:  0.33269602   Accuracy:  0.875\n",
      "Iteration:  1357  Loss:  0.27664974   Accuracy:  0.9140625\n",
      "Iteration:  1358  Loss:  0.26702112   Accuracy:  0.921875\n",
      "Iteration:  1359  Loss:  0.40986758   Accuracy:  0.8984375\n",
      "Iteration:  1360  Loss:  0.28967687   Accuracy:  0.9375\n",
      "Iteration:  1361  Loss:  0.18729085   Accuracy:  0.96875\n",
      "Iteration:  1362  Loss:  0.38587427   Accuracy:  0.9140625\n",
      "Iteration:  1363  Loss:  0.23449844   Accuracy:  0.9453125\n",
      "Iteration:  1364  Loss:  0.20129842   Accuracy:  0.9375\n",
      "Iteration:  1365  Loss:  0.2577553   Accuracy:  0.9140625\n",
      "Iteration:  1366  Loss:  0.1632375   Accuracy:  0.9609375\n",
      "Iteration:  1367  Loss:  0.16148084   Accuracy:  0.9375\n",
      "Iteration:  1368  Loss:  0.2938168   Accuracy:  0.8984375\n",
      "Iteration:  1369  Loss:  0.17748588   Accuracy:  0.9609375\n",
      "Iteration:  1370  Loss:  0.42132014   Accuracy:  0.9375\n",
      "Iteration:  1371  Loss:  0.43526325   Accuracy:  0.9296875\n",
      "Iteration:  1372  Loss:  0.54180104   Accuracy:  0.8515625\n",
      "Iteration:  1373  Loss:  0.2158143   Accuracy:  0.9140625\n",
      "Iteration:  1374  Loss:  0.3139732   Accuracy:  0.953125\n",
      "Iteration:  1375  Loss:  0.30919716   Accuracy:  0.90625\n",
      "Iteration:  1376  Loss:  0.5047305   Accuracy:  0.859375\n",
      "Iteration:  1377  Loss:  0.50398076   Accuracy:  0.8828125\n",
      "Iteration:  1378  Loss:  0.27290523   Accuracy:  0.9296875\n",
      "Iteration:  1379  Loss:  0.24472679   Accuracy:  0.921875\n",
      "Iteration:  1380  Loss:  0.27017784   Accuracy:  0.90625\n",
      "Iteration:  1381  Loss:  0.18941754   Accuracy:  0.9296875\n",
      "Iteration:  1382  Loss:  0.25405702   Accuracy:  0.9140625\n",
      "Iteration:  1383  Loss:  0.22736692   Accuracy:  0.953125\n",
      "Iteration:  1384  Loss:  0.22099221   Accuracy:  0.9296875\n",
      "Iteration:  1385  Loss:  0.2825532   Accuracy:  0.90625\n",
      "Iteration:  1386  Loss:  0.41517156   Accuracy:  0.8671875\n",
      "Iteration:  1387  Loss:  0.31441063   Accuracy:  0.90625\n",
      "Iteration:  1388  Loss:  0.29650816   Accuracy:  0.8984375\n",
      "Iteration:  1389  Loss:  0.21492451   Accuracy:  0.921875\n",
      "Iteration:  1390  Loss:  0.3584248   Accuracy:  0.875\n",
      "Iteration:  1391  Loss:  0.462259   Accuracy:  0.90625\n",
      "Iteration:  1392  Loss:  0.20325693   Accuracy:  0.9375\n",
      "Iteration:  1393  Loss:  0.2995823   Accuracy:  0.921875\n",
      "Iteration:  1394  Loss:  0.31990474   Accuracy:  0.8984375\n",
      "Iteration:  1395  Loss:  0.18860152   Accuracy:  0.9609375\n",
      "Iteration:  1396  Loss:  0.299564   Accuracy:  0.890625\n",
      "Iteration:  1397  Loss:  0.26944852   Accuracy:  0.9140625\n",
      "Iteration:  1398  Loss:  0.29671088   Accuracy:  0.9140625\n",
      "Iteration:  1399  Loss:  0.29174313   Accuracy:  0.90625\n",
      "Iteration:  1400  Loss:  0.42722884   Accuracy:  0.859375\n",
      "Iteration:  1401  Loss:  0.3886017   Accuracy:  0.8828125\n",
      "Iteration:  1402  Loss:  0.37111747   Accuracy:  0.9296875\n",
      "Iteration:  1403  Loss:  0.40399757   Accuracy:  0.8984375\n",
      "Iteration:  1404  Loss:  0.24836104   Accuracy:  0.921875\n",
      "Iteration:  1405  Loss:  0.29603487   Accuracy:  0.90625\n",
      "Iteration:  1406  Loss:  0.36037388   Accuracy:  0.8984375\n",
      "Iteration:  1407  Loss:  0.23517744   Accuracy:  0.9453125\n",
      "Iteration:  1408  Loss:  0.37642115   Accuracy:  0.921875\n",
      "Iteration:  1409  Loss:  0.37863487   Accuracy:  0.8671875\n",
      "Iteration:  1410  Loss:  0.27443695   Accuracy:  0.90625\n",
      "Iteration:  1411  Loss:  0.20170417   Accuracy:  0.9375\n",
      "Iteration:  1412  Loss:  0.45261502   Accuracy:  0.84375\n",
      "Iteration:  1413  Loss:  0.35271776   Accuracy:  0.90625\n",
      "Iteration:  1414  Loss:  0.17183116   Accuracy:  0.953125\n",
      "Iteration:  1415  Loss:  0.31378347   Accuracy:  0.875\n",
      "Iteration:  1416  Loss:  0.18333894   Accuracy:  0.9375\n",
      "Iteration:  1417  Loss:  0.3571496   Accuracy:  0.8984375\n",
      "Iteration:  1418  Loss:  0.30122572   Accuracy:  0.8828125\n",
      "Iteration:  1419  Loss:  0.23042646   Accuracy:  0.921875\n",
      "Iteration:  1420  Loss:  0.32610494   Accuracy:  0.890625\n",
      "Iteration:  1421  Loss:  0.29888946   Accuracy:  0.921875\n",
      "Iteration:  1422  Loss:  0.33868837   Accuracy:  0.8984375\n",
      "Iteration:  1423  Loss:  0.3447047   Accuracy:  0.90625\n",
      "Iteration:  1424  Loss:  0.21565974   Accuracy:  0.9375\n",
      "Iteration:  1425  Loss:  0.31669623   Accuracy:  0.8828125\n",
      "Iteration:  1426  Loss:  0.21065792   Accuracy:  0.9296875\n",
      "Iteration:  1427  Loss:  0.2988466   Accuracy:  0.921875\n",
      "Iteration:  1428  Loss:  0.3076385   Accuracy:  0.9140625\n",
      "Iteration:  1429  Loss:  0.40599167   Accuracy:  0.90625\n",
      "Iteration:  1430  Loss:  0.34387338   Accuracy:  0.890625\n",
      "Iteration:  1431  Loss:  0.23112535   Accuracy:  0.9453125\n",
      "Iteration:  1432  Loss:  0.27536166   Accuracy:  0.9296875\n",
      "Iteration:  1433  Loss:  0.25363392   Accuracy:  0.921875\n",
      "Iteration:  1434  Loss:  0.42240703   Accuracy:  0.875\n",
      "Iteration:  1435  Loss:  0.34453657   Accuracy:  0.8984375\n",
      "Iteration:  1436  Loss:  0.4159415   Accuracy:  0.875\n",
      "Iteration:  1437  Loss:  0.41060215   Accuracy:  0.9140625\n",
      "Iteration:  1438  Loss:  0.20050885   Accuracy:  0.9609375\n",
      "Iteration:  1439  Loss:  0.307317   Accuracy:  0.921875\n",
      "Iteration:  1440  Loss:  0.24143127   Accuracy:  0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1441  Loss:  0.3702774   Accuracy:  0.90625\n",
      "Iteration:  1442  Loss:  0.36211997   Accuracy:  0.8828125\n",
      "Iteration:  1443  Loss:  0.33169028   Accuracy:  0.9375\n",
      "Iteration:  1444  Loss:  0.25083205   Accuracy:  0.921875\n",
      "Iteration:  1445  Loss:  0.15654533   Accuracy:  0.9609375\n",
      "Iteration:  1446  Loss:  0.22133413   Accuracy:  0.921875\n",
      "Iteration:  1447  Loss:  0.24790579   Accuracy:  0.9375\n",
      "Iteration:  1448  Loss:  0.16828716   Accuracy:  0.96875\n",
      "Iteration:  1449  Loss:  0.28936732   Accuracy:  0.8984375\n",
      "Iteration:  1450  Loss:  0.28470796   Accuracy:  0.921875\n",
      "Iteration:  1451  Loss:  0.23172852   Accuracy:  0.9375\n",
      "Iteration:  1452  Loss:  0.24603976   Accuracy:  0.9375\n",
      "Iteration:  1453  Loss:  0.35237968   Accuracy:  0.8828125\n",
      "Iteration:  1454  Loss:  0.20926698   Accuracy:  0.953125\n",
      "Iteration:  1455  Loss:  0.26017448   Accuracy:  0.9375\n",
      "Iteration:  1456  Loss:  0.38891208   Accuracy:  0.9140625\n",
      "Iteration:  1457  Loss:  0.29859006   Accuracy:  0.953125\n",
      "Iteration:  1458  Loss:  0.19966666   Accuracy:  0.9453125\n",
      "Iteration:  1459  Loss:  0.26999244   Accuracy:  0.8984375\n",
      "Iteration:  1460  Loss:  0.25629938   Accuracy:  0.9140625\n",
      "Iteration:  1461  Loss:  0.46973345   Accuracy:  0.8359375\n",
      "Iteration:  1462  Loss:  0.2117698   Accuracy:  0.9453125\n",
      "Iteration:  1463  Loss:  0.33346605   Accuracy:  0.921875\n",
      "Iteration:  1464  Loss:  0.32406667   Accuracy:  0.9296875\n",
      "Iteration:  1465  Loss:  0.39485884   Accuracy:  0.8984375\n",
      "Iteration:  1466  Loss:  0.24356326   Accuracy:  0.9375\n",
      "Iteration:  1467  Loss:  0.25479537   Accuracy:  0.9296875\n",
      "Iteration:  1468  Loss:  0.28533602   Accuracy:  0.890625\n",
      "Iteration:  1469  Loss:  0.29942805   Accuracy:  0.921875\n",
      "Iteration:  1470  Loss:  0.18483466   Accuracy:  0.9609375\n",
      "Iteration:  1471  Loss:  0.44830814   Accuracy:  0.890625\n",
      "Iteration:  1472  Loss:  0.2300606   Accuracy:  0.9375\n",
      "Iteration:  1473  Loss:  0.42180544   Accuracy:  0.8984375\n",
      "Iteration:  1474  Loss:  0.441455   Accuracy:  0.890625\n",
      "Iteration:  1475  Loss:  0.23251082   Accuracy:  0.921875\n",
      "Iteration:  1476  Loss:  0.3249942   Accuracy:  0.921875\n",
      "Iteration:  1477  Loss:  0.3200431   Accuracy:  0.921875\n",
      "Iteration:  1478  Loss:  0.26048967   Accuracy:  0.9140625\n",
      "Iteration:  1479  Loss:  0.22073604   Accuracy:  0.921875\n",
      "Iteration:  1480  Loss:  0.38739517   Accuracy:  0.921875\n",
      "Iteration:  1481  Loss:  0.2636641   Accuracy:  0.9140625\n",
      "Iteration:  1482  Loss:  0.24924746   Accuracy:  0.96875\n",
      "Iteration:  1483  Loss:  0.20201746   Accuracy:  0.953125\n",
      "Iteration:  1484  Loss:  0.33734587   Accuracy:  0.9375\n",
      "Iteration:  1485  Loss:  0.14256254   Accuracy:  0.9453125\n",
      "Iteration:  1486  Loss:  0.152311   Accuracy:  0.96875\n",
      "Iteration:  1487  Loss:  0.21782936   Accuracy:  0.9609375\n",
      "Iteration:  1488  Loss:  0.23797914   Accuracy:  0.9296875\n",
      "Iteration:  1489  Loss:  0.23930278   Accuracy:  0.9296875\n",
      "Iteration:  1490  Loss:  0.28771806   Accuracy:  0.90625\n",
      "Iteration:  1491  Loss:  0.20051152   Accuracy:  0.9453125\n",
      "Iteration:  1492  Loss:  0.18838549   Accuracy:  0.9609375\n",
      "Iteration:  1493  Loss:  0.38957417   Accuracy:  0.859375\n",
      "Iteration:  1494  Loss:  0.31091958   Accuracy:  0.90625\n",
      "Iteration:  1495  Loss:  0.2347925   Accuracy:  0.9609375\n",
      "Iteration:  1496  Loss:  0.31339625   Accuracy:  0.9375\n",
      "Iteration:  1497  Loss:  0.38746125   Accuracy:  0.875\n",
      "Iteration:  1498  Loss:  0.29595262   Accuracy:  0.921875\n",
      "Iteration:  1499  Loss:  0.38225502   Accuracy:  0.890625\n",
      "Iteration:  1500  Loss:  0.45476237   Accuracy:  0.84375\n",
      "Iteration:  1501  Loss:  0.28563184   Accuracy:  0.921875\n",
      "Iteration:  1502  Loss:  0.30905434   Accuracy:  0.9296875\n",
      "Iteration:  1503  Loss:  0.45259476   Accuracy:  0.859375\n",
      "Iteration:  1504  Loss:  0.2613933   Accuracy:  0.921875\n",
      "Iteration:  1505  Loss:  0.46340978   Accuracy:  0.8828125\n",
      "Iteration:  1506  Loss:  0.22622237   Accuracy:  0.9375\n",
      "Iteration:  1507  Loss:  0.22958624   Accuracy:  0.921875\n",
      "Iteration:  1508  Loss:  0.4398718   Accuracy:  0.859375\n",
      "Iteration:  1509  Loss:  0.47324336   Accuracy:  0.90625\n",
      "Iteration:  1510  Loss:  0.23174785   Accuracy:  0.9453125\n",
      "Iteration:  1511  Loss:  0.2547702   Accuracy:  0.9140625\n",
      "Iteration:  1512  Loss:  0.23746547   Accuracy:  0.9609375\n",
      "Iteration:  1513  Loss:  0.38655263   Accuracy:  0.90625\n",
      "Iteration:  1514  Loss:  0.33571565   Accuracy:  0.90625\n",
      "Iteration:  1515  Loss:  0.2878062   Accuracy:  0.890625\n",
      "Iteration:  1516  Loss:  0.23339933   Accuracy:  0.9375\n",
      "Iteration:  1517  Loss:  0.34824586   Accuracy:  0.9140625\n",
      "Iteration:  1518  Loss:  0.2975732   Accuracy:  0.921875\n",
      "Iteration:  1519  Loss:  0.31122404   Accuracy:  0.9296875\n",
      "Iteration:  1520  Loss:  0.4537508   Accuracy:  0.859375\n",
      "Iteration:  1521  Loss:  0.23452643   Accuracy:  0.9375\n",
      "Iteration:  1522  Loss:  0.32662597   Accuracy:  0.921875\n",
      "Iteration:  1523  Loss:  0.22112182   Accuracy:  0.9140625\n",
      "Iteration:  1524  Loss:  0.16455439   Accuracy:  0.9609375\n",
      "Iteration:  1525  Loss:  0.279983   Accuracy:  0.8828125\n",
      "Iteration:  1526  Loss:  0.24877656   Accuracy:  0.9140625\n",
      "Iteration:  1527  Loss:  0.35106638   Accuracy:  0.9140625\n",
      "Iteration:  1528  Loss:  0.1757561   Accuracy:  0.9453125\n",
      "Iteration:  1529  Loss:  0.2466976   Accuracy:  0.9453125\n",
      "Iteration:  1530  Loss:  0.28089833   Accuracy:  0.9140625\n",
      "Iteration:  1531  Loss:  0.38888705   Accuracy:  0.8828125\n",
      "Iteration:  1532  Loss:  0.2766238   Accuracy:  0.9296875\n",
      "Iteration:  1533  Loss:  0.18437436   Accuracy:  0.921875\n",
      "Iteration:  1534  Loss:  0.31333476   Accuracy:  0.90625\n",
      "Iteration:  1535  Loss:  0.21419108   Accuracy:  0.9375\n",
      "Iteration:  1536  Loss:  0.3074953   Accuracy:  0.890625\n",
      "Iteration:  1537  Loss:  0.3408383   Accuracy:  0.890625\n",
      "Iteration:  1538  Loss:  0.3488303   Accuracy:  0.9140625\n",
      "Iteration:  1539  Loss:  0.19154269   Accuracy:  0.9609375\n",
      "Iteration:  1540  Loss:  0.21863788   Accuracy:  0.953125\n",
      "Iteration:  1541  Loss:  0.36519533   Accuracy:  0.921875\n",
      "Iteration:  1542  Loss:  0.20393273   Accuracy:  0.9609375\n",
      "Iteration:  1543  Loss:  0.2821808   Accuracy:  0.9140625\n",
      "Iteration:  1544  Loss:  0.17552206   Accuracy:  0.953125\n",
      "Iteration:  1545  Loss:  0.2595294   Accuracy:  0.9140625\n",
      "Iteration:  1546  Loss:  0.25785205   Accuracy:  0.9375\n",
      "Iteration:  1547  Loss:  0.39228514   Accuracy:  0.890625\n",
      "Iteration:  1548  Loss:  0.25673503   Accuracy:  0.9375\n",
      "Iteration:  1549  Loss:  0.2497336   Accuracy:  0.9296875\n",
      "Iteration:  1550  Loss:  0.25379574   Accuracy:  0.921875\n",
      "Iteration:  1551  Loss:  0.26720318   Accuracy:  0.921875\n",
      "Iteration:  1552  Loss:  0.36652043   Accuracy:  0.8828125\n",
      "Iteration:  1553  Loss:  0.38611677   Accuracy:  0.9296875\n",
      "Iteration:  1554  Loss:  0.2539664   Accuracy:  0.9453125\n",
      "Iteration:  1555  Loss:  0.23911682   Accuracy:  0.9375\n",
      "Iteration:  1556  Loss:  0.38493687   Accuracy:  0.890625\n",
      "Iteration:  1557  Loss:  0.115596764   Accuracy:  0.984375\n",
      "Iteration:  1558  Loss:  0.32946673   Accuracy:  0.90625\n",
      "Iteration:  1559  Loss:  0.26190224   Accuracy:  0.9296875\n",
      "Iteration:  1560  Loss:  0.28453305   Accuracy:  0.921875\n",
      "Iteration:  1561  Loss:  0.2616759   Accuracy:  0.9296875\n",
      "Iteration:  1562  Loss:  0.25698626   Accuracy:  0.890625\n",
      "Iteration:  1563  Loss:  0.25470382   Accuracy:  0.921875\n",
      "Iteration:  1564  Loss:  0.2080695   Accuracy:  0.9296875\n",
      "Iteration:  1565  Loss:  0.27439648   Accuracy:  0.9296875\n",
      "Iteration:  1566  Loss:  0.1507847   Accuracy:  0.9375\n",
      "Iteration:  1567  Loss:  0.22444624   Accuracy:  0.953125\n",
      "Iteration:  1568  Loss:  0.26621562   Accuracy:  0.9375\n",
      "Iteration:  1569  Loss:  0.22435412   Accuracy:  0.921875\n",
      "Iteration:  1570  Loss:  0.39618215   Accuracy:  0.90625\n",
      "Iteration:  1571  Loss:  0.22326021   Accuracy:  0.9453125\n",
      "Iteration:  1572  Loss:  0.21871486   Accuracy:  0.9140625\n",
      "Iteration:  1573  Loss:  0.24928916   Accuracy:  0.921875\n",
      "Iteration:  1574  Loss:  0.3752988   Accuracy:  0.859375\n",
      "Iteration:  1575  Loss:  0.3216957   Accuracy:  0.9296875\n",
      "Iteration:  1576  Loss:  0.17562462   Accuracy:  0.953125\n",
      "Iteration:  1577  Loss:  0.15706849   Accuracy:  0.9765625\n",
      "Iteration:  1578  Loss:  0.23437136   Accuracy:  0.921875\n",
      "Iteration:  1579  Loss:  0.29199922   Accuracy:  0.90625\n",
      "Iteration:  1580  Loss:  0.2731455   Accuracy:  0.9140625\n",
      "Iteration:  1581  Loss:  0.20284823   Accuracy:  0.9375\n",
      "Iteration:  1582  Loss:  0.1997605   Accuracy:  0.9375\n",
      "Iteration:  1583  Loss:  0.30568197   Accuracy:  0.9296875\n",
      "Iteration:  1584  Loss:  0.23979324   Accuracy:  0.9140625\n",
      "Iteration:  1585  Loss:  0.32811058   Accuracy:  0.90625\n",
      "Iteration:  1586  Loss:  0.27106372   Accuracy:  0.9140625\n",
      "Iteration:  1587  Loss:  0.27821428   Accuracy:  0.90625\n",
      "Iteration:  1588  Loss:  0.32728848   Accuracy:  0.8828125\n",
      "Iteration:  1589  Loss:  0.14587301   Accuracy:  0.9453125\n",
      "Iteration:  1590  Loss:  0.31367338   Accuracy:  0.90625\n",
      "Iteration:  1591  Loss:  0.4040309   Accuracy:  0.890625\n",
      "Iteration:  1592  Loss:  0.20560572   Accuracy:  0.9375\n",
      "Iteration:  1593  Loss:  0.21524373   Accuracy:  0.9453125\n",
      "Iteration:  1594  Loss:  0.22856377   Accuracy:  0.9296875\n",
      "Iteration:  1595  Loss:  0.27777413   Accuracy:  0.9375\n",
      "Iteration:  1596  Loss:  0.30057263   Accuracy:  0.8828125\n",
      "Iteration:  1597  Loss:  0.2521695   Accuracy:  0.9296875\n",
      "Iteration:  1598  Loss:  0.17583473   Accuracy:  0.953125\n",
      "Iteration:  1599  Loss:  0.2421695   Accuracy:  0.9375\n",
      "Iteration:  1600  Loss:  0.3169859   Accuracy:  0.9140625\n",
      "Iteration:  1601  Loss:  0.27379143   Accuracy:  0.921875\n",
      "Iteration:  1602  Loss:  0.23835808   Accuracy:  0.9453125\n",
      "Iteration:  1603  Loss:  0.28110427   Accuracy:  0.921875\n",
      "Iteration:  1604  Loss:  0.31770474   Accuracy:  0.875\n",
      "Iteration:  1605  Loss:  0.23848175   Accuracy:  0.9296875\n",
      "Iteration:  1606  Loss:  0.30431664   Accuracy:  0.9453125\n",
      "Iteration:  1607  Loss:  0.32143256   Accuracy:  0.921875\n",
      "Iteration:  1608  Loss:  0.14215364   Accuracy:  0.9765625\n",
      "Iteration:  1609  Loss:  0.2760615   Accuracy:  0.8984375\n",
      "Iteration:  1610  Loss:  0.29669958   Accuracy:  0.90625\n",
      "Iteration:  1611  Loss:  0.44243252   Accuracy:  0.8828125\n",
      "Iteration:  1612  Loss:  0.22379386   Accuracy:  0.921875\n",
      "Iteration:  1613  Loss:  0.23064542   Accuracy:  0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1614  Loss:  0.24210286   Accuracy:  0.890625\n",
      "Iteration:  1615  Loss:  0.17420757   Accuracy:  0.9296875\n",
      "Iteration:  1616  Loss:  0.21500786   Accuracy:  0.9453125\n",
      "Iteration:  1617  Loss:  0.27415797   Accuracy:  0.9140625\n",
      "Iteration:  1618  Loss:  0.28108183   Accuracy:  0.8828125\n",
      "Iteration:  1619  Loss:  0.27993938   Accuracy:  0.8984375\n",
      "Iteration:  1620  Loss:  0.23107567   Accuracy:  0.9296875\n",
      "Iteration:  1621  Loss:  0.2608724   Accuracy:  0.9375\n",
      "Iteration:  1622  Loss:  0.3117014   Accuracy:  0.9140625\n",
      "Iteration:  1623  Loss:  0.3133137   Accuracy:  0.875\n",
      "Iteration:  1624  Loss:  0.42223868   Accuracy:  0.8828125\n",
      "Iteration:  1625  Loss:  0.17370388   Accuracy:  0.953125\n",
      "Iteration:  1626  Loss:  0.37853345   Accuracy:  0.90625\n",
      "Iteration:  1627  Loss:  0.22801773   Accuracy:  0.9140625\n",
      "Iteration:  1628  Loss:  0.36226243   Accuracy:  0.921875\n",
      "Iteration:  1629  Loss:  0.30735806   Accuracy:  0.8984375\n",
      "Iteration:  1630  Loss:  0.3819921   Accuracy:  0.875\n",
      "Iteration:  1631  Loss:  0.15240137   Accuracy:  0.9609375\n",
      "Iteration:  1632  Loss:  0.4704984   Accuracy:  0.875\n",
      "Iteration:  1633  Loss:  0.25770772   Accuracy:  0.921875\n",
      "Iteration:  1634  Loss:  0.21090548   Accuracy:  0.9375\n",
      "Iteration:  1635  Loss:  0.37047547   Accuracy:  0.8984375\n",
      "Iteration:  1636  Loss:  0.3928271   Accuracy:  0.90625\n",
      "Iteration:  1637  Loss:  0.3056094   Accuracy:  0.921875\n",
      "Iteration:  1638  Loss:  0.36388752   Accuracy:  0.8828125\n",
      "Iteration:  1639  Loss:  0.25849894   Accuracy:  0.921875\n",
      "Iteration:  1640  Loss:  0.31067193   Accuracy:  0.90625\n",
      "Iteration:  1641  Loss:  0.2866865   Accuracy:  0.90625\n",
      "Iteration:  1642  Loss:  0.547953   Accuracy:  0.828125\n",
      "Iteration:  1643  Loss:  0.16281535   Accuracy:  0.921875\n",
      "Iteration:  1644  Loss:  0.47279724   Accuracy:  0.875\n",
      "Iteration:  1645  Loss:  0.23762211   Accuracy:  0.90625\n",
      "Iteration:  1646  Loss:  0.3208288   Accuracy:  0.9140625\n",
      "Iteration:  1647  Loss:  0.37352565   Accuracy:  0.9140625\n",
      "Iteration:  1648  Loss:  0.34408498   Accuracy:  0.9140625\n",
      "Iteration:  1649  Loss:  0.34875605   Accuracy:  0.9296875\n",
      "Iteration:  1650  Loss:  0.2901606   Accuracy:  0.8984375\n",
      "Iteration:  1651  Loss:  0.35698622   Accuracy:  0.8828125\n",
      "Iteration:  1652  Loss:  0.40448058   Accuracy:  0.8828125\n",
      "Iteration:  1653  Loss:  0.36859962   Accuracy:  0.890625\n",
      "Iteration:  1654  Loss:  0.33952132   Accuracy:  0.9296875\n",
      "Iteration:  1655  Loss:  0.38860163   Accuracy:  0.9140625\n",
      "Iteration:  1656  Loss:  0.27466917   Accuracy:  0.9296875\n",
      "Iteration:  1657  Loss:  0.28735766   Accuracy:  0.90625\n",
      "Iteration:  1658  Loss:  0.27090937   Accuracy:  0.90625\n",
      "Iteration:  1659  Loss:  0.18966125   Accuracy:  0.9453125\n",
      "Iteration:  1660  Loss:  0.27554417   Accuracy:  0.921875\n",
      "Iteration:  1661  Loss:  0.24605653   Accuracy:  0.9453125\n",
      "Iteration:  1662  Loss:  0.24559289   Accuracy:  0.9375\n",
      "Iteration:  1663  Loss:  0.30929306   Accuracy:  0.8984375\n",
      "Iteration:  1664  Loss:  0.32463944   Accuracy:  0.8671875\n",
      "Iteration:  1665  Loss:  0.29584944   Accuracy:  0.9453125\n",
      "Iteration:  1666  Loss:  0.47128308   Accuracy:  0.90625\n",
      "Iteration:  1667  Loss:  0.32381645   Accuracy:  0.9140625\n",
      "Iteration:  1668  Loss:  0.264989   Accuracy:  0.9296875\n",
      "Iteration:  1669  Loss:  0.36397928   Accuracy:  0.8984375\n",
      "Iteration:  1670  Loss:  0.41491824   Accuracy:  0.859375\n",
      "Iteration:  1671  Loss:  0.4145465   Accuracy:  0.8828125\n",
      "Iteration:  1672  Loss:  0.27626276   Accuracy:  0.9296875\n",
      "Iteration:  1673  Loss:  0.36191928   Accuracy:  0.90625\n",
      "Iteration:  1674  Loss:  0.3735027   Accuracy:  0.8828125\n",
      "Iteration:  1675  Loss:  0.23800676   Accuracy:  0.921875\n",
      "Iteration:  1676  Loss:  0.36051652   Accuracy:  0.890625\n",
      "Iteration:  1677  Loss:  0.37008625   Accuracy:  0.875\n",
      "Iteration:  1678  Loss:  0.330001   Accuracy:  0.8984375\n",
      "Iteration:  1679  Loss:  0.26610613   Accuracy:  0.9140625\n",
      "Iteration:  1680  Loss:  0.3834872   Accuracy:  0.9296875\n",
      "Iteration:  1681  Loss:  0.29298174   Accuracy:  0.9296875\n",
      "Iteration:  1682  Loss:  0.26555222   Accuracy:  0.9140625\n",
      "Iteration:  1683  Loss:  0.36142066   Accuracy:  0.9140625\n",
      "Iteration:  1684  Loss:  0.2884473   Accuracy:  0.921875\n",
      "Iteration:  1685  Loss:  0.3966392   Accuracy:  0.90625\n",
      "Iteration:  1686  Loss:  0.36674863   Accuracy:  0.9375\n",
      "Iteration:  1687  Loss:  0.30808097   Accuracy:  0.921875\n",
      "Iteration:  1688  Loss:  0.4263416   Accuracy:  0.8515625\n",
      "Iteration:  1689  Loss:  0.19504006   Accuracy:  0.9453125\n",
      "Iteration:  1690  Loss:  0.24741273   Accuracy:  0.9296875\n",
      "Iteration:  1691  Loss:  0.19675791   Accuracy:  0.9453125\n",
      "Iteration:  1692  Loss:  0.3703365   Accuracy:  0.875\n",
      "Iteration:  1693  Loss:  0.23887981   Accuracy:  0.9296875\n",
      "Iteration:  1694  Loss:  0.34447482   Accuracy:  0.8984375\n",
      "Iteration:  1695  Loss:  0.24717487   Accuracy:  0.9453125\n",
      "Iteration:  1696  Loss:  0.28753397   Accuracy:  0.921875\n",
      "Iteration:  1697  Loss:  0.20664191   Accuracy:  0.9375\n",
      "Iteration:  1698  Loss:  0.39125648   Accuracy:  0.890625\n",
      "Iteration:  1699  Loss:  0.17509606   Accuracy:  0.953125\n",
      "Iteration:  1700  Loss:  0.21263301   Accuracy:  0.953125\n",
      "Iteration:  1701  Loss:  0.18659994   Accuracy:  0.953125\n",
      "Iteration:  1702  Loss:  0.32727396   Accuracy:  0.9140625\n",
      "Iteration:  1703  Loss:  0.22126798   Accuracy:  0.9375\n",
      "Iteration:  1704  Loss:  0.32394212   Accuracy:  0.921875\n",
      "Iteration:  1705  Loss:  0.19124526   Accuracy:  0.953125\n",
      "Iteration:  1706  Loss:  0.31139827   Accuracy:  0.8984375\n",
      "Iteration:  1707  Loss:  0.18183199   Accuracy:  0.9609375\n",
      "Iteration:  1708  Loss:  0.30454695   Accuracy:  0.90625\n",
      "Iteration:  1709  Loss:  0.14845873   Accuracy:  0.96875\n",
      "Iteration:  1710  Loss:  0.36587897   Accuracy:  0.90625\n",
      "Iteration:  1711  Loss:  0.14142267   Accuracy:  0.9609375\n",
      "Iteration:  1712  Loss:  0.31279415   Accuracy:  0.8984375\n",
      "Iteration:  1713  Loss:  0.2206176   Accuracy:  0.9375\n",
      "Iteration:  1714  Loss:  0.21313444   Accuracy:  0.953125\n",
      "Iteration:  1715  Loss:  0.2241796   Accuracy:  0.9609375\n",
      "Iteration:  1716  Loss:  0.30166405   Accuracy:  0.9375\n",
      "Iteration:  1717  Loss:  0.37324885   Accuracy:  0.890625\n",
      "Iteration:  1718  Loss:  0.22318895   Accuracy:  0.9609375\n",
      "Iteration:  1719  Loss:  0.4354258   Accuracy:  0.8828125\n",
      "Iteration:  1720  Loss:  0.31853488   Accuracy:  0.890625\n",
      "Iteration:  1721  Loss:  0.1905499   Accuracy:  0.9453125\n",
      "Iteration:  1722  Loss:  0.16160873   Accuracy:  0.9375\n",
      "Iteration:  1723  Loss:  0.33953258   Accuracy:  0.890625\n",
      "Iteration:  1724  Loss:  0.27745274   Accuracy:  0.9453125\n",
      "Iteration:  1725  Loss:  0.2441645   Accuracy:  0.9375\n",
      "Iteration:  1726  Loss:  0.1625021   Accuracy:  0.9375\n",
      "Iteration:  1727  Loss:  0.2508338   Accuracy:  0.921875\n",
      "Iteration:  1728  Loss:  0.34530723   Accuracy:  0.890625\n",
      "Iteration:  1729  Loss:  0.294438   Accuracy:  0.9140625\n",
      "Iteration:  1730  Loss:  0.20022023   Accuracy:  0.9296875\n",
      "Iteration:  1731  Loss:  0.28795272   Accuracy:  0.90625\n",
      "Iteration:  1732  Loss:  0.26451123   Accuracy:  0.9375\n",
      "Iteration:  1733  Loss:  0.31788313   Accuracy:  0.8984375\n",
      "Iteration:  1734  Loss:  0.21422398   Accuracy:  0.9375\n",
      "Iteration:  1735  Loss:  0.24298134   Accuracy:  0.9375\n",
      "Iteration:  1736  Loss:  0.27056897   Accuracy:  0.8984375\n",
      "Iteration:  1737  Loss:  0.37164307   Accuracy:  0.90625\n",
      "Iteration:  1738  Loss:  0.28850037   Accuracy:  0.9296875\n",
      "Iteration:  1739  Loss:  0.42321405   Accuracy:  0.890625\n",
      "Iteration:  1740  Loss:  0.24734358   Accuracy:  0.90625\n",
      "Iteration:  1741  Loss:  0.21474302   Accuracy:  0.953125\n",
      "Iteration:  1742  Loss:  0.31486082   Accuracy:  0.90625\n",
      "Iteration:  1743  Loss:  0.29386455   Accuracy:  0.921875\n",
      "Iteration:  1744  Loss:  0.37476537   Accuracy:  0.921875\n",
      "Iteration:  1745  Loss:  0.47838855   Accuracy:  0.8671875\n",
      "Iteration:  1746  Loss:  0.28149825   Accuracy:  0.9296875\n",
      "Iteration:  1747  Loss:  0.33575833   Accuracy:  0.859375\n",
      "Iteration:  1748  Loss:  0.20075804   Accuracy:  0.9296875\n",
      "Iteration:  1749  Loss:  0.22189473   Accuracy:  0.90625\n",
      "Iteration:  1750  Loss:  0.3079216   Accuracy:  0.9140625\n",
      "Iteration:  1751  Loss:  0.21270236   Accuracy:  0.9375\n",
      "Iteration:  1752  Loss:  0.21079084   Accuracy:  0.9375\n",
      "Iteration:  1753  Loss:  0.17955554   Accuracy:  0.953125\n",
      "Iteration:  1754  Loss:  0.26579309   Accuracy:  0.9140625\n",
      "Iteration:  1755  Loss:  0.24723928   Accuracy:  0.8984375\n",
      "Iteration:  1756  Loss:  0.19573893   Accuracy:  0.9296875\n",
      "Iteration:  1757  Loss:  0.3169322   Accuracy:  0.8984375\n",
      "Iteration:  1758  Loss:  0.42125246   Accuracy:  0.8671875\n",
      "Iteration:  1759  Loss:  0.33389923   Accuracy:  0.90625\n",
      "Iteration:  1760  Loss:  0.3417023   Accuracy:  0.90625\n",
      "Iteration:  1761  Loss:  0.20093232   Accuracy:  0.953125\n",
      "Iteration:  1762  Loss:  0.2560519   Accuracy:  0.890625\n",
      "Iteration:  1763  Loss:  0.29862645   Accuracy:  0.9140625\n",
      "Iteration:  1764  Loss:  0.20946345   Accuracy:  0.9296875\n",
      "Iteration:  1765  Loss:  0.19743922   Accuracy:  0.9453125\n",
      "Iteration:  1766  Loss:  0.18823744   Accuracy:  0.9453125\n",
      "Iteration:  1767  Loss:  0.28023806   Accuracy:  0.9296875\n",
      "Iteration:  1768  Loss:  0.38870227   Accuracy:  0.921875\n",
      "Iteration:  1769  Loss:  0.17411514   Accuracy:  0.953125\n",
      "Iteration:  1770  Loss:  0.36696762   Accuracy:  0.8828125\n",
      "Iteration:  1771  Loss:  0.23377538   Accuracy:  0.9375\n",
      "Iteration:  1772  Loss:  0.2481865   Accuracy:  0.9296875\n",
      "Iteration:  1773  Loss:  0.24619901   Accuracy:  0.921875\n",
      "Iteration:  1774  Loss:  0.3172309   Accuracy:  0.90625\n",
      "Iteration:  1775  Loss:  0.159001   Accuracy:  0.9375\n",
      "Iteration:  1776  Loss:  0.3832683   Accuracy:  0.890625\n",
      "Iteration:  1777  Loss:  0.2269293   Accuracy:  0.9296875\n",
      "Iteration:  1778  Loss:  0.29692575   Accuracy:  0.90625\n",
      "Iteration:  1779  Loss:  0.27488688   Accuracy:  0.9140625\n",
      "Iteration:  1780  Loss:  0.21070306   Accuracy:  0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1781  Loss:  0.3569339   Accuracy:  0.8984375\n",
      "Iteration:  1782  Loss:  0.18686634   Accuracy:  0.9609375\n",
      "Iteration:  1783  Loss:  0.36941868   Accuracy:  0.890625\n",
      "Iteration:  1784  Loss:  0.20006731   Accuracy:  0.921875\n",
      "Iteration:  1785  Loss:  0.23890164   Accuracy:  0.9140625\n",
      "Iteration:  1786  Loss:  0.2973688   Accuracy:  0.921875\n",
      "Iteration:  1787  Loss:  0.21839482   Accuracy:  0.9296875\n",
      "Iteration:  1788  Loss:  0.22512658   Accuracy:  0.9453125\n",
      "Iteration:  1789  Loss:  0.27751583   Accuracy:  0.9296875\n",
      "Iteration:  1790  Loss:  0.3285253   Accuracy:  0.9140625\n",
      "Iteration:  1791  Loss:  0.15351883   Accuracy:  0.953125\n",
      "Iteration:  1792  Loss:  0.26719832   Accuracy:  0.9140625\n",
      "Iteration:  1793  Loss:  0.25305355   Accuracy:  0.9609375\n",
      "Iteration:  1794  Loss:  0.2867368   Accuracy:  0.9140625\n",
      "Iteration:  1795  Loss:  0.38663644   Accuracy:  0.875\n",
      "Iteration:  1796  Loss:  0.2701362   Accuracy:  0.90625\n",
      "Iteration:  1797  Loss:  0.18679327   Accuracy:  0.9609375\n",
      "Iteration:  1798  Loss:  0.12850113   Accuracy:  0.9609375\n",
      "Iteration:  1799  Loss:  0.43552443   Accuracy:  0.9140625\n",
      "Iteration:  1800  Loss:  0.31242755   Accuracy:  0.890625\n",
      "Iteration:  1801  Loss:  0.3104939   Accuracy:  0.8984375\n",
      "Iteration:  1802  Loss:  0.23661137   Accuracy:  0.953125\n",
      "Iteration:  1803  Loss:  0.21482244   Accuracy:  0.9453125\n",
      "Iteration:  1804  Loss:  0.20388338   Accuracy:  0.921875\n",
      "Iteration:  1805  Loss:  0.20626643   Accuracy:  0.9375\n",
      "Iteration:  1806  Loss:  0.2520851   Accuracy:  0.90625\n",
      "Iteration:  1807  Loss:  0.2624413   Accuracy:  0.921875\n",
      "Iteration:  1808  Loss:  0.23671831   Accuracy:  0.9375\n",
      "Iteration:  1809  Loss:  0.2896314   Accuracy:  0.90625\n",
      "Iteration:  1810  Loss:  0.2750101   Accuracy:  0.8984375\n",
      "Iteration:  1811  Loss:  0.3758705   Accuracy:  0.9375\n",
      "Iteration:  1812  Loss:  0.30527595   Accuracy:  0.8984375\n",
      "Iteration:  1813  Loss:  0.24118876   Accuracy:  0.9140625\n",
      "Iteration:  1814  Loss:  0.18749838   Accuracy:  0.9453125\n",
      "Iteration:  1815  Loss:  0.30628797   Accuracy:  0.8828125\n",
      "Iteration:  1816  Loss:  0.29336068   Accuracy:  0.9296875\n",
      "Iteration:  1817  Loss:  0.3389356   Accuracy:  0.921875\n",
      "Iteration:  1818  Loss:  0.25836423   Accuracy:  0.9453125\n",
      "Iteration:  1819  Loss:  0.27358672   Accuracy:  0.9296875\n",
      "Iteration:  1820  Loss:  0.45369187   Accuracy:  0.8984375\n",
      "Iteration:  1821  Loss:  0.2496475   Accuracy:  0.9140625\n",
      "Iteration:  1822  Loss:  0.21183307   Accuracy:  0.921875\n",
      "Iteration:  1823  Loss:  0.21456784   Accuracy:  0.9453125\n",
      "Iteration:  1824  Loss:  0.24841088   Accuracy:  0.9453125\n",
      "Iteration:  1825  Loss:  0.30928305   Accuracy:  0.890625\n",
      "Iteration:  1826  Loss:  0.22908166   Accuracy:  0.9375\n",
      "Iteration:  1827  Loss:  0.3726954   Accuracy:  0.921875\n",
      "Iteration:  1828  Loss:  0.26541927   Accuracy:  0.9296875\n",
      "Iteration:  1829  Loss:  0.29618943   Accuracy:  0.921875\n",
      "Iteration:  1830  Loss:  0.26538876   Accuracy:  0.9140625\n",
      "Iteration:  1831  Loss:  0.28725296   Accuracy:  0.8984375\n",
      "Iteration:  1832  Loss:  0.4718091   Accuracy:  0.8984375\n",
      "Iteration:  1833  Loss:  0.17743677   Accuracy:  0.953125\n",
      "Iteration:  1834  Loss:  0.25806776   Accuracy:  0.9453125\n",
      "Iteration:  1835  Loss:  0.37746283   Accuracy:  0.90625\n",
      "Iteration:  1836  Loss:  0.3374173   Accuracy:  0.9140625\n",
      "Iteration:  1837  Loss:  0.19292706   Accuracy:  0.953125\n",
      "Iteration:  1838  Loss:  0.3768685   Accuracy:  0.90625\n",
      "Iteration:  1839  Loss:  0.3255909   Accuracy:  0.90625\n",
      "Iteration:  1840  Loss:  0.23256558   Accuracy:  0.921875\n",
      "Iteration:  1841  Loss:  0.25345162   Accuracy:  0.9375\n",
      "Iteration:  1842  Loss:  0.26314825   Accuracy:  0.9375\n",
      "Iteration:  1843  Loss:  0.24354826   Accuracy:  0.9375\n",
      "Iteration:  1844  Loss:  0.23935814   Accuracy:  0.921875\n",
      "Iteration:  1845  Loss:  0.4115456   Accuracy:  0.8828125\n",
      "Iteration:  1846  Loss:  0.3091897   Accuracy:  0.90625\n",
      "Iteration:  1847  Loss:  0.30692613   Accuracy:  0.90625\n",
      "Iteration:  1848  Loss:  0.2963688   Accuracy:  0.921875\n",
      "Iteration:  1849  Loss:  0.29441655   Accuracy:  0.90625\n",
      "Iteration:  1850  Loss:  0.19361702   Accuracy:  0.9609375\n",
      "Iteration:  1851  Loss:  0.16388695   Accuracy:  0.9609375\n",
      "Iteration:  1852  Loss:  0.25320148   Accuracy:  0.9140625\n",
      "Iteration:  1853  Loss:  0.30009696   Accuracy:  0.9140625\n",
      "Iteration:  1854  Loss:  0.30101544   Accuracy:  0.953125\n",
      "Iteration:  1855  Loss:  0.36870348   Accuracy:  0.8671875\n",
      "Iteration:  1856  Loss:  0.31329533   Accuracy:  0.8984375\n",
      "Iteration:  1857  Loss:  0.32615912   Accuracy:  0.90625\n",
      "Iteration:  1858  Loss:  0.18008691   Accuracy:  0.9609375\n",
      "Iteration:  1859  Loss:  0.19213289   Accuracy:  0.9375\n",
      "Iteration:  1860  Loss:  0.30040783   Accuracy:  0.921875\n",
      "Iteration:  1861  Loss:  0.18543617   Accuracy:  0.9375\n",
      "Iteration:  1862  Loss:  0.15639605   Accuracy:  0.984375\n",
      "Iteration:  1863  Loss:  0.20696573   Accuracy:  0.9375\n",
      "Iteration:  1864  Loss:  0.37320927   Accuracy:  0.8984375\n",
      "Iteration:  1865  Loss:  0.34108415   Accuracy:  0.9140625\n",
      "Iteration:  1866  Loss:  0.17641774   Accuracy:  0.9375\n",
      "Iteration:  1867  Loss:  0.28962255   Accuracy:  0.9296875\n",
      "Iteration:  1868  Loss:  0.48789588   Accuracy:  0.890625\n",
      "Iteration:  1869  Loss:  0.21299168   Accuracy:  0.9296875\n",
      "Iteration:  1870  Loss:  0.30222997   Accuracy:  0.90625\n",
      "Iteration:  1871  Loss:  0.2978014   Accuracy:  0.921875\n",
      "Iteration:  1872  Loss:  0.30481791   Accuracy:  0.90625\n",
      "Iteration:  1873  Loss:  0.38788363   Accuracy:  0.8828125\n",
      "Iteration:  1874  Loss:  0.20075713   Accuracy:  0.9296875\n",
      "Iteration:  1875  Loss:  0.20169282   Accuracy:  0.9375\n",
      "Iteration:  1876  Loss:  0.29462257   Accuracy:  0.921875\n",
      "Iteration:  1877  Loss:  0.26113343   Accuracy:  0.9296875\n",
      "Iteration:  1878  Loss:  0.18924552   Accuracy:  0.9453125\n",
      "Iteration:  1879  Loss:  0.35909814   Accuracy:  0.875\n",
      "Iteration:  1880  Loss:  0.3492247   Accuracy:  0.8984375\n",
      "Iteration:  1881  Loss:  0.32500058   Accuracy:  0.90625\n",
      "Iteration:  1882  Loss:  0.32854325   Accuracy:  0.9296875\n",
      "Iteration:  1883  Loss:  0.19624123   Accuracy:  0.953125\n",
      "Iteration:  1884  Loss:  0.31931677   Accuracy:  0.8984375\n",
      "Iteration:  1885  Loss:  0.35813603   Accuracy:  0.875\n",
      "Iteration:  1886  Loss:  0.42256021   Accuracy:  0.890625\n",
      "Iteration:  1887  Loss:  0.263542   Accuracy:  0.8984375\n",
      "Iteration:  1888  Loss:  0.23225169   Accuracy:  0.9375\n",
      "Iteration:  1889  Loss:  0.18947887   Accuracy:  0.9375\n",
      "Iteration:  1890  Loss:  0.2758569   Accuracy:  0.921875\n",
      "Iteration:  1891  Loss:  0.39910147   Accuracy:  0.8828125\n",
      "Iteration:  1892  Loss:  0.14557688   Accuracy:  0.953125\n",
      "Iteration:  1893  Loss:  0.2831433   Accuracy:  0.921875\n",
      "Iteration:  1894  Loss:  0.28872836   Accuracy:  0.9140625\n",
      "Iteration:  1895  Loss:  0.28320217   Accuracy:  0.890625\n",
      "Iteration:  1896  Loss:  0.22183527   Accuracy:  0.9375\n",
      "Iteration:  1897  Loss:  0.2813102   Accuracy:  0.9296875\n",
      "Iteration:  1898  Loss:  0.3207293   Accuracy:  0.90625\n",
      "Iteration:  1899  Loss:  0.24418235   Accuracy:  0.9296875\n",
      "Iteration:  1900  Loss:  0.22552523   Accuracy:  0.9453125\n",
      "Iteration:  1901  Loss:  0.2612669   Accuracy:  0.8984375\n",
      "Iteration:  1902  Loss:  0.2919817   Accuracy:  0.9296875\n",
      "Iteration:  1903  Loss:  0.23699313   Accuracy:  0.90625\n",
      "Iteration:  1904  Loss:  0.29388112   Accuracy:  0.9140625\n",
      "Iteration:  1905  Loss:  0.14814866   Accuracy:  0.953125\n",
      "Iteration:  1906  Loss:  0.3715872   Accuracy:  0.90625\n",
      "Iteration:  1907  Loss:  0.17089549   Accuracy:  0.9453125\n",
      "Iteration:  1908  Loss:  0.31498092   Accuracy:  0.9140625\n",
      "Iteration:  1909  Loss:  0.27703094   Accuracy:  0.90625\n",
      "Iteration:  1910  Loss:  0.25146368   Accuracy:  0.90625\n",
      "Iteration:  1911  Loss:  0.16699767   Accuracy:  0.953125\n",
      "Iteration:  1912  Loss:  0.42750284   Accuracy:  0.8828125\n",
      "Iteration:  1913  Loss:  0.2414921   Accuracy:  0.9453125\n",
      "Iteration:  1914  Loss:  0.336016   Accuracy:  0.890625\n",
      "Iteration:  1915  Loss:  0.27891362   Accuracy:  0.9140625\n",
      "Iteration:  1916  Loss:  0.14979911   Accuracy:  0.9609375\n",
      "Iteration:  1917  Loss:  0.17971873   Accuracy:  0.9453125\n",
      "Iteration:  1918  Loss:  0.43735692   Accuracy:  0.875\n",
      "Iteration:  1919  Loss:  0.26481515   Accuracy:  0.921875\n",
      "Iteration:  1920  Loss:  0.34691414   Accuracy:  0.8984375\n",
      "Iteration:  1921  Loss:  0.27763057   Accuracy:  0.9296875\n",
      "Iteration:  1922  Loss:  0.25308773   Accuracy:  0.9140625\n",
      "Iteration:  1923  Loss:  0.2095697   Accuracy:  0.9453125\n",
      "Iteration:  1924  Loss:  0.4058448   Accuracy:  0.8671875\n",
      "Iteration:  1925  Loss:  0.20214446   Accuracy:  0.953125\n",
      "Iteration:  1926  Loss:  0.22780183   Accuracy:  0.90625\n",
      "Iteration:  1927  Loss:  0.25825948   Accuracy:  0.9296875\n",
      "Iteration:  1928  Loss:  0.27116644   Accuracy:  0.9375\n",
      "Iteration:  1929  Loss:  0.355018   Accuracy:  0.8984375\n",
      "Iteration:  1930  Loss:  0.23623312   Accuracy:  0.921875\n",
      "Iteration:  1931  Loss:  0.39613903   Accuracy:  0.8984375\n",
      "Iteration:  1932  Loss:  0.27340353   Accuracy:  0.9296875\n",
      "Iteration:  1933  Loss:  0.2906937   Accuracy:  0.9375\n",
      "Iteration:  1934  Loss:  0.28120613   Accuracy:  0.8828125\n",
      "Iteration:  1935  Loss:  0.27952468   Accuracy:  0.90625\n",
      "Iteration:  1936  Loss:  0.32300994   Accuracy:  0.9296875\n",
      "Iteration:  1937  Loss:  0.29495418   Accuracy:  0.90625\n",
      "Iteration:  1938  Loss:  0.28345093   Accuracy:  0.90625\n",
      "Iteration:  1939  Loss:  0.31740752   Accuracy:  0.9140625\n",
      "Iteration:  1940  Loss:  0.34475556   Accuracy:  0.8984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1941  Loss:  0.24320145   Accuracy:  0.8984375\n",
      "Iteration:  1942  Loss:  0.24558368   Accuracy:  0.9375\n",
      "Iteration:  1943  Loss:  0.33524874   Accuracy:  0.875\n",
      "Iteration:  1944  Loss:  0.26401734   Accuracy:  0.9140625\n",
      "Iteration:  1945  Loss:  0.3244912   Accuracy:  0.9140625\n",
      "Iteration:  1946  Loss:  0.2252385   Accuracy:  0.9453125\n",
      "Iteration:  1947  Loss:  0.221433   Accuracy:  0.921875\n",
      "Iteration:  1948  Loss:  0.25553006   Accuracy:  0.90625\n",
      "Iteration:  1949  Loss:  0.227435   Accuracy:  0.9296875\n",
      "Iteration:  1950  Loss:  0.3307797   Accuracy:  0.90625\n",
      "Iteration:  1951  Loss:  0.2622085   Accuracy:  0.9140625\n",
      "Iteration:  1952  Loss:  0.25713712   Accuracy:  0.921875\n",
      "Iteration:  1953  Loss:  0.19825104   Accuracy:  0.9453125\n",
      "Iteration:  1954  Loss:  0.41635793   Accuracy:  0.8984375\n",
      "Iteration:  1955  Loss:  0.23264483   Accuracy:  0.90625\n",
      "Iteration:  1956  Loss:  0.34872857   Accuracy:  0.9140625\n",
      "Iteration:  1957  Loss:  0.4942869   Accuracy:  0.875\n",
      "Iteration:  1958  Loss:  0.2627321   Accuracy:  0.921875\n",
      "Iteration:  1959  Loss:  0.2943287   Accuracy:  0.9453125\n",
      "Iteration:  1960  Loss:  0.28068453   Accuracy:  0.9296875\n",
      "Iteration:  1961  Loss:  0.26241994   Accuracy:  0.9296875\n",
      "Iteration:  1962  Loss:  0.21195555   Accuracy:  0.921875\n",
      "Iteration:  1963  Loss:  0.26595324   Accuracy:  0.9140625\n",
      "Iteration:  1964  Loss:  0.3946965   Accuracy:  0.890625\n",
      "Iteration:  1965  Loss:  0.2554199   Accuracy:  0.953125\n",
      "Iteration:  1966  Loss:  0.44333518   Accuracy:  0.8515625\n",
      "Iteration:  1967  Loss:  0.3294469   Accuracy:  0.890625\n",
      "Iteration:  1968  Loss:  0.17121544   Accuracy:  0.9453125\n",
      "Iteration:  1969  Loss:  0.40736362   Accuracy:  0.90625\n",
      "Iteration:  1970  Loss:  0.3345332   Accuracy:  0.9296875\n",
      "Iteration:  1971  Loss:  0.40015733   Accuracy:  0.8671875\n",
      "Iteration:  1972  Loss:  0.25905356   Accuracy:  0.9375\n",
      "Iteration:  1973  Loss:  0.26202974   Accuracy:  0.953125\n",
      "Iteration:  1974  Loss:  0.21875304   Accuracy:  0.90625\n",
      "Iteration:  1975  Loss:  0.31143695   Accuracy:  0.90625\n",
      "Iteration:  1976  Loss:  0.39983028   Accuracy:  0.90625\n",
      "Iteration:  1977  Loss:  0.32345623   Accuracy:  0.9140625\n",
      "Iteration:  1978  Loss:  0.23875663   Accuracy:  0.90625\n",
      "Iteration:  1979  Loss:  0.23152491   Accuracy:  0.921875\n",
      "Iteration:  1980  Loss:  0.24898098   Accuracy:  0.9296875\n",
      "Iteration:  1981  Loss:  0.2243368   Accuracy:  0.9296875\n",
      "Iteration:  1982  Loss:  0.27315155   Accuracy:  0.90625\n",
      "Iteration:  1983  Loss:  0.18635431   Accuracy:  0.921875\n",
      "Iteration:  1984  Loss:  0.38691366   Accuracy:  0.921875\n",
      "Iteration:  1985  Loss:  0.22862107   Accuracy:  0.9296875\n",
      "Iteration:  1986  Loss:  0.25265267   Accuracy:  0.9296875\n",
      "Iteration:  1987  Loss:  0.2240423   Accuracy:  0.9296875\n",
      "Iteration:  1988  Loss:  0.23512626   Accuracy:  0.9375\n",
      "Iteration:  1989  Loss:  0.2615249   Accuracy:  0.9453125\n",
      "Iteration:  1990  Loss:  0.34120435   Accuracy:  0.8828125\n",
      "Iteration:  1991  Loss:  0.26792416   Accuracy:  0.921875\n",
      "Iteration:  1992  Loss:  0.47638434   Accuracy:  0.875\n",
      "Iteration:  1993  Loss:  0.1307337   Accuracy:  0.9609375\n",
      "Iteration:  1994  Loss:  0.3023234   Accuracy:  0.921875\n",
      "Iteration:  1995  Loss:  0.3370186   Accuracy:  0.921875\n",
      "Iteration:  1996  Loss:  0.22830763   Accuracy:  0.9296875\n",
      "Iteration:  1997  Loss:  0.24489997   Accuracy:  0.9140625\n",
      "Iteration:  1998  Loss:  0.19374971   Accuracy:  0.9375\n",
      "Iteration:  1999  Loss:  0.24689716   Accuracy:  0.921875\n",
      "Iteration:  2000  Loss:  0.31572157   Accuracy:  0.9140625\n",
      "Iteration:  2001  Loss:  0.23956944   Accuracy:  0.9296875\n",
      "Iteration:  2002  Loss:  0.25120062   Accuracy:  0.921875\n",
      "Iteration:  2003  Loss:  0.2491892   Accuracy:  0.9609375\n",
      "Iteration:  2004  Loss:  0.22012684   Accuracy:  0.9140625\n",
      "Iteration:  2005  Loss:  0.26926804   Accuracy:  0.9296875\n",
      "Iteration:  2006  Loss:  0.18353742   Accuracy:  0.9375\n",
      "Iteration:  2007  Loss:  0.2710637   Accuracy:  0.9375\n",
      "Iteration:  2008  Loss:  0.3973127   Accuracy:  0.890625\n",
      "Iteration:  2009  Loss:  0.27958083   Accuracy:  0.9296875\n",
      "Iteration:  2010  Loss:  0.11552726   Accuracy:  0.984375\n",
      "Iteration:  2011  Loss:  0.35046306   Accuracy:  0.9140625\n",
      "Iteration:  2012  Loss:  0.18164599   Accuracy:  0.9453125\n",
      "Iteration:  2013  Loss:  0.20856176   Accuracy:  0.9375\n",
      "Iteration:  2014  Loss:  0.3893955   Accuracy:  0.875\n",
      "Iteration:  2015  Loss:  0.32825136   Accuracy:  0.9296875\n",
      "Iteration:  2016  Loss:  0.1895994   Accuracy:  0.953125\n",
      "Iteration:  2017  Loss:  0.46434224   Accuracy:  0.8828125\n",
      "Iteration:  2018  Loss:  0.47768682   Accuracy:  0.8828125\n",
      "Iteration:  2019  Loss:  0.3218904   Accuracy:  0.9140625\n",
      "Iteration:  2020  Loss:  0.22386837   Accuracy:  0.9296875\n",
      "Iteration:  2021  Loss:  0.30433092   Accuracy:  0.9140625\n",
      "Iteration:  2022  Loss:  0.3032947   Accuracy:  0.90625\n",
      "Iteration:  2023  Loss:  0.34076104   Accuracy:  0.921875\n",
      "Iteration:  2024  Loss:  0.3156205   Accuracy:  0.90625\n",
      "Iteration:  2025  Loss:  0.39194208   Accuracy:  0.8984375\n",
      "Iteration:  2026  Loss:  0.3755483   Accuracy:  0.9296875\n",
      "Iteration:  2027  Loss:  0.36958295   Accuracy:  0.890625\n",
      "Iteration:  2028  Loss:  0.23469158   Accuracy:  0.9375\n",
      "Iteration:  2029  Loss:  0.19600964   Accuracy:  0.9453125\n",
      "Iteration:  2030  Loss:  0.19214173   Accuracy:  0.9453125\n",
      "Iteration:  2031  Loss:  0.27209336   Accuracy:  0.90625\n",
      "Iteration:  2032  Loss:  0.3716381   Accuracy:  0.8828125\n",
      "Iteration:  2033  Loss:  0.33708262   Accuracy:  0.90625\n",
      "Iteration:  2034  Loss:  0.18918562   Accuracy:  0.953125\n",
      "Iteration:  2035  Loss:  0.20797235   Accuracy:  0.9375\n",
      "Iteration:  2036  Loss:  0.21619025   Accuracy:  0.9375\n",
      "Iteration:  2037  Loss:  0.28873506   Accuracy:  0.90625\n",
      "Iteration:  2038  Loss:  0.21820045   Accuracy:  0.9296875\n",
      "Iteration:  2039  Loss:  0.33892998   Accuracy:  0.890625\n",
      "Iteration:  2040  Loss:  0.10925148   Accuracy:  0.96875\n",
      "Iteration:  2041  Loss:  0.24085525   Accuracy:  0.90625\n",
      "Iteration:  2042  Loss:  0.29195526   Accuracy:  0.9296875\n",
      "Iteration:  2043  Loss:  0.17592591   Accuracy:  0.9609375\n",
      "Iteration:  2044  Loss:  0.24949048   Accuracy:  0.9296875\n",
      "Iteration:  2045  Loss:  0.24887167   Accuracy:  0.9140625\n",
      "Iteration:  2046  Loss:  0.26992932   Accuracy:  0.9140625\n",
      "Iteration:  2047  Loss:  0.25678807   Accuracy:  0.9296875\n",
      "Iteration:  2048  Loss:  0.32362536   Accuracy:  0.9296875\n",
      "Iteration:  2049  Loss:  0.33006573   Accuracy:  0.9140625\n",
      "Iteration:  2050  Loss:  0.2836181   Accuracy:  0.8984375\n",
      "Iteration:  2051  Loss:  0.30050912   Accuracy:  0.8984375\n",
      "Iteration:  2052  Loss:  0.18978676   Accuracy:  0.9609375\n",
      "Iteration:  2053  Loss:  0.44683254   Accuracy:  0.9140625\n",
      "Iteration:  2054  Loss:  0.43385568   Accuracy:  0.8671875\n",
      "Iteration:  2055  Loss:  0.29139423   Accuracy:  0.90625\n",
      "Iteration:  2056  Loss:  0.28542477   Accuracy:  0.890625\n",
      "Iteration:  2057  Loss:  0.268838   Accuracy:  0.9375\n",
      "Iteration:  2058  Loss:  0.30248982   Accuracy:  0.8828125\n",
      "Iteration:  2059  Loss:  0.29709855   Accuracy:  0.8984375\n",
      "Iteration:  2060  Loss:  0.16795634   Accuracy:  0.953125\n",
      "Iteration:  2061  Loss:  0.41773236   Accuracy:  0.921875\n",
      "Iteration:  2062  Loss:  0.4229514   Accuracy:  0.859375\n",
      "Iteration:  2063  Loss:  0.20024222   Accuracy:  0.953125\n",
      "Iteration:  2064  Loss:  0.20293877   Accuracy:  0.9296875\n",
      "Iteration:  2065  Loss:  0.3888144   Accuracy:  0.890625\n",
      "Iteration:  2066  Loss:  0.39063132   Accuracy:  0.9140625\n",
      "Iteration:  2067  Loss:  0.31235987   Accuracy:  0.890625\n",
      "Iteration:  2068  Loss:  0.2947229   Accuracy:  0.8984375\n",
      "Iteration:  2069  Loss:  0.19501421   Accuracy:  0.9453125\n",
      "Iteration:  2070  Loss:  0.21923178   Accuracy:  0.9140625\n",
      "Iteration:  2071  Loss:  0.20514947   Accuracy:  0.9453125\n",
      "Iteration:  2072  Loss:  0.24339819   Accuracy:  0.921875\n",
      "Iteration:  2073  Loss:  0.22078148   Accuracy:  0.9453125\n",
      "Iteration:  2074  Loss:  0.22833852   Accuracy:  0.9296875\n",
      "Iteration:  2075  Loss:  0.33960915   Accuracy:  0.8828125\n",
      "Iteration:  2076  Loss:  0.24672939   Accuracy:  0.8984375\n",
      "Iteration:  2077  Loss:  0.19024399   Accuracy:  0.9375\n",
      "Iteration:  2078  Loss:  0.33265436   Accuracy:  0.9140625\n",
      "Iteration:  2079  Loss:  0.2816128   Accuracy:  0.9140625\n",
      "Iteration:  2080  Loss:  0.42418516   Accuracy:  0.8984375\n",
      "Iteration:  2081  Loss:  0.25782073   Accuracy:  0.921875\n",
      "Iteration:  2082  Loss:  0.45141003   Accuracy:  0.8828125\n",
      "Iteration:  2083  Loss:  0.16010456   Accuracy:  0.9453125\n",
      "Iteration:  2084  Loss:  0.16583227   Accuracy:  0.953125\n",
      "Iteration:  2085  Loss:  0.15975308   Accuracy:  0.953125\n",
      "Iteration:  2086  Loss:  0.20176943   Accuracy:  0.921875\n",
      "Iteration:  2087  Loss:  0.28557727   Accuracy:  0.953125\n",
      "Iteration:  2088  Loss:  0.38812822   Accuracy:  0.8828125\n",
      "Iteration:  2089  Loss:  0.3992635   Accuracy:  0.90625\n",
      "Iteration:  2090  Loss:  0.18314789   Accuracy:  0.9375\n",
      "Iteration:  2091  Loss:  0.23881343   Accuracy:  0.921875\n",
      "Iteration:  2092  Loss:  0.29056123   Accuracy:  0.8984375\n",
      "Iteration:  2093  Loss:  0.25827116   Accuracy:  0.8984375\n",
      "Iteration:  2094  Loss:  0.30927667   Accuracy:  0.90625\n",
      "Iteration:  2095  Loss:  0.31517506   Accuracy:  0.875\n",
      "Iteration:  2096  Loss:  0.29789245   Accuracy:  0.921875\n",
      "Iteration:  2097  Loss:  0.119593635   Accuracy:  0.9765625\n",
      "Iteration:  2098  Loss:  0.34759787   Accuracy:  0.90625\n",
      "Iteration:  2099  Loss:  0.22112316   Accuracy:  0.953125\n",
      "Iteration:  2100  Loss:  0.2223963   Accuracy:  0.9453125\n",
      "Iteration:  2101  Loss:  0.26224488   Accuracy:  0.9140625\n",
      "Iteration:  2102  Loss:  0.23653287   Accuracy:  0.9296875\n",
      "Iteration:  2103  Loss:  0.2172218   Accuracy:  0.9453125\n",
      "Iteration:  2104  Loss:  0.18272439   Accuracy:  0.953125\n",
      "Iteration:  2105  Loss:  0.36858955   Accuracy:  0.9140625\n",
      "Iteration:  2106  Loss:  0.28799838   Accuracy:  0.90625\n",
      "Iteration:  2107  Loss:  0.35307175   Accuracy:  0.9140625\n",
      "Iteration:  2108  Loss:  0.26686984   Accuracy:  0.90625\n",
      "Iteration:  2109  Loss:  0.2555102   Accuracy:  0.9140625\n",
      "Iteration:  2110  Loss:  0.23008253   Accuracy:  0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2111  Loss:  0.20131978   Accuracy:  0.9375\n",
      "Iteration:  2112  Loss:  0.3751483   Accuracy:  0.8984375\n",
      "Iteration:  2113  Loss:  0.19238174   Accuracy:  0.9453125\n",
      "Iteration:  2114  Loss:  0.21406671   Accuracy:  0.9453125\n",
      "Iteration:  2115  Loss:  0.3846533   Accuracy:  0.90625\n",
      "Iteration:  2116  Loss:  0.3534721   Accuracy:  0.90625\n",
      "Iteration:  2117  Loss:  0.3109679   Accuracy:  0.90625\n",
      "Iteration:  2118  Loss:  0.29539695   Accuracy:  0.9140625\n",
      "Iteration:  2119  Loss:  0.32260603   Accuracy:  0.9375\n",
      "Iteration:  2120  Loss:  0.27467132   Accuracy:  0.90625\n",
      "Iteration:  2121  Loss:  0.3238924   Accuracy:  0.9375\n",
      "Iteration:  2122  Loss:  0.20167822   Accuracy:  0.953125\n",
      "Iteration:  2123  Loss:  0.29637188   Accuracy:  0.9140625\n",
      "Iteration:  2124  Loss:  0.22792393   Accuracy:  0.9375\n",
      "Iteration:  2125  Loss:  0.3944352   Accuracy:  0.90625\n",
      "Iteration:  2126  Loss:  0.32450822   Accuracy:  0.8984375\n",
      "Iteration:  2127  Loss:  0.33001384   Accuracy:  0.9140625\n",
      "Iteration:  2128  Loss:  0.26097438   Accuracy:  0.9375\n",
      "Iteration:  2129  Loss:  0.23504153   Accuracy:  0.9375\n",
      "Iteration:  2130  Loss:  0.27686614   Accuracy:  0.9375\n",
      "Iteration:  2131  Loss:  0.17984173   Accuracy:  0.953125\n",
      "Iteration:  2132  Loss:  0.29800054   Accuracy:  0.890625\n",
      "Iteration:  2133  Loss:  0.35075304   Accuracy:  0.90625\n",
      "Iteration:  2134  Loss:  0.20194794   Accuracy:  0.953125\n",
      "Iteration:  2135  Loss:  0.25953066   Accuracy:  0.9140625\n",
      "Iteration:  2136  Loss:  0.33032507   Accuracy:  0.875\n",
      "Iteration:  2137  Loss:  0.356892   Accuracy:  0.875\n",
      "Iteration:  2138  Loss:  0.21695434   Accuracy:  0.9375\n",
      "Iteration:  2139  Loss:  0.2675242   Accuracy:  0.90625\n",
      "Iteration:  2140  Loss:  0.28240147   Accuracy:  0.921875\n",
      "Iteration:  2141  Loss:  0.25247306   Accuracy:  0.90625\n",
      "Iteration:  2142  Loss:  0.23282738   Accuracy:  0.9453125\n",
      "Iteration:  2143  Loss:  0.38065165   Accuracy:  0.8671875\n",
      "Iteration:  2144  Loss:  0.2733532   Accuracy:  0.921875\n",
      "Iteration:  2145  Loss:  0.14271988   Accuracy:  0.9765625\n",
      "Iteration:  2146  Loss:  0.25111395   Accuracy:  0.921875\n",
      "Iteration:  2147  Loss:  0.27616218   Accuracy:  0.90625\n",
      "Iteration:  2148  Loss:  0.28244314   Accuracy:  0.921875\n",
      "Iteration:  2149  Loss:  0.22891542   Accuracy:  0.9375\n",
      "Iteration:  2150  Loss:  0.20073497   Accuracy:  0.9296875\n",
      "Iteration:  2151  Loss:  0.38360187   Accuracy:  0.8828125\n",
      "Iteration:  2152  Loss:  0.2134358   Accuracy:  0.9375\n",
      "Iteration:  2153  Loss:  0.32748917   Accuracy:  0.953125\n",
      "Iteration:  2154  Loss:  0.36455864   Accuracy:  0.90625\n",
      "Iteration:  2155  Loss:  0.21813832   Accuracy:  0.9375\n",
      "Iteration:  2156  Loss:  0.18178514   Accuracy:  0.953125\n",
      "Iteration:  2157  Loss:  0.16822404   Accuracy:  0.9609375\n",
      "Iteration:  2158  Loss:  0.19681725   Accuracy:  0.9453125\n",
      "Iteration:  2159  Loss:  0.15741333   Accuracy:  0.9453125\n",
      "Iteration:  2160  Loss:  0.23861867   Accuracy:  0.9296875\n",
      "Iteration:  2161  Loss:  0.43955922   Accuracy:  0.8359375\n",
      "Iteration:  2162  Loss:  0.36373526   Accuracy:  0.921875\n",
      "Iteration:  2163  Loss:  0.22315572   Accuracy:  0.953125\n",
      "Iteration:  2164  Loss:  0.32707366   Accuracy:  0.90625\n",
      "Iteration:  2165  Loss:  0.3161813   Accuracy:  0.9140625\n",
      "Iteration:  2166  Loss:  0.26758522   Accuracy:  0.9140625\n",
      "Iteration:  2167  Loss:  0.2466064   Accuracy:  0.8984375\n",
      "Iteration:  2168  Loss:  0.318413   Accuracy:  0.9296875\n",
      "Iteration:  2169  Loss:  0.44074535   Accuracy:  0.90625\n",
      "Iteration:  2170  Loss:  0.30485755   Accuracy:  0.9375\n",
      "Iteration:  2171  Loss:  0.28800544   Accuracy:  0.9140625\n",
      "Iteration:  2172  Loss:  0.33449522   Accuracy:  0.90625\n",
      "Iteration:  2173  Loss:  0.26464432   Accuracy:  0.90625\n",
      "Iteration:  2174  Loss:  0.2907548   Accuracy:  0.9140625\n",
      "Iteration:  2175  Loss:  0.3267952   Accuracy:  0.875\n",
      "Iteration:  2176  Loss:  0.2063089   Accuracy:  0.953125\n",
      "Iteration:  2177  Loss:  0.2892459   Accuracy:  0.9375\n",
      "Iteration:  2178  Loss:  0.21275145   Accuracy:  0.921875\n",
      "Iteration:  2179  Loss:  0.24969234   Accuracy:  0.9296875\n",
      "Iteration:  2180  Loss:  0.26211828   Accuracy:  0.9140625\n",
      "Iteration:  2181  Loss:  0.2293672   Accuracy:  0.9453125\n",
      "Iteration:  2182  Loss:  0.24071157   Accuracy:  0.921875\n",
      "Iteration:  2183  Loss:  0.27644524   Accuracy:  0.9140625\n",
      "Iteration:  2184  Loss:  0.22517294   Accuracy:  0.9296875\n",
      "Iteration:  2185  Loss:  0.3343516   Accuracy:  0.90625\n",
      "Iteration:  2186  Loss:  0.32521662   Accuracy:  0.921875\n",
      "Iteration:  2187  Loss:  0.30128065   Accuracy:  0.90625\n",
      "Iteration:  2188  Loss:  0.22210349   Accuracy:  0.921875\n",
      "Iteration:  2189  Loss:  0.24946052   Accuracy:  0.9296875\n",
      "Iteration:  2190  Loss:  0.21004675   Accuracy:  0.953125\n",
      "Iteration:  2191  Loss:  0.14991899   Accuracy:  0.96875\n",
      "Iteration:  2192  Loss:  0.17193037   Accuracy:  0.9453125\n",
      "Iteration:  2193  Loss:  0.441363   Accuracy:  0.875\n",
      "Iteration:  2194  Loss:  0.22062533   Accuracy:  0.9375\n",
      "Iteration:  2195  Loss:  0.31978244   Accuracy:  0.890625\n",
      "Iteration:  2196  Loss:  0.21668309   Accuracy:  0.9140625\n",
      "Iteration:  2197  Loss:  0.26141384   Accuracy:  0.9296875\n",
      "Iteration:  2198  Loss:  0.23584199   Accuracy:  0.9140625\n",
      "Iteration:  2199  Loss:  0.48631042   Accuracy:  0.8984375\n",
      "Iteration:  2200  Loss:  0.22318867   Accuracy:  0.9296875\n",
      "Iteration:  2201  Loss:  0.22584082   Accuracy:  0.9453125\n",
      "Iteration:  2202  Loss:  0.47277647   Accuracy:  0.9140625\n",
      "Iteration:  2203  Loss:  0.3163924   Accuracy:  0.9296875\n",
      "Iteration:  2204  Loss:  0.20857029   Accuracy:  0.9375\n",
      "Iteration:  2205  Loss:  0.25308624   Accuracy:  0.921875\n",
      "Iteration:  2206  Loss:  0.1782299   Accuracy:  0.953125\n",
      "Iteration:  2207  Loss:  0.21922454   Accuracy:  0.9609375\n",
      "Iteration:  2208  Loss:  0.23367208   Accuracy:  0.9453125\n",
      "Iteration:  2209  Loss:  0.29475927   Accuracy:  0.9296875\n",
      "Iteration:  2210  Loss:  0.3126275   Accuracy:  0.8828125\n",
      "Iteration:  2211  Loss:  0.23611143   Accuracy:  0.953125\n",
      "Iteration:  2212  Loss:  0.23976809   Accuracy:  0.9375\n",
      "Iteration:  2213  Loss:  0.3240164   Accuracy:  0.9140625\n",
      "Iteration:  2214  Loss:  0.2808095   Accuracy:  0.9296875\n",
      "Iteration:  2215  Loss:  0.3225131   Accuracy:  0.921875\n",
      "Iteration:  2216  Loss:  0.40962082   Accuracy:  0.921875\n",
      "Iteration:  2217  Loss:  0.17782979   Accuracy:  0.9375\n",
      "Iteration:  2218  Loss:  0.24173892   Accuracy:  0.921875\n",
      "Iteration:  2219  Loss:  0.3625201   Accuracy:  0.90625\n",
      "Iteration:  2220  Loss:  0.14934072   Accuracy:  0.9765625\n",
      "Iteration:  2221  Loss:  0.30200213   Accuracy:  0.9140625\n",
      "Iteration:  2222  Loss:  0.37250173   Accuracy:  0.9296875\n",
      "Iteration:  2223  Loss:  0.23770589   Accuracy:  0.921875\n",
      "Iteration:  2224  Loss:  0.17133185   Accuracy:  0.9375\n",
      "Iteration:  2225  Loss:  0.2408364   Accuracy:  0.9375\n",
      "Iteration:  2226  Loss:  0.22805476   Accuracy:  0.9296875\n",
      "Iteration:  2227  Loss:  0.39561114   Accuracy:  0.90625\n",
      "Iteration:  2228  Loss:  0.37642652   Accuracy:  0.9296875\n",
      "Iteration:  2229  Loss:  0.33230013   Accuracy:  0.8984375\n",
      "Iteration:  2230  Loss:  0.34475833   Accuracy:  0.9140625\n",
      "Iteration:  2231  Loss:  0.27938434   Accuracy:  0.9296875\n",
      "Iteration:  2232  Loss:  0.20149276   Accuracy:  0.921875\n",
      "Iteration:  2233  Loss:  0.10778304   Accuracy:  0.9609375\n",
      "Iteration:  2234  Loss:  0.25857544   Accuracy:  0.9296875\n",
      "Iteration:  2235  Loss:  0.16421859   Accuracy:  0.9609375\n",
      "Iteration:  2236  Loss:  0.42860276   Accuracy:  0.8671875\n",
      "Iteration:  2237  Loss:  0.2655424   Accuracy:  0.921875\n",
      "Iteration:  2238  Loss:  0.30222705   Accuracy:  0.890625\n",
      "Iteration:  2239  Loss:  0.307711   Accuracy:  0.9140625\n",
      "Iteration:  2240  Loss:  0.46741065   Accuracy:  0.890625\n",
      "Iteration:  2241  Loss:  0.43189391   Accuracy:  0.8671875\n",
      "Iteration:  2242  Loss:  0.31554008   Accuracy:  0.90625\n",
      "Iteration:  2243  Loss:  0.36129308   Accuracy:  0.9140625\n",
      "Iteration:  2244  Loss:  0.2357643   Accuracy:  0.9140625\n",
      "Iteration:  2245  Loss:  0.22455204   Accuracy:  0.9375\n",
      "Iteration:  2246  Loss:  0.30078977   Accuracy:  0.90625\n",
      "Iteration:  2247  Loss:  0.35173878   Accuracy:  0.890625\n",
      "Iteration:  2248  Loss:  0.23809591   Accuracy:  0.921875\n",
      "Iteration:  2249  Loss:  0.30816597   Accuracy:  0.8828125\n",
      "Iteration:  2250  Loss:  0.25589713   Accuracy:  0.9296875\n",
      "Iteration:  2251  Loss:  0.28685418   Accuracy:  0.890625\n",
      "Iteration:  2252  Loss:  0.24711421   Accuracy:  0.9296875\n",
      "Iteration:  2253  Loss:  0.44676137   Accuracy:  0.875\n",
      "Iteration:  2254  Loss:  0.25021455   Accuracy:  0.921875\n",
      "Iteration:  2255  Loss:  0.17724395   Accuracy:  0.9296875\n",
      "Iteration:  2256  Loss:  0.27777448   Accuracy:  0.9140625\n",
      "Iteration:  2257  Loss:  0.2981922   Accuracy:  0.890625\n",
      "Iteration:  2258  Loss:  0.3360901   Accuracy:  0.90625\n",
      "Iteration:  2259  Loss:  0.26686597   Accuracy:  0.90625\n",
      "Iteration:  2260  Loss:  0.2616344   Accuracy:  0.921875\n",
      "Iteration:  2261  Loss:  0.3056481   Accuracy:  0.90625\n",
      "Iteration:  2262  Loss:  0.2612402   Accuracy:  0.9375\n",
      "Iteration:  2263  Loss:  0.27644938   Accuracy:  0.9296875\n",
      "Iteration:  2264  Loss:  0.24854109   Accuracy:  0.921875\n",
      "Iteration:  2265  Loss:  0.19272052   Accuracy:  0.953125\n",
      "Iteration:  2266  Loss:  0.26027685   Accuracy:  0.921875\n",
      "Iteration:  2267  Loss:  0.28012013   Accuracy:  0.9296875\n",
      "Iteration:  2268  Loss:  0.23917915   Accuracy:  0.9296875\n",
      "Iteration:  2269  Loss:  0.28254348   Accuracy:  0.9375\n",
      "Iteration:  2270  Loss:  0.2653203   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2271  Loss:  0.20304918   Accuracy:  0.9375\n",
      "Iteration:  2272  Loss:  0.1669983   Accuracy:  0.9453125\n",
      "Iteration:  2273  Loss:  0.23730206   Accuracy:  0.9375\n",
      "Iteration:  2274  Loss:  0.3379115   Accuracy:  0.921875\n",
      "Iteration:  2275  Loss:  0.19775572   Accuracy:  0.9375\n",
      "Iteration:  2276  Loss:  0.17556983   Accuracy:  0.9453125\n",
      "Iteration:  2277  Loss:  0.31745902   Accuracy:  0.9375\n",
      "Iteration:  2278  Loss:  0.23380455   Accuracy:  0.953125\n",
      "Iteration:  2279  Loss:  0.23860869   Accuracy:  0.9296875\n",
      "Iteration:  2280  Loss:  0.18914673   Accuracy:  0.9375\n",
      "Iteration:  2281  Loss:  0.20403628   Accuracy:  0.9609375\n",
      "Iteration:  2282  Loss:  0.35809678   Accuracy:  0.875\n",
      "Iteration:  2283  Loss:  0.2515312   Accuracy:  0.90625\n",
      "Iteration:  2284  Loss:  0.3364213   Accuracy:  0.921875\n",
      "Iteration:  2285  Loss:  0.3009447   Accuracy:  0.90625\n",
      "Iteration:  2286  Loss:  0.18984637   Accuracy:  0.9375\n",
      "Iteration:  2287  Loss:  0.18327986   Accuracy:  0.9453125\n",
      "Iteration:  2288  Loss:  0.3455086   Accuracy:  0.9140625\n",
      "Iteration:  2289  Loss:  0.33088902   Accuracy:  0.90625\n",
      "Iteration:  2290  Loss:  0.2251596   Accuracy:  0.9296875\n",
      "Iteration:  2291  Loss:  0.27135393   Accuracy:  0.921875\n",
      "Iteration:  2292  Loss:  0.2681781   Accuracy:  0.921875\n",
      "Iteration:  2293  Loss:  0.26449433   Accuracy:  0.8984375\n",
      "Iteration:  2294  Loss:  0.34073415   Accuracy:  0.890625\n",
      "Iteration:  2295  Loss:  0.2497119   Accuracy:  0.9296875\n",
      "Iteration:  2296  Loss:  0.37522182   Accuracy:  0.9140625\n",
      "Iteration:  2297  Loss:  0.46293893   Accuracy:  0.8515625\n",
      "Iteration:  2298  Loss:  0.3151154   Accuracy:  0.90625\n",
      "Iteration:  2299  Loss:  0.2076405   Accuracy:  0.9375\n",
      "Iteration:  2300  Loss:  0.18064106   Accuracy:  0.9140625\n",
      "Iteration:  2301  Loss:  0.3146674   Accuracy:  0.90625\n",
      "Iteration:  2302  Loss:  0.3519979   Accuracy:  0.9296875\n",
      "Iteration:  2303  Loss:  0.27130118   Accuracy:  0.9296875\n",
      "Iteration:  2304  Loss:  0.17776145   Accuracy:  0.9609375\n",
      "Iteration:  2305  Loss:  0.3209203   Accuracy:  0.9296875\n",
      "Iteration:  2306  Loss:  0.2488509   Accuracy:  0.9296875\n",
      "Iteration:  2307  Loss:  0.179311   Accuracy:  0.9296875\n",
      "Iteration:  2308  Loss:  0.22650547   Accuracy:  0.9375\n",
      "Iteration:  2309  Loss:  0.28812122   Accuracy:  0.9375\n",
      "Iteration:  2310  Loss:  0.28453168   Accuracy:  0.921875\n",
      "Iteration:  2311  Loss:  0.35112083   Accuracy:  0.90625\n",
      "Iteration:  2312  Loss:  0.33454484   Accuracy:  0.9140625\n",
      "Iteration:  2313  Loss:  0.49418527   Accuracy:  0.8828125\n",
      "Iteration:  2314  Loss:  0.2400082   Accuracy:  0.9375\n",
      "Iteration:  2315  Loss:  0.26278687   Accuracy:  0.9140625\n",
      "Iteration:  2316  Loss:  0.3556568   Accuracy:  0.8828125\n",
      "Iteration:  2317  Loss:  0.3514283   Accuracy:  0.90625\n",
      "Iteration:  2318  Loss:  0.23170751   Accuracy:  0.953125\n",
      "Iteration:  2319  Loss:  0.44182456   Accuracy:  0.8984375\n",
      "Iteration:  2320  Loss:  0.25823623   Accuracy:  0.921875\n",
      "Iteration:  2321  Loss:  0.32534978   Accuracy:  0.90625\n",
      "Iteration:  2322  Loss:  0.25405067   Accuracy:  0.9140625\n",
      "Iteration:  2323  Loss:  0.2516836   Accuracy:  0.9375\n",
      "Iteration:  2324  Loss:  0.2671879   Accuracy:  0.9296875\n",
      "Iteration:  2325  Loss:  0.15408441   Accuracy:  0.9609375\n",
      "Iteration:  2326  Loss:  0.2678882   Accuracy:  0.9375\n",
      "Iteration:  2327  Loss:  0.27879733   Accuracy:  0.9453125\n",
      "Iteration:  2328  Loss:  0.18648803   Accuracy:  0.9609375\n",
      "Iteration:  2329  Loss:  0.54844284   Accuracy:  0.875\n",
      "Iteration:  2330  Loss:  0.23204173   Accuracy:  0.9375\n",
      "Iteration:  2331  Loss:  0.3186648   Accuracy:  0.9375\n",
      "Iteration:  2332  Loss:  0.2351784   Accuracy:  0.921875\n",
      "Iteration:  2333  Loss:  0.28269726   Accuracy:  0.9375\n",
      "Iteration:  2334  Loss:  0.29234356   Accuracy:  0.9375\n",
      "Iteration:  2335  Loss:  0.27387506   Accuracy:  0.921875\n",
      "Iteration:  2336  Loss:  0.3448519   Accuracy:  0.9140625\n",
      "Iteration:  2337  Loss:  0.12989703   Accuracy:  0.96875\n",
      "Iteration:  2338  Loss:  0.24336395   Accuracy:  0.8984375\n",
      "Iteration:  2339  Loss:  0.40417987   Accuracy:  0.90625\n",
      "Iteration:  2340  Loss:  0.11781315   Accuracy:  0.96875\n",
      "Iteration:  2341  Loss:  0.3417495   Accuracy:  0.8828125\n",
      "Iteration:  2342  Loss:  0.21813282   Accuracy:  0.9375\n",
      "Iteration:  2343  Loss:  0.19424   Accuracy:  0.9296875\n",
      "Iteration:  2344  Loss:  0.209143   Accuracy:  0.9375\n",
      "Iteration:  2345  Loss:  0.2545814   Accuracy:  0.921875\n",
      "Iteration:  2346  Loss:  0.33915046   Accuracy:  0.9140625\n",
      "Iteration:  2347  Loss:  0.26913023   Accuracy:  0.921875\n",
      "Iteration:  2348  Loss:  0.3627994   Accuracy:  0.9296875\n",
      "Iteration:  2349  Loss:  0.23369652   Accuracy:  0.9375\n",
      "Iteration:  2350  Loss:  0.2811214   Accuracy:  0.8984375\n",
      "Iteration:  2351  Loss:  0.30365282   Accuracy:  0.90625\n",
      "Iteration:  2352  Loss:  0.22334825   Accuracy:  0.921875\n",
      "Iteration:  2353  Loss:  0.30135107   Accuracy:  0.9296875\n",
      "Iteration:  2354  Loss:  0.1954698   Accuracy:  0.9375\n",
      "Iteration:  2355  Loss:  0.28587976   Accuracy:  0.921875\n",
      "Iteration:  2356  Loss:  0.2278505   Accuracy:  0.9375\n",
      "Iteration:  2357  Loss:  0.28725484   Accuracy:  0.9453125\n",
      "Iteration:  2358  Loss:  0.40946928   Accuracy:  0.890625\n",
      "Iteration:  2359  Loss:  0.23910731   Accuracy:  0.921875\n",
      "Iteration:  2360  Loss:  0.27700529   Accuracy:  0.9296875\n",
      "Iteration:  2361  Loss:  0.1964094   Accuracy:  0.9296875\n",
      "Iteration:  2362  Loss:  0.18364461   Accuracy:  0.921875\n",
      "Iteration:  2363  Loss:  0.24850439   Accuracy:  0.921875\n",
      "Iteration:  2364  Loss:  0.3157874   Accuracy:  0.890625\n",
      "Iteration:  2365  Loss:  0.3674029   Accuracy:  0.9140625\n",
      "Iteration:  2366  Loss:  0.26789978   Accuracy:  0.9140625\n",
      "Iteration:  2367  Loss:  0.40198904   Accuracy:  0.8984375\n",
      "Iteration:  2368  Loss:  0.39766967   Accuracy:  0.953125\n",
      "Iteration:  2369  Loss:  0.20432019   Accuracy:  0.9375\n",
      "Iteration:  2370  Loss:  0.24196935   Accuracy:  0.8984375\n",
      "Iteration:  2371  Loss:  0.43955275   Accuracy:  0.8828125\n",
      "Iteration:  2372  Loss:  0.23544514   Accuracy:  0.9453125\n",
      "Iteration:  2373  Loss:  0.3396694   Accuracy:  0.8984375\n",
      "Iteration:  2374  Loss:  0.23493761   Accuracy:  0.921875\n",
      "Iteration:  2375  Loss:  0.2331408   Accuracy:  0.9296875\n",
      "Iteration:  2376  Loss:  0.2559824   Accuracy:  0.9453125\n",
      "Iteration:  2377  Loss:  0.22900434   Accuracy:  0.921875\n",
      "Iteration:  2378  Loss:  0.19270918   Accuracy:  0.9140625\n",
      "Iteration:  2379  Loss:  0.30135405   Accuracy:  0.90625\n",
      "Iteration:  2380  Loss:  0.34647837   Accuracy:  0.90625\n",
      "Iteration:  2381  Loss:  0.33515984   Accuracy:  0.8984375\n",
      "Iteration:  2382  Loss:  0.17696804   Accuracy:  0.9609375\n",
      "Iteration:  2383  Loss:  0.17825171   Accuracy:  0.9453125\n",
      "Iteration:  2384  Loss:  0.1588929   Accuracy:  0.96875\n",
      "Iteration:  2385  Loss:  0.40404287   Accuracy:  0.90625\n",
      "Iteration:  2386  Loss:  0.3447382   Accuracy:  0.875\n",
      "Iteration:  2387  Loss:  0.36956602   Accuracy:  0.890625\n",
      "Iteration:  2388  Loss:  0.22929972   Accuracy:  0.9375\n",
      "Iteration:  2389  Loss:  0.23526406   Accuracy:  0.9453125\n",
      "Iteration:  2390  Loss:  0.23537144   Accuracy:  0.9453125\n",
      "Iteration:  2391  Loss:  0.2573471   Accuracy:  0.921875\n",
      "Iteration:  2392  Loss:  0.3107684   Accuracy:  0.890625\n",
      "Iteration:  2393  Loss:  0.26272795   Accuracy:  0.9140625\n",
      "Iteration:  2394  Loss:  0.28926405   Accuracy:  0.8984375\n",
      "Iteration:  2395  Loss:  0.34341434   Accuracy:  0.9375\n",
      "Iteration:  2396  Loss:  0.21540932   Accuracy:  0.9296875\n",
      "Iteration:  2397  Loss:  0.2551557   Accuracy:  0.921875\n",
      "Iteration:  2398  Loss:  0.31620884   Accuracy:  0.9140625\n",
      "Iteration:  2399  Loss:  0.24560502   Accuracy:  0.921875\n",
      "Iteration:  2400  Loss:  0.47223672   Accuracy:  0.8671875\n",
      "Iteration:  2401  Loss:  0.34090585   Accuracy:  0.8671875\n",
      "Iteration:  2402  Loss:  0.28520852   Accuracy:  0.890625\n",
      "Iteration:  2403  Loss:  0.30547667   Accuracy:  0.90625\n",
      "Iteration:  2404  Loss:  0.24936141   Accuracy:  0.9453125\n",
      "Iteration:  2405  Loss:  0.32561395   Accuracy:  0.921875\n",
      "Iteration:  2406  Loss:  0.34221518   Accuracy:  0.8984375\n",
      "Iteration:  2407  Loss:  0.334244   Accuracy:  0.921875\n",
      "Iteration:  2408  Loss:  0.2999584   Accuracy:  0.90625\n",
      "Iteration:  2409  Loss:  0.28203806   Accuracy:  0.921875\n",
      "Iteration:  2410  Loss:  0.43844342   Accuracy:  0.859375\n",
      "Iteration:  2411  Loss:  0.36151862   Accuracy:  0.9140625\n",
      "Iteration:  2412  Loss:  0.49641138   Accuracy:  0.8671875\n",
      "Iteration:  2413  Loss:  0.27742076   Accuracy:  0.9296875\n",
      "Iteration:  2414  Loss:  0.27522147   Accuracy:  0.9453125\n",
      "Iteration:  2415  Loss:  0.16700481   Accuracy:  0.953125\n",
      "Iteration:  2416  Loss:  0.34753346   Accuracy:  0.921875\n",
      "Iteration:  2417  Loss:  0.3063439   Accuracy:  0.90625\n",
      "Iteration:  2418  Loss:  0.3301837   Accuracy:  0.953125\n",
      "Iteration:  2419  Loss:  0.37718552   Accuracy:  0.9140625\n",
      "Iteration:  2420  Loss:  0.20283908   Accuracy:  0.9375\n",
      "Iteration:  2421  Loss:  0.3604411   Accuracy:  0.9140625\n",
      "Iteration:  2422  Loss:  0.31047297   Accuracy:  0.890625\n",
      "Iteration:  2423  Loss:  0.22889371   Accuracy:  0.921875\n",
      "Iteration:  2424  Loss:  0.2258623   Accuracy:  0.953125\n",
      "Iteration:  2425  Loss:  0.23713839   Accuracy:  0.9296875\n",
      "Iteration:  2426  Loss:  0.21059617   Accuracy:  0.9375\n",
      "Iteration:  2427  Loss:  0.45618498   Accuracy:  0.859375\n",
      "Iteration:  2428  Loss:  0.24733075   Accuracy:  0.921875\n",
      "Iteration:  2429  Loss:  0.33740324   Accuracy:  0.9375\n",
      "Iteration:  2430  Loss:  0.3041657   Accuracy:  0.9140625\n",
      "Iteration:  2431  Loss:  0.33693045   Accuracy:  0.890625\n",
      "Iteration:  2432  Loss:  0.22637475   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2433  Loss:  0.24353218   Accuracy:  0.921875\n",
      "Iteration:  2434  Loss:  0.14427534   Accuracy:  0.9609375\n",
      "Iteration:  2435  Loss:  0.19063419   Accuracy:  0.921875\n",
      "Iteration:  2436  Loss:  0.2660262   Accuracy:  0.9296875\n",
      "Iteration:  2437  Loss:  0.19431452   Accuracy:  0.9375\n",
      "Iteration:  2438  Loss:  0.21004651   Accuracy:  0.953125\n",
      "Iteration:  2439  Loss:  0.33015314   Accuracy:  0.8984375\n",
      "Iteration:  2440  Loss:  0.1955893   Accuracy:  0.9453125\n",
      "Iteration:  2441  Loss:  0.3106967   Accuracy:  0.9140625\n",
      "Iteration:  2442  Loss:  0.27037066   Accuracy:  0.9140625\n",
      "Iteration:  2443  Loss:  0.27366343   Accuracy:  0.8984375\n",
      "Iteration:  2444  Loss:  0.31489813   Accuracy:  0.890625\n",
      "Iteration:  2445  Loss:  0.12578468   Accuracy:  0.96875\n",
      "Iteration:  2446  Loss:  0.2136835   Accuracy:  0.9296875\n",
      "Iteration:  2447  Loss:  0.29318902   Accuracy:  0.9375\n",
      "Iteration:  2448  Loss:  0.23447666   Accuracy:  0.921875\n",
      "Iteration:  2449  Loss:  0.3276897   Accuracy:  0.9375\n",
      "Iteration:  2450  Loss:  0.19390836   Accuracy:  0.9453125\n",
      "Iteration:  2451  Loss:  0.47245985   Accuracy:  0.921875\n",
      "Iteration:  2452  Loss:  0.13997899   Accuracy:  0.96875\n",
      "Iteration:  2453  Loss:  0.26905084   Accuracy:  0.90625\n",
      "Iteration:  2454  Loss:  0.10671283   Accuracy:  0.9765625\n",
      "Iteration:  2455  Loss:  0.21619152   Accuracy:  0.953125\n",
      "Iteration:  2456  Loss:  0.32776016   Accuracy:  0.90625\n",
      "Iteration:  2457  Loss:  0.24536794   Accuracy:  0.90625\n",
      "Iteration:  2458  Loss:  0.21257523   Accuracy:  0.9375\n",
      "Iteration:  2459  Loss:  0.21332528   Accuracy:  0.953125\n",
      "Iteration:  2460  Loss:  0.28929663   Accuracy:  0.9296875\n",
      "Iteration:  2461  Loss:  0.25724226   Accuracy:  0.921875\n",
      "Iteration:  2462  Loss:  0.2374464   Accuracy:  0.921875\n",
      "Iteration:  2463  Loss:  0.34486264   Accuracy:  0.90625\n",
      "Iteration:  2464  Loss:  0.2502612   Accuracy:  0.9375\n",
      "Iteration:  2465  Loss:  0.2702037   Accuracy:  0.921875\n",
      "Iteration:  2466  Loss:  0.31171578   Accuracy:  0.8828125\n",
      "Iteration:  2467  Loss:  0.33076447   Accuracy:  0.9140625\n",
      "Iteration:  2468  Loss:  0.27470306   Accuracy:  0.9296875\n",
      "Iteration:  2469  Loss:  0.2973717   Accuracy:  0.90625\n",
      "Iteration:  2470  Loss:  0.29810694   Accuracy:  0.875\n",
      "Iteration:  2471  Loss:  0.34536403   Accuracy:  0.8984375\n",
      "Iteration:  2472  Loss:  0.15960397   Accuracy:  0.9453125\n",
      "Iteration:  2473  Loss:  0.2339957   Accuracy:  0.9296875\n",
      "Iteration:  2474  Loss:  0.32288736   Accuracy:  0.9296875\n",
      "Iteration:  2475  Loss:  0.1746825   Accuracy:  0.9609375\n",
      "Iteration:  2476  Loss:  0.20627844   Accuracy:  0.921875\n",
      "Iteration:  2477  Loss:  0.25466752   Accuracy:  0.9453125\n",
      "Iteration:  2478  Loss:  0.25067085   Accuracy:  0.9296875\n",
      "Iteration:  2479  Loss:  0.3094218   Accuracy:  0.890625\n",
      "Iteration:  2480  Loss:  0.14945373   Accuracy:  0.96875\n",
      "Iteration:  2481  Loss:  0.3056644   Accuracy:  0.90625\n",
      "Iteration:  2482  Loss:  0.25523823   Accuracy:  0.9296875\n",
      "Iteration:  2483  Loss:  0.31987232   Accuracy:  0.8984375\n",
      "Iteration:  2484  Loss:  0.3227075   Accuracy:  0.890625\n",
      "Iteration:  2485  Loss:  0.25896913   Accuracy:  0.9375\n",
      "Iteration:  2486  Loss:  0.29653767   Accuracy:  0.9453125\n",
      "Iteration:  2487  Loss:  0.27758414   Accuracy:  0.9296875\n",
      "Iteration:  2488  Loss:  0.19321276   Accuracy:  0.9296875\n",
      "Iteration:  2489  Loss:  0.23285979   Accuracy:  0.921875\n",
      "Iteration:  2490  Loss:  0.22652824   Accuracy:  0.90625\n",
      "Iteration:  2491  Loss:  0.23109162   Accuracy:  0.9375\n",
      "Iteration:  2492  Loss:  0.19757646   Accuracy:  0.953125\n",
      "Iteration:  2493  Loss:  0.39949834   Accuracy:  0.8984375\n",
      "Iteration:  2494  Loss:  0.24011478   Accuracy:  0.9375\n",
      "Iteration:  2495  Loss:  0.3897114   Accuracy:  0.90625\n",
      "Iteration:  2496  Loss:  0.20520703   Accuracy:  0.9296875\n",
      "Iteration:  2497  Loss:  0.42877597   Accuracy:  0.8828125\n",
      "Iteration:  2498  Loss:  0.25994247   Accuracy:  0.953125\n",
      "Iteration:  2499  Loss:  0.5137235   Accuracy:  0.8828125\n",
      "Iteration:  2500  Loss:  0.20926026   Accuracy:  0.9453125\n",
      "Iteration:  2501  Loss:  0.36670658   Accuracy:  0.875\n",
      "Iteration:  2502  Loss:  0.15390109   Accuracy:  0.9609375\n",
      "Iteration:  2503  Loss:  0.17102769   Accuracy:  0.9453125\n",
      "Iteration:  2504  Loss:  0.2796737   Accuracy:  0.9296875\n",
      "Iteration:  2505  Loss:  0.3246634   Accuracy:  0.9453125\n",
      "Iteration:  2506  Loss:  0.23982279   Accuracy:  0.9453125\n",
      "Iteration:  2507  Loss:  0.33228076   Accuracy:  0.8984375\n",
      "Iteration:  2508  Loss:  0.36672688   Accuracy:  0.890625\n",
      "Iteration:  2509  Loss:  0.31183618   Accuracy:  0.8984375\n",
      "Iteration:  2510  Loss:  0.30808413   Accuracy:  0.953125\n",
      "Iteration:  2511  Loss:  0.4285399   Accuracy:  0.859375\n",
      "Iteration:  2512  Loss:  0.3073326   Accuracy:  0.921875\n",
      "Iteration:  2513  Loss:  0.31929123   Accuracy:  0.8828125\n",
      "Iteration:  2514  Loss:  0.33711147   Accuracy:  0.890625\n",
      "Iteration:  2515  Loss:  0.22970936   Accuracy:  0.9453125\n",
      "Iteration:  2516  Loss:  0.2716643   Accuracy:  0.9375\n",
      "Iteration:  2517  Loss:  0.22717819   Accuracy:  0.9453125\n",
      "Iteration:  2518  Loss:  0.20261872   Accuracy:  0.96875\n",
      "Iteration:  2519  Loss:  0.27851453   Accuracy:  0.921875\n",
      "Iteration:  2520  Loss:  0.23168042   Accuracy:  0.9375\n",
      "Iteration:  2521  Loss:  0.28947616   Accuracy:  0.9375\n",
      "Iteration:  2522  Loss:  0.31946903   Accuracy:  0.921875\n",
      "Iteration:  2523  Loss:  0.33336103   Accuracy:  0.90625\n",
      "Iteration:  2524  Loss:  0.22142397   Accuracy:  0.953125\n",
      "Iteration:  2525  Loss:  0.36344105   Accuracy:  0.90625\n",
      "Iteration:  2526  Loss:  0.24768241   Accuracy:  0.890625\n",
      "Iteration:  2527  Loss:  0.316839   Accuracy:  0.9296875\n",
      "Iteration:  2528  Loss:  0.3103301   Accuracy:  0.9140625\n",
      "Iteration:  2529  Loss:  0.25705358   Accuracy:  0.9609375\n",
      "Iteration:  2530  Loss:  0.26561582   Accuracy:  0.9375\n",
      "Iteration:  2531  Loss:  0.17693456   Accuracy:  0.9453125\n",
      "Iteration:  2532  Loss:  0.19274235   Accuracy:  0.9609375\n",
      "Iteration:  2533  Loss:  0.28304338   Accuracy:  0.9296875\n",
      "Iteration:  2534  Loss:  0.26872915   Accuracy:  0.953125\n",
      "Iteration:  2535  Loss:  0.18192512   Accuracy:  0.9296875\n",
      "Iteration:  2536  Loss:  0.37195572   Accuracy:  0.921875\n",
      "Iteration:  2537  Loss:  0.27191702   Accuracy:  0.90625\n",
      "Iteration:  2538  Loss:  0.14894639   Accuracy:  0.96875\n",
      "Iteration:  2539  Loss:  0.43891147   Accuracy:  0.9140625\n",
      "Iteration:  2540  Loss:  0.2656867   Accuracy:  0.921875\n",
      "Iteration:  2541  Loss:  0.21798232   Accuracy:  0.9296875\n",
      "Iteration:  2542  Loss:  0.23888978   Accuracy:  0.9296875\n",
      "Iteration:  2543  Loss:  0.23027432   Accuracy:  0.9296875\n",
      "Iteration:  2544  Loss:  0.312429   Accuracy:  0.921875\n",
      "Iteration:  2545  Loss:  0.29028693   Accuracy:  0.953125\n",
      "Iteration:  2546  Loss:  0.22855371   Accuracy:  0.9375\n",
      "Iteration:  2547  Loss:  0.17911215   Accuracy:  0.9375\n",
      "Iteration:  2548  Loss:  0.25056803   Accuracy:  0.9375\n",
      "Iteration:  2549  Loss:  0.24112648   Accuracy:  0.921875\n",
      "Iteration:  2550  Loss:  0.30238065   Accuracy:  0.9453125\n",
      "Iteration:  2551  Loss:  0.27312213   Accuracy:  0.9296875\n",
      "Iteration:  2552  Loss:  0.17511556   Accuracy:  0.953125\n",
      "Iteration:  2553  Loss:  0.43571073   Accuracy:  0.90625\n",
      "Iteration:  2554  Loss:  0.20815149   Accuracy:  0.9375\n",
      "Iteration:  2555  Loss:  0.3098451   Accuracy:  0.921875\n",
      "Iteration:  2556  Loss:  0.26354635   Accuracy:  0.9140625\n",
      "Iteration:  2557  Loss:  0.27763826   Accuracy:  0.921875\n",
      "Iteration:  2558  Loss:  0.28377387   Accuracy:  0.9375\n",
      "Iteration:  2559  Loss:  0.30128625   Accuracy:  0.890625\n",
      "Iteration:  2560  Loss:  0.37008265   Accuracy:  0.890625\n",
      "Iteration:  2561  Loss:  0.2894405   Accuracy:  0.921875\n",
      "Iteration:  2562  Loss:  0.20195904   Accuracy:  0.953125\n",
      "Iteration:  2563  Loss:  0.29594466   Accuracy:  0.8984375\n",
      "Iteration:  2564  Loss:  0.20881845   Accuracy:  0.9296875\n",
      "Iteration:  2565  Loss:  0.3700495   Accuracy:  0.921875\n",
      "Iteration:  2566  Loss:  0.12149611   Accuracy:  0.9765625\n",
      "Iteration:  2567  Loss:  0.22978513   Accuracy:  0.9375\n",
      "Iteration:  2568  Loss:  0.26847613   Accuracy:  0.9140625\n",
      "Iteration:  2569  Loss:  0.22681737   Accuracy:  0.9453125\n",
      "Iteration:  2570  Loss:  0.22548099   Accuracy:  0.9140625\n",
      "Iteration:  2571  Loss:  0.1767687   Accuracy:  0.9296875\n",
      "Iteration:  2572  Loss:  0.23067899   Accuracy:  0.90625\n",
      "Iteration:  2573  Loss:  0.26173502   Accuracy:  0.9296875\n",
      "Iteration:  2574  Loss:  0.3268161   Accuracy:  0.90625\n",
      "Iteration:  2575  Loss:  0.18832679   Accuracy:  0.9453125\n",
      "Iteration:  2576  Loss:  0.18989104   Accuracy:  0.953125\n",
      "Iteration:  2577  Loss:  0.29434448   Accuracy:  0.9296875\n",
      "Iteration:  2578  Loss:  0.40750805   Accuracy:  0.875\n",
      "Iteration:  2579  Loss:  0.3957539   Accuracy:  0.90625\n",
      "Iteration:  2580  Loss:  0.20538011   Accuracy:  0.9375\n",
      "Iteration:  2581  Loss:  0.286404   Accuracy:  0.875\n",
      "Iteration:  2582  Loss:  0.23417924   Accuracy:  0.9296875\n",
      "Iteration:  2583  Loss:  0.18001059   Accuracy:  0.953125\n",
      "Iteration:  2584  Loss:  0.14289331   Accuracy:  0.96875\n",
      "Iteration:  2585  Loss:  0.3545237   Accuracy:  0.90625\n",
      "Iteration:  2586  Loss:  0.38008952   Accuracy:  0.8828125\n",
      "Iteration:  2587  Loss:  0.18294775   Accuracy:  0.953125\n",
      "Iteration:  2588  Loss:  0.33727756   Accuracy:  0.890625\n",
      "Iteration:  2589  Loss:  0.3821659   Accuracy:  0.8984375\n",
      "Iteration:  2590  Loss:  0.27632937   Accuracy:  0.9296875\n",
      "Iteration:  2591  Loss:  0.17115514   Accuracy:  0.9453125\n",
      "Iteration:  2592  Loss:  0.17143334   Accuracy:  0.9453125\n",
      "Iteration:  2593  Loss:  0.18574782   Accuracy:  0.9609375\n",
      "Iteration:  2594  Loss:  0.18390122   Accuracy:  0.9453125\n",
      "Iteration:  2595  Loss:  0.22034779   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2596  Loss:  0.2668573   Accuracy:  0.9453125\n",
      "Iteration:  2597  Loss:  0.24825871   Accuracy:  0.9140625\n",
      "Iteration:  2598  Loss:  0.32362682   Accuracy:  0.90625\n",
      "Iteration:  2599  Loss:  0.30374545   Accuracy:  0.9375\n",
      "Iteration:  2600  Loss:  0.23762201   Accuracy:  0.9453125\n",
      "Iteration:  2601  Loss:  0.30020916   Accuracy:  0.9140625\n",
      "Iteration:  2602  Loss:  0.48384878   Accuracy:  0.90625\n",
      "Iteration:  2603  Loss:  0.120423906   Accuracy:  0.9609375\n",
      "Iteration:  2604  Loss:  0.3543139   Accuracy:  0.9140625\n",
      "Iteration:  2605  Loss:  0.33270186   Accuracy:  0.8984375\n",
      "Iteration:  2606  Loss:  0.25542673   Accuracy:  0.9375\n",
      "Iteration:  2607  Loss:  0.29528058   Accuracy:  0.9140625\n",
      "Iteration:  2608  Loss:  0.27268094   Accuracy:  0.9296875\n",
      "Iteration:  2609  Loss:  0.18541193   Accuracy:  0.9453125\n",
      "Iteration:  2610  Loss:  0.18551724   Accuracy:  0.9453125\n",
      "Iteration:  2611  Loss:  0.15298957   Accuracy:  0.953125\n",
      "Iteration:  2612  Loss:  0.26737693   Accuracy:  0.9296875\n",
      "Iteration:  2613  Loss:  0.26197323   Accuracy:  0.890625\n",
      "Iteration:  2614  Loss:  0.27003872   Accuracy:  0.9296875\n",
      "Iteration:  2615  Loss:  0.26373297   Accuracy:  0.9296875\n",
      "Iteration:  2616  Loss:  0.1701188   Accuracy:  0.9375\n",
      "Iteration:  2617  Loss:  0.2229153   Accuracy:  0.9453125\n",
      "Iteration:  2618  Loss:  0.13496578   Accuracy:  0.9609375\n",
      "Iteration:  2619  Loss:  0.34751406   Accuracy:  0.9140625\n",
      "Iteration:  2620  Loss:  0.34199363   Accuracy:  0.921875\n",
      "Iteration:  2621  Loss:  0.33901253   Accuracy:  0.8984375\n",
      "Iteration:  2622  Loss:  0.3056077   Accuracy:  0.890625\n",
      "Iteration:  2623  Loss:  0.17682868   Accuracy:  0.9453125\n",
      "Iteration:  2624  Loss:  0.23690364   Accuracy:  0.9375\n",
      "Iteration:  2625  Loss:  0.23845695   Accuracy:  0.9140625\n",
      "Iteration:  2626  Loss:  0.3273606   Accuracy:  0.9140625\n",
      "Iteration:  2627  Loss:  0.22671603   Accuracy:  0.921875\n",
      "Iteration:  2628  Loss:  0.23305938   Accuracy:  0.9453125\n",
      "Iteration:  2629  Loss:  0.22024548   Accuracy:  0.921875\n",
      "Iteration:  2630  Loss:  0.24749376   Accuracy:  0.8984375\n",
      "Iteration:  2631  Loss:  0.21260348   Accuracy:  0.953125\n",
      "Iteration:  2632  Loss:  0.16159138   Accuracy:  0.9296875\n",
      "Iteration:  2633  Loss:  0.3847006   Accuracy:  0.8984375\n",
      "Iteration:  2634  Loss:  0.26265714   Accuracy:  0.921875\n",
      "Iteration:  2635  Loss:  0.132514   Accuracy:  0.9609375\n",
      "Iteration:  2636  Loss:  0.3089472   Accuracy:  0.9140625\n",
      "Iteration:  2637  Loss:  0.14666569   Accuracy:  0.9609375\n",
      "Iteration:  2638  Loss:  0.34425122   Accuracy:  0.890625\n",
      "Iteration:  2639  Loss:  0.44751155   Accuracy:  0.890625\n",
      "Iteration:  2640  Loss:  0.2860252   Accuracy:  0.90625\n",
      "Iteration:  2641  Loss:  0.1758969   Accuracy:  0.9609375\n",
      "Iteration:  2642  Loss:  0.326224   Accuracy:  0.9296875\n",
      "Iteration:  2643  Loss:  0.16182326   Accuracy:  0.921875\n",
      "Iteration:  2644  Loss:  0.41221362   Accuracy:  0.8984375\n",
      "Iteration:  2645  Loss:  0.31676078   Accuracy:  0.890625\n",
      "Iteration:  2646  Loss:  0.309584   Accuracy:  0.90625\n",
      "Iteration:  2647  Loss:  0.19838545   Accuracy:  0.9296875\n",
      "Iteration:  2648  Loss:  0.19197553   Accuracy:  0.953125\n",
      "Iteration:  2649  Loss:  0.16020703   Accuracy:  0.9609375\n",
      "Iteration:  2650  Loss:  0.3440262   Accuracy:  0.921875\n",
      "Iteration:  2651  Loss:  0.28097662   Accuracy:  0.9140625\n",
      "Iteration:  2652  Loss:  0.35727724   Accuracy:  0.9296875\n",
      "Iteration:  2653  Loss:  0.2218537   Accuracy:  0.9296875\n",
      "Iteration:  2654  Loss:  0.18418743   Accuracy:  0.9296875\n",
      "Iteration:  2655  Loss:  0.24014783   Accuracy:  0.9453125\n",
      "Iteration:  2656  Loss:  0.23975953   Accuracy:  0.953125\n",
      "Iteration:  2657  Loss:  0.24761894   Accuracy:  0.9375\n",
      "Iteration:  2658  Loss:  0.27993956   Accuracy:  0.921875\n",
      "Iteration:  2659  Loss:  0.3609671   Accuracy:  0.875\n",
      "Iteration:  2660  Loss:  0.21940432   Accuracy:  0.9609375\n",
      "Iteration:  2661  Loss:  0.11929268   Accuracy:  0.9609375\n",
      "Iteration:  2662  Loss:  0.16212016   Accuracy:  0.96875\n",
      "Iteration:  2663  Loss:  0.38361585   Accuracy:  0.890625\n",
      "Iteration:  2664  Loss:  0.34023052   Accuracy:  0.9140625\n",
      "Iteration:  2665  Loss:  0.2889786   Accuracy:  0.9453125\n",
      "Iteration:  2666  Loss:  0.20985672   Accuracy:  0.9453125\n",
      "Iteration:  2667  Loss:  0.3018025   Accuracy:  0.9140625\n",
      "Iteration:  2668  Loss:  0.21872833   Accuracy:  0.9453125\n",
      "Iteration:  2669  Loss:  0.21959445   Accuracy:  0.9296875\n",
      "Iteration:  2670  Loss:  0.32061142   Accuracy:  0.9140625\n",
      "Iteration:  2671  Loss:  0.31079713   Accuracy:  0.921875\n",
      "Iteration:  2672  Loss:  0.29809064   Accuracy:  0.9296875\n",
      "Iteration:  2673  Loss:  0.30426615   Accuracy:  0.9296875\n",
      "Iteration:  2674  Loss:  0.27822253   Accuracy:  0.9140625\n",
      "Iteration:  2675  Loss:  0.48560584   Accuracy:  0.90625\n",
      "Iteration:  2676  Loss:  0.30070412   Accuracy:  0.9140625\n",
      "Iteration:  2677  Loss:  0.18476257   Accuracy:  0.953125\n",
      "Iteration:  2678  Loss:  0.24441367   Accuracy:  0.9453125\n",
      "Iteration:  2679  Loss:  0.23660874   Accuracy:  0.9453125\n",
      "Iteration:  2680  Loss:  0.20978704   Accuracy:  0.921875\n",
      "Iteration:  2681  Loss:  0.14955097   Accuracy:  0.96875\n",
      "Iteration:  2682  Loss:  0.24344352   Accuracy:  0.9453125\n",
      "Iteration:  2683  Loss:  0.22625093   Accuracy:  0.9296875\n",
      "Iteration:  2684  Loss:  0.1627266   Accuracy:  0.953125\n",
      "Iteration:  2685  Loss:  0.19943169   Accuracy:  0.9296875\n",
      "Iteration:  2686  Loss:  0.29405424   Accuracy:  0.921875\n",
      "Iteration:  2687  Loss:  0.29809767   Accuracy:  0.890625\n",
      "Iteration:  2688  Loss:  0.17618313   Accuracy:  0.9375\n",
      "Iteration:  2689  Loss:  0.21552278   Accuracy:  0.9453125\n",
      "Iteration:  2690  Loss:  0.30426702   Accuracy:  0.8984375\n",
      "Iteration:  2691  Loss:  0.24332473   Accuracy:  0.921875\n",
      "Iteration:  2692  Loss:  0.26121885   Accuracy:  0.921875\n",
      "Iteration:  2693  Loss:  0.37560493   Accuracy:  0.90625\n",
      "Iteration:  2694  Loss:  0.21352693   Accuracy:  0.9296875\n",
      "Iteration:  2695  Loss:  0.42323738   Accuracy:  0.90625\n",
      "Iteration:  2696  Loss:  0.27374613   Accuracy:  0.921875\n",
      "Iteration:  2697  Loss:  0.29849017   Accuracy:  0.9140625\n",
      "Iteration:  2698  Loss:  0.3836734   Accuracy:  0.8828125\n",
      "Iteration:  2699  Loss:  0.1903661   Accuracy:  0.9296875\n",
      "Iteration:  2700  Loss:  0.16234273   Accuracy:  0.953125\n",
      "Iteration:  2701  Loss:  0.30577588   Accuracy:  0.90625\n",
      "Iteration:  2702  Loss:  0.23667595   Accuracy:  0.9375\n",
      "Iteration:  2703  Loss:  0.16689491   Accuracy:  0.9375\n",
      "Iteration:  2704  Loss:  0.20564336   Accuracy:  0.9296875\n",
      "Iteration:  2705  Loss:  0.22609821   Accuracy:  0.9375\n",
      "Iteration:  2706  Loss:  0.21038026   Accuracy:  0.9296875\n",
      "Iteration:  2707  Loss:  0.30367887   Accuracy:  0.90625\n",
      "Iteration:  2708  Loss:  0.18638271   Accuracy:  0.9453125\n",
      "Iteration:  2709  Loss:  0.26634184   Accuracy:  0.921875\n",
      "Iteration:  2710  Loss:  0.22395913   Accuracy:  0.921875\n",
      "Iteration:  2711  Loss:  0.35884973   Accuracy:  0.90625\n",
      "Iteration:  2712  Loss:  0.29327732   Accuracy:  0.9140625\n",
      "Iteration:  2713  Loss:  0.20783873   Accuracy:  0.9453125\n",
      "Iteration:  2714  Loss:  0.27075088   Accuracy:  0.9453125\n",
      "Iteration:  2715  Loss:  0.27542815   Accuracy:  0.9296875\n",
      "Iteration:  2716  Loss:  0.24154419   Accuracy:  0.921875\n",
      "Iteration:  2717  Loss:  0.17183419   Accuracy:  0.9375\n",
      "Iteration:  2718  Loss:  0.17484489   Accuracy:  0.9375\n",
      "Iteration:  2719  Loss:  0.23440439   Accuracy:  0.9375\n",
      "Iteration:  2720  Loss:  0.21177685   Accuracy:  0.9375\n",
      "Iteration:  2721  Loss:  0.30225307   Accuracy:  0.921875\n",
      "Iteration:  2722  Loss:  0.25789768   Accuracy:  0.9140625\n",
      "Iteration:  2723  Loss:  0.24612558   Accuracy:  0.9453125\n",
      "Iteration:  2724  Loss:  0.3182856   Accuracy:  0.9296875\n",
      "Iteration:  2725  Loss:  0.33336574   Accuracy:  0.90625\n",
      "Iteration:  2726  Loss:  0.34146142   Accuracy:  0.8828125\n",
      "Iteration:  2727  Loss:  0.34436464   Accuracy:  0.890625\n",
      "Iteration:  2728  Loss:  0.27366948   Accuracy:  0.921875\n",
      "Iteration:  2729  Loss:  0.21762782   Accuracy:  0.921875\n",
      "Iteration:  2730  Loss:  0.31172022   Accuracy:  0.9140625\n",
      "Iteration:  2731  Loss:  0.2639615   Accuracy:  0.921875\n",
      "Iteration:  2732  Loss:  0.30538243   Accuracy:  0.90625\n",
      "Iteration:  2733  Loss:  0.24952853   Accuracy:  0.9140625\n",
      "Iteration:  2734  Loss:  0.21692511   Accuracy:  0.953125\n",
      "Iteration:  2735  Loss:  0.5177736   Accuracy:  0.9296875\n",
      "Iteration:  2736  Loss:  0.33779684   Accuracy:  0.921875\n",
      "Iteration:  2737  Loss:  0.18732782   Accuracy:  0.9375\n",
      "Iteration:  2738  Loss:  0.32300642   Accuracy:  0.9296875\n",
      "Iteration:  2739  Loss:  0.3468507   Accuracy:  0.9140625\n",
      "Iteration:  2740  Loss:  0.24410033   Accuracy:  0.9140625\n",
      "Iteration:  2741  Loss:  0.31725907   Accuracy:  0.8984375\n",
      "Iteration:  2742  Loss:  0.27799052   Accuracy:  0.9140625\n",
      "Iteration:  2743  Loss:  0.37624192   Accuracy:  0.8984375\n",
      "Iteration:  2744  Loss:  0.27533606   Accuracy:  0.921875\n",
      "Iteration:  2745  Loss:  0.16817534   Accuracy:  0.9296875\n",
      "Iteration:  2746  Loss:  0.40271032   Accuracy:  0.9140625\n",
      "Iteration:  2747  Loss:  0.23109393   Accuracy:  0.9453125\n",
      "Iteration:  2748  Loss:  0.29718804   Accuracy:  0.9296875\n",
      "Iteration:  2749  Loss:  0.25074497   Accuracy:  0.9453125\n",
      "Iteration:  2750  Loss:  0.14167611   Accuracy:  0.953125\n",
      "Iteration:  2751  Loss:  0.33196586   Accuracy:  0.90625\n",
      "Iteration:  2752  Loss:  0.20940888   Accuracy:  0.9296875\n",
      "Iteration:  2753  Loss:  0.3308212   Accuracy:  0.890625\n",
      "Iteration:  2754  Loss:  0.18984523   Accuracy:  0.9296875\n",
      "Iteration:  2755  Loss:  0.21899743   Accuracy:  0.9140625\n",
      "Iteration:  2756  Loss:  0.21113938   Accuracy:  0.9296875\n",
      "Iteration:  2757  Loss:  0.30668813   Accuracy:  0.9140625\n",
      "Iteration:  2758  Loss:  0.2518671   Accuracy:  0.9375\n",
      "Iteration:  2759  Loss:  0.25171995   Accuracy:  0.9453125\n",
      "Iteration:  2760  Loss:  0.21800248   Accuracy:  0.90625\n",
      "Iteration:  2761  Loss:  0.21822692   Accuracy:  0.953125\n",
      "Iteration:  2762  Loss:  0.3508516   Accuracy:  0.8515625\n",
      "Iteration:  2763  Loss:  0.3579799   Accuracy:  0.890625\n",
      "Iteration:  2764  Loss:  0.36520383   Accuracy:  0.8671875\n",
      "Iteration:  2765  Loss:  0.31794298   Accuracy:  0.921875\n",
      "Iteration:  2766  Loss:  0.30088654   Accuracy:  0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2767  Loss:  0.24779965   Accuracy:  0.9453125\n",
      "Iteration:  2768  Loss:  0.3710997   Accuracy:  0.90625\n",
      "Iteration:  2769  Loss:  0.21891972   Accuracy:  0.921875\n",
      "Iteration:  2770  Loss:  0.17408296   Accuracy:  0.96875\n",
      "Iteration:  2771  Loss:  0.27288383   Accuracy:  0.9296875\n",
      "Iteration:  2772  Loss:  0.3152091   Accuracy:  0.890625\n",
      "Iteration:  2773  Loss:  0.31096315   Accuracy:  0.9140625\n",
      "Iteration:  2774  Loss:  0.311526   Accuracy:  0.90625\n",
      "Iteration:  2775  Loss:  0.2176006   Accuracy:  0.921875\n",
      "Iteration:  2776  Loss:  0.31526035   Accuracy:  0.890625\n",
      "Iteration:  2777  Loss:  0.2195972   Accuracy:  0.921875\n",
      "Iteration:  2778  Loss:  0.3850923   Accuracy:  0.90625\n",
      "Iteration:  2779  Loss:  0.09966092   Accuracy:  0.9765625\n",
      "Iteration:  2780  Loss:  0.23660511   Accuracy:  0.9453125\n",
      "Iteration:  2781  Loss:  0.36102372   Accuracy:  0.8828125\n",
      "Iteration:  2782  Loss:  0.21578756   Accuracy:  0.9453125\n",
      "Iteration:  2783  Loss:  0.13408586   Accuracy:  0.9609375\n",
      "Iteration:  2784  Loss:  0.24494213   Accuracy:  0.953125\n",
      "Iteration:  2785  Loss:  0.27135804   Accuracy:  0.9375\n",
      "Iteration:  2786  Loss:  0.34207648   Accuracy:  0.9140625\n",
      "Iteration:  2787  Loss:  0.13066646   Accuracy:  0.96875\n",
      "Iteration:  2788  Loss:  0.3180656   Accuracy:  0.921875\n",
      "Iteration:  2789  Loss:  0.20616719   Accuracy:  0.9375\n",
      "Iteration:  2790  Loss:  0.17166503   Accuracy:  0.953125\n",
      "Iteration:  2791  Loss:  0.24616498   Accuracy:  0.9140625\n",
      "Iteration:  2792  Loss:  0.21593252   Accuracy:  0.9453125\n",
      "Iteration:  2793  Loss:  0.27536127   Accuracy:  0.9140625\n",
      "Iteration:  2794  Loss:  0.24050821   Accuracy:  0.890625\n",
      "Iteration:  2795  Loss:  0.19764712   Accuracy:  0.9140625\n",
      "Iteration:  2796  Loss:  0.34138313   Accuracy:  0.8984375\n",
      "Iteration:  2797  Loss:  0.24127224   Accuracy:  0.9296875\n",
      "Iteration:  2798  Loss:  0.21596257   Accuracy:  0.9453125\n",
      "Iteration:  2799  Loss:  0.19299185   Accuracy:  0.9296875\n",
      "Iteration:  2800  Loss:  0.42053872   Accuracy:  0.8984375\n",
      "Iteration:  2801  Loss:  0.23535325   Accuracy:  0.921875\n",
      "Iteration:  2802  Loss:  0.16613704   Accuracy:  0.9609375\n",
      "Iteration:  2803  Loss:  0.18530731   Accuracy:  0.9375\n",
      "Iteration:  2804  Loss:  0.22784683   Accuracy:  0.9453125\n",
      "Iteration:  2805  Loss:  0.23912479   Accuracy:  0.9140625\n",
      "Iteration:  2806  Loss:  0.24605769   Accuracy:  0.90625\n",
      "Iteration:  2807  Loss:  0.25049075   Accuracy:  0.9296875\n",
      "Iteration:  2808  Loss:  0.21549845   Accuracy:  0.953125\n",
      "Iteration:  2809  Loss:  0.46815133   Accuracy:  0.8671875\n",
      "Iteration:  2810  Loss:  0.2411834   Accuracy:  0.921875\n",
      "Iteration:  2811  Loss:  0.29896948   Accuracy:  0.953125\n",
      "Iteration:  2812  Loss:  0.21139959   Accuracy:  0.9453125\n",
      "Iteration:  2813  Loss:  0.34772986   Accuracy:  0.890625\n",
      "Iteration:  2814  Loss:  0.3073967   Accuracy:  0.9140625\n",
      "Iteration:  2815  Loss:  0.20083326   Accuracy:  0.9453125\n",
      "Iteration:  2816  Loss:  0.24829376   Accuracy:  0.90625\n",
      "Iteration:  2817  Loss:  0.25434014   Accuracy:  0.921875\n",
      "Iteration:  2818  Loss:  0.19604969   Accuracy:  0.953125\n",
      "Iteration:  2819  Loss:  0.24593157   Accuracy:  0.9140625\n",
      "Iteration:  2820  Loss:  0.3330304   Accuracy:  0.9453125\n",
      "Iteration:  2821  Loss:  0.19987637   Accuracy:  0.9375\n",
      "Iteration:  2822  Loss:  0.18573062   Accuracy:  0.953125\n",
      "Iteration:  2823  Loss:  0.363067   Accuracy:  0.8984375\n",
      "Iteration:  2824  Loss:  0.22433418   Accuracy:  0.90625\n",
      "Iteration:  2825  Loss:  0.20880839   Accuracy:  0.921875\n",
      "Iteration:  2826  Loss:  0.3318888   Accuracy:  0.8984375\n",
      "Iteration:  2827  Loss:  0.27144617   Accuracy:  0.9140625\n",
      "Iteration:  2828  Loss:  0.30593377   Accuracy:  0.953125\n",
      "Iteration:  2829  Loss:  0.4432272   Accuracy:  0.890625\n",
      "Iteration:  2830  Loss:  0.33547854   Accuracy:  0.890625\n",
      "Iteration:  2831  Loss:  0.31230342   Accuracy:  0.9140625\n",
      "Iteration:  2832  Loss:  0.2569272   Accuracy:  0.9375\n",
      "Iteration:  2833  Loss:  0.2809125   Accuracy:  0.921875\n",
      "Iteration:  2834  Loss:  0.1879622   Accuracy:  0.953125\n",
      "Iteration:  2835  Loss:  0.17412144   Accuracy:  0.953125\n",
      "Iteration:  2836  Loss:  0.2306924   Accuracy:  0.9375\n",
      "Iteration:  2837  Loss:  0.19068632   Accuracy:  0.9453125\n",
      "Iteration:  2838  Loss:  0.23908177   Accuracy:  0.9296875\n",
      "Iteration:  2839  Loss:  0.31333435   Accuracy:  0.9140625\n",
      "Iteration:  2840  Loss:  0.28748772   Accuracy:  0.9296875\n",
      "Iteration:  2841  Loss:  0.2513485   Accuracy:  0.8828125\n",
      "Iteration:  2842  Loss:  0.18212274   Accuracy:  0.9296875\n",
      "Iteration:  2843  Loss:  0.37938625   Accuracy:  0.90625\n",
      "Iteration:  2844  Loss:  0.3040348   Accuracy:  0.9140625\n",
      "Iteration:  2845  Loss:  0.46327913   Accuracy:  0.8828125\n",
      "Iteration:  2846  Loss:  0.27052477   Accuracy:  0.9140625\n",
      "Iteration:  2847  Loss:  0.35060185   Accuracy:  0.9296875\n",
      "Iteration:  2848  Loss:  0.2605758   Accuracy:  0.9140625\n",
      "Iteration:  2849  Loss:  0.20437306   Accuracy:  0.921875\n",
      "Iteration:  2850  Loss:  0.19553922   Accuracy:  0.9375\n",
      "Iteration:  2851  Loss:  0.24991469   Accuracy:  0.9296875\n",
      "Iteration:  2852  Loss:  0.31588215   Accuracy:  0.9140625\n",
      "Iteration:  2853  Loss:  0.33323157   Accuracy:  0.875\n",
      "Iteration:  2854  Loss:  0.29746512   Accuracy:  0.9296875\n",
      "Iteration:  2855  Loss:  0.382461   Accuracy:  0.9296875\n",
      "Iteration:  2856  Loss:  0.20136294   Accuracy:  0.921875\n",
      "Iteration:  2857  Loss:  0.38122806   Accuracy:  0.8515625\n",
      "Iteration:  2858  Loss:  0.29819727   Accuracy:  0.9375\n",
      "Iteration:  2859  Loss:  0.32277483   Accuracy:  0.921875\n",
      "Iteration:  2860  Loss:  0.20334335   Accuracy:  0.9375\n",
      "Iteration:  2861  Loss:  0.20467055   Accuracy:  0.9609375\n",
      "Iteration:  2862  Loss:  0.22075436   Accuracy:  0.9140625\n",
      "Iteration:  2863  Loss:  0.19072752   Accuracy:  0.953125\n",
      "Iteration:  2864  Loss:  0.40158767   Accuracy:  0.8984375\n",
      "Iteration:  2865  Loss:  0.27709866   Accuracy:  0.890625\n",
      "Iteration:  2866  Loss:  0.24906574   Accuracy:  0.921875\n",
      "Iteration:  2867  Loss:  0.15382771   Accuracy:  0.9609375\n",
      "Iteration:  2868  Loss:  0.275348   Accuracy:  0.90625\n",
      "Iteration:  2869  Loss:  0.25390506   Accuracy:  0.9375\n",
      "Iteration:  2870  Loss:  0.26612738   Accuracy:  0.9296875\n",
      "Iteration:  2871  Loss:  0.37498698   Accuracy:  0.8984375\n",
      "Iteration:  2872  Loss:  0.17422464   Accuracy:  0.9375\n",
      "Iteration:  2873  Loss:  0.22189125   Accuracy:  0.953125\n",
      "Iteration:  2874  Loss:  0.24176249   Accuracy:  0.9453125\n",
      "Iteration:  2875  Loss:  0.24646975   Accuracy:  0.9140625\n",
      "Iteration:  2876  Loss:  0.24778107   Accuracy:  0.9140625\n",
      "Iteration:  2877  Loss:  0.26745188   Accuracy:  0.90625\n",
      "Iteration:  2878  Loss:  0.32866058   Accuracy:  0.921875\n",
      "Iteration:  2879  Loss:  0.34014282   Accuracy:  0.921875\n",
      "Iteration:  2880  Loss:  0.19192511   Accuracy:  0.9296875\n",
      "Iteration:  2881  Loss:  0.22715452   Accuracy:  0.9375\n",
      "Iteration:  2882  Loss:  0.3224467   Accuracy:  0.9296875\n",
      "Iteration:  2883  Loss:  0.23214646   Accuracy:  0.9140625\n",
      "Iteration:  2884  Loss:  0.2921154   Accuracy:  0.9140625\n",
      "Iteration:  2885  Loss:  0.13179344   Accuracy:  0.96875\n",
      "Iteration:  2886  Loss:  0.49040538   Accuracy:  0.8671875\n",
      "Iteration:  2887  Loss:  0.40360558   Accuracy:  0.90625\n",
      "Iteration:  2888  Loss:  0.19604552   Accuracy:  0.9609375\n",
      "Iteration:  2889  Loss:  0.3212577   Accuracy:  0.9140625\n",
      "Iteration:  2890  Loss:  0.28667188   Accuracy:  0.921875\n",
      "Iteration:  2891  Loss:  0.21699685   Accuracy:  0.953125\n",
      "Iteration:  2892  Loss:  0.22102036   Accuracy:  0.9140625\n",
      "Iteration:  2893  Loss:  0.20644769   Accuracy:  0.9453125\n",
      "Iteration:  2894  Loss:  0.36263287   Accuracy:  0.90625\n",
      "Iteration:  2895  Loss:  0.2377243   Accuracy:  0.9453125\n",
      "Iteration:  2896  Loss:  0.44936842   Accuracy:  0.9140625\n",
      "Iteration:  2897  Loss:  0.4180889   Accuracy:  0.84375\n",
      "Iteration:  2898  Loss:  0.24496938   Accuracy:  0.953125\n",
      "Iteration:  2899  Loss:  0.32020298   Accuracy:  0.90625\n",
      "Iteration:  2900  Loss:  0.14829424   Accuracy:  0.9609375\n",
      "Iteration:  2901  Loss:  0.17419922   Accuracy:  0.9609375\n",
      "Iteration:  2902  Loss:  0.32514077   Accuracy:  0.921875\n",
      "Iteration:  2903  Loss:  0.30824214   Accuracy:  0.8984375\n",
      "Iteration:  2904  Loss:  0.27240676   Accuracy:  0.890625\n",
      "Iteration:  2905  Loss:  0.2106122   Accuracy:  0.9140625\n",
      "Iteration:  2906  Loss:  0.27794775   Accuracy:  0.90625\n",
      "Iteration:  2907  Loss:  0.238983   Accuracy:  0.9375\n",
      "Iteration:  2908  Loss:  0.15125638   Accuracy:  0.953125\n",
      "Iteration:  2909  Loss:  0.18501613   Accuracy:  0.9453125\n",
      "Iteration:  2910  Loss:  0.3843978   Accuracy:  0.8828125\n",
      "Iteration:  2911  Loss:  0.30353725   Accuracy:  0.8984375\n",
      "Iteration:  2912  Loss:  0.26322305   Accuracy:  0.921875\n",
      "Iteration:  2913  Loss:  0.20084164   Accuracy:  0.9296875\n",
      "Iteration:  2914  Loss:  0.31169274   Accuracy:  0.890625\n",
      "Iteration:  2915  Loss:  0.23275639   Accuracy:  0.9296875\n",
      "Iteration:  2916  Loss:  0.12576014   Accuracy:  0.953125\n",
      "Iteration:  2917  Loss:  0.33988702   Accuracy:  0.9140625\n",
      "Iteration:  2918  Loss:  0.2871047   Accuracy:  0.8984375\n",
      "Iteration:  2919  Loss:  0.21012574   Accuracy:  0.953125\n",
      "Iteration:  2920  Loss:  0.24727309   Accuracy:  0.90625\n",
      "Iteration:  2921  Loss:  0.24878466   Accuracy:  0.921875\n",
      "Iteration:  2922  Loss:  0.21709165   Accuracy:  0.953125\n",
      "Iteration:  2923  Loss:  0.18996763   Accuracy:  0.9296875\n",
      "Iteration:  2924  Loss:  0.26855183   Accuracy:  0.9296875\n",
      "Iteration:  2925  Loss:  0.20327637   Accuracy:  0.9375\n",
      "Iteration:  2926  Loss:  0.24932516   Accuracy:  0.90625\n",
      "Iteration:  2927  Loss:  0.21764766   Accuracy:  0.9375\n",
      "Iteration:  2928  Loss:  0.35356477   Accuracy:  0.8671875\n",
      "Iteration:  2929  Loss:  0.30372944   Accuracy:  0.90625\n",
      "Iteration:  2930  Loss:  0.36444634   Accuracy:  0.8984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2931  Loss:  0.23974557   Accuracy:  0.90625\n",
      "Iteration:  2932  Loss:  0.36067063   Accuracy:  0.8984375\n",
      "Iteration:  2933  Loss:  0.3421625   Accuracy:  0.8984375\n",
      "Iteration:  2934  Loss:  0.3598708   Accuracy:  0.8984375\n",
      "Iteration:  2935  Loss:  0.23722965   Accuracy:  0.9609375\n",
      "Iteration:  2936  Loss:  0.3086124   Accuracy:  0.921875\n",
      "Iteration:  2937  Loss:  0.34746873   Accuracy:  0.8984375\n",
      "Iteration:  2938  Loss:  0.18592362   Accuracy:  0.953125\n",
      "Iteration:  2939  Loss:  0.22050054   Accuracy:  0.9296875\n",
      "Iteration:  2940  Loss:  0.2710962   Accuracy:  0.90625\n",
      "Iteration:  2941  Loss:  0.23310526   Accuracy:  0.9453125\n",
      "Iteration:  2942  Loss:  0.18767701   Accuracy:  0.953125\n",
      "Iteration:  2943  Loss:  0.4357549   Accuracy:  0.890625\n",
      "Iteration:  2944  Loss:  0.18422239   Accuracy:  0.9296875\n",
      "Iteration:  2945  Loss:  0.42822167   Accuracy:  0.9140625\n",
      "Iteration:  2946  Loss:  0.17809758   Accuracy:  0.9296875\n",
      "Iteration:  2947  Loss:  0.42889416   Accuracy:  0.8828125\n",
      "Iteration:  2948  Loss:  0.24205473   Accuracy:  0.90625\n",
      "Iteration:  2949  Loss:  0.19510296   Accuracy:  0.953125\n",
      "Iteration:  2950  Loss:  0.31543142   Accuracy:  0.921875\n",
      "Iteration:  2951  Loss:  0.20271523   Accuracy:  0.9140625\n",
      "Iteration:  2952  Loss:  0.35839453   Accuracy:  0.8828125\n",
      "Iteration:  2953  Loss:  0.25673538   Accuracy:  0.9296875\n",
      "Iteration:  2954  Loss:  0.3024101   Accuracy:  0.8984375\n",
      "Iteration:  2955  Loss:  0.15694878   Accuracy:  0.953125\n",
      "Iteration:  2956  Loss:  0.17176265   Accuracy:  0.9609375\n",
      "Iteration:  2957  Loss:  0.37194753   Accuracy:  0.890625\n",
      "Iteration:  2958  Loss:  0.11507752   Accuracy:  0.9765625\n",
      "Iteration:  2959  Loss:  0.18391344   Accuracy:  0.9609375\n",
      "Iteration:  2960  Loss:  0.42715415   Accuracy:  0.875\n",
      "Iteration:  2961  Loss:  0.41118583   Accuracy:  0.90625\n",
      "Iteration:  2962  Loss:  0.3476069   Accuracy:  0.859375\n",
      "Iteration:  2963  Loss:  0.3184948   Accuracy:  0.9140625\n",
      "Iteration:  2964  Loss:  0.26078215   Accuracy:  0.9296875\n",
      "Iteration:  2965  Loss:  0.23567921   Accuracy:  0.9296875\n",
      "Iteration:  2966  Loss:  0.19663315   Accuracy:  0.953125\n",
      "Iteration:  2967  Loss:  0.33268085   Accuracy:  0.90625\n",
      "Iteration:  2968  Loss:  0.16068482   Accuracy:  0.984375\n",
      "Iteration:  2969  Loss:  0.31294852   Accuracy:  0.9375\n",
      "Iteration:  2970  Loss:  0.20970348   Accuracy:  0.9375\n",
      "Iteration:  2971  Loss:  0.3651203   Accuracy:  0.9140625\n",
      "Iteration:  2972  Loss:  0.2724323   Accuracy:  0.9296875\n",
      "Iteration:  2973  Loss:  0.30589938   Accuracy:  0.9296875\n",
      "Iteration:  2974  Loss:  0.2624897   Accuracy:  0.921875\n",
      "Iteration:  2975  Loss:  0.20763543   Accuracy:  0.953125\n",
      "Iteration:  2976  Loss:  0.3270333   Accuracy:  0.875\n",
      "Iteration:  2977  Loss:  0.23897098   Accuracy:  0.9453125\n",
      "Iteration:  2978  Loss:  0.2598657   Accuracy:  0.9296875\n",
      "Iteration:  2979  Loss:  0.27858126   Accuracy:  0.9140625\n",
      "Iteration:  2980  Loss:  0.25671986   Accuracy:  0.9296875\n",
      "Iteration:  2981  Loss:  0.13185886   Accuracy:  0.953125\n",
      "Iteration:  2982  Loss:  0.3044458   Accuracy:  0.9140625\n",
      "Iteration:  2983  Loss:  0.1945034   Accuracy:  0.9296875\n",
      "Iteration:  2984  Loss:  0.30059814   Accuracy:  0.9296875\n",
      "Iteration:  2985  Loss:  0.3485622   Accuracy:  0.8984375\n",
      "Iteration:  2986  Loss:  0.41075253   Accuracy:  0.875\n",
      "Iteration:  2987  Loss:  0.15439318   Accuracy:  0.953125\n",
      "Iteration:  2988  Loss:  0.39490038   Accuracy:  0.8984375\n",
      "Iteration:  2989  Loss:  0.2070472   Accuracy:  0.9375\n",
      "Iteration:  2990  Loss:  0.26318878   Accuracy:  0.9140625\n",
      "Iteration:  2991  Loss:  0.33459184   Accuracy:  0.90625\n",
      "Iteration:  2992  Loss:  0.1525389   Accuracy:  0.9375\n",
      "Iteration:  2993  Loss:  0.22825415   Accuracy:  0.953125\n",
      "Iteration:  2994  Loss:  0.3474703   Accuracy:  0.921875\n",
      "Iteration:  2995  Loss:  0.36659294   Accuracy:  0.8984375\n",
      "Iteration:  2996  Loss:  0.17118332   Accuracy:  0.9609375\n",
      "Iteration:  2997  Loss:  0.32519448   Accuracy:  0.90625\n",
      "Iteration:  2998  Loss:  0.23286732   Accuracy:  0.9375\n",
      "Iteration:  2999  Loss:  0.33253062   Accuracy:  0.9140625\n",
      "Iteration:  3000  Loss:  0.43832082   Accuracy:  0.8828125\n",
      "Iteration:  3001  Loss:  0.39502025   Accuracy:  0.8828125\n",
      "Iteration:  3002  Loss:  0.25714228   Accuracy:  0.8984375\n",
      "Iteration:  3003  Loss:  0.22536436   Accuracy:  0.921875\n",
      "Iteration:  3004  Loss:  0.16178945   Accuracy:  0.9609375\n",
      "Iteration:  3005  Loss:  0.26780707   Accuracy:  0.90625\n",
      "Iteration:  3006  Loss:  0.22302239   Accuracy:  0.953125\n",
      "Iteration:  3007  Loss:  0.30734563   Accuracy:  0.90625\n",
      "Iteration:  3008  Loss:  0.2471996   Accuracy:  0.9375\n",
      "Iteration:  3009  Loss:  0.20628147   Accuracy:  0.953125\n",
      "Iteration:  3010  Loss:  0.28221443   Accuracy:  0.9296875\n",
      "Iteration:  3011  Loss:  0.3305002   Accuracy:  0.8828125\n",
      "Iteration:  3012  Loss:  0.15698704   Accuracy:  0.953125\n",
      "Iteration:  3013  Loss:  0.2418043   Accuracy:  0.9375\n",
      "Iteration:  3014  Loss:  0.3464977   Accuracy:  0.90625\n",
      "Iteration:  3015  Loss:  0.32633096   Accuracy:  0.90625\n",
      "Iteration:  3016  Loss:  0.1314454   Accuracy:  0.9609375\n",
      "Iteration:  3017  Loss:  0.38249707   Accuracy:  0.90625\n",
      "Iteration:  3018  Loss:  0.2651602   Accuracy:  0.90625\n",
      "Iteration:  3019  Loss:  0.22536662   Accuracy:  0.9453125\n",
      "Iteration:  3020  Loss:  0.16902263   Accuracy:  0.96875\n",
      "Iteration:  3021  Loss:  0.19956946   Accuracy:  0.9453125\n",
      "Iteration:  3022  Loss:  0.19719076   Accuracy:  0.921875\n",
      "Iteration:  3023  Loss:  0.2746129   Accuracy:  0.9296875\n",
      "Iteration:  3024  Loss:  0.3756488   Accuracy:  0.9140625\n",
      "Iteration:  3025  Loss:  0.2028161   Accuracy:  0.9453125\n",
      "Iteration:  3026  Loss:  0.40581277   Accuracy:  0.890625\n",
      "Iteration:  3027  Loss:  0.3651464   Accuracy:  0.8828125\n",
      "Iteration:  3028  Loss:  0.21855015   Accuracy:  0.953125\n",
      "Iteration:  3029  Loss:  0.20306484   Accuracy:  0.9296875\n",
      "Iteration:  3030  Loss:  0.25724614   Accuracy:  0.9140625\n",
      "Iteration:  3031  Loss:  0.3101917   Accuracy:  0.9140625\n",
      "Iteration:  3032  Loss:  0.27783567   Accuracy:  0.9140625\n",
      "Iteration:  3033  Loss:  0.39311635   Accuracy:  0.890625\n",
      "Iteration:  3034  Loss:  0.3355345   Accuracy:  0.8828125\n",
      "Iteration:  3035  Loss:  0.4109514   Accuracy:  0.890625\n",
      "Iteration:  3036  Loss:  0.2063961   Accuracy:  0.921875\n",
      "Iteration:  3037  Loss:  0.19275609   Accuracy:  0.9296875\n",
      "Iteration:  3038  Loss:  0.26424164   Accuracy:  0.9375\n",
      "Iteration:  3039  Loss:  0.20396276   Accuracy:  0.9375\n",
      "Iteration:  3040  Loss:  0.3123611   Accuracy:  0.9140625\n",
      "Iteration:  3041  Loss:  0.17698869   Accuracy:  0.9609375\n",
      "Iteration:  3042  Loss:  0.18918145   Accuracy:  0.9375\n",
      "Iteration:  3043  Loss:  0.22407353   Accuracy:  0.9375\n",
      "Iteration:  3044  Loss:  0.2187995   Accuracy:  0.921875\n",
      "Iteration:  3045  Loss:  0.15908682   Accuracy:  0.953125\n",
      "Iteration:  3046  Loss:  0.30619478   Accuracy:  0.90625\n",
      "Iteration:  3047  Loss:  0.24863744   Accuracy:  0.90625\n",
      "Iteration:  3048  Loss:  0.22263412   Accuracy:  0.921875\n",
      "Iteration:  3049  Loss:  0.22296154   Accuracy:  0.90625\n",
      "Iteration:  3050  Loss:  0.46942604   Accuracy:  0.8984375\n",
      "Iteration:  3051  Loss:  0.33978546   Accuracy:  0.8984375\n",
      "Iteration:  3052  Loss:  0.19735841   Accuracy:  0.921875\n",
      "Iteration:  3053  Loss:  0.37830523   Accuracy:  0.90625\n",
      "Iteration:  3054  Loss:  0.22979257   Accuracy:  0.9296875\n",
      "Iteration:  3055  Loss:  0.23124304   Accuracy:  0.9140625\n",
      "Iteration:  3056  Loss:  0.16778068   Accuracy:  0.9609375\n",
      "Iteration:  3057  Loss:  0.21877424   Accuracy:  0.9453125\n",
      "Iteration:  3058  Loss:  0.19901992   Accuracy:  0.9609375\n",
      "Iteration:  3059  Loss:  0.15880597   Accuracy:  0.9453125\n",
      "Iteration:  3060  Loss:  0.27186275   Accuracy:  0.9375\n",
      "Iteration:  3061  Loss:  0.21741003   Accuracy:  0.921875\n",
      "Iteration:  3062  Loss:  0.33932418   Accuracy:  0.921875\n",
      "Iteration:  3063  Loss:  0.24384657   Accuracy:  0.921875\n",
      "Iteration:  3064  Loss:  0.25561172   Accuracy:  0.9296875\n",
      "Iteration:  3065  Loss:  0.31381947   Accuracy:  0.9140625\n",
      "Iteration:  3066  Loss:  0.2430066   Accuracy:  0.9296875\n",
      "Iteration:  3067  Loss:  0.19177948   Accuracy:  0.9375\n",
      "Iteration:  3068  Loss:  0.31904405   Accuracy:  0.921875\n",
      "Iteration:  3069  Loss:  0.20902774   Accuracy:  0.9296875\n",
      "Iteration:  3070  Loss:  0.57448053   Accuracy:  0.859375\n",
      "Iteration:  3071  Loss:  0.12299284   Accuracy:  0.9765625\n",
      "Iteration:  3072  Loss:  0.20314604   Accuracy:  0.9375\n",
      "Iteration:  3073  Loss:  0.23471761   Accuracy:  0.9140625\n",
      "Iteration:  3074  Loss:  0.28647402   Accuracy:  0.9453125\n",
      "Iteration:  3075  Loss:  0.14907232   Accuracy:  0.9609375\n",
      "Iteration:  3076  Loss:  0.26857927   Accuracy:  0.9140625\n",
      "Iteration:  3077  Loss:  0.2611866   Accuracy:  0.953125\n",
      "Iteration:  3078  Loss:  0.5261631   Accuracy:  0.8671875\n",
      "Iteration:  3079  Loss:  0.26875877   Accuracy:  0.9296875\n",
      "Iteration:  3080  Loss:  0.2965222   Accuracy:  0.9375\n",
      "Iteration:  3081  Loss:  0.22745976   Accuracy:  0.9375\n",
      "Iteration:  3082  Loss:  0.2289114   Accuracy:  0.9296875\n",
      "Iteration:  3083  Loss:  0.24866365   Accuracy:  0.9453125\n",
      "Iteration:  3084  Loss:  0.36647958   Accuracy:  0.8984375\n",
      "Iteration:  3085  Loss:  0.28865874   Accuracy:  0.9140625\n",
      "Iteration:  3086  Loss:  0.3073776   Accuracy:  0.921875\n",
      "Iteration:  3087  Loss:  0.3376884   Accuracy:  0.8984375\n",
      "Iteration:  3088  Loss:  0.3306434   Accuracy:  0.890625\n",
      "Iteration:  3089  Loss:  0.16919187   Accuracy:  0.9609375\n",
      "Iteration:  3090  Loss:  0.2688973   Accuracy:  0.9375\n",
      "Iteration:  3091  Loss:  0.19213495   Accuracy:  0.953125\n",
      "Iteration:  3092  Loss:  0.30421132   Accuracy:  0.9140625\n",
      "Iteration:  3093  Loss:  0.27329   Accuracy:  0.9609375\n",
      "Iteration:  3094  Loss:  0.28779927   Accuracy:  0.90625\n",
      "Iteration:  3095  Loss:  0.36470205   Accuracy:  0.9140625\n",
      "Iteration:  3096  Loss:  0.18173268   Accuracy:  0.953125\n",
      "Iteration:  3097  Loss:  0.27054787   Accuracy:  0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3098  Loss:  0.29311696   Accuracy:  0.90625\n",
      "Iteration:  3099  Loss:  0.42321384   Accuracy:  0.90625\n",
      "Iteration:  3100  Loss:  0.4598904   Accuracy:  0.8515625\n",
      "Iteration:  3101  Loss:  0.2685066   Accuracy:  0.90625\n",
      "Iteration:  3102  Loss:  0.3910831   Accuracy:  0.921875\n",
      "Iteration:  3103  Loss:  0.19970676   Accuracy:  0.9453125\n",
      "Iteration:  3104  Loss:  0.15287364   Accuracy:  0.9609375\n",
      "Iteration:  3105  Loss:  0.22003925   Accuracy:  0.9296875\n",
      "Iteration:  3106  Loss:  0.20033939   Accuracy:  0.953125\n",
      "Iteration:  3107  Loss:  0.21411036   Accuracy:  0.890625\n",
      "Iteration:  3108  Loss:  0.19109417   Accuracy:  0.96875\n",
      "Iteration:  3109  Loss:  0.17742157   Accuracy:  0.953125\n",
      "Iteration:  3110  Loss:  0.22247079   Accuracy:  0.9140625\n",
      "Iteration:  3111  Loss:  0.28760082   Accuracy:  0.9453125\n",
      "Iteration:  3112  Loss:  0.2944343   Accuracy:  0.953125\n",
      "Iteration:  3113  Loss:  0.26027235   Accuracy:  0.9375\n",
      "Iteration:  3114  Loss:  0.44052103   Accuracy:  0.90625\n",
      "Iteration:  3115  Loss:  0.3135383   Accuracy:  0.9140625\n",
      "Iteration:  3116  Loss:  0.21046877   Accuracy:  0.9453125\n",
      "Iteration:  3117  Loss:  0.22170985   Accuracy:  0.9296875\n",
      "Iteration:  3118  Loss:  0.1966062   Accuracy:  0.953125\n",
      "Iteration:  3119  Loss:  0.13502099   Accuracy:  0.9609375\n",
      "Iteration:  3120  Loss:  0.26840633   Accuracy:  0.9375\n",
      "Iteration:  3121  Loss:  0.26752457   Accuracy:  0.8984375\n",
      "Iteration:  3122  Loss:  0.33335796   Accuracy:  0.8984375\n",
      "Iteration:  3123  Loss:  0.17073068   Accuracy:  0.9609375\n",
      "Iteration:  3124  Loss:  0.42329597   Accuracy:  0.9453125\n",
      "Iteration:  3125  Loss:  0.4779494   Accuracy:  0.890625\n",
      "Iteration:  3126  Loss:  0.33892456   Accuracy:  0.9296875\n",
      "Iteration:  3127  Loss:  0.26885635   Accuracy:  0.9375\n",
      "Iteration:  3128  Loss:  0.2824491   Accuracy:  0.9375\n",
      "Iteration:  3129  Loss:  0.35041606   Accuracy:  0.8828125\n",
      "Iteration:  3130  Loss:  0.21434319   Accuracy:  0.9296875\n",
      "Iteration:  3131  Loss:  0.42746472   Accuracy:  0.8671875\n",
      "Iteration:  3132  Loss:  0.3879316   Accuracy:  0.8828125\n",
      "Iteration:  3133  Loss:  0.41419366   Accuracy:  0.8671875\n",
      "Iteration:  3134  Loss:  0.26076746   Accuracy:  0.921875\n",
      "Iteration:  3135  Loss:  0.29445255   Accuracy:  0.921875\n",
      "Iteration:  3136  Loss:  0.4473676   Accuracy:  0.921875\n",
      "Iteration:  3137  Loss:  0.16140518   Accuracy:  0.96875\n",
      "Iteration:  3138  Loss:  0.21731108   Accuracy:  0.9453125\n",
      "Iteration:  3139  Loss:  0.23426706   Accuracy:  0.90625\n",
      "Iteration:  3140  Loss:  0.2879889   Accuracy:  0.9453125\n",
      "Iteration:  3141  Loss:  0.3939925   Accuracy:  0.859375\n",
      "Iteration:  3142  Loss:  0.23818468   Accuracy:  0.921875\n",
      "Iteration:  3143  Loss:  0.16275421   Accuracy:  0.96875\n",
      "Iteration:  3144  Loss:  0.18746945   Accuracy:  0.921875\n",
      "Iteration:  3145  Loss:  0.32805493   Accuracy:  0.921875\n",
      "Iteration:  3146  Loss:  0.26325855   Accuracy:  0.9296875\n",
      "Iteration:  3147  Loss:  0.13023219   Accuracy:  0.9609375\n",
      "Iteration:  3148  Loss:  0.20235415   Accuracy:  0.9375\n",
      "Iteration:  3149  Loss:  0.28238922   Accuracy:  0.9140625\n",
      "Iteration:  3150  Loss:  0.3025198   Accuracy:  0.9375\n",
      "Iteration:  3151  Loss:  0.22384845   Accuracy:  0.9296875\n",
      "Iteration:  3152  Loss:  0.2498474   Accuracy:  0.9296875\n",
      "Iteration:  3153  Loss:  0.38748947   Accuracy:  0.890625\n",
      "Iteration:  3154  Loss:  0.32350397   Accuracy:  0.9140625\n",
      "Iteration:  3155  Loss:  0.13614507   Accuracy:  0.96875\n",
      "Iteration:  3156  Loss:  0.33503947   Accuracy:  0.921875\n",
      "Iteration:  3157  Loss:  0.3955303   Accuracy:  0.8828125\n",
      "Iteration:  3158  Loss:  0.45851147   Accuracy:  0.859375\n",
      "Iteration:  3159  Loss:  0.18226257   Accuracy:  0.9375\n",
      "Iteration:  3160  Loss:  0.29061124   Accuracy:  0.9140625\n",
      "Iteration:  3161  Loss:  0.18913524   Accuracy:  0.96875\n",
      "Iteration:  3162  Loss:  0.17160103   Accuracy:  0.9453125\n",
      "Iteration:  3163  Loss:  0.18068948   Accuracy:  0.9375\n",
      "Iteration:  3164  Loss:  0.3581909   Accuracy:  0.8828125\n",
      "Iteration:  3165  Loss:  0.26913443   Accuracy:  0.90625\n",
      "Iteration:  3166  Loss:  0.22215545   Accuracy:  0.9453125\n",
      "Iteration:  3167  Loss:  0.26153135   Accuracy:  0.8984375\n",
      "Iteration:  3168  Loss:  0.416318   Accuracy:  0.9140625\n",
      "Iteration:  3169  Loss:  0.19929495   Accuracy:  0.9140625\n",
      "Iteration:  3170  Loss:  0.3529163   Accuracy:  0.90625\n",
      "Iteration:  3171  Loss:  0.16350615   Accuracy:  0.9609375\n",
      "Iteration:  3172  Loss:  0.18158625   Accuracy:  0.953125\n",
      "Iteration:  3173  Loss:  0.2655869   Accuracy:  0.9140625\n",
      "Iteration:  3174  Loss:  0.21485095   Accuracy:  0.953125\n",
      "Iteration:  3175  Loss:  0.17998265   Accuracy:  0.9140625\n",
      "Iteration:  3176  Loss:  0.21887536   Accuracy:  0.9375\n",
      "Iteration:  3177  Loss:  0.14761828   Accuracy:  0.9453125\n",
      "Iteration:  3178  Loss:  0.25894856   Accuracy:  0.90625\n",
      "Iteration:  3179  Loss:  0.23020431   Accuracy:  0.921875\n",
      "Iteration:  3180  Loss:  0.22842874   Accuracy:  0.90625\n",
      "Iteration:  3181  Loss:  0.48278636   Accuracy:  0.875\n",
      "Iteration:  3182  Loss:  0.2824872   Accuracy:  0.8984375\n",
      "Iteration:  3183  Loss:  0.2907248   Accuracy:  0.890625\n",
      "Iteration:  3184  Loss:  0.34019923   Accuracy:  0.890625\n",
      "Iteration:  3185  Loss:  0.12521413   Accuracy:  0.9765625\n",
      "Iteration:  3186  Loss:  0.23143028   Accuracy:  0.9140625\n",
      "Iteration:  3187  Loss:  0.32462412   Accuracy:  0.9140625\n",
      "Iteration:  3188  Loss:  0.3515164   Accuracy:  0.8984375\n",
      "Iteration:  3189  Loss:  0.20057434   Accuracy:  0.9296875\n",
      "Iteration:  3190  Loss:  0.19351853   Accuracy:  0.9296875\n",
      "Iteration:  3191  Loss:  0.16347009   Accuracy:  0.9609375\n",
      "Iteration:  3192  Loss:  0.21163246   Accuracy:  0.9296875\n",
      "Iteration:  3193  Loss:  0.21794778   Accuracy:  0.921875\n",
      "Iteration:  3194  Loss:  0.3054015   Accuracy:  0.90625\n",
      "Iteration:  3195  Loss:  0.26699895   Accuracy:  0.8984375\n",
      "Iteration:  3196  Loss:  0.2081978   Accuracy:  0.9375\n",
      "Iteration:  3197  Loss:  0.28149205   Accuracy:  0.9375\n",
      "Iteration:  3198  Loss:  0.28979278   Accuracy:  0.90625\n",
      "Iteration:  3199  Loss:  0.28355977   Accuracy:  0.9296875\n",
      "Iteration:  3200  Loss:  0.23218903   Accuracy:  0.9296875\n",
      "Iteration:  3201  Loss:  0.11833699   Accuracy:  0.96875\n",
      "Iteration:  3202  Loss:  0.20456314   Accuracy:  0.953125\n",
      "Iteration:  3203  Loss:  0.28631386   Accuracy:  0.90625\n",
      "Iteration:  3204  Loss:  0.12802991   Accuracy:  0.96875\n",
      "Iteration:  3205  Loss:  0.21052574   Accuracy:  0.9140625\n",
      "Iteration:  3206  Loss:  0.38336167   Accuracy:  0.8828125\n",
      "Iteration:  3207  Loss:  0.24530868   Accuracy:  0.921875\n",
      "Iteration:  3208  Loss:  0.18811929   Accuracy:  0.9375\n",
      "Iteration:  3209  Loss:  0.22226276   Accuracy:  0.9375\n",
      "Iteration:  3210  Loss:  0.36266527   Accuracy:  0.9375\n",
      "Iteration:  3211  Loss:  0.22409874   Accuracy:  0.9296875\n",
      "Iteration:  3212  Loss:  0.2271645   Accuracy:  0.9296875\n",
      "Iteration:  3213  Loss:  0.38916665   Accuracy:  0.8828125\n",
      "Iteration:  3214  Loss:  0.3038459   Accuracy:  0.9140625\n",
      "Iteration:  3215  Loss:  0.2649354   Accuracy:  0.953125\n",
      "Iteration:  3216  Loss:  0.19615844   Accuracy:  0.9375\n",
      "Iteration:  3217  Loss:  0.23633078   Accuracy:  0.9375\n",
      "Iteration:  3218  Loss:  0.23094133   Accuracy:  0.90625\n",
      "Iteration:  3219  Loss:  0.3030482   Accuracy:  0.90625\n",
      "Iteration:  3220  Loss:  0.23373577   Accuracy:  0.9296875\n",
      "Iteration:  3221  Loss:  0.16706453   Accuracy:  0.9453125\n",
      "Iteration:  3222  Loss:  0.33398125   Accuracy:  0.875\n",
      "Iteration:  3223  Loss:  0.2124014   Accuracy:  0.9296875\n",
      "Iteration:  3224  Loss:  0.15972468   Accuracy:  0.96875\n",
      "Iteration:  3225  Loss:  0.18183424   Accuracy:  0.9609375\n",
      "Iteration:  3226  Loss:  0.16194728   Accuracy:  0.953125\n",
      "Iteration:  3227  Loss:  0.33641532   Accuracy:  0.8984375\n",
      "Iteration:  3228  Loss:  0.22075453   Accuracy:  0.9140625\n",
      "Iteration:  3229  Loss:  0.21992913   Accuracy:  0.9296875\n",
      "Iteration:  3230  Loss:  0.21506271   Accuracy:  0.9453125\n",
      "Iteration:  3231  Loss:  0.133422   Accuracy:  0.953125\n",
      "Iteration:  3232  Loss:  0.13087863   Accuracy:  0.9765625\n",
      "Iteration:  3233  Loss:  0.1526843   Accuracy:  0.9375\n",
      "Iteration:  3234  Loss:  0.21238284   Accuracy:  0.953125\n",
      "Iteration:  3235  Loss:  0.22837162   Accuracy:  0.9375\n",
      "Iteration:  3236  Loss:  0.2890419   Accuracy:  0.921875\n",
      "Iteration:  3237  Loss:  0.2549771   Accuracy:  0.9296875\n",
      "Iteration:  3238  Loss:  0.22109243   Accuracy:  0.953125\n",
      "Iteration:  3239  Loss:  0.29509333   Accuracy:  0.90625\n",
      "Iteration:  3240  Loss:  0.24180868   Accuracy:  0.9375\n",
      "Iteration:  3241  Loss:  0.20589983   Accuracy:  0.9296875\n",
      "Iteration:  3242  Loss:  0.27461746   Accuracy:  0.9140625\n",
      "Iteration:  3243  Loss:  0.27189785   Accuracy:  0.9296875\n",
      "Iteration:  3244  Loss:  0.35058302   Accuracy:  0.890625\n",
      "Iteration:  3245  Loss:  0.3178161   Accuracy:  0.8984375\n",
      "Iteration:  3246  Loss:  0.47280356   Accuracy:  0.859375\n",
      "Iteration:  3247  Loss:  0.30381116   Accuracy:  0.90625\n",
      "Iteration:  3248  Loss:  0.20911056   Accuracy:  0.953125\n",
      "Iteration:  3249  Loss:  0.23572011   Accuracy:  0.921875\n",
      "Iteration:  3250  Loss:  0.26580098   Accuracy:  0.90625\n",
      "Iteration:  3251  Loss:  0.28559664   Accuracy:  0.90625\n",
      "Iteration:  3252  Loss:  0.26033723   Accuracy:  0.9453125\n",
      "Iteration:  3253  Loss:  0.23986848   Accuracy:  0.921875\n",
      "Iteration:  3254  Loss:  0.2948097   Accuracy:  0.90625\n",
      "Iteration:  3255  Loss:  0.21804231   Accuracy:  0.9375\n",
      "Iteration:  3256  Loss:  0.24734478   Accuracy:  0.9375\n",
      "Iteration:  3257  Loss:  0.40421665   Accuracy:  0.921875\n",
      "Iteration:  3258  Loss:  0.17157799   Accuracy:  0.9453125\n",
      "Iteration:  3259  Loss:  0.19364028   Accuracy:  0.9609375\n",
      "Iteration:  3260  Loss:  0.47795528   Accuracy:  0.9140625\n",
      "Iteration:  3261  Loss:  0.26085097   Accuracy:  0.890625\n",
      "Iteration:  3262  Loss:  0.20492224   Accuracy:  0.9453125\n",
      "Iteration:  3263  Loss:  0.34515962   Accuracy:  0.90625\n",
      "Iteration:  3264  Loss:  0.1556373   Accuracy:  0.9453125\n",
      "Iteration:  3265  Loss:  0.16551544   Accuracy:  0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3266  Loss:  0.34369195   Accuracy:  0.8984375\n",
      "Iteration:  3267  Loss:  0.34265023   Accuracy:  0.9296875\n",
      "Iteration:  3268  Loss:  0.2608999   Accuracy:  0.9375\n",
      "Iteration:  3269  Loss:  0.34450984   Accuracy:  0.9296875\n",
      "Iteration:  3270  Loss:  0.25980735   Accuracy:  0.9296875\n",
      "Iteration:  3271  Loss:  0.19387755   Accuracy:  0.9453125\n",
      "Iteration:  3272  Loss:  0.26126993   Accuracy:  0.890625\n",
      "Iteration:  3273  Loss:  0.3032066   Accuracy:  0.921875\n",
      "Iteration:  3274  Loss:  0.20273833   Accuracy:  0.9375\n",
      "Iteration:  3275  Loss:  0.22421268   Accuracy:  0.9375\n",
      "Iteration:  3276  Loss:  0.32379317   Accuracy:  0.921875\n",
      "Iteration:  3277  Loss:  0.19294359   Accuracy:  0.953125\n",
      "Iteration:  3278  Loss:  0.26524124   Accuracy:  0.921875\n",
      "Iteration:  3279  Loss:  0.32095426   Accuracy:  0.9296875\n",
      "Iteration:  3280  Loss:  0.15155351   Accuracy:  0.953125\n",
      "Iteration:  3281  Loss:  0.21645284   Accuracy:  0.9296875\n",
      "Iteration:  3282  Loss:  0.3706159   Accuracy:  0.8984375\n",
      "Iteration:  3283  Loss:  0.25887975   Accuracy:  0.9140625\n",
      "Iteration:  3284  Loss:  0.23881876   Accuracy:  0.921875\n",
      "Iteration:  3285  Loss:  0.26610857   Accuracy:  0.9375\n",
      "Iteration:  3286  Loss:  0.1255936   Accuracy:  0.9453125\n",
      "Iteration:  3287  Loss:  0.21448517   Accuracy:  0.953125\n",
      "Iteration:  3288  Loss:  0.20089313   Accuracy:  0.9453125\n",
      "Iteration:  3289  Loss:  0.25086483   Accuracy:  0.9296875\n",
      "Iteration:  3290  Loss:  0.23121853   Accuracy:  0.953125\n",
      "Iteration:  3291  Loss:  0.2890328   Accuracy:  0.9296875\n",
      "Iteration:  3292  Loss:  0.13478498   Accuracy:  0.9765625\n",
      "Iteration:  3293  Loss:  0.21660712   Accuracy:  0.9453125\n",
      "Iteration:  3294  Loss:  0.23393174   Accuracy:  0.921875\n",
      "Iteration:  3295  Loss:  0.22151944   Accuracy:  0.9453125\n",
      "Iteration:  3296  Loss:  0.21195063   Accuracy:  0.921875\n",
      "Iteration:  3297  Loss:  0.3082487   Accuracy:  0.953125\n",
      "Iteration:  3298  Loss:  0.3079871   Accuracy:  0.9375\n",
      "Iteration:  3299  Loss:  0.16369605   Accuracy:  0.953125\n",
      "Iteration:  3300  Loss:  0.25790286   Accuracy:  0.9453125\n",
      "Iteration:  3301  Loss:  0.42217433   Accuracy:  0.8828125\n",
      "Iteration:  3302  Loss:  0.3461771   Accuracy:  0.9140625\n",
      "Iteration:  3303  Loss:  0.2522369   Accuracy:  0.921875\n",
      "Iteration:  3304  Loss:  0.23263705   Accuracy:  0.9140625\n",
      "Iteration:  3305  Loss:  0.34097433   Accuracy:  0.90625\n",
      "Iteration:  3306  Loss:  0.34852254   Accuracy:  0.921875\n",
      "Iteration:  3307  Loss:  0.3225546   Accuracy:  0.921875\n",
      "Iteration:  3308  Loss:  0.31956327   Accuracy:  0.8984375\n",
      "Iteration:  3309  Loss:  0.28996515   Accuracy:  0.8984375\n",
      "Iteration:  3310  Loss:  0.23269022   Accuracy:  0.9375\n",
      "Iteration:  3311  Loss:  0.21388961   Accuracy:  0.9453125\n",
      "Iteration:  3312  Loss:  0.34564927   Accuracy:  0.90625\n",
      "Iteration:  3313  Loss:  0.31247658   Accuracy:  0.9140625\n",
      "Iteration:  3314  Loss:  0.31487656   Accuracy:  0.921875\n",
      "Iteration:  3315  Loss:  0.29019225   Accuracy:  0.9140625\n",
      "Iteration:  3316  Loss:  0.25531042   Accuracy:  0.9296875\n",
      "Iteration:  3317  Loss:  0.31008556   Accuracy:  0.9140625\n",
      "Iteration:  3318  Loss:  0.15882592   Accuracy:  0.9453125\n",
      "Iteration:  3319  Loss:  0.17040315   Accuracy:  0.9453125\n",
      "Iteration:  3320  Loss:  0.17036444   Accuracy:  0.953125\n",
      "Iteration:  3321  Loss:  0.16021052   Accuracy:  0.9609375\n",
      "Iteration:  3322  Loss:  0.17209223   Accuracy:  0.9453125\n",
      "Iteration:  3323  Loss:  0.38551402   Accuracy:  0.8984375\n",
      "Iteration:  3324  Loss:  0.27854538   Accuracy:  0.9296875\n",
      "Iteration:  3325  Loss:  0.2522205   Accuracy:  0.9296875\n",
      "Iteration:  3326  Loss:  0.27758998   Accuracy:  0.9140625\n",
      "Iteration:  3327  Loss:  0.23287335   Accuracy:  0.953125\n",
      "Iteration:  3328  Loss:  0.22010706   Accuracy:  0.9140625\n",
      "Iteration:  3329  Loss:  0.19617665   Accuracy:  0.9296875\n",
      "Iteration:  3330  Loss:  0.35352534   Accuracy:  0.8671875\n",
      "Iteration:  3331  Loss:  0.20681101   Accuracy:  0.9609375\n",
      "Iteration:  3332  Loss:  0.31120574   Accuracy:  0.921875\n",
      "Iteration:  3333  Loss:  0.18117774   Accuracy:  0.9453125\n",
      "Iteration:  3334  Loss:  0.2770814   Accuracy:  0.9140625\n",
      "Iteration:  3335  Loss:  0.40336388   Accuracy:  0.8828125\n",
      "Iteration:  3336  Loss:  0.5991751   Accuracy:  0.8984375\n",
      "Iteration:  3337  Loss:  0.22519574   Accuracy:  0.9609375\n",
      "Iteration:  3338  Loss:  0.27884614   Accuracy:  0.8984375\n",
      "Iteration:  3339  Loss:  0.22736338   Accuracy:  0.890625\n",
      "Iteration:  3340  Loss:  0.28124815   Accuracy:  0.9140625\n",
      "Iteration:  3341  Loss:  0.43759647   Accuracy:  0.890625\n",
      "Iteration:  3342  Loss:  0.31142786   Accuracy:  0.953125\n",
      "Iteration:  3343  Loss:  0.23731688   Accuracy:  0.921875\n",
      "Iteration:  3344  Loss:  0.2234674   Accuracy:  0.953125\n",
      "Iteration:  3345  Loss:  0.29492527   Accuracy:  0.921875\n",
      "Iteration:  3346  Loss:  0.24030839   Accuracy:  0.9375\n",
      "Iteration:  3347  Loss:  0.37293604   Accuracy:  0.890625\n",
      "Iteration:  3348  Loss:  0.1952212   Accuracy:  0.9296875\n",
      "Iteration:  3349  Loss:  0.31081063   Accuracy:  0.9375\n",
      "Iteration:  3350  Loss:  0.25317478   Accuracy:  0.9140625\n",
      "Iteration:  3351  Loss:  0.3672758   Accuracy:  0.9140625\n",
      "Iteration:  3352  Loss:  0.40727544   Accuracy:  0.875\n",
      "Iteration:  3353  Loss:  0.17779343   Accuracy:  0.9453125\n",
      "Iteration:  3354  Loss:  0.13916712   Accuracy:  0.96875\n",
      "Iteration:  3355  Loss:  0.1954585   Accuracy:  0.9609375\n",
      "Iteration:  3356  Loss:  0.2454919   Accuracy:  0.9375\n",
      "Iteration:  3357  Loss:  0.23856063   Accuracy:  0.953125\n",
      "Iteration:  3358  Loss:  0.14046621   Accuracy:  0.9609375\n",
      "Iteration:  3359  Loss:  0.29223192   Accuracy:  0.8984375\n",
      "Iteration:  3360  Loss:  0.34440148   Accuracy:  0.921875\n",
      "Iteration:  3361  Loss:  0.21552005   Accuracy:  0.953125\n",
      "Iteration:  3362  Loss:  0.40914297   Accuracy:  0.890625\n",
      "Iteration:  3363  Loss:  0.28631204   Accuracy:  0.9375\n",
      "Iteration:  3364  Loss:  0.3666299   Accuracy:  0.8671875\n",
      "Iteration:  3365  Loss:  0.21487921   Accuracy:  0.921875\n",
      "Iteration:  3366  Loss:  0.22725289   Accuracy:  0.9375\n",
      "Iteration:  3367  Loss:  0.44787458   Accuracy:  0.90625\n",
      "Iteration:  3368  Loss:  0.16141757   Accuracy:  0.9609375\n",
      "Iteration:  3369  Loss:  0.42483282   Accuracy:  0.8828125\n",
      "Iteration:  3370  Loss:  0.19322005   Accuracy:  0.953125\n",
      "Iteration:  3371  Loss:  0.15642412   Accuracy:  0.96875\n",
      "Iteration:  3372  Loss:  0.35033473   Accuracy:  0.8984375\n",
      "Iteration:  3373  Loss:  0.36542723   Accuracy:  0.890625\n",
      "Iteration:  3374  Loss:  0.31799078   Accuracy:  0.9296875\n",
      "Iteration:  3375  Loss:  0.22498691   Accuracy:  0.9453125\n",
      "Iteration:  3376  Loss:  0.27732092   Accuracy:  0.90625\n",
      "Iteration:  3377  Loss:  0.32167017   Accuracy:  0.9296875\n",
      "Iteration:  3378  Loss:  0.23534381   Accuracy:  0.9375\n",
      "Iteration:  3379  Loss:  0.16285735   Accuracy:  0.9453125\n",
      "Iteration:  3380  Loss:  0.1943495   Accuracy:  0.9375\n",
      "Iteration:  3381  Loss:  0.19480193   Accuracy:  0.9296875\n",
      "Iteration:  3382  Loss:  0.28704897   Accuracy:  0.9296875\n",
      "Iteration:  3383  Loss:  0.3106706   Accuracy:  0.890625\n",
      "Iteration:  3384  Loss:  0.24365363   Accuracy:  0.9375\n",
      "Iteration:  3385  Loss:  0.18457045   Accuracy:  0.953125\n",
      "Iteration:  3386  Loss:  0.18044591   Accuracy:  0.9609375\n",
      "Iteration:  3387  Loss:  0.2555585   Accuracy:  0.9375\n",
      "Iteration:  3388  Loss:  0.283786   Accuracy:  0.90625\n",
      "Iteration:  3389  Loss:  0.2643482   Accuracy:  0.9140625\n",
      "Iteration:  3390  Loss:  0.24452764   Accuracy:  0.9375\n",
      "Iteration:  3391  Loss:  0.26044062   Accuracy:  0.9296875\n",
      "Iteration:  3392  Loss:  0.26180494   Accuracy:  0.90625\n",
      "Iteration:  3393  Loss:  0.2964255   Accuracy:  0.921875\n",
      "Iteration:  3394  Loss:  0.28425583   Accuracy:  0.8984375\n",
      "Iteration:  3395  Loss:  0.26582396   Accuracy:  0.90625\n",
      "Iteration:  3396  Loss:  0.29730394   Accuracy:  0.8984375\n",
      "Iteration:  3397  Loss:  0.34283185   Accuracy:  0.8984375\n",
      "Iteration:  3398  Loss:  0.31862625   Accuracy:  0.953125\n",
      "Iteration:  3399  Loss:  0.30726194   Accuracy:  0.90625\n",
      "Iteration:  3400  Loss:  0.30025756   Accuracy:  0.9140625\n",
      "Iteration:  3401  Loss:  0.20647928   Accuracy:  0.9453125\n",
      "Iteration:  3402  Loss:  0.18938407   Accuracy:  0.9453125\n",
      "Iteration:  3403  Loss:  0.33705136   Accuracy:  0.890625\n",
      "Iteration:  3404  Loss:  0.29848516   Accuracy:  0.921875\n",
      "Iteration:  3405  Loss:  0.2569378   Accuracy:  0.9375\n",
      "Iteration:  3406  Loss:  0.23896928   Accuracy:  0.921875\n",
      "Iteration:  3407  Loss:  0.3091011   Accuracy:  0.90625\n",
      "Iteration:  3408  Loss:  0.18054363   Accuracy:  0.9140625\n",
      "Iteration:  3409  Loss:  0.46489263   Accuracy:  0.890625\n",
      "Iteration:  3410  Loss:  0.25820023   Accuracy:  0.8984375\n",
      "Iteration:  3411  Loss:  0.31587988   Accuracy:  0.9453125\n",
      "Iteration:  3412  Loss:  0.1613027   Accuracy:  0.953125\n",
      "Iteration:  3413  Loss:  0.3151305   Accuracy:  0.9296875\n",
      "Iteration:  3414  Loss:  0.36937052   Accuracy:  0.8984375\n",
      "Iteration:  3415  Loss:  0.47760597   Accuracy:  0.8984375\n",
      "Iteration:  3416  Loss:  0.17220053   Accuracy:  0.9609375\n",
      "Iteration:  3417  Loss:  0.29572573   Accuracy:  0.8984375\n",
      "Iteration:  3418  Loss:  0.2115287   Accuracy:  0.9453125\n",
      "Iteration:  3419  Loss:  0.41451272   Accuracy:  0.9296875\n",
      "Iteration:  3420  Loss:  0.31262043   Accuracy:  0.921875\n",
      "Iteration:  3421  Loss:  0.3033432   Accuracy:  0.890625\n",
      "Iteration:  3422  Loss:  0.30494493   Accuracy:  0.9609375\n",
      "Iteration:  3423  Loss:  0.46100813   Accuracy:  0.90625\n",
      "Iteration:  3424  Loss:  0.44114536   Accuracy:  0.8828125\n",
      "Iteration:  3425  Loss:  0.25640398   Accuracy:  0.9453125\n",
      "Iteration:  3426  Loss:  0.32340354   Accuracy:  0.8984375\n",
      "Iteration:  3427  Loss:  0.31301808   Accuracy:  0.9140625\n",
      "Iteration:  3428  Loss:  0.28342512   Accuracy:  0.890625\n",
      "Iteration:  3429  Loss:  0.3192292   Accuracy:  0.890625\n",
      "Iteration:  3430  Loss:  0.302382   Accuracy:  0.90625\n",
      "Iteration:  3431  Loss:  0.20581508   Accuracy:  0.9453125\n",
      "Iteration:  3432  Loss:  0.21650568   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3433  Loss:  0.31640765   Accuracy:  0.9375\n",
      "Iteration:  3434  Loss:  0.300042   Accuracy:  0.921875\n",
      "Iteration:  3435  Loss:  0.22722147   Accuracy:  0.9140625\n",
      "Iteration:  3436  Loss:  0.31098872   Accuracy:  0.9140625\n",
      "Iteration:  3437  Loss:  0.29468057   Accuracy:  0.9453125\n",
      "Iteration:  3438  Loss:  0.24256822   Accuracy:  0.9296875\n",
      "Iteration:  3439  Loss:  0.3022914   Accuracy:  0.8828125\n",
      "Iteration:  3440  Loss:  0.2593761   Accuracy:  0.921875\n",
      "Iteration:  3441  Loss:  0.15389055   Accuracy:  0.9609375\n",
      "Iteration:  3442  Loss:  0.19263412   Accuracy:  0.9375\n",
      "Iteration:  3443  Loss:  0.17698234   Accuracy:  0.921875\n",
      "Iteration:  3444  Loss:  0.26442158   Accuracy:  0.9375\n",
      "Iteration:  3445  Loss:  0.22677904   Accuracy:  0.9296875\n",
      "Iteration:  3446  Loss:  0.17333598   Accuracy:  0.96875\n",
      "Iteration:  3447  Loss:  0.18055016   Accuracy:  0.9609375\n",
      "Iteration:  3448  Loss:  0.20948815   Accuracy:  0.9140625\n",
      "Iteration:  3449  Loss:  0.33126584   Accuracy:  0.9296875\n",
      "Iteration:  3450  Loss:  0.28657523   Accuracy:  0.9296875\n",
      "Iteration:  3451  Loss:  0.35220662   Accuracy:  0.90625\n",
      "Iteration:  3452  Loss:  0.35515505   Accuracy:  0.90625\n",
      "Iteration:  3453  Loss:  0.41845578   Accuracy:  0.9296875\n",
      "Iteration:  3454  Loss:  0.24757609   Accuracy:  0.9375\n",
      "Iteration:  3455  Loss:  0.23059496   Accuracy:  0.9453125\n",
      "Iteration:  3456  Loss:  0.3268577   Accuracy:  0.921875\n",
      "Iteration:  3457  Loss:  0.2343469   Accuracy:  0.921875\n",
      "Iteration:  3458  Loss:  0.26220897   Accuracy:  0.9453125\n",
      "Iteration:  3459  Loss:  0.43370605   Accuracy:  0.8828125\n",
      "Iteration:  3460  Loss:  0.23191214   Accuracy:  0.921875\n",
      "Iteration:  3461  Loss:  0.3511847   Accuracy:  0.8984375\n",
      "Iteration:  3462  Loss:  0.38446528   Accuracy:  0.9140625\n",
      "Iteration:  3463  Loss:  0.26713738   Accuracy:  0.953125\n",
      "Iteration:  3464  Loss:  0.43648425   Accuracy:  0.875\n",
      "Iteration:  3465  Loss:  0.33725733   Accuracy:  0.9453125\n",
      "Iteration:  3466  Loss:  0.14725742   Accuracy:  0.9453125\n",
      "Iteration:  3467  Loss:  0.33457202   Accuracy:  0.890625\n",
      "Iteration:  3468  Loss:  0.25371945   Accuracy:  0.9140625\n",
      "Iteration:  3469  Loss:  0.20423244   Accuracy:  0.9375\n",
      "Iteration:  3470  Loss:  0.25056577   Accuracy:  0.9375\n",
      "Iteration:  3471  Loss:  0.36170244   Accuracy:  0.921875\n",
      "Iteration:  3472  Loss:  0.3696471   Accuracy:  0.9140625\n",
      "Iteration:  3473  Loss:  0.37310466   Accuracy:  0.9375\n",
      "Iteration:  3474  Loss:  0.19072676   Accuracy:  0.921875\n",
      "Iteration:  3475  Loss:  0.2418766   Accuracy:  0.9453125\n",
      "Iteration:  3476  Loss:  0.17043224   Accuracy:  0.953125\n",
      "Iteration:  3477  Loss:  0.1737463   Accuracy:  0.9609375\n",
      "Iteration:  3478  Loss:  0.256931   Accuracy:  0.890625\n",
      "Iteration:  3479  Loss:  0.35007146   Accuracy:  0.8984375\n",
      "Iteration:  3480  Loss:  0.20440915   Accuracy:  0.921875\n",
      "Iteration:  3481  Loss:  0.2560177   Accuracy:  0.9296875\n",
      "Iteration:  3482  Loss:  0.3312443   Accuracy:  0.8828125\n",
      "Iteration:  3483  Loss:  0.26599517   Accuracy:  0.953125\n",
      "Iteration:  3484  Loss:  0.25628033   Accuracy:  0.9140625\n",
      "Iteration:  3485  Loss:  0.35698953   Accuracy:  0.9375\n",
      "Iteration:  3486  Loss:  0.18944266   Accuracy:  0.9296875\n",
      "Iteration:  3487  Loss:  0.1913943   Accuracy:  0.9453125\n",
      "Iteration:  3488  Loss:  0.2927635   Accuracy:  0.9140625\n",
      "Iteration:  3489  Loss:  0.49037904   Accuracy:  0.875\n",
      "Iteration:  3490  Loss:  0.39333862   Accuracy:  0.890625\n",
      "Iteration:  3491  Loss:  0.30597046   Accuracy:  0.9375\n",
      "Iteration:  3492  Loss:  0.3669745   Accuracy:  0.9296875\n",
      "Iteration:  3493  Loss:  0.23361042   Accuracy:  0.9296875\n",
      "Iteration:  3494  Loss:  0.27574027   Accuracy:  0.9296875\n",
      "Iteration:  3495  Loss:  0.35238743   Accuracy:  0.890625\n",
      "Iteration:  3496  Loss:  0.29256865   Accuracy:  0.9296875\n",
      "Iteration:  3497  Loss:  0.2388502   Accuracy:  0.9140625\n",
      "Iteration:  3498  Loss:  0.36909643   Accuracy:  0.890625\n",
      "Iteration:  3499  Loss:  0.3979794   Accuracy:  0.890625\n",
      "Iteration:  3500  Loss:  0.16105415   Accuracy:  0.953125\n",
      "Iteration:  3501  Loss:  0.20811635   Accuracy:  0.921875\n",
      "Iteration:  3502  Loss:  0.43814725   Accuracy:  0.8828125\n",
      "Iteration:  3503  Loss:  0.20883006   Accuracy:  0.9140625\n",
      "Iteration:  3504  Loss:  0.234043   Accuracy:  0.9140625\n",
      "Iteration:  3505  Loss:  0.28150675   Accuracy:  0.90625\n",
      "Iteration:  3506  Loss:  0.22650647   Accuracy:  0.9453125\n",
      "Iteration:  3507  Loss:  0.18381694   Accuracy:  0.9453125\n",
      "Iteration:  3508  Loss:  0.3144405   Accuracy:  0.90625\n",
      "Iteration:  3509  Loss:  0.22076416   Accuracy:  0.9453125\n",
      "Iteration:  3510  Loss:  0.33988523   Accuracy:  0.8984375\n",
      "Iteration:  3511  Loss:  0.17958517   Accuracy:  0.9453125\n",
      "Iteration:  3512  Loss:  0.30546758   Accuracy:  0.9140625\n",
      "Iteration:  3513  Loss:  0.3319566   Accuracy:  0.9140625\n",
      "Iteration:  3514  Loss:  0.20256814   Accuracy:  0.9453125\n",
      "Iteration:  3515  Loss:  0.20206389   Accuracy:  0.9296875\n",
      "Iteration:  3516  Loss:  0.25667566   Accuracy:  0.90625\n",
      "Iteration:  3517  Loss:  0.2550006   Accuracy:  0.9296875\n",
      "Iteration:  3518  Loss:  0.16631609   Accuracy:  0.96875\n",
      "Iteration:  3519  Loss:  0.3762158   Accuracy:  0.90625\n",
      "Iteration:  3520  Loss:  0.20718104   Accuracy:  0.9375\n",
      "Iteration:  3521  Loss:  0.26593333   Accuracy:  0.90625\n",
      "Iteration:  3522  Loss:  0.12714744   Accuracy:  0.9609375\n",
      "Iteration:  3523  Loss:  0.19280733   Accuracy:  0.9140625\n",
      "Iteration:  3524  Loss:  0.38178766   Accuracy:  0.8984375\n",
      "Iteration:  3525  Loss:  0.2906344   Accuracy:  0.9140625\n",
      "Iteration:  3526  Loss:  0.2627764   Accuracy:  0.9453125\n",
      "Iteration:  3527  Loss:  0.35922307   Accuracy:  0.8984375\n",
      "Iteration:  3528  Loss:  0.18891042   Accuracy:  0.921875\n",
      "Iteration:  3529  Loss:  0.18158165   Accuracy:  0.953125\n",
      "Iteration:  3530  Loss:  0.17078209   Accuracy:  0.953125\n",
      "Iteration:  3531  Loss:  0.3506368   Accuracy:  0.890625\n",
      "Iteration:  3532  Loss:  0.20837113   Accuracy:  0.921875\n",
      "Iteration:  3533  Loss:  0.16229214   Accuracy:  0.9375\n",
      "Iteration:  3534  Loss:  0.26658326   Accuracy:  0.9140625\n",
      "Iteration:  3535  Loss:  0.2643868   Accuracy:  0.9609375\n",
      "Iteration:  3536  Loss:  0.48112148   Accuracy:  0.890625\n",
      "Iteration:  3537  Loss:  0.22576497   Accuracy:  0.9375\n",
      "Iteration:  3538  Loss:  0.1689346   Accuracy:  0.9453125\n",
      "Iteration:  3539  Loss:  0.20991662   Accuracy:  0.9296875\n",
      "Iteration:  3540  Loss:  0.19021216   Accuracy:  0.953125\n",
      "Iteration:  3541  Loss:  0.2600891   Accuracy:  0.9296875\n",
      "Iteration:  3542  Loss:  0.19717851   Accuracy:  0.9453125\n",
      "Iteration:  3543  Loss:  0.30638853   Accuracy:  0.9140625\n",
      "Iteration:  3544  Loss:  0.2791342   Accuracy:  0.921875\n",
      "Iteration:  3545  Loss:  0.25693822   Accuracy:  0.9453125\n",
      "Iteration:  3546  Loss:  0.29747748   Accuracy:  0.9296875\n",
      "Iteration:  3547  Loss:  0.3597984   Accuracy:  0.90625\n",
      "Iteration:  3548  Loss:  0.28847176   Accuracy:  0.8984375\n",
      "Iteration:  3549  Loss:  0.26420075   Accuracy:  0.90625\n",
      "Iteration:  3550  Loss:  0.18562096   Accuracy:  0.9375\n",
      "Iteration:  3551  Loss:  0.25910282   Accuracy:  0.921875\n",
      "Iteration:  3552  Loss:  0.27023715   Accuracy:  0.90625\n",
      "Iteration:  3553  Loss:  0.17622018   Accuracy:  0.9609375\n",
      "Iteration:  3554  Loss:  0.35018092   Accuracy:  0.9296875\n",
      "Iteration:  3555  Loss:  0.33338875   Accuracy:  0.9453125\n",
      "Iteration:  3556  Loss:  0.23344907   Accuracy:  0.9140625\n",
      "Iteration:  3557  Loss:  0.39832845   Accuracy:  0.921875\n",
      "Iteration:  3558  Loss:  0.24108976   Accuracy:  0.9296875\n",
      "Iteration:  3559  Loss:  0.16867475   Accuracy:  0.9609375\n",
      "Iteration:  3560  Loss:  0.12459328   Accuracy:  0.9765625\n",
      "Iteration:  3561  Loss:  0.23536283   Accuracy:  0.9453125\n",
      "Iteration:  3562  Loss:  0.23461334   Accuracy:  0.8984375\n",
      "Iteration:  3563  Loss:  0.1735388   Accuracy:  0.9453125\n",
      "Iteration:  3564  Loss:  0.3468626   Accuracy:  0.8984375\n",
      "Iteration:  3565  Loss:  0.4345603   Accuracy:  0.859375\n",
      "Iteration:  3566  Loss:  0.24145778   Accuracy:  0.9296875\n",
      "Iteration:  3567  Loss:  0.38082683   Accuracy:  0.9140625\n",
      "Iteration:  3568  Loss:  0.21741553   Accuracy:  0.9296875\n",
      "Iteration:  3569  Loss:  0.23294602   Accuracy:  0.9375\n",
      "Iteration:  3570  Loss:  0.33585787   Accuracy:  0.90625\n",
      "Iteration:  3571  Loss:  0.25442752   Accuracy:  0.9140625\n",
      "Iteration:  3572  Loss:  0.26984102   Accuracy:  0.9453125\n",
      "Iteration:  3573  Loss:  0.27298614   Accuracy:  0.9375\n",
      "Iteration:  3574  Loss:  0.30274898   Accuracy:  0.890625\n",
      "Iteration:  3575  Loss:  0.27310365   Accuracy:  0.9140625\n",
      "Iteration:  3576  Loss:  0.092421666   Accuracy:  0.9765625\n",
      "Iteration:  3577  Loss:  0.13124901   Accuracy:  0.9609375\n",
      "Iteration:  3578  Loss:  0.16969228   Accuracy:  0.9453125\n",
      "Iteration:  3579  Loss:  0.25690067   Accuracy:  0.9296875\n",
      "Iteration:  3580  Loss:  0.3268423   Accuracy:  0.921875\n",
      "Iteration:  3581  Loss:  0.40587303   Accuracy:  0.90625\n",
      "Iteration:  3582  Loss:  0.238205   Accuracy:  0.9375\n",
      "Iteration:  3583  Loss:  0.22861126   Accuracy:  0.9375\n",
      "Iteration:  3584  Loss:  0.25591615   Accuracy:  0.921875\n",
      "Iteration:  3585  Loss:  0.29236394   Accuracy:  0.9375\n",
      "Iteration:  3586  Loss:  0.39123893   Accuracy:  0.9296875\n",
      "Iteration:  3587  Loss:  0.3518647   Accuracy:  0.9140625\n",
      "Iteration:  3588  Loss:  0.21634614   Accuracy:  0.9375\n",
      "Iteration:  3589  Loss:  0.29080278   Accuracy:  0.9296875\n",
      "Iteration:  3590  Loss:  0.37238374   Accuracy:  0.8671875\n",
      "Iteration:  3591  Loss:  0.23091449   Accuracy:  0.921875\n",
      "Iteration:  3592  Loss:  0.2386952   Accuracy:  0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3593  Loss:  0.32147816   Accuracy:  0.9296875\n",
      "Iteration:  3594  Loss:  0.4786354   Accuracy:  0.875\n",
      "Iteration:  3595  Loss:  0.17709535   Accuracy:  0.9453125\n",
      "Iteration:  3596  Loss:  0.20031196   Accuracy:  0.921875\n",
      "Iteration:  3597  Loss:  0.24892962   Accuracy:  0.9453125\n",
      "Iteration:  3598  Loss:  0.21250975   Accuracy:  0.921875\n",
      "Iteration:  3599  Loss:  0.3421663   Accuracy:  0.9296875\n",
      "Iteration:  3600  Loss:  0.19985452   Accuracy:  0.921875\n",
      "Iteration:  3601  Loss:  0.2675711   Accuracy:  0.90625\n",
      "Iteration:  3602  Loss:  0.3392108   Accuracy:  0.875\n",
      "Iteration:  3603  Loss:  0.3847099   Accuracy:  0.9140625\n",
      "Iteration:  3604  Loss:  0.42988938   Accuracy:  0.8828125\n",
      "Iteration:  3605  Loss:  0.2838656   Accuracy:  0.921875\n",
      "Iteration:  3606  Loss:  0.31872308   Accuracy:  0.90625\n",
      "Iteration:  3607  Loss:  0.2925016   Accuracy:  0.90625\n",
      "Iteration:  3608  Loss:  0.2328312   Accuracy:  0.9296875\n",
      "Iteration:  3609  Loss:  0.19535753   Accuracy:  0.9453125\n",
      "Iteration:  3610  Loss:  0.26468328   Accuracy:  0.90625\n",
      "Iteration:  3611  Loss:  0.15983398   Accuracy:  0.953125\n",
      "Iteration:  3612  Loss:  0.26462436   Accuracy:  0.9375\n",
      "Iteration:  3613  Loss:  0.31726068   Accuracy:  0.90625\n",
      "Iteration:  3614  Loss:  0.2756678   Accuracy:  0.9375\n",
      "Iteration:  3615  Loss:  0.24074955   Accuracy:  0.921875\n",
      "Iteration:  3616  Loss:  0.39870074   Accuracy:  0.8828125\n",
      "Iteration:  3617  Loss:  0.13878015   Accuracy:  0.96875\n",
      "Iteration:  3618  Loss:  0.15951051   Accuracy:  0.9609375\n",
      "Iteration:  3619  Loss:  0.26002836   Accuracy:  0.9375\n",
      "Iteration:  3620  Loss:  0.25405577   Accuracy:  0.9375\n",
      "Iteration:  3621  Loss:  0.36283213   Accuracy:  0.921875\n",
      "Iteration:  3622  Loss:  0.23368067   Accuracy:  0.921875\n",
      "Iteration:  3623  Loss:  0.41268045   Accuracy:  0.90625\n",
      "Iteration:  3624  Loss:  0.35311085   Accuracy:  0.9375\n",
      "Iteration:  3625  Loss:  0.2738791   Accuracy:  0.921875\n",
      "Iteration:  3626  Loss:  0.25191817   Accuracy:  0.9375\n",
      "Iteration:  3627  Loss:  0.24212533   Accuracy:  0.9375\n",
      "Iteration:  3628  Loss:  0.18487963   Accuracy:  0.9375\n",
      "Iteration:  3629  Loss:  0.24553117   Accuracy:  0.9296875\n",
      "Iteration:  3630  Loss:  0.33446068   Accuracy:  0.9296875\n",
      "Iteration:  3631  Loss:  0.1382074   Accuracy:  0.96875\n",
      "Iteration:  3632  Loss:  0.3276491   Accuracy:  0.890625\n",
      "Iteration:  3633  Loss:  0.248575   Accuracy:  0.90625\n",
      "Iteration:  3634  Loss:  0.24354136   Accuracy:  0.9296875\n",
      "Iteration:  3635  Loss:  0.37067336   Accuracy:  0.921875\n",
      "Iteration:  3636  Loss:  0.23598354   Accuracy:  0.9375\n",
      "Iteration:  3637  Loss:  0.13576597   Accuracy:  0.9765625\n",
      "Iteration:  3638  Loss:  0.26072022   Accuracy:  0.921875\n",
      "Iteration:  3639  Loss:  0.27127492   Accuracy:  0.9375\n",
      "Iteration:  3640  Loss:  0.27346614   Accuracy:  0.953125\n",
      "Iteration:  3641  Loss:  0.313611   Accuracy:  0.859375\n",
      "Iteration:  3642  Loss:  0.13627836   Accuracy:  0.9765625\n",
      "Iteration:  3643  Loss:  0.27065915   Accuracy:  0.9296875\n",
      "Iteration:  3644  Loss:  0.16808617   Accuracy:  0.9375\n",
      "Iteration:  3645  Loss:  0.21955365   Accuracy:  0.9453125\n",
      "Iteration:  3646  Loss:  0.28399587   Accuracy:  0.90625\n",
      "Iteration:  3647  Loss:  0.21175754   Accuracy:  0.921875\n",
      "Iteration:  3648  Loss:  0.24161173   Accuracy:  0.921875\n",
      "Iteration:  3649  Loss:  0.26154095   Accuracy:  0.9453125\n",
      "Iteration:  3650  Loss:  0.3112257   Accuracy:  0.8828125\n",
      "Iteration:  3651  Loss:  0.27008817   Accuracy:  0.90625\n",
      "Iteration:  3652  Loss:  0.41789195   Accuracy:  0.8515625\n",
      "Iteration:  3653  Loss:  0.3222898   Accuracy:  0.953125\n",
      "Iteration:  3654  Loss:  0.21404895   Accuracy:  0.953125\n",
      "Iteration:  3655  Loss:  0.23802055   Accuracy:  0.9453125\n",
      "Iteration:  3656  Loss:  0.3835981   Accuracy:  0.9296875\n",
      "Iteration:  3657  Loss:  0.347462   Accuracy:  0.9296875\n",
      "Iteration:  3658  Loss:  0.19427519   Accuracy:  0.9609375\n",
      "Iteration:  3659  Loss:  0.35860986   Accuracy:  0.875\n",
      "Iteration:  3660  Loss:  0.37456042   Accuracy:  0.90625\n",
      "Iteration:  3661  Loss:  0.20706335   Accuracy:  0.9453125\n",
      "Iteration:  3662  Loss:  0.3290014   Accuracy:  0.921875\n",
      "Iteration:  3663  Loss:  0.1307737   Accuracy:  0.96875\n",
      "Iteration:  3664  Loss:  0.18978772   Accuracy:  0.9375\n",
      "Iteration:  3665  Loss:  0.2309318   Accuracy:  0.9375\n",
      "Iteration:  3666  Loss:  0.15246257   Accuracy:  0.953125\n",
      "Iteration:  3667  Loss:  0.34733722   Accuracy:  0.90625\n",
      "Iteration:  3668  Loss:  0.5114968   Accuracy:  0.875\n",
      "Iteration:  3669  Loss:  0.3191328   Accuracy:  0.90625\n",
      "Iteration:  3670  Loss:  0.29833093   Accuracy:  0.921875\n",
      "Iteration:  3671  Loss:  0.08755213   Accuracy:  0.984375\n",
      "Iteration:  3672  Loss:  0.19466287   Accuracy:  0.9140625\n",
      "Iteration:  3673  Loss:  0.16231397   Accuracy:  0.9609375\n",
      "Iteration:  3674  Loss:  0.37325844   Accuracy:  0.875\n",
      "Iteration:  3675  Loss:  0.30641297   Accuracy:  0.953125\n",
      "Iteration:  3676  Loss:  0.29340166   Accuracy:  0.9453125\n",
      "Iteration:  3677  Loss:  0.20763844   Accuracy:  0.9453125\n",
      "Iteration:  3678  Loss:  0.3098984   Accuracy:  0.90625\n",
      "Iteration:  3679  Loss:  0.5281069   Accuracy:  0.921875\n",
      "Iteration:  3680  Loss:  0.20610613   Accuracy:  0.9375\n",
      "Iteration:  3681  Loss:  0.2873038   Accuracy:  0.90625\n",
      "Iteration:  3682  Loss:  0.16203426   Accuracy:  0.9375\n",
      "Iteration:  3683  Loss:  0.43778473   Accuracy:  0.8828125\n",
      "Iteration:  3684  Loss:  0.24815631   Accuracy:  0.9375\n",
      "Iteration:  3685  Loss:  0.17352258   Accuracy:  0.9609375\n",
      "Iteration:  3686  Loss:  0.28040192   Accuracy:  0.8984375\n",
      "Iteration:  3687  Loss:  0.37522882   Accuracy:  0.9296875\n",
      "Iteration:  3688  Loss:  0.25439227   Accuracy:  0.9375\n",
      "Iteration:  3689  Loss:  0.28299922   Accuracy:  0.8984375\n",
      "Iteration:  3690  Loss:  0.3494131   Accuracy:  0.9140625\n",
      "Iteration:  3691  Loss:  0.28156927   Accuracy:  0.9296875\n",
      "Iteration:  3692  Loss:  0.3675532   Accuracy:  0.90625\n",
      "Iteration:  3693  Loss:  0.3784633   Accuracy:  0.8984375\n",
      "Iteration:  3694  Loss:  0.183919   Accuracy:  0.9375\n",
      "Iteration:  3695  Loss:  0.22741407   Accuracy:  0.9296875\n",
      "Iteration:  3696  Loss:  0.25174338   Accuracy:  0.9296875\n",
      "Iteration:  3697  Loss:  0.27380708   Accuracy:  0.890625\n",
      "Iteration:  3698  Loss:  0.3296227   Accuracy:  0.9140625\n",
      "Iteration:  3699  Loss:  0.27823853   Accuracy:  0.90625\n",
      "Iteration:  3700  Loss:  0.42071134   Accuracy:  0.90625\n",
      "Iteration:  3701  Loss:  0.19173178   Accuracy:  0.9296875\n",
      "Iteration:  3702  Loss:  0.23889153   Accuracy:  0.953125\n",
      "Iteration:  3703  Loss:  0.33667868   Accuracy:  0.921875\n",
      "Iteration:  3704  Loss:  0.39824218   Accuracy:  0.8984375\n",
      "Iteration:  3705  Loss:  0.3631583   Accuracy:  0.90625\n",
      "Iteration:  3706  Loss:  0.24558826   Accuracy:  0.9375\n",
      "Iteration:  3707  Loss:  0.2509269   Accuracy:  0.90625\n",
      "Iteration:  3708  Loss:  0.16137071   Accuracy:  0.953125\n",
      "Iteration:  3709  Loss:  0.29344153   Accuracy:  0.9140625\n",
      "Iteration:  3710  Loss:  0.19566138   Accuracy:  0.9296875\n",
      "Iteration:  3711  Loss:  0.25682724   Accuracy:  0.90625\n",
      "Iteration:  3712  Loss:  0.2951544   Accuracy:  0.890625\n",
      "Iteration:  3713  Loss:  0.32829034   Accuracy:  0.90625\n",
      "Iteration:  3714  Loss:  0.2298315   Accuracy:  0.9140625\n",
      "Iteration:  3715  Loss:  0.22729377   Accuracy:  0.9296875\n",
      "Iteration:  3716  Loss:  0.29641742   Accuracy:  0.9140625\n",
      "Iteration:  3717  Loss:  0.1969983   Accuracy:  0.9375\n",
      "Iteration:  3718  Loss:  0.26960224   Accuracy:  0.9140625\n",
      "Iteration:  3719  Loss:  0.32785153   Accuracy:  0.8984375\n",
      "Iteration:  3720  Loss:  0.3153007   Accuracy:  0.921875\n",
      "Iteration:  3721  Loss:  0.21967945   Accuracy:  0.9453125\n",
      "Iteration:  3722  Loss:  0.24391976   Accuracy:  0.9375\n",
      "Iteration:  3723  Loss:  0.276566   Accuracy:  0.921875\n",
      "Iteration:  3724  Loss:  0.20998551   Accuracy:  0.9375\n",
      "Iteration:  3725  Loss:  0.4085303   Accuracy:  0.8828125\n",
      "Iteration:  3726  Loss:  0.23697302   Accuracy:  0.921875\n",
      "Iteration:  3727  Loss:  0.3453879   Accuracy:  0.921875\n",
      "Iteration:  3728  Loss:  0.16659346   Accuracy:  0.9375\n",
      "Iteration:  3729  Loss:  0.2120462   Accuracy:  0.9375\n",
      "Iteration:  3730  Loss:  0.41708148   Accuracy:  0.890625\n",
      "Iteration:  3731  Loss:  0.19242527   Accuracy:  0.953125\n",
      "Iteration:  3732  Loss:  0.19838953   Accuracy:  0.9296875\n",
      "Iteration:  3733  Loss:  0.2526   Accuracy:  0.9140625\n",
      "Iteration:  3734  Loss:  0.20839599   Accuracy:  0.9453125\n",
      "Iteration:  3735  Loss:  0.21947725   Accuracy:  0.9375\n",
      "Iteration:  3736  Loss:  0.16043083   Accuracy:  0.953125\n",
      "Iteration:  3737  Loss:  0.2447359   Accuracy:  0.921875\n",
      "Iteration:  3738  Loss:  0.20213202   Accuracy:  0.9296875\n",
      "Iteration:  3739  Loss:  0.29441544   Accuracy:  0.9140625\n",
      "Iteration:  3740  Loss:  0.21484444   Accuracy:  0.921875\n",
      "Iteration:  3741  Loss:  0.34986272   Accuracy:  0.921875\n",
      "Iteration:  3742  Loss:  0.30816662   Accuracy:  0.9140625\n",
      "Iteration:  3743  Loss:  0.2138863   Accuracy:  0.9609375\n",
      "Iteration:  3744  Loss:  0.15087739   Accuracy:  0.96875\n",
      "Iteration:  3745  Loss:  0.20353378   Accuracy:  0.9609375\n",
      "Iteration:  3746  Loss:  0.3445202   Accuracy:  0.8984375\n",
      "Iteration:  3747  Loss:  0.23787767   Accuracy:  0.9296875\n",
      "Iteration:  3748  Loss:  0.26585296   Accuracy:  0.9375\n",
      "Iteration:  3749  Loss:  0.18802574   Accuracy:  0.953125\n",
      "Iteration:  3750  Loss:  0.20891163   Accuracy:  0.9453125\n",
      "Iteration:  3751  Loss:  0.24002549   Accuracy:  0.921875\n",
      "Iteration:  3752  Loss:  0.35133874   Accuracy:  0.8671875\n",
      "Iteration:  3753  Loss:  0.13778411   Accuracy:  0.96875\n",
      "Iteration:  3754  Loss:  0.19242913   Accuracy:  0.953125\n",
      "Iteration:  3755  Loss:  0.28559315   Accuracy:  0.9140625\n",
      "Iteration:  3756  Loss:  0.3769281   Accuracy:  0.9140625\n",
      "Iteration:  3757  Loss:  0.45602608   Accuracy:  0.8984375\n",
      "Iteration:  3758  Loss:  0.25969917   Accuracy:  0.9296875\n",
      "Iteration:  3759  Loss:  0.29233402   Accuracy:  0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3760  Loss:  0.22031248   Accuracy:  0.90625\n",
      "Iteration:  3761  Loss:  0.18165854   Accuracy:  0.953125\n",
      "Iteration:  3762  Loss:  0.36242452   Accuracy:  0.8828125\n",
      "Iteration:  3763  Loss:  0.26219818   Accuracy:  0.9375\n",
      "Iteration:  3764  Loss:  0.1825141   Accuracy:  0.9609375\n",
      "Iteration:  3765  Loss:  0.20705388   Accuracy:  0.921875\n",
      "Iteration:  3766  Loss:  0.22166976   Accuracy:  0.9453125\n",
      "Iteration:  3767  Loss:  0.17242637   Accuracy:  0.953125\n",
      "Iteration:  3768  Loss:  0.27181023   Accuracy:  0.9296875\n",
      "Iteration:  3769  Loss:  0.31056678   Accuracy:  0.9140625\n",
      "Iteration:  3770  Loss:  0.27790758   Accuracy:  0.890625\n",
      "Iteration:  3771  Loss:  0.17188923   Accuracy:  0.96875\n",
      "Iteration:  3772  Loss:  0.29629377   Accuracy:  0.921875\n",
      "Iteration:  3773  Loss:  0.27712888   Accuracy:  0.9375\n",
      "Iteration:  3774  Loss:  0.2789783   Accuracy:  0.9375\n",
      "Iteration:  3775  Loss:  0.14448385   Accuracy:  0.9453125\n",
      "Iteration:  3776  Loss:  0.38545662   Accuracy:  0.9140625\n",
      "Iteration:  3777  Loss:  0.2975437   Accuracy:  0.9296875\n",
      "Iteration:  3778  Loss:  0.20046976   Accuracy:  0.9453125\n",
      "Iteration:  3779  Loss:  0.23950084   Accuracy:  0.8984375\n",
      "Iteration:  3780  Loss:  0.3226487   Accuracy:  0.90625\n",
      "Iteration:  3781  Loss:  0.37233758   Accuracy:  0.9140625\n",
      "Iteration:  3782  Loss:  0.19191852   Accuracy:  0.953125\n",
      "Iteration:  3783  Loss:  0.59486324   Accuracy:  0.8671875\n",
      "Iteration:  3784  Loss:  0.2618442   Accuracy:  0.90625\n",
      "Iteration:  3785  Loss:  0.21481223   Accuracy:  0.953125\n",
      "Iteration:  3786  Loss:  0.33874163   Accuracy:  0.9296875\n",
      "Iteration:  3787  Loss:  0.33092728   Accuracy:  0.890625\n",
      "Iteration:  3788  Loss:  0.16979054   Accuracy:  0.9609375\n",
      "Iteration:  3789  Loss:  0.14818525   Accuracy:  0.9765625\n",
      "Iteration:  3790  Loss:  0.2526383   Accuracy:  0.8984375\n",
      "Iteration:  3791  Loss:  0.33268085   Accuracy:  0.8828125\n",
      "Iteration:  3792  Loss:  0.30348748   Accuracy:  0.8984375\n",
      "Iteration:  3793  Loss:  0.1942201   Accuracy:  0.953125\n",
      "Iteration:  3794  Loss:  0.1781171   Accuracy:  0.9609375\n",
      "Iteration:  3795  Loss:  0.26239848   Accuracy:  0.9375\n",
      "Iteration:  3796  Loss:  0.21357128   Accuracy:  0.9453125\n",
      "Iteration:  3797  Loss:  0.20753726   Accuracy:  0.9296875\n",
      "Iteration:  3798  Loss:  0.22619566   Accuracy:  0.953125\n",
      "Iteration:  3799  Loss:  0.16223758   Accuracy:  0.9609375\n",
      "Iteration:  3800  Loss:  0.1880845   Accuracy:  0.9609375\n",
      "Iteration:  3801  Loss:  0.33681178   Accuracy:  0.9296875\n",
      "Iteration:  3802  Loss:  0.21361332   Accuracy:  0.9296875\n",
      "Iteration:  3803  Loss:  0.21710521   Accuracy:  0.921875\n",
      "Iteration:  3804  Loss:  0.27603698   Accuracy:  0.90625\n",
      "Iteration:  3805  Loss:  0.37980503   Accuracy:  0.8984375\n",
      "Iteration:  3806  Loss:  0.33776796   Accuracy:  0.9296875\n",
      "Iteration:  3807  Loss:  0.22783408   Accuracy:  0.9140625\n",
      "Iteration:  3808  Loss:  0.20935638   Accuracy:  0.9453125\n",
      "Iteration:  3809  Loss:  0.3385892   Accuracy:  0.921875\n",
      "Iteration:  3810  Loss:  0.25166237   Accuracy:  0.9296875\n",
      "Iteration:  3811  Loss:  0.38337696   Accuracy:  0.90625\n",
      "Iteration:  3812  Loss:  0.24266559   Accuracy:  0.9375\n",
      "Iteration:  3813  Loss:  0.24411571   Accuracy:  0.9296875\n",
      "Iteration:  3814  Loss:  0.23720647   Accuracy:  0.921875\n",
      "Iteration:  3815  Loss:  0.25740683   Accuracy:  0.921875\n",
      "Iteration:  3816  Loss:  0.2884603   Accuracy:  0.921875\n",
      "Iteration:  3817  Loss:  0.20599936   Accuracy:  0.9375\n",
      "Iteration:  3818  Loss:  0.3176548   Accuracy:  0.9140625\n",
      "Iteration:  3819  Loss:  0.16767095   Accuracy:  0.9453125\n",
      "Iteration:  3820  Loss:  0.3010151   Accuracy:  0.8984375\n",
      "Iteration:  3821  Loss:  0.21659803   Accuracy:  0.9296875\n",
      "Iteration:  3822  Loss:  0.25121233   Accuracy:  0.9296875\n",
      "Iteration:  3823  Loss:  0.32494548   Accuracy:  0.921875\n",
      "Iteration:  3824  Loss:  0.222789   Accuracy:  0.90625\n",
      "Iteration:  3825  Loss:  0.2094196   Accuracy:  0.9609375\n",
      "Iteration:  3826  Loss:  0.27289298   Accuracy:  0.90625\n",
      "Iteration:  3827  Loss:  0.28387442   Accuracy:  0.9375\n",
      "Iteration:  3828  Loss:  0.20454484   Accuracy:  0.953125\n",
      "Iteration:  3829  Loss:  0.24188545   Accuracy:  0.9453125\n",
      "Iteration:  3830  Loss:  0.19249754   Accuracy:  0.96875\n",
      "Iteration:  3831  Loss:  0.20191434   Accuracy:  0.953125\n",
      "Iteration:  3832  Loss:  0.28342876   Accuracy:  0.921875\n",
      "Iteration:  3833  Loss:  0.31789088   Accuracy:  0.9140625\n",
      "Iteration:  3834  Loss:  0.19120713   Accuracy:  0.9375\n",
      "Iteration:  3835  Loss:  0.25275803   Accuracy:  0.921875\n",
      "Iteration:  3836  Loss:  0.31694588   Accuracy:  0.90625\n",
      "Iteration:  3837  Loss:  0.25529832   Accuracy:  0.9375\n",
      "Iteration:  3838  Loss:  0.4106977   Accuracy:  0.890625\n",
      "Iteration:  3839  Loss:  0.19156326   Accuracy:  0.9296875\n",
      "Iteration:  3840  Loss:  0.23480052   Accuracy:  0.9375\n",
      "Iteration:  3841  Loss:  0.3391738   Accuracy:  0.90625\n",
      "Iteration:  3842  Loss:  0.29081482   Accuracy:  0.921875\n",
      "Iteration:  3843  Loss:  0.1995128   Accuracy:  0.9140625\n",
      "Iteration:  3844  Loss:  0.29658994   Accuracy:  0.90625\n",
      "Iteration:  3845  Loss:  0.1846114   Accuracy:  0.953125\n",
      "Iteration:  3846  Loss:  0.31194112   Accuracy:  0.9140625\n",
      "Iteration:  3847  Loss:  0.30233347   Accuracy:  0.921875\n",
      "Iteration:  3848  Loss:  0.19211677   Accuracy:  0.9375\n",
      "Iteration:  3849  Loss:  0.23027264   Accuracy:  0.90625\n",
      "Iteration:  3850  Loss:  0.28129408   Accuracy:  0.9375\n",
      "Iteration:  3851  Loss:  0.2381748   Accuracy:  0.9140625\n",
      "Iteration:  3852  Loss:  0.29357404   Accuracy:  0.9609375\n",
      "Iteration:  3853  Loss:  0.35624394   Accuracy:  0.84375\n",
      "Iteration:  3854  Loss:  0.1722132   Accuracy:  0.9609375\n",
      "Iteration:  3855  Loss:  0.3076525   Accuracy:  0.9140625\n",
      "Iteration:  3856  Loss:  0.3114562   Accuracy:  0.9296875\n",
      "Iteration:  3857  Loss:  0.22137226   Accuracy:  0.9140625\n",
      "Iteration:  3858  Loss:  0.13342229   Accuracy:  0.96875\n",
      "Iteration:  3859  Loss:  0.09294143   Accuracy:  0.9765625\n",
      "Iteration:  3860  Loss:  0.18286106   Accuracy:  0.9375\n",
      "Iteration:  3861  Loss:  0.198596   Accuracy:  0.9453125\n",
      "Iteration:  3862  Loss:  0.2904786   Accuracy:  0.90625\n",
      "Iteration:  3863  Loss:  0.2525092   Accuracy:  0.9375\n",
      "Iteration:  3864  Loss:  0.15626317   Accuracy:  0.9453125\n",
      "Iteration:  3865  Loss:  0.2170358   Accuracy:  0.9375\n",
      "Iteration:  3866  Loss:  0.21284771   Accuracy:  0.9296875\n",
      "Iteration:  3867  Loss:  0.21274495   Accuracy:  0.921875\n",
      "Iteration:  3868  Loss:  0.3154517   Accuracy:  0.90625\n",
      "Iteration:  3869  Loss:  0.16449371   Accuracy:  0.9609375\n",
      "Iteration:  3870  Loss:  0.26733646   Accuracy:  0.9140625\n",
      "Iteration:  3871  Loss:  0.26177648   Accuracy:  0.9453125\n",
      "Iteration:  3872  Loss:  0.17148834   Accuracy:  0.953125\n",
      "Iteration:  3873  Loss:  0.23667383   Accuracy:  0.9375\n",
      "Iteration:  3874  Loss:  0.21482074   Accuracy:  0.9296875\n",
      "Iteration:  3875  Loss:  0.3075424   Accuracy:  0.9140625\n",
      "Iteration:  3876  Loss:  0.28728536   Accuracy:  0.953125\n",
      "Iteration:  3877  Loss:  0.31312016   Accuracy:  0.875\n",
      "Iteration:  3878  Loss:  0.18944284   Accuracy:  0.9375\n",
      "Iteration:  3879  Loss:  0.36311358   Accuracy:  0.8984375\n",
      "Iteration:  3880  Loss:  0.28110835   Accuracy:  0.890625\n",
      "Iteration:  3881  Loss:  0.15353861   Accuracy:  0.9609375\n",
      "Iteration:  3882  Loss:  0.22549504   Accuracy:  0.9453125\n",
      "Iteration:  3883  Loss:  0.35383475   Accuracy:  0.8984375\n",
      "Iteration:  3884  Loss:  0.2888295   Accuracy:  0.921875\n",
      "Iteration:  3885  Loss:  0.30318075   Accuracy:  0.921875\n",
      "Iteration:  3886  Loss:  0.13732935   Accuracy:  0.9765625\n",
      "Iteration:  3887  Loss:  0.37886655   Accuracy:  0.875\n",
      "Iteration:  3888  Loss:  0.22257386   Accuracy:  0.921875\n",
      "Iteration:  3889  Loss:  0.31704482   Accuracy:  0.9296875\n",
      "Iteration:  3890  Loss:  0.21037993   Accuracy:  0.9609375\n",
      "Iteration:  3891  Loss:  0.27684984   Accuracy:  0.921875\n",
      "Iteration:  3892  Loss:  0.29986477   Accuracy:  0.9140625\n",
      "Iteration:  3893  Loss:  0.23500678   Accuracy:  0.90625\n",
      "Iteration:  3894  Loss:  0.2662916   Accuracy:  0.9140625\n",
      "Iteration:  3895  Loss:  0.28506875   Accuracy:  0.90625\n",
      "Iteration:  3896  Loss:  0.13603228   Accuracy:  0.96875\n",
      "Iteration:  3897  Loss:  0.27420896   Accuracy:  0.9140625\n",
      "Iteration:  3898  Loss:  0.15965368   Accuracy:  0.9375\n",
      "Iteration:  3899  Loss:  0.43770736   Accuracy:  0.875\n",
      "Iteration:  3900  Loss:  0.1576642   Accuracy:  0.9375\n",
      "Iteration:  3901  Loss:  0.2986271   Accuracy:  0.9140625\n",
      "Iteration:  3902  Loss:  0.16416061   Accuracy:  0.96875\n",
      "Iteration:  3903  Loss:  0.34299958   Accuracy:  0.8984375\n",
      "Iteration:  3904  Loss:  0.19765286   Accuracy:  0.9375\n",
      "Iteration:  3905  Loss:  0.18773636   Accuracy:  0.953125\n",
      "Iteration:  3906  Loss:  0.3195261   Accuracy:  0.9375\n",
      "Iteration:  3907  Loss:  0.2572181   Accuracy:  0.921875\n",
      "Iteration:  3908  Loss:  0.2770651   Accuracy:  0.921875\n",
      "Iteration:  3909  Loss:  0.17720225   Accuracy:  0.9609375\n",
      "Iteration:  3910  Loss:  0.15102266   Accuracy:  0.9453125\n",
      "Iteration:  3911  Loss:  0.30640572   Accuracy:  0.9140625\n",
      "Iteration:  3912  Loss:  0.2038178   Accuracy:  0.9453125\n",
      "Iteration:  3913  Loss:  0.21446538   Accuracy:  0.921875\n",
      "Iteration:  3914  Loss:  0.36233583   Accuracy:  0.90625\n",
      "Iteration:  3915  Loss:  0.2435075   Accuracy:  0.9375\n",
      "Iteration:  3916  Loss:  0.3821758   Accuracy:  0.9140625\n",
      "Iteration:  3917  Loss:  0.28250235   Accuracy:  0.9375\n",
      "Iteration:  3918  Loss:  0.21692502   Accuracy:  0.9140625\n",
      "Iteration:  3919  Loss:  0.28271493   Accuracy:  0.90625\n",
      "Iteration:  3920  Loss:  0.34039968   Accuracy:  0.890625\n",
      "Iteration:  3921  Loss:  0.31548628   Accuracy:  0.9140625\n",
      "Iteration:  3922  Loss:  0.33928484   Accuracy:  0.890625\n",
      "Iteration:  3923  Loss:  0.41610315   Accuracy:  0.890625\n",
      "Iteration:  3924  Loss:  0.25409597   Accuracy:  0.9375\n",
      "Iteration:  3925  Loss:  0.3197001   Accuracy:  0.9140625\n",
      "Iteration:  3926  Loss:  0.39030376   Accuracy:  0.8984375\n",
      "Iteration:  3927  Loss:  0.09457188   Accuracy:  0.96875\n",
      "Iteration:  3928  Loss:  0.2856457   Accuracy:  0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3929  Loss:  0.24710609   Accuracy:  0.921875\n",
      "Iteration:  3930  Loss:  0.30527523   Accuracy:  0.8828125\n",
      "Iteration:  3931  Loss:  0.34668377   Accuracy:  0.890625\n",
      "Iteration:  3932  Loss:  0.2692699   Accuracy:  0.9140625\n",
      "Iteration:  3933  Loss:  0.20557289   Accuracy:  0.9609375\n",
      "Iteration:  3934  Loss:  0.259237   Accuracy:  0.9375\n",
      "Iteration:  3935  Loss:  0.20289509   Accuracy:  0.9453125\n",
      "Iteration:  3936  Loss:  0.14745739   Accuracy:  0.953125\n",
      "Iteration:  3937  Loss:  0.26726127   Accuracy:  0.921875\n",
      "Iteration:  3938  Loss:  0.30553746   Accuracy:  0.9453125\n",
      "Iteration:  3939  Loss:  0.2507471   Accuracy:  0.953125\n",
      "Iteration:  3940  Loss:  0.23739368   Accuracy:  0.9296875\n",
      "Iteration:  3941  Loss:  0.36231044   Accuracy:  0.90625\n",
      "Iteration:  3942  Loss:  0.27163103   Accuracy:  0.9296875\n",
      "Iteration:  3943  Loss:  0.13306731   Accuracy:  0.953125\n",
      "Iteration:  3944  Loss:  0.23246184   Accuracy:  0.921875\n",
      "Iteration:  3945  Loss:  0.25616676   Accuracy:  0.890625\n",
      "Iteration:  3946  Loss:  0.24494672   Accuracy:  0.921875\n",
      "Iteration:  3947  Loss:  0.26282346   Accuracy:  0.9375\n",
      "Iteration:  3948  Loss:  0.19981012   Accuracy:  0.953125\n",
      "Iteration:  3949  Loss:  0.29717705   Accuracy:  0.9375\n",
      "Iteration:  3950  Loss:  0.2016919   Accuracy:  0.9296875\n",
      "Iteration:  3951  Loss:  0.2296693   Accuracy:  0.9453125\n",
      "Iteration:  3952  Loss:  0.38784844   Accuracy:  0.8984375\n",
      "Iteration:  3953  Loss:  0.31991002   Accuracy:  0.875\n",
      "Iteration:  3954  Loss:  0.30169922   Accuracy:  0.8984375\n",
      "Iteration:  3955  Loss:  0.38394392   Accuracy:  0.875\n",
      "Iteration:  3956  Loss:  0.27425545   Accuracy:  0.9296875\n",
      "Iteration:  3957  Loss:  0.38358814   Accuracy:  0.890625\n",
      "Iteration:  3958  Loss:  0.20733127   Accuracy:  0.9453125\n",
      "Iteration:  3959  Loss:  0.35362118   Accuracy:  0.8984375\n",
      "Iteration:  3960  Loss:  0.37230343   Accuracy:  0.875\n",
      "Iteration:  3961  Loss:  0.20832758   Accuracy:  0.953125\n",
      "Iteration:  3962  Loss:  0.26208392   Accuracy:  0.9296875\n",
      "Iteration:  3963  Loss:  0.18969375   Accuracy:  0.9453125\n",
      "Iteration:  3964  Loss:  0.24153034   Accuracy:  0.921875\n",
      "Iteration:  3965  Loss:  0.30316257   Accuracy:  0.9375\n",
      "Iteration:  3966  Loss:  0.2352845   Accuracy:  0.9375\n",
      "Iteration:  3967  Loss:  0.41009668   Accuracy:  0.9140625\n",
      "Iteration:  3968  Loss:  0.18879293   Accuracy:  0.953125\n",
      "Iteration:  3969  Loss:  0.15936704   Accuracy:  0.9375\n",
      "Iteration:  3970  Loss:  0.26738983   Accuracy:  0.9296875\n",
      "Iteration:  3971  Loss:  0.35454795   Accuracy:  0.890625\n",
      "Iteration:  3972  Loss:  0.18247019   Accuracy:  0.953125\n",
      "Iteration:  3973  Loss:  0.33464462   Accuracy:  0.9453125\n",
      "Iteration:  3974  Loss:  0.20892829   Accuracy:  0.9453125\n",
      "Iteration:  3975  Loss:  0.44862399   Accuracy:  0.859375\n",
      "Iteration:  3976  Loss:  0.2678999   Accuracy:  0.9296875\n",
      "Iteration:  3977  Loss:  0.26958007   Accuracy:  0.9140625\n",
      "Iteration:  3978  Loss:  0.22134052   Accuracy:  0.9140625\n",
      "Iteration:  3979  Loss:  0.24555664   Accuracy:  0.9453125\n",
      "Iteration:  3980  Loss:  0.30956313   Accuracy:  0.8984375\n",
      "Iteration:  3981  Loss:  0.2765085   Accuracy:  0.9140625\n",
      "Iteration:  3982  Loss:  0.20858675   Accuracy:  0.96875\n",
      "Iteration:  3983  Loss:  0.21433285   Accuracy:  0.9375\n",
      "Iteration:  3984  Loss:  0.18407102   Accuracy:  0.9296875\n",
      "Iteration:  3985  Loss:  0.44854504   Accuracy:  0.9375\n",
      "Iteration:  3986  Loss:  0.21484359   Accuracy:  0.9296875\n",
      "Iteration:  3987  Loss:  0.22095814   Accuracy:  0.9296875\n",
      "Iteration:  3988  Loss:  0.23869227   Accuracy:  0.9140625\n",
      "Iteration:  3989  Loss:  0.28100717   Accuracy:  0.9140625\n",
      "Iteration:  3990  Loss:  0.2883346   Accuracy:  0.90625\n",
      "Iteration:  3991  Loss:  0.43686843   Accuracy:  0.9140625\n",
      "Iteration:  3992  Loss:  0.2729841   Accuracy:  0.9296875\n",
      "Iteration:  3993  Loss:  0.34383494   Accuracy:  0.90625\n",
      "Iteration:  3994  Loss:  0.2815413   Accuracy:  0.9140625\n",
      "Iteration:  3995  Loss:  0.122007735   Accuracy:  0.9609375\n",
      "Iteration:  3996  Loss:  0.30793712   Accuracy:  0.90625\n",
      "Iteration:  3997  Loss:  0.18871936   Accuracy:  0.9453125\n",
      "Iteration:  3998  Loss:  0.45970276   Accuracy:  0.875\n",
      "Iteration:  3999  Loss:  0.2791116   Accuracy:  0.90625\n",
      "Iteration:  4000  Loss:  0.16210088   Accuracy:  0.9609375\n",
      "Iteration:  4001  Loss:  0.17769925   Accuracy:  0.9453125\n",
      "Iteration:  4002  Loss:  0.2786711   Accuracy:  0.9453125\n",
      "Iteration:  4003  Loss:  0.31933552   Accuracy:  0.9140625\n",
      "Iteration:  4004  Loss:  0.3221891   Accuracy:  0.90625\n",
      "Iteration:  4005  Loss:  0.25165278   Accuracy:  0.953125\n",
      "Iteration:  4006  Loss:  0.25541374   Accuracy:  0.921875\n",
      "Iteration:  4007  Loss:  0.16027296   Accuracy:  0.9453125\n",
      "Iteration:  4008  Loss:  0.17971797   Accuracy:  0.953125\n",
      "Iteration:  4009  Loss:  0.17741781   Accuracy:  0.9375\n",
      "Iteration:  4010  Loss:  0.13983381   Accuracy:  0.953125\n",
      "Iteration:  4011  Loss:  0.24828966   Accuracy:  0.9375\n",
      "Iteration:  4012  Loss:  0.1993071   Accuracy:  0.921875\n",
      "Iteration:  4013  Loss:  0.19661507   Accuracy:  0.9375\n",
      "Iteration:  4014  Loss:  0.32056564   Accuracy:  0.921875\n",
      "Iteration:  4015  Loss:  0.2640138   Accuracy:  0.9375\n",
      "Iteration:  4016  Loss:  0.22226757   Accuracy:  0.9296875\n",
      "Iteration:  4017  Loss:  0.23568338   Accuracy:  0.9296875\n",
      "Iteration:  4018  Loss:  0.21512294   Accuracy:  0.9375\n",
      "Iteration:  4019  Loss:  0.26922315   Accuracy:  0.921875\n",
      "Iteration:  4020  Loss:  0.26797122   Accuracy:  0.8828125\n",
      "Iteration:  4021  Loss:  0.184145   Accuracy:  0.9453125\n",
      "Iteration:  4022  Loss:  0.17058608   Accuracy:  0.953125\n",
      "Iteration:  4023  Loss:  0.26278523   Accuracy:  0.9375\n",
      "Iteration:  4024  Loss:  0.35566938   Accuracy:  0.8828125\n",
      "Iteration:  4025  Loss:  0.3129849   Accuracy:  0.890625\n",
      "Iteration:  4026  Loss:  0.30608618   Accuracy:  0.9140625\n",
      "Iteration:  4027  Loss:  0.3190225   Accuracy:  0.9140625\n",
      "Iteration:  4028  Loss:  0.18425134   Accuracy:  0.9453125\n",
      "Iteration:  4029  Loss:  0.1622862   Accuracy:  0.953125\n",
      "Iteration:  4030  Loss:  0.18692271   Accuracy:  0.9296875\n",
      "Iteration:  4031  Loss:  0.2852844   Accuracy:  0.9375\n",
      "Iteration:  4032  Loss:  0.2369999   Accuracy:  0.9453125\n",
      "Iteration:  4033  Loss:  0.32767826   Accuracy:  0.9140625\n",
      "Iteration:  4034  Loss:  0.22925875   Accuracy:  0.9453125\n",
      "Iteration:  4035  Loss:  0.24616838   Accuracy:  0.90625\n",
      "Iteration:  4036  Loss:  0.29720628   Accuracy:  0.90625\n",
      "Iteration:  4037  Loss:  0.31395188   Accuracy:  0.9140625\n",
      "Iteration:  4038  Loss:  0.2293688   Accuracy:  0.9140625\n",
      "Iteration:  4039  Loss:  0.31308115   Accuracy:  0.890625\n",
      "Iteration:  4040  Loss:  0.41953528   Accuracy:  0.890625\n",
      "Iteration:  4041  Loss:  0.27939272   Accuracy:  0.921875\n",
      "Iteration:  4042  Loss:  0.39239323   Accuracy:  0.890625\n",
      "Iteration:  4043  Loss:  0.18430223   Accuracy:  0.96875\n",
      "Iteration:  4044  Loss:  0.29217064   Accuracy:  0.8984375\n",
      "Iteration:  4045  Loss:  0.17700957   Accuracy:  0.953125\n",
      "Iteration:  4046  Loss:  0.41305274   Accuracy:  0.921875\n",
      "Iteration:  4047  Loss:  0.2552715   Accuracy:  0.9140625\n",
      "Iteration:  4048  Loss:  0.13964012   Accuracy:  0.9609375\n",
      "Iteration:  4049  Loss:  0.2129558   Accuracy:  0.9375\n",
      "Iteration:  4050  Loss:  0.5078617   Accuracy:  0.90625\n",
      "Iteration:  4051  Loss:  0.2980944   Accuracy:  0.9296875\n",
      "Iteration:  4052  Loss:  0.21754803   Accuracy:  0.9296875\n",
      "Iteration:  4053  Loss:  0.2977063   Accuracy:  0.875\n",
      "Iteration:  4054  Loss:  0.3183002   Accuracy:  0.9140625\n",
      "Iteration:  4055  Loss:  0.24338062   Accuracy:  0.8984375\n",
      "Iteration:  4056  Loss:  0.23970771   Accuracy:  0.921875\n",
      "Iteration:  4057  Loss:  0.28563493   Accuracy:  0.9140625\n",
      "Iteration:  4058  Loss:  0.21606705   Accuracy:  0.921875\n",
      "Iteration:  4059  Loss:  0.25941092   Accuracy:  0.921875\n",
      "Iteration:  4060  Loss:  0.2763108   Accuracy:  0.921875\n",
      "Iteration:  4061  Loss:  0.23229077   Accuracy:  0.90625\n",
      "Iteration:  4062  Loss:  0.18381944   Accuracy:  0.953125\n",
      "Iteration:  4063  Loss:  0.25804257   Accuracy:  0.921875\n",
      "Iteration:  4064  Loss:  0.21875867   Accuracy:  0.9296875\n",
      "Iteration:  4065  Loss:  0.23040643   Accuracy:  0.9375\n",
      "Iteration:  4066  Loss:  0.24847336   Accuracy:  0.9140625\n",
      "Iteration:  4067  Loss:  0.25941056   Accuracy:  0.90625\n",
      "Iteration:  4068  Loss:  0.3287238   Accuracy:  0.90625\n",
      "Iteration:  4069  Loss:  0.17010729   Accuracy:  0.9375\n",
      "Iteration:  4070  Loss:  0.3503154   Accuracy:  0.90625\n",
      "Iteration:  4071  Loss:  0.3172108   Accuracy:  0.8984375\n",
      "Iteration:  4072  Loss:  0.2750783   Accuracy:  0.9296875\n",
      "Iteration:  4073  Loss:  0.36068416   Accuracy:  0.921875\n",
      "Iteration:  4074  Loss:  0.22136824   Accuracy:  0.9375\n",
      "Iteration:  4075  Loss:  0.1394037   Accuracy:  0.96875\n",
      "Iteration:  4076  Loss:  0.3069136   Accuracy:  0.9296875\n",
      "Iteration:  4077  Loss:  0.21798058   Accuracy:  0.9453125\n",
      "Iteration:  4078  Loss:  0.17306094   Accuracy:  0.953125\n",
      "Iteration:  4079  Loss:  0.16116837   Accuracy:  0.9375\n",
      "Iteration:  4080  Loss:  0.22126803   Accuracy:  0.9375\n",
      "Iteration:  4081  Loss:  0.28251427   Accuracy:  0.9140625\n",
      "Iteration:  4082  Loss:  0.35083342   Accuracy:  0.8984375\n",
      "Iteration:  4083  Loss:  0.48147345   Accuracy:  0.875\n",
      "Iteration:  4084  Loss:  0.1351735   Accuracy:  0.96875\n",
      "Iteration:  4085  Loss:  0.2798789   Accuracy:  0.9375\n",
      "Iteration:  4086  Loss:  0.29551136   Accuracy:  0.9375\n",
      "Iteration:  4087  Loss:  0.2423316   Accuracy:  0.953125\n",
      "Iteration:  4088  Loss:  0.30960774   Accuracy:  0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4089  Loss:  0.28564554   Accuracy:  0.921875\n",
      "Iteration:  4090  Loss:  0.2704301   Accuracy:  0.90625\n",
      "Iteration:  4091  Loss:  0.14876008   Accuracy:  0.9609375\n",
      "Iteration:  4092  Loss:  0.22525804   Accuracy:  0.9375\n",
      "Iteration:  4093  Loss:  0.25214478   Accuracy:  0.921875\n",
      "Iteration:  4094  Loss:  0.2442261   Accuracy:  0.890625\n",
      "Iteration:  4095  Loss:  0.270923   Accuracy:  0.9296875\n",
      "Iteration:  4096  Loss:  0.26439512   Accuracy:  0.9375\n",
      "Iteration:  4097  Loss:  0.18037786   Accuracy:  0.953125\n",
      "Iteration:  4098  Loss:  0.41443002   Accuracy:  0.890625\n",
      "Iteration:  4099  Loss:  0.24977505   Accuracy:  0.9296875\n",
      "Iteration:  4100  Loss:  0.23542756   Accuracy:  0.9375\n",
      "Iteration:  4101  Loss:  0.23200949   Accuracy:  0.9140625\n",
      "Iteration:  4102  Loss:  0.17096952   Accuracy:  0.953125\n",
      "Iteration:  4103  Loss:  0.2578624   Accuracy:  0.921875\n",
      "Iteration:  4104  Loss:  0.14698723   Accuracy:  0.96875\n",
      "Iteration:  4105  Loss:  0.1578293   Accuracy:  0.953125\n",
      "Iteration:  4106  Loss:  0.23097812   Accuracy:  0.9296875\n",
      "Iteration:  4107  Loss:  0.19986808   Accuracy:  0.9296875\n",
      "Iteration:  4108  Loss:  0.3480698   Accuracy:  0.90625\n",
      "Iteration:  4109  Loss:  0.25269574   Accuracy:  0.9609375\n",
      "Iteration:  4110  Loss:  0.13783047   Accuracy:  0.953125\n",
      "Iteration:  4111  Loss:  0.19206649   Accuracy:  0.9453125\n",
      "Iteration:  4112  Loss:  0.25411063   Accuracy:  0.953125\n",
      "Iteration:  4113  Loss:  0.1830634   Accuracy:  0.953125\n",
      "Iteration:  4114  Loss:  0.19160953   Accuracy:  0.9375\n",
      "Iteration:  4115  Loss:  0.2416603   Accuracy:  0.9375\n",
      "Iteration:  4116  Loss:  0.20876458   Accuracy:  0.9140625\n",
      "Iteration:  4117  Loss:  0.23319876   Accuracy:  0.921875\n",
      "Iteration:  4118  Loss:  0.28115225   Accuracy:  0.9375\n",
      "Iteration:  4119  Loss:  0.22693819   Accuracy:  0.9375\n",
      "Iteration:  4120  Loss:  0.26196733   Accuracy:  0.9296875\n",
      "Iteration:  4121  Loss:  0.2593174   Accuracy:  0.9296875\n",
      "Iteration:  4122  Loss:  0.28402936   Accuracy:  0.9375\n",
      "Iteration:  4123  Loss:  0.32535437   Accuracy:  0.9296875\n",
      "Iteration:  4124  Loss:  0.32690683   Accuracy:  0.90625\n",
      "Iteration:  4125  Loss:  0.26713753   Accuracy:  0.921875\n",
      "Iteration:  4126  Loss:  0.4087606   Accuracy:  0.90625\n",
      "Iteration:  4127  Loss:  0.1628023   Accuracy:  0.9609375\n",
      "Iteration:  4128  Loss:  0.20951006   Accuracy:  0.9296875\n",
      "Iteration:  4129  Loss:  0.30634177   Accuracy:  0.9375\n",
      "Iteration:  4130  Loss:  0.13502079   Accuracy:  0.953125\n",
      "Iteration:  4131  Loss:  0.18523909   Accuracy:  0.9375\n",
      "Iteration:  4132  Loss:  0.28106904   Accuracy:  0.9296875\n",
      "Iteration:  4133  Loss:  0.25366923   Accuracy:  0.8984375\n",
      "Iteration:  4134  Loss:  0.293455   Accuracy:  0.90625\n",
      "Iteration:  4135  Loss:  0.22005488   Accuracy:  0.953125\n",
      "Iteration:  4136  Loss:  0.40189534   Accuracy:  0.8984375\n",
      "Iteration:  4137  Loss:  0.2133799   Accuracy:  0.9140625\n",
      "Iteration:  4138  Loss:  0.25923753   Accuracy:  0.921875\n",
      "Iteration:  4139  Loss:  0.12614003   Accuracy:  0.9609375\n",
      "Iteration:  4140  Loss:  0.2052269   Accuracy:  0.9375\n",
      "Iteration:  4141  Loss:  0.26484546   Accuracy:  0.9140625\n",
      "Iteration:  4142  Loss:  0.20115104   Accuracy:  0.921875\n",
      "Iteration:  4143  Loss:  0.22783147   Accuracy:  0.9453125\n",
      "Iteration:  4144  Loss:  0.35570148   Accuracy:  0.8984375\n",
      "Iteration:  4145  Loss:  0.23629825   Accuracy:  0.921875\n",
      "Iteration:  4146  Loss:  0.18027648   Accuracy:  0.9453125\n",
      "Iteration:  4147  Loss:  0.21371934   Accuracy:  0.9375\n",
      "Iteration:  4148  Loss:  0.16540681   Accuracy:  0.9375\n",
      "Iteration:  4149  Loss:  0.15932845   Accuracy:  0.96875\n",
      "Iteration:  4150  Loss:  0.3019244   Accuracy:  0.9296875\n",
      "Iteration:  4151  Loss:  0.23155499   Accuracy:  0.9453125\n",
      "Iteration:  4152  Loss:  0.26264194   Accuracy:  0.8984375\n",
      "Iteration:  4153  Loss:  0.21780208   Accuracy:  0.9140625\n",
      "Iteration:  4154  Loss:  0.20514196   Accuracy:  0.9375\n",
      "Iteration:  4155  Loss:  0.256685   Accuracy:  0.9296875\n",
      "Iteration:  4156  Loss:  0.2840745   Accuracy:  0.9140625\n",
      "Iteration:  4157  Loss:  0.4034431   Accuracy:  0.8828125\n",
      "Iteration:  4158  Loss:  0.34643245   Accuracy:  0.9140625\n",
      "Iteration:  4159  Loss:  0.2414446   Accuracy:  0.8984375\n",
      "Iteration:  4160  Loss:  0.19169107   Accuracy:  0.9296875\n",
      "Iteration:  4161  Loss:  0.25999942   Accuracy:  0.9296875\n",
      "Iteration:  4162  Loss:  0.2398417   Accuracy:  0.9296875\n",
      "Iteration:  4163  Loss:  0.1924358   Accuracy:  0.96875\n",
      "Iteration:  4164  Loss:  0.15178701   Accuracy:  0.953125\n",
      "Iteration:  4165  Loss:  0.22972386   Accuracy:  0.9140625\n",
      "Iteration:  4166  Loss:  0.1941531   Accuracy:  0.921875\n",
      "Iteration:  4167  Loss:  0.29947463   Accuracy:  0.890625\n",
      "Iteration:  4168  Loss:  0.28471905   Accuracy:  0.90625\n",
      "Iteration:  4169  Loss:  0.23135348   Accuracy:  0.9375\n",
      "Iteration:  4170  Loss:  0.21212423   Accuracy:  0.9296875\n",
      "Iteration:  4171  Loss:  0.21601762   Accuracy:  0.9453125\n",
      "Iteration:  4172  Loss:  0.20605218   Accuracy:  0.9453125\n",
      "Iteration:  4173  Loss:  0.31557122   Accuracy:  0.9140625\n",
      "Iteration:  4174  Loss:  0.29512227   Accuracy:  0.9140625\n",
      "Iteration:  4175  Loss:  0.25160706   Accuracy:  0.921875\n",
      "Iteration:  4176  Loss:  0.32768717   Accuracy:  0.90625\n",
      "Iteration:  4177  Loss:  0.24269158   Accuracy:  0.921875\n",
      "Iteration:  4178  Loss:  0.30970904   Accuracy:  0.8984375\n",
      "Iteration:  4179  Loss:  0.44712904   Accuracy:  0.90625\n",
      "Iteration:  4180  Loss:  0.28487098   Accuracy:  0.890625\n",
      "Iteration:  4181  Loss:  0.26890483   Accuracy:  0.875\n",
      "Iteration:  4182  Loss:  0.31462544   Accuracy:  0.9140625\n",
      "Iteration:  4183  Loss:  0.2967831   Accuracy:  0.9453125\n",
      "Iteration:  4184  Loss:  0.26429245   Accuracy:  0.9296875\n",
      "Iteration:  4185  Loss:  0.29491425   Accuracy:  0.9140625\n",
      "Iteration:  4186  Loss:  0.13315201   Accuracy:  0.953125\n",
      "Iteration:  4187  Loss:  0.28138933   Accuracy:  0.9140625\n",
      "Iteration:  4188  Loss:  0.1651295   Accuracy:  0.9765625\n",
      "Iteration:  4189  Loss:  0.28652132   Accuracy:  0.8984375\n",
      "Iteration:  4190  Loss:  0.22834474   Accuracy:  0.90625\n",
      "Iteration:  4191  Loss:  0.23483868   Accuracy:  0.921875\n",
      "Iteration:  4192  Loss:  0.2656517   Accuracy:  0.921875\n",
      "Iteration:  4193  Loss:  0.19468343   Accuracy:  0.953125\n",
      "Iteration:  4194  Loss:  0.323822   Accuracy:  0.9453125\n",
      "Iteration:  4195  Loss:  0.40266946   Accuracy:  0.9140625\n",
      "Iteration:  4196  Loss:  0.32281482   Accuracy:  0.9375\n",
      "Iteration:  4197  Loss:  0.3008797   Accuracy:  0.9453125\n",
      "Iteration:  4198  Loss:  0.41286543   Accuracy:  0.890625\n",
      "Iteration:  4199  Loss:  0.2797339   Accuracy:  0.9453125\n",
      "Iteration:  4200  Loss:  0.2788608   Accuracy:  0.9296875\n",
      "Iteration:  4201  Loss:  0.32986808   Accuracy:  0.890625\n",
      "Iteration:  4202  Loss:  0.3935336   Accuracy:  0.90625\n",
      "Iteration:  4203  Loss:  0.24531615   Accuracy:  0.9375\n",
      "Iteration:  4204  Loss:  0.30543852   Accuracy:  0.9140625\n",
      "Iteration:  4205  Loss:  0.27764866   Accuracy:  0.9140625\n",
      "Iteration:  4206  Loss:  0.24269876   Accuracy:  0.9296875\n",
      "Iteration:  4207  Loss:  0.2949904   Accuracy:  0.9140625\n",
      "Iteration:  4208  Loss:  0.19714957   Accuracy:  0.9453125\n",
      "Iteration:  4209  Loss:  0.15205127   Accuracy:  0.9453125\n",
      "Iteration:  4210  Loss:  0.3296848   Accuracy:  0.921875\n",
      "Iteration:  4211  Loss:  0.18947598   Accuracy:  0.9296875\n",
      "Iteration:  4212  Loss:  0.25362504   Accuracy:  0.8984375\n",
      "Iteration:  4213  Loss:  0.37576872   Accuracy:  0.9140625\n",
      "Iteration:  4214  Loss:  0.19638063   Accuracy:  0.921875\n",
      "Iteration:  4215  Loss:  0.18327513   Accuracy:  0.9296875\n",
      "Iteration:  4216  Loss:  0.23367755   Accuracy:  0.921875\n",
      "Iteration:  4217  Loss:  0.25242484   Accuracy:  0.921875\n",
      "Iteration:  4218  Loss:  0.15126675   Accuracy:  0.9609375\n",
      "Iteration:  4219  Loss:  0.24413571   Accuracy:  0.9296875\n",
      "Iteration:  4220  Loss:  0.28635496   Accuracy:  0.90625\n",
      "Iteration:  4221  Loss:  0.23170128   Accuracy:  0.9140625\n",
      "Iteration:  4222  Loss:  0.23788539   Accuracy:  0.921875\n",
      "Iteration:  4223  Loss:  0.35107893   Accuracy:  0.9296875\n",
      "Iteration:  4224  Loss:  0.27051982   Accuracy:  0.9140625\n",
      "Iteration:  4225  Loss:  0.29824933   Accuracy:  0.9296875\n",
      "Iteration:  4226  Loss:  0.20755613   Accuracy:  0.9453125\n",
      "Iteration:  4227  Loss:  0.47613293   Accuracy:  0.8828125\n",
      "Iteration:  4228  Loss:  0.23148924   Accuracy:  0.9296875\n",
      "Iteration:  4229  Loss:  0.29717112   Accuracy:  0.8984375\n",
      "Iteration:  4230  Loss:  0.21532756   Accuracy:  0.9453125\n",
      "Iteration:  4231  Loss:  0.34880817   Accuracy:  0.8828125\n",
      "Iteration:  4232  Loss:  0.1956422   Accuracy:  0.9375\n",
      "Iteration:  4233  Loss:  0.1964025   Accuracy:  0.9296875\n",
      "Iteration:  4234  Loss:  0.15072821   Accuracy:  0.953125\n",
      "Iteration:  4235  Loss:  0.25881594   Accuracy:  0.890625\n",
      "Iteration:  4236  Loss:  0.21543357   Accuracy:  0.921875\n",
      "Iteration:  4237  Loss:  0.19339387   Accuracy:  0.96875\n",
      "Iteration:  4238  Loss:  0.35462487   Accuracy:  0.9140625\n",
      "Iteration:  4239  Loss:  0.13616303   Accuracy:  0.9765625\n",
      "Iteration:  4240  Loss:  0.19503854   Accuracy:  0.9296875\n",
      "Iteration:  4241  Loss:  0.23857126   Accuracy:  0.953125\n",
      "Iteration:  4242  Loss:  0.29996252   Accuracy:  0.8984375\n",
      "Iteration:  4243  Loss:  0.40637285   Accuracy:  0.921875\n",
      "Iteration:  4244  Loss:  0.39315978   Accuracy:  0.8984375\n",
      "Iteration:  4245  Loss:  0.3940819   Accuracy:  0.921875\n",
      "Iteration:  4246  Loss:  0.24977788   Accuracy:  0.921875\n",
      "Iteration:  4247  Loss:  0.49618253   Accuracy:  0.859375\n",
      "Iteration:  4248  Loss:  0.2856604   Accuracy:  0.9140625\n",
      "Iteration:  4249  Loss:  0.2549594   Accuracy:  0.90625\n",
      "Iteration:  4250  Loss:  0.3402444   Accuracy:  0.90625\n",
      "Iteration:  4251  Loss:  0.16095367   Accuracy:  0.9609375\n",
      "Iteration:  4252  Loss:  0.1939931   Accuracy:  0.953125\n",
      "Iteration:  4253  Loss:  0.21950322   Accuracy:  0.9375\n",
      "Iteration:  4254  Loss:  0.26229784   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4255  Loss:  0.41596824   Accuracy:  0.8984375\n",
      "Iteration:  4256  Loss:  0.23501776   Accuracy:  0.9375\n",
      "Iteration:  4257  Loss:  0.35231936   Accuracy:  0.9140625\n",
      "Iteration:  4258  Loss:  0.26050106   Accuracy:  0.953125\n",
      "Iteration:  4259  Loss:  0.20832944   Accuracy:  0.9453125\n",
      "Iteration:  4260  Loss:  0.26715052   Accuracy:  0.9453125\n",
      "Iteration:  4261  Loss:  0.35828376   Accuracy:  0.90625\n",
      "Iteration:  4262  Loss:  0.16503623   Accuracy:  0.96875\n",
      "Iteration:  4263  Loss:  0.21577756   Accuracy:  0.9140625\n",
      "Iteration:  4264  Loss:  0.30526793   Accuracy:  0.90625\n",
      "Iteration:  4265  Loss:  0.14608727   Accuracy:  0.9375\n",
      "Iteration:  4266  Loss:  0.11033499   Accuracy:  0.96875\n",
      "Iteration:  4267  Loss:  0.23031451   Accuracy:  0.9453125\n",
      "Iteration:  4268  Loss:  0.30743325   Accuracy:  0.9140625\n",
      "Iteration:  4269  Loss:  0.32712218   Accuracy:  0.921875\n",
      "Iteration:  4270  Loss:  0.238494   Accuracy:  0.953125\n",
      "Iteration:  4271  Loss:  0.386249   Accuracy:  0.8671875\n",
      "Iteration:  4272  Loss:  0.32497188   Accuracy:  0.90625\n",
      "Iteration:  4273  Loss:  0.3091479   Accuracy:  0.9140625\n",
      "Iteration:  4274  Loss:  0.24770531   Accuracy:  0.9296875\n",
      "Iteration:  4275  Loss:  0.25005552   Accuracy:  0.9140625\n",
      "Iteration:  4276  Loss:  0.25269836   Accuracy:  0.921875\n",
      "Iteration:  4277  Loss:  0.21889901   Accuracy:  0.9375\n",
      "Iteration:  4278  Loss:  0.35050267   Accuracy:  0.890625\n",
      "Iteration:  4279  Loss:  0.20202708   Accuracy:  0.9375\n",
      "Iteration:  4280  Loss:  0.24260382   Accuracy:  0.9140625\n",
      "Iteration:  4281  Loss:  0.28998446   Accuracy:  0.9609375\n",
      "Iteration:  4282  Loss:  0.34569615   Accuracy:  0.9296875\n",
      "Iteration:  4283  Loss:  0.41822416   Accuracy:  0.9453125\n",
      "Iteration:  4284  Loss:  0.20263286   Accuracy:  0.9296875\n",
      "Iteration:  4285  Loss:  0.323421   Accuracy:  0.9375\n",
      "Iteration:  4286  Loss:  0.15979916   Accuracy:  0.9609375\n",
      "Iteration:  4287  Loss:  0.26934424   Accuracy:  0.9140625\n",
      "Iteration:  4288  Loss:  0.20848453   Accuracy:  0.9140625\n",
      "Iteration:  4289  Loss:  0.24820656   Accuracy:  0.921875\n",
      "Iteration:  4290  Loss:  0.26004195   Accuracy:  0.9296875\n",
      "Iteration:  4291  Loss:  0.3902097   Accuracy:  0.90625\n",
      "Iteration:  4292  Loss:  0.20668828   Accuracy:  0.9375\n",
      "Iteration:  4293  Loss:  0.2179263   Accuracy:  0.9375\n",
      "Iteration:  4294  Loss:  0.22753282   Accuracy:  0.9375\n",
      "Iteration:  4295  Loss:  0.326342   Accuracy:  0.8984375\n",
      "Iteration:  4296  Loss:  0.12707257   Accuracy:  0.96875\n",
      "Iteration:  4297  Loss:  0.3103663   Accuracy:  0.890625\n",
      "Iteration:  4298  Loss:  0.23027983   Accuracy:  0.9296875\n",
      "Iteration:  4299  Loss:  0.22003108   Accuracy:  0.9140625\n",
      "Iteration:  4300  Loss:  0.13804577   Accuracy:  0.953125\n",
      "Iteration:  4301  Loss:  0.14469808   Accuracy:  0.9609375\n",
      "Iteration:  4302  Loss:  0.29490563   Accuracy:  0.921875\n",
      "Iteration:  4303  Loss:  0.2566814   Accuracy:  0.9375\n",
      "Iteration:  4304  Loss:  0.30155292   Accuracy:  0.8671875\n",
      "Iteration:  4305  Loss:  0.22742075   Accuracy:  0.9375\n",
      "Iteration:  4306  Loss:  0.2043332   Accuracy:  0.9453125\n",
      "Iteration:  4307  Loss:  0.2163696   Accuracy:  0.921875\n",
      "Iteration:  4308  Loss:  0.28444472   Accuracy:  0.9375\n",
      "Iteration:  4309  Loss:  0.3126477   Accuracy:  0.921875\n",
      "Iteration:  4310  Loss:  0.30055785   Accuracy:  0.90625\n",
      "Iteration:  4311  Loss:  0.26086152   Accuracy:  0.9296875\n",
      "Iteration:  4312  Loss:  0.2433277   Accuracy:  0.9375\n",
      "Iteration:  4313  Loss:  0.19121087   Accuracy:  0.9375\n",
      "Iteration:  4314  Loss:  0.22349587   Accuracy:  0.953125\n",
      "Iteration:  4315  Loss:  0.34459665   Accuracy:  0.90625\n",
      "Iteration:  4316  Loss:  0.26703197   Accuracy:  0.9609375\n",
      "Iteration:  4317  Loss:  0.17243777   Accuracy:  0.9375\n",
      "Iteration:  4318  Loss:  0.3908564   Accuracy:  0.90625\n",
      "Iteration:  4319  Loss:  0.17091213   Accuracy:  0.9609375\n",
      "Iteration:  4320  Loss:  0.30472478   Accuracy:  0.9375\n",
      "Iteration:  4321  Loss:  0.31161964   Accuracy:  0.890625\n",
      "Iteration:  4322  Loss:  0.29365414   Accuracy:  0.90625\n",
      "Iteration:  4323  Loss:  0.25594652   Accuracy:  0.921875\n",
      "Iteration:  4324  Loss:  0.29759783   Accuracy:  0.90625\n",
      "Iteration:  4325  Loss:  0.25161025   Accuracy:  0.9140625\n",
      "Iteration:  4326  Loss:  0.23083621   Accuracy:  0.921875\n",
      "Iteration:  4327  Loss:  0.21331114   Accuracy:  0.9453125\n",
      "Iteration:  4328  Loss:  0.2902641   Accuracy:  0.9140625\n",
      "Iteration:  4329  Loss:  0.21212868   Accuracy:  0.921875\n",
      "Iteration:  4330  Loss:  0.18728438   Accuracy:  0.9296875\n",
      "Iteration:  4331  Loss:  0.25341067   Accuracy:  0.9453125\n",
      "Iteration:  4332  Loss:  0.14539748   Accuracy:  0.9375\n",
      "Iteration:  4333  Loss:  0.20682086   Accuracy:  0.9375\n",
      "Iteration:  4334  Loss:  0.21795171   Accuracy:  0.921875\n",
      "Iteration:  4335  Loss:  0.3587059   Accuracy:  0.90625\n",
      "Iteration:  4336  Loss:  0.27110684   Accuracy:  0.9296875\n",
      "Iteration:  4337  Loss:  0.24528325   Accuracy:  0.9609375\n",
      "Iteration:  4338  Loss:  0.29707718   Accuracy:  0.9296875\n",
      "Iteration:  4339  Loss:  0.21235628   Accuracy:  0.9453125\n",
      "Iteration:  4340  Loss:  0.31099328   Accuracy:  0.9140625\n",
      "Iteration:  4341  Loss:  0.11773421   Accuracy:  0.96875\n",
      "Iteration:  4342  Loss:  0.21440047   Accuracy:  0.9375\n",
      "Iteration:  4343  Loss:  0.15634592   Accuracy:  0.9609375\n",
      "Iteration:  4344  Loss:  0.36957383   Accuracy:  0.8984375\n",
      "Iteration:  4345  Loss:  0.33402744   Accuracy:  0.8984375\n",
      "Iteration:  4346  Loss:  0.16696948   Accuracy:  0.9609375\n",
      "Iteration:  4347  Loss:  0.34216398   Accuracy:  0.90625\n",
      "Iteration:  4348  Loss:  0.17275152   Accuracy:  0.9609375\n",
      "Iteration:  4349  Loss:  0.27854252   Accuracy:  0.9375\n",
      "Iteration:  4350  Loss:  0.13926546   Accuracy:  0.9765625\n",
      "Iteration:  4351  Loss:  0.28897393   Accuracy:  0.890625\n",
      "Iteration:  4352  Loss:  0.26955405   Accuracy:  0.90625\n",
      "Iteration:  4353  Loss:  0.23119134   Accuracy:  0.9453125\n",
      "Iteration:  4354  Loss:  0.30802062   Accuracy:  0.921875\n",
      "Iteration:  4355  Loss:  0.4209166   Accuracy:  0.8984375\n",
      "Iteration:  4356  Loss:  0.32474238   Accuracy:  0.90625\n",
      "Iteration:  4357  Loss:  0.37275773   Accuracy:  0.9140625\n",
      "Iteration:  4358  Loss:  0.21447378   Accuracy:  0.9453125\n",
      "Iteration:  4359  Loss:  0.21644017   Accuracy:  0.9140625\n",
      "Iteration:  4360  Loss:  0.100755155   Accuracy:  0.96875\n",
      "Iteration:  4361  Loss:  0.22527415   Accuracy:  0.9453125\n",
      "Iteration:  4362  Loss:  0.24978927   Accuracy:  0.9453125\n",
      "Iteration:  4363  Loss:  0.19626175   Accuracy:  0.9375\n",
      "Iteration:  4364  Loss:  0.28944486   Accuracy:  0.9296875\n",
      "Iteration:  4365  Loss:  0.33893132   Accuracy:  0.9296875\n",
      "Iteration:  4366  Loss:  0.16876023   Accuracy:  0.96875\n",
      "Iteration:  4367  Loss:  0.30513126   Accuracy:  0.9296875\n",
      "Iteration:  4368  Loss:  0.15311086   Accuracy:  0.953125\n",
      "Iteration:  4369  Loss:  0.1764627   Accuracy:  0.9375\n",
      "Iteration:  4370  Loss:  0.20420022   Accuracy:  0.921875\n",
      "Iteration:  4371  Loss:  0.3493133   Accuracy:  0.9140625\n",
      "Iteration:  4372  Loss:  0.173702   Accuracy:  0.9609375\n",
      "Iteration:  4373  Loss:  0.355766   Accuracy:  0.921875\n",
      "Iteration:  4374  Loss:  0.20377253   Accuracy:  0.9453125\n",
      "Iteration:  4375  Loss:  0.26561415   Accuracy:  0.9140625\n",
      "Iteration:  4376  Loss:  0.18649393   Accuracy:  0.9609375\n",
      "Iteration:  4377  Loss:  0.25141022   Accuracy:  0.921875\n",
      "Iteration:  4378  Loss:  0.44742715   Accuracy:  0.8515625\n",
      "Iteration:  4379  Loss:  0.34616113   Accuracy:  0.8984375\n",
      "Iteration:  4380  Loss:  0.21665455   Accuracy:  0.9375\n",
      "Iteration:  4381  Loss:  0.26580423   Accuracy:  0.9453125\n",
      "Iteration:  4382  Loss:  0.24579972   Accuracy:  0.8984375\n",
      "Iteration:  4383  Loss:  0.2015492   Accuracy:  0.953125\n",
      "Iteration:  4384  Loss:  0.3441036   Accuracy:  0.9140625\n",
      "Iteration:  4385  Loss:  0.24315043   Accuracy:  0.9375\n",
      "Iteration:  4386  Loss:  0.31126896   Accuracy:  0.9140625\n",
      "Iteration:  4387  Loss:  0.28697056   Accuracy:  0.8984375\n",
      "Iteration:  4388  Loss:  0.17780675   Accuracy:  0.953125\n",
      "Iteration:  4389  Loss:  0.3465386   Accuracy:  0.9140625\n",
      "Iteration:  4390  Loss:  0.3311203   Accuracy:  0.9140625\n",
      "Iteration:  4391  Loss:  0.21260227   Accuracy:  0.9453125\n",
      "Iteration:  4392  Loss:  0.121997416   Accuracy:  0.96875\n",
      "Iteration:  4393  Loss:  0.33567166   Accuracy:  0.9140625\n",
      "Iteration:  4394  Loss:  0.25664175   Accuracy:  0.921875\n",
      "Iteration:  4395  Loss:  0.3825416   Accuracy:  0.8671875\n",
      "Iteration:  4396  Loss:  0.2754522   Accuracy:  0.921875\n",
      "Iteration:  4397  Loss:  0.2596603   Accuracy:  0.9296875\n",
      "Iteration:  4398  Loss:  0.18532307   Accuracy:  0.9296875\n",
      "Iteration:  4399  Loss:  0.29170126   Accuracy:  0.8984375\n",
      "Iteration:  4400  Loss:  0.3376983   Accuracy:  0.90625\n",
      "Iteration:  4401  Loss:  0.29983163   Accuracy:  0.9296875\n",
      "Iteration:  4402  Loss:  0.23278086   Accuracy:  0.921875\n",
      "Iteration:  4403  Loss:  0.34038687   Accuracy:  0.890625\n",
      "Iteration:  4404  Loss:  0.32557416   Accuracy:  0.9140625\n",
      "Iteration:  4405  Loss:  0.15768756   Accuracy:  0.9453125\n",
      "Iteration:  4406  Loss:  0.20595144   Accuracy:  0.9375\n",
      "Iteration:  4407  Loss:  0.19561335   Accuracy:  0.9609375\n",
      "Iteration:  4408  Loss:  0.28959948   Accuracy:  0.890625\n",
      "Iteration:  4409  Loss:  0.23092787   Accuracy:  0.90625\n",
      "Iteration:  4410  Loss:  0.3459465   Accuracy:  0.9140625\n",
      "Iteration:  4411  Loss:  0.23662719   Accuracy:  0.9140625\n",
      "Iteration:  4412  Loss:  0.21884564   Accuracy:  0.9140625\n",
      "Iteration:  4413  Loss:  0.3658713   Accuracy:  0.90625\n",
      "Iteration:  4414  Loss:  0.43155837   Accuracy:  0.890625\n",
      "Iteration:  4415  Loss:  0.40849403   Accuracy:  0.8984375\n",
      "Iteration:  4416  Loss:  0.17473957   Accuracy:  0.953125\n",
      "Iteration:  4417  Loss:  0.15137097   Accuracy:  0.9765625\n",
      "Iteration:  4418  Loss:  0.19096199   Accuracy:  0.9375\n",
      "Iteration:  4419  Loss:  0.26919562   Accuracy:  0.9296875\n",
      "Iteration:  4420  Loss:  0.22723585   Accuracy:  0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4421  Loss:  0.34998643   Accuracy:  0.8984375\n",
      "Iteration:  4422  Loss:  0.25222754   Accuracy:  0.921875\n",
      "Iteration:  4423  Loss:  0.15171105   Accuracy:  0.953125\n",
      "Iteration:  4424  Loss:  0.23714697   Accuracy:  0.9453125\n",
      "Iteration:  4425  Loss:  0.22239685   Accuracy:  0.9140625\n",
      "Iteration:  4426  Loss:  0.2806639   Accuracy:  0.921875\n",
      "Iteration:  4427  Loss:  0.3586297   Accuracy:  0.859375\n",
      "Iteration:  4428  Loss:  0.15963851   Accuracy:  0.9375\n",
      "Iteration:  4429  Loss:  0.23776421   Accuracy:  0.9296875\n",
      "Iteration:  4430  Loss:  0.12455127   Accuracy:  0.953125\n",
      "Iteration:  4431  Loss:  0.26650515   Accuracy:  0.9375\n",
      "Iteration:  4432  Loss:  0.30590597   Accuracy:  0.921875\n",
      "Iteration:  4433  Loss:  0.37505487   Accuracy:  0.8828125\n",
      "Iteration:  4434  Loss:  0.4581421   Accuracy:  0.8671875\n",
      "Iteration:  4435  Loss:  0.36568305   Accuracy:  0.8984375\n",
      "Iteration:  4436  Loss:  0.21622384   Accuracy:  0.953125\n",
      "Iteration:  4437  Loss:  0.15941906   Accuracy:  0.9375\n",
      "Iteration:  4438  Loss:  0.13322642   Accuracy:  0.96875\n",
      "Iteration:  4439  Loss:  0.25919247   Accuracy:  0.90625\n",
      "Iteration:  4440  Loss:  0.27051353   Accuracy:  0.9375\n",
      "Iteration:  4441  Loss:  0.35826552   Accuracy:  0.90625\n",
      "Iteration:  4442  Loss:  0.4766425   Accuracy:  0.8671875\n",
      "Iteration:  4443  Loss:  0.31781742   Accuracy:  0.9140625\n",
      "Iteration:  4444  Loss:  0.15353625   Accuracy:  0.9453125\n",
      "Iteration:  4445  Loss:  0.24044156   Accuracy:  0.9296875\n",
      "Iteration:  4446  Loss:  0.308509   Accuracy:  0.90625\n",
      "Iteration:  4447  Loss:  0.25306097   Accuracy:  0.953125\n",
      "Iteration:  4448  Loss:  0.22450192   Accuracy:  0.953125\n",
      "Iteration:  4449  Loss:  0.26339224   Accuracy:  0.953125\n",
      "Iteration:  4450  Loss:  0.5135205   Accuracy:  0.890625\n",
      "Iteration:  4451  Loss:  0.32011613   Accuracy:  0.921875\n",
      "Iteration:  4452  Loss:  0.29596403   Accuracy:  0.9296875\n",
      "Iteration:  4453  Loss:  0.18279593   Accuracy:  0.953125\n",
      "Iteration:  4454  Loss:  0.26304436   Accuracy:  0.9296875\n",
      "Iteration:  4455  Loss:  0.22536816   Accuracy:  0.921875\n",
      "Iteration:  4456  Loss:  0.28105122   Accuracy:  0.9375\n",
      "Iteration:  4457  Loss:  0.283147   Accuracy:  0.9375\n",
      "Iteration:  4458  Loss:  0.24848849   Accuracy:  0.953125\n",
      "Iteration:  4459  Loss:  0.22614618   Accuracy:  0.9296875\n",
      "Iteration:  4460  Loss:  0.32626808   Accuracy:  0.90625\n",
      "Iteration:  4461  Loss:  0.23811802   Accuracy:  0.90625\n",
      "Iteration:  4462  Loss:  0.11373468   Accuracy:  0.9765625\n",
      "Iteration:  4463  Loss:  0.25828332   Accuracy:  0.921875\n",
      "Iteration:  4464  Loss:  0.21130407   Accuracy:  0.9375\n",
      "Iteration:  4465  Loss:  0.36720052   Accuracy:  0.9140625\n",
      "Iteration:  4466  Loss:  0.24368806   Accuracy:  0.8984375\n",
      "Iteration:  4467  Loss:  0.3031218   Accuracy:  0.8984375\n",
      "Iteration:  4468  Loss:  0.37139732   Accuracy:  0.90625\n",
      "Iteration:  4469  Loss:  0.17025454   Accuracy:  0.9375\n",
      "Iteration:  4470  Loss:  0.24325967   Accuracy:  0.9140625\n",
      "Iteration:  4471  Loss:  0.2064154   Accuracy:  0.9296875\n",
      "Iteration:  4472  Loss:  0.3809921   Accuracy:  0.921875\n",
      "Iteration:  4473  Loss:  0.28390387   Accuracy:  0.921875\n",
      "Iteration:  4474  Loss:  0.31838572   Accuracy:  0.921875\n",
      "Iteration:  4475  Loss:  0.20638777   Accuracy:  0.921875\n",
      "Iteration:  4476  Loss:  0.2905149   Accuracy:  0.9140625\n",
      "Iteration:  4477  Loss:  0.21442577   Accuracy:  0.9296875\n",
      "Iteration:  4478  Loss:  0.17645316   Accuracy:  0.9375\n",
      "Iteration:  4479  Loss:  0.18425477   Accuracy:  0.953125\n",
      "Iteration:  4480  Loss:  0.23595811   Accuracy:  0.90625\n",
      "Iteration:  4481  Loss:  0.32609722   Accuracy:  0.8828125\n",
      "Iteration:  4482  Loss:  0.1758489   Accuracy:  0.953125\n",
      "Iteration:  4483  Loss:  0.21357755   Accuracy:  0.9375\n",
      "Iteration:  4484  Loss:  0.22737823   Accuracy:  0.921875\n",
      "Iteration:  4485  Loss:  0.51146936   Accuracy:  0.875\n",
      "Iteration:  4486  Loss:  0.26476738   Accuracy:  0.9140625\n",
      "Iteration:  4487  Loss:  0.36215094   Accuracy:  0.90625\n",
      "Iteration:  4488  Loss:  0.3250726   Accuracy:  0.921875\n",
      "Iteration:  4489  Loss:  0.22160396   Accuracy:  0.9375\n",
      "Iteration:  4490  Loss:  0.1794765   Accuracy:  0.9453125\n",
      "Iteration:  4491  Loss:  0.38545933   Accuracy:  0.9140625\n",
      "Iteration:  4492  Loss:  0.17306659   Accuracy:  0.9296875\n",
      "Iteration:  4493  Loss:  0.17711346   Accuracy:  0.9453125\n",
      "Iteration:  4494  Loss:  0.2164666   Accuracy:  0.9609375\n",
      "Iteration:  4495  Loss:  0.14054933   Accuracy:  0.9296875\n",
      "Iteration:  4496  Loss:  0.39676845   Accuracy:  0.9140625\n",
      "Iteration:  4497  Loss:  0.15485878   Accuracy:  0.953125\n",
      "Iteration:  4498  Loss:  0.4794465   Accuracy:  0.875\n",
      "Iteration:  4499  Loss:  0.24801286   Accuracy:  0.9296875\n",
      "Iteration:  4500  Loss:  0.46825495   Accuracy:  0.8515625\n",
      "Iteration:  4501  Loss:  0.26184946   Accuracy:  0.9140625\n",
      "Iteration:  4502  Loss:  0.19263369   Accuracy:  0.921875\n",
      "Iteration:  4503  Loss:  0.25182626   Accuracy:  0.9296875\n",
      "Iteration:  4504  Loss:  0.27860683   Accuracy:  0.9375\n",
      "Iteration:  4505  Loss:  0.30082786   Accuracy:  0.9453125\n",
      "Iteration:  4506  Loss:  0.32063335   Accuracy:  0.921875\n",
      "Iteration:  4507  Loss:  0.19446927   Accuracy:  0.921875\n",
      "Iteration:  4508  Loss:  0.169651   Accuracy:  0.9453125\n",
      "Iteration:  4509  Loss:  0.27057636   Accuracy:  0.9296875\n",
      "Iteration:  4510  Loss:  0.20819253   Accuracy:  0.9375\n",
      "Iteration:  4511  Loss:  0.19608805   Accuracy:  0.9453125\n",
      "Iteration:  4512  Loss:  0.33339962   Accuracy:  0.90625\n",
      "Iteration:  4513  Loss:  0.21734405   Accuracy:  0.953125\n",
      "Iteration:  4514  Loss:  0.36718035   Accuracy:  0.90625\n",
      "Iteration:  4515  Loss:  0.2857221   Accuracy:  0.9140625\n",
      "Iteration:  4516  Loss:  0.20596592   Accuracy:  0.9453125\n",
      "Iteration:  4517  Loss:  0.27846006   Accuracy:  0.921875\n",
      "Iteration:  4518  Loss:  0.17360581   Accuracy:  0.953125\n",
      "Iteration:  4519  Loss:  0.39145362   Accuracy:  0.9140625\n",
      "Iteration:  4520  Loss:  0.21918114   Accuracy:  0.9375\n",
      "Iteration:  4521  Loss:  0.26358736   Accuracy:  0.921875\n",
      "Iteration:  4522  Loss:  0.30129352   Accuracy:  0.9140625\n",
      "Iteration:  4523  Loss:  0.27108964   Accuracy:  0.9296875\n",
      "Iteration:  4524  Loss:  0.27034402   Accuracy:  0.921875\n",
      "Iteration:  4525  Loss:  0.4204609   Accuracy:  0.875\n",
      "Iteration:  4526  Loss:  0.33785957   Accuracy:  0.921875\n",
      "Iteration:  4527  Loss:  0.16231921   Accuracy:  0.9375\n",
      "Iteration:  4528  Loss:  0.20303449   Accuracy:  0.9453125\n",
      "Iteration:  4529  Loss:  0.19338977   Accuracy:  0.9453125\n",
      "Iteration:  4530  Loss:  0.3223295   Accuracy:  0.8984375\n",
      "Iteration:  4531  Loss:  0.29084054   Accuracy:  0.9296875\n",
      "Iteration:  4532  Loss:  0.3760857   Accuracy:  0.90625\n",
      "Iteration:  4533  Loss:  0.22850758   Accuracy:  0.9453125\n",
      "Iteration:  4534  Loss:  0.15196939   Accuracy:  0.9453125\n",
      "Iteration:  4535  Loss:  0.30053958   Accuracy:  0.9140625\n",
      "Iteration:  4536  Loss:  0.22811118   Accuracy:  0.9375\n",
      "Iteration:  4537  Loss:  0.20247449   Accuracy:  0.9375\n",
      "Iteration:  4538  Loss:  0.21057728   Accuracy:  0.9140625\n",
      "Iteration:  4539  Loss:  0.147077   Accuracy:  0.9609375\n",
      "Iteration:  4540  Loss:  0.176604   Accuracy:  0.9453125\n",
      "Iteration:  4541  Loss:  0.22689098   Accuracy:  0.921875\n",
      "Iteration:  4542  Loss:  0.2614077   Accuracy:  0.9453125\n",
      "Iteration:  4543  Loss:  0.3430878   Accuracy:  0.9140625\n",
      "Iteration:  4544  Loss:  0.3558108   Accuracy:  0.8828125\n",
      "Iteration:  4545  Loss:  0.35534996   Accuracy:  0.9453125\n",
      "Iteration:  4546  Loss:  0.24246104   Accuracy:  0.9453125\n",
      "Iteration:  4547  Loss:  0.19752087   Accuracy:  0.9375\n",
      "Iteration:  4548  Loss:  0.12665619   Accuracy:  0.96875\n",
      "Iteration:  4549  Loss:  0.22962119   Accuracy:  0.9140625\n",
      "Iteration:  4550  Loss:  0.3173962   Accuracy:  0.9140625\n",
      "Iteration:  4551  Loss:  0.1438973   Accuracy:  0.953125\n",
      "Iteration:  4552  Loss:  0.20810226   Accuracy:  0.9453125\n",
      "Iteration:  4553  Loss:  0.292501   Accuracy:  0.9140625\n",
      "Iteration:  4554  Loss:  0.33241767   Accuracy:  0.8828125\n",
      "Iteration:  4555  Loss:  0.18846793   Accuracy:  0.9609375\n",
      "Iteration:  4556  Loss:  0.17634404   Accuracy:  0.9375\n",
      "Iteration:  4557  Loss:  0.25272983   Accuracy:  0.9375\n",
      "Iteration:  4558  Loss:  0.2754579   Accuracy:  0.921875\n",
      "Iteration:  4559  Loss:  0.21850313   Accuracy:  0.9296875\n",
      "Iteration:  4560  Loss:  0.18527856   Accuracy:  0.953125\n",
      "Iteration:  4561  Loss:  0.23225714   Accuracy:  0.9140625\n",
      "Iteration:  4562  Loss:  0.17376345   Accuracy:  0.9453125\n",
      "Iteration:  4563  Loss:  0.28268263   Accuracy:  0.9375\n",
      "Iteration:  4564  Loss:  0.24794   Accuracy:  0.9296875\n",
      "Iteration:  4565  Loss:  0.32508135   Accuracy:  0.9375\n",
      "Iteration:  4566  Loss:  0.23807207   Accuracy:  0.921875\n",
      "Iteration:  4567  Loss:  0.12986004   Accuracy:  0.9453125\n",
      "Iteration:  4568  Loss:  0.14095224   Accuracy:  0.9375\n",
      "Iteration:  4569  Loss:  0.27932948   Accuracy:  0.890625\n",
      "Iteration:  4570  Loss:  0.24233094   Accuracy:  0.921875\n",
      "Iteration:  4571  Loss:  0.17594048   Accuracy:  0.953125\n",
      "Iteration:  4572  Loss:  0.22950682   Accuracy:  0.9296875\n",
      "Iteration:  4573  Loss:  0.21069808   Accuracy:  0.90625\n",
      "Iteration:  4574  Loss:  0.23688988   Accuracy:  0.9140625\n",
      "Iteration:  4575  Loss:  0.35106292   Accuracy:  0.8828125\n",
      "Iteration:  4576  Loss:  0.20682755   Accuracy:  0.9609375\n",
      "Iteration:  4577  Loss:  0.2531193   Accuracy:  0.9296875\n",
      "Iteration:  4578  Loss:  0.16310306   Accuracy:  0.953125\n",
      "Iteration:  4579  Loss:  0.19854878   Accuracy:  0.953125\n",
      "Iteration:  4580  Loss:  0.27795523   Accuracy:  0.90625\n",
      "Iteration:  4581  Loss:  0.12263465   Accuracy:  0.9609375\n",
      "Iteration:  4582  Loss:  0.2527245   Accuracy:  0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4583  Loss:  0.18824452   Accuracy:  0.953125\n",
      "Iteration:  4584  Loss:  0.2944032   Accuracy:  0.90625\n",
      "Iteration:  4585  Loss:  0.28386024   Accuracy:  0.9296875\n",
      "Iteration:  4586  Loss:  0.2576775   Accuracy:  0.9296875\n",
      "Iteration:  4587  Loss:  0.20993935   Accuracy:  0.9375\n",
      "Iteration:  4588  Loss:  0.29587346   Accuracy:  0.8671875\n",
      "Iteration:  4589  Loss:  0.19814566   Accuracy:  0.921875\n",
      "Iteration:  4590  Loss:  0.23063335   Accuracy:  0.9609375\n",
      "Iteration:  4591  Loss:  0.24120706   Accuracy:  0.9375\n",
      "Iteration:  4592  Loss:  0.22248468   Accuracy:  0.9140625\n",
      "Iteration:  4593  Loss:  0.16870034   Accuracy:  0.953125\n",
      "Iteration:  4594  Loss:  0.22437365   Accuracy:  0.890625\n",
      "Iteration:  4595  Loss:  0.12928058   Accuracy:  0.96875\n",
      "Iteration:  4596  Loss:  0.28696108   Accuracy:  0.9453125\n",
      "Iteration:  4597  Loss:  0.1548469   Accuracy:  0.9453125\n",
      "Iteration:  4598  Loss:  0.3469898   Accuracy:  0.9140625\n",
      "Iteration:  4599  Loss:  0.25880986   Accuracy:  0.90625\n",
      "Iteration:  4600  Loss:  0.26876807   Accuracy:  0.921875\n",
      "Iteration:  4601  Loss:  0.44283497   Accuracy:  0.875\n",
      "Iteration:  4602  Loss:  0.20663732   Accuracy:  0.9296875\n",
      "Iteration:  4603  Loss:  0.25078604   Accuracy:  0.921875\n",
      "Iteration:  4604  Loss:  0.43617135   Accuracy:  0.890625\n",
      "Iteration:  4605  Loss:  0.22811076   Accuracy:  0.9296875\n",
      "Iteration:  4606  Loss:  0.23621616   Accuracy:  0.953125\n",
      "Iteration:  4607  Loss:  0.19768019   Accuracy:  0.9296875\n",
      "Iteration:  4608  Loss:  0.34747106   Accuracy:  0.8984375\n",
      "Iteration:  4609  Loss:  0.30706236   Accuracy:  0.9140625\n",
      "Iteration:  4610  Loss:  0.19627403   Accuracy:  0.953125\n",
      "Iteration:  4611  Loss:  0.2938519   Accuracy:  0.9296875\n",
      "Iteration:  4612  Loss:  0.28827456   Accuracy:  0.90625\n",
      "Iteration:  4613  Loss:  0.4960599   Accuracy:  0.8828125\n",
      "Iteration:  4614  Loss:  0.3828299   Accuracy:  0.9140625\n",
      "Iteration:  4615  Loss:  0.1769642   Accuracy:  0.9296875\n",
      "Iteration:  4616  Loss:  0.22487447   Accuracy:  0.9609375\n",
      "Iteration:  4617  Loss:  0.25577986   Accuracy:  0.890625\n",
      "Iteration:  4618  Loss:  0.39225042   Accuracy:  0.90625\n",
      "Iteration:  4619  Loss:  0.41081136   Accuracy:  0.9375\n",
      "Iteration:  4620  Loss:  0.22201139   Accuracy:  0.9453125\n",
      "Iteration:  4621  Loss:  0.21351364   Accuracy:  0.953125\n",
      "Iteration:  4622  Loss:  0.29932907   Accuracy:  0.9140625\n",
      "Iteration:  4623  Loss:  0.21210371   Accuracy:  0.9453125\n",
      "Iteration:  4624  Loss:  0.13645151   Accuracy:  0.953125\n",
      "Iteration:  4625  Loss:  0.15657598   Accuracy:  0.9609375\n",
      "Iteration:  4626  Loss:  0.24589752   Accuracy:  0.9453125\n",
      "Iteration:  4627  Loss:  0.25362134   Accuracy:  0.90625\n",
      "Iteration:  4628  Loss:  0.2598778   Accuracy:  0.90625\n",
      "Iteration:  4629  Loss:  0.22074229   Accuracy:  0.90625\n",
      "Iteration:  4630  Loss:  0.44633266   Accuracy:  0.875\n",
      "Iteration:  4631  Loss:  0.23581001   Accuracy:  0.9453125\n",
      "Iteration:  4632  Loss:  0.31629544   Accuracy:  0.9140625\n",
      "Iteration:  4633  Loss:  0.18637052   Accuracy:  0.9375\n",
      "Iteration:  4634  Loss:  0.30218863   Accuracy:  0.921875\n",
      "Iteration:  4635  Loss:  0.40987712   Accuracy:  0.9140625\n",
      "Iteration:  4636  Loss:  0.25830004   Accuracy:  0.9453125\n",
      "Iteration:  4637  Loss:  0.2343818   Accuracy:  0.9453125\n",
      "Iteration:  4638  Loss:  0.24349257   Accuracy:  0.9140625\n",
      "Iteration:  4639  Loss:  0.22781597   Accuracy:  0.9609375\n",
      "Iteration:  4640  Loss:  0.27124265   Accuracy:  0.921875\n",
      "Iteration:  4641  Loss:  0.29284158   Accuracy:  0.9296875\n",
      "Iteration:  4642  Loss:  0.18948692   Accuracy:  0.9375\n",
      "Iteration:  4643  Loss:  0.14004466   Accuracy:  0.9453125\n",
      "Iteration:  4644  Loss:  0.24735717   Accuracy:  0.9453125\n",
      "Iteration:  4645  Loss:  0.36073852   Accuracy:  0.921875\n",
      "Iteration:  4646  Loss:  0.26005492   Accuracy:  0.9296875\n",
      "Iteration:  4647  Loss:  0.45543382   Accuracy:  0.9453125\n",
      "Iteration:  4648  Loss:  0.26389262   Accuracy:  0.90625\n",
      "Iteration:  4649  Loss:  0.25464338   Accuracy:  0.9140625\n",
      "Iteration:  4650  Loss:  0.3137065   Accuracy:  0.90625\n",
      "Iteration:  4651  Loss:  0.3537847   Accuracy:  0.9296875\n",
      "Iteration:  4652  Loss:  0.20542449   Accuracy:  0.921875\n",
      "Iteration:  4653  Loss:  0.3293812   Accuracy:  0.9140625\n",
      "Iteration:  4654  Loss:  0.31845966   Accuracy:  0.9296875\n",
      "Iteration:  4655  Loss:  0.33621538   Accuracy:  0.90625\n",
      "Iteration:  4656  Loss:  0.19624528   Accuracy:  0.9296875\n",
      "Iteration:  4657  Loss:  0.34494984   Accuracy:  0.921875\n",
      "Iteration:  4658  Loss:  0.3120071   Accuracy:  0.9296875\n",
      "Iteration:  4659  Loss:  0.37478665   Accuracy:  0.8984375\n",
      "Iteration:  4660  Loss:  0.18650869   Accuracy:  0.9375\n",
      "Iteration:  4661  Loss:  0.28316575   Accuracy:  0.9140625\n",
      "Iteration:  4662  Loss:  0.15267211   Accuracy:  0.96875\n",
      "Iteration:  4663  Loss:  0.23296791   Accuracy:  0.9296875\n",
      "Iteration:  4664  Loss:  0.30375993   Accuracy:  0.8984375\n",
      "Iteration:  4665  Loss:  0.5118998   Accuracy:  0.859375\n",
      "Iteration:  4666  Loss:  0.2230062   Accuracy:  0.9375\n",
      "Iteration:  4667  Loss:  0.16722086   Accuracy:  0.953125\n",
      "Iteration:  4668  Loss:  0.29266477   Accuracy:  0.921875\n",
      "Iteration:  4669  Loss:  0.37311053   Accuracy:  0.9140625\n",
      "Iteration:  4670  Loss:  0.21234545   Accuracy:  0.90625\n",
      "Iteration:  4671  Loss:  0.2889638   Accuracy:  0.9453125\n",
      "Iteration:  4672  Loss:  0.2129122   Accuracy:  0.96875\n",
      "Iteration:  4673  Loss:  0.27916026   Accuracy:  0.9375\n",
      "Iteration:  4674  Loss:  0.19504552   Accuracy:  0.9296875\n",
      "Iteration:  4675  Loss:  0.29946128   Accuracy:  0.9140625\n",
      "Iteration:  4676  Loss:  0.32255602   Accuracy:  0.8828125\n",
      "Iteration:  4677  Loss:  0.27664286   Accuracy:  0.9375\n",
      "Iteration:  4678  Loss:  0.16354764   Accuracy:  0.9375\n",
      "Iteration:  4679  Loss:  0.24069177   Accuracy:  0.9453125\n",
      "Iteration:  4680  Loss:  0.15753843   Accuracy:  0.96875\n",
      "Iteration:  4681  Loss:  0.17092526   Accuracy:  0.9375\n",
      "Iteration:  4682  Loss:  0.14954081   Accuracy:  0.953125\n",
      "Iteration:  4683  Loss:  0.21005587   Accuracy:  0.921875\n",
      "Iteration:  4684  Loss:  0.19835423   Accuracy:  0.921875\n",
      "Iteration:  4685  Loss:  0.17645456   Accuracy:  0.9609375\n",
      "Iteration:  4686  Loss:  0.21754688   Accuracy:  0.9296875\n",
      "Iteration:  4687  Loss:  0.1680327   Accuracy:  0.9296875\n",
      "Iteration:  4688  Loss:  0.24186477   Accuracy:  0.9296875\n",
      "Iteration:  4689  Loss:  0.30718854   Accuracy:  0.9140625\n",
      "Iteration:  4690  Loss:  0.27128398   Accuracy:  0.9375\n",
      "Iteration:  4691  Loss:  0.32001498   Accuracy:  0.90625\n",
      "Iteration:  4692  Loss:  0.20862414   Accuracy:  0.9453125\n",
      "Iteration:  4693  Loss:  0.48690456   Accuracy:  0.9140625\n",
      "Iteration:  4694  Loss:  0.30260998   Accuracy:  0.90625\n",
      "Iteration:  4695  Loss:  0.29381752   Accuracy:  0.953125\n",
      "Iteration:  4696  Loss:  0.31555185   Accuracy:  0.9140625\n",
      "Iteration:  4697  Loss:  0.19028139   Accuracy:  0.953125\n",
      "Iteration:  4698  Loss:  0.19495149   Accuracy:  0.9296875\n",
      "Iteration:  4699  Loss:  0.21621501   Accuracy:  0.9375\n",
      "Iteration:  4700  Loss:  0.19681183   Accuracy:  0.9453125\n",
      "Iteration:  4701  Loss:  0.18715031   Accuracy:  0.953125\n",
      "Iteration:  4702  Loss:  0.24350557   Accuracy:  0.921875\n",
      "Iteration:  4703  Loss:  0.2832318   Accuracy:  0.9375\n",
      "Iteration:  4704  Loss:  0.22902814   Accuracy:  0.9296875\n",
      "Iteration:  4705  Loss:  0.3888729   Accuracy:  0.890625\n",
      "Iteration:  4706  Loss:  0.25378916   Accuracy:  0.921875\n",
      "Iteration:  4707  Loss:  0.32136816   Accuracy:  0.9140625\n",
      "Iteration:  4708  Loss:  0.22721173   Accuracy:  0.9453125\n",
      "Iteration:  4709  Loss:  0.1840965   Accuracy:  0.9609375\n",
      "Iteration:  4710  Loss:  0.1670467   Accuracy:  0.9453125\n",
      "Iteration:  4711  Loss:  0.26192462   Accuracy:  0.9453125\n",
      "Iteration:  4712  Loss:  0.40225282   Accuracy:  0.8828125\n",
      "Iteration:  4713  Loss:  0.42595276   Accuracy:  0.90625\n",
      "Iteration:  4714  Loss:  0.2005663   Accuracy:  0.953125\n",
      "Iteration:  4715  Loss:  0.23924926   Accuracy:  0.953125\n",
      "Iteration:  4716  Loss:  0.20934793   Accuracy:  0.9453125\n",
      "Iteration:  4717  Loss:  0.4205826   Accuracy:  0.8984375\n",
      "Iteration:  4718  Loss:  0.29845887   Accuracy:  0.921875\n",
      "Iteration:  4719  Loss:  0.18447724   Accuracy:  0.9375\n",
      "Iteration:  4720  Loss:  0.27793077   Accuracy:  0.8671875\n",
      "Iteration:  4721  Loss:  0.25362897   Accuracy:  0.9140625\n",
      "Iteration:  4722  Loss:  0.4090181   Accuracy:  0.9140625\n",
      "Iteration:  4723  Loss:  0.26789227   Accuracy:  0.90625\n",
      "Iteration:  4724  Loss:  0.26046783   Accuracy:  0.9140625\n",
      "Iteration:  4725  Loss:  0.32567808   Accuracy:  0.8984375\n",
      "Iteration:  4726  Loss:  0.25673357   Accuracy:  0.9375\n",
      "Iteration:  4727  Loss:  0.2664299   Accuracy:  0.90625\n",
      "Iteration:  4728  Loss:  0.12633684   Accuracy:  0.9765625\n",
      "Iteration:  4729  Loss:  0.13890052   Accuracy:  0.9609375\n",
      "Iteration:  4730  Loss:  0.26427487   Accuracy:  0.9296875\n",
      "Iteration:  4731  Loss:  0.27852768   Accuracy:  0.9140625\n",
      "Iteration:  4732  Loss:  0.2492499   Accuracy:  0.9453125\n",
      "Iteration:  4733  Loss:  0.19576824   Accuracy:  0.9609375\n",
      "Iteration:  4734  Loss:  0.28143203   Accuracy:  0.9609375\n",
      "Iteration:  4735  Loss:  0.24360976   Accuracy:  0.9453125\n",
      "Iteration:  4736  Loss:  0.362566   Accuracy:  0.9296875\n",
      "Iteration:  4737  Loss:  0.19893572   Accuracy:  0.9453125\n",
      "Iteration:  4738  Loss:  0.2755015   Accuracy:  0.9140625\n",
      "Iteration:  4739  Loss:  0.43547055   Accuracy:  0.8828125\n",
      "Iteration:  4740  Loss:  0.22896138   Accuracy:  0.9296875\n",
      "Iteration:  4741  Loss:  0.24239947   Accuracy:  0.9453125\n",
      "Iteration:  4742  Loss:  0.28769225   Accuracy:  0.90625\n",
      "Iteration:  4743  Loss:  0.21504726   Accuracy:  0.9296875\n",
      "Iteration:  4744  Loss:  0.29497164   Accuracy:  0.90625\n",
      "Iteration:  4745  Loss:  0.32461426   Accuracy:  0.921875\n",
      "Iteration:  4746  Loss:  0.2437844   Accuracy:  0.9140625\n",
      "Iteration:  4747  Loss:  0.3034279   Accuracy:  0.9296875\n",
      "Iteration:  4748  Loss:  0.25585353   Accuracy:  0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4749  Loss:  0.34774673   Accuracy:  0.90625\n",
      "Iteration:  4750  Loss:  0.25394133   Accuracy:  0.9296875\n",
      "Iteration:  4751  Loss:  0.34306687   Accuracy:  0.90625\n",
      "Iteration:  4752  Loss:  0.20534295   Accuracy:  0.9453125\n",
      "Iteration:  4753  Loss:  0.194873   Accuracy:  0.9375\n",
      "Iteration:  4754  Loss:  0.36334372   Accuracy:  0.875\n",
      "Iteration:  4755  Loss:  0.26170886   Accuracy:  0.9296875\n",
      "Iteration:  4756  Loss:  0.15028739   Accuracy:  0.9609375\n",
      "Iteration:  4757  Loss:  0.3011222   Accuracy:  0.890625\n",
      "Iteration:  4758  Loss:  0.26853314   Accuracy:  0.890625\n",
      "Iteration:  4759  Loss:  0.25076252   Accuracy:  0.9375\n",
      "Iteration:  4760  Loss:  0.19331801   Accuracy:  0.953125\n",
      "Iteration:  4761  Loss:  0.21203248   Accuracy:  0.921875\n",
      "Iteration:  4762  Loss:  0.32660222   Accuracy:  0.9296875\n",
      "Iteration:  4763  Loss:  0.44127107   Accuracy:  0.8828125\n",
      "Iteration:  4764  Loss:  0.21939926   Accuracy:  0.9296875\n",
      "Iteration:  4765  Loss:  0.1631945   Accuracy:  0.9609375\n",
      "Iteration:  4766  Loss:  0.2527349   Accuracy:  0.9296875\n",
      "Iteration:  4767  Loss:  0.24184944   Accuracy:  0.9375\n",
      "Iteration:  4768  Loss:  0.27421787   Accuracy:  0.9140625\n",
      "Iteration:  4769  Loss:  0.26338974   Accuracy:  0.90625\n",
      "Iteration:  4770  Loss:  0.36180425   Accuracy:  0.90625\n",
      "Iteration:  4771  Loss:  0.33568332   Accuracy:  0.9296875\n",
      "Iteration:  4772  Loss:  0.49681863   Accuracy:  0.890625\n",
      "Iteration:  4773  Loss:  0.40941823   Accuracy:  0.8984375\n",
      "Iteration:  4774  Loss:  0.20481217   Accuracy:  0.9453125\n",
      "Iteration:  4775  Loss:  0.21916114   Accuracy:  0.921875\n",
      "Iteration:  4776  Loss:  0.30250365   Accuracy:  0.90625\n",
      "Iteration:  4777  Loss:  0.16460659   Accuracy:  0.9609375\n",
      "Iteration:  4778  Loss:  0.2872519   Accuracy:  0.90625\n",
      "Iteration:  4779  Loss:  0.43423837   Accuracy:  0.921875\n",
      "Iteration:  4780  Loss:  0.2951117   Accuracy:  0.9140625\n",
      "Iteration:  4781  Loss:  0.2516135   Accuracy:  0.90625\n",
      "Iteration:  4782  Loss:  0.3357078   Accuracy:  0.8984375\n",
      "Iteration:  4783  Loss:  0.30099434   Accuracy:  0.921875\n",
      "Iteration:  4784  Loss:  0.19024175   Accuracy:  0.9140625\n",
      "Iteration:  4785  Loss:  0.22309566   Accuracy:  0.9453125\n",
      "Iteration:  4786  Loss:  0.2681297   Accuracy:  0.9296875\n",
      "Iteration:  4787  Loss:  0.16909266   Accuracy:  0.953125\n",
      "Iteration:  4788  Loss:  0.17292154   Accuracy:  0.9453125\n",
      "Iteration:  4789  Loss:  0.12624785   Accuracy:  0.96875\n",
      "Iteration:  4790  Loss:  0.28662354   Accuracy:  0.890625\n",
      "Iteration:  4791  Loss:  0.36593765   Accuracy:  0.921875\n",
      "Iteration:  4792  Loss:  0.31905243   Accuracy:  0.90625\n",
      "Iteration:  4793  Loss:  0.32399917   Accuracy:  0.9140625\n",
      "Iteration:  4794  Loss:  0.2574213   Accuracy:  0.921875\n",
      "Iteration:  4795  Loss:  0.21318164   Accuracy:  0.9375\n",
      "Iteration:  4796  Loss:  0.21307977   Accuracy:  0.9140625\n",
      "Iteration:  4797  Loss:  0.36573392   Accuracy:  0.875\n",
      "Iteration:  4798  Loss:  0.29612905   Accuracy:  0.921875\n",
      "Iteration:  4799  Loss:  0.20093244   Accuracy:  0.9375\n",
      "Iteration:  4800  Loss:  0.31276852   Accuracy:  0.921875\n",
      "Iteration:  4801  Loss:  0.25200027   Accuracy:  0.9296875\n",
      "Iteration:  4802  Loss:  0.21956721   Accuracy:  0.9453125\n",
      "Iteration:  4803  Loss:  0.27948356   Accuracy:  0.921875\n",
      "Iteration:  4804  Loss:  0.31999582   Accuracy:  0.921875\n",
      "Iteration:  4805  Loss:  0.26832524   Accuracy:  0.921875\n",
      "Iteration:  4806  Loss:  0.26491866   Accuracy:  0.890625\n",
      "Iteration:  4807  Loss:  0.17721342   Accuracy:  0.953125\n",
      "Iteration:  4808  Loss:  0.20473145   Accuracy:  0.921875\n",
      "Iteration:  4809  Loss:  0.15235889   Accuracy:  0.9375\n",
      "Iteration:  4810  Loss:  0.20197555   Accuracy:  0.953125\n",
      "Iteration:  4811  Loss:  0.21609825   Accuracy:  0.9375\n",
      "Iteration:  4812  Loss:  0.3192818   Accuracy:  0.9296875\n",
      "Iteration:  4813  Loss:  0.23091325   Accuracy:  0.9296875\n",
      "Iteration:  4814  Loss:  0.29948318   Accuracy:  0.9375\n",
      "Iteration:  4815  Loss:  0.51371205   Accuracy:  0.8359375\n",
      "Iteration:  4816  Loss:  0.29277366   Accuracy:  0.90625\n",
      "Iteration:  4817  Loss:  0.29599354   Accuracy:  0.90625\n",
      "Iteration:  4818  Loss:  0.23756903   Accuracy:  0.9140625\n",
      "Iteration:  4819  Loss:  0.15936424   Accuracy:  0.9453125\n",
      "Iteration:  4820  Loss:  0.3063973   Accuracy:  0.921875\n",
      "Iteration:  4821  Loss:  0.38910288   Accuracy:  0.9296875\n",
      "Iteration:  4822  Loss:  0.32451546   Accuracy:  0.90625\n",
      "Iteration:  4823  Loss:  0.251759   Accuracy:  0.9453125\n",
      "Iteration:  4824  Loss:  0.17666149   Accuracy:  0.9375\n",
      "Iteration:  4825  Loss:  0.16470657   Accuracy:  0.953125\n",
      "Iteration:  4826  Loss:  0.3738916   Accuracy:  0.8671875\n",
      "Iteration:  4827  Loss:  0.5186223   Accuracy:  0.8359375\n",
      "Iteration:  4828  Loss:  0.17976663   Accuracy:  0.921875\n",
      "Iteration:  4829  Loss:  0.36249954   Accuracy:  0.8828125\n",
      "Iteration:  4830  Loss:  0.13888153   Accuracy:  0.9609375\n",
      "Iteration:  4831  Loss:  0.24373193   Accuracy:  0.921875\n",
      "Iteration:  4832  Loss:  0.22404785   Accuracy:  0.9453125\n",
      "Iteration:  4833  Loss:  0.4111906   Accuracy:  0.8984375\n",
      "Iteration:  4834  Loss:  0.34231046   Accuracy:  0.8828125\n",
      "Iteration:  4835  Loss:  0.16286941   Accuracy:  0.953125\n",
      "Iteration:  4836  Loss:  0.28343785   Accuracy:  0.9140625\n",
      "Iteration:  4837  Loss:  0.2669112   Accuracy:  0.9296875\n",
      "Iteration:  4838  Loss:  0.12888078   Accuracy:  0.96875\n",
      "Iteration:  4839  Loss:  0.22965428   Accuracy:  0.9140625\n",
      "Iteration:  4840  Loss:  0.19506599   Accuracy:  0.9609375\n",
      "Iteration:  4841  Loss:  0.27188164   Accuracy:  0.921875\n",
      "Iteration:  4842  Loss:  0.24427465   Accuracy:  0.9140625\n",
      "Iteration:  4843  Loss:  0.19705327   Accuracy:  0.953125\n",
      "Iteration:  4844  Loss:  0.1856581   Accuracy:  0.9140625\n",
      "Iteration:  4845  Loss:  0.16782755   Accuracy:  0.9453125\n",
      "Iteration:  4846  Loss:  0.4225508   Accuracy:  0.8828125\n",
      "Iteration:  4847  Loss:  0.21138147   Accuracy:  0.9453125\n",
      "Iteration:  4848  Loss:  0.26534888   Accuracy:  0.9296875\n",
      "Iteration:  4849  Loss:  0.40700006   Accuracy:  0.8984375\n",
      "Iteration:  4850  Loss:  0.2713219   Accuracy:  0.9375\n",
      "Iteration:  4851  Loss:  0.21448673   Accuracy:  0.9375\n",
      "Iteration:  4852  Loss:  0.28178513   Accuracy:  0.9140625\n",
      "Iteration:  4853  Loss:  0.21201144   Accuracy:  0.9296875\n",
      "Iteration:  4854  Loss:  0.26402244   Accuracy:  0.9296875\n",
      "Iteration:  4855  Loss:  0.11882846   Accuracy:  0.9765625\n",
      "Iteration:  4856  Loss:  0.1528162   Accuracy:  0.9609375\n",
      "Iteration:  4857  Loss:  0.14123951   Accuracy:  0.9453125\n",
      "Iteration:  4858  Loss:  0.151991   Accuracy:  0.9453125\n",
      "Iteration:  4859  Loss:  0.3328507   Accuracy:  0.90625\n",
      "Iteration:  4860  Loss:  0.30662104   Accuracy:  0.9140625\n",
      "Iteration:  4861  Loss:  0.25177032   Accuracy:  0.9140625\n",
      "Iteration:  4862  Loss:  0.21671236   Accuracy:  0.9375\n",
      "Iteration:  4863  Loss:  0.27679428   Accuracy:  0.921875\n",
      "Iteration:  4864  Loss:  0.16408914   Accuracy:  0.9609375\n",
      "Iteration:  4865  Loss:  0.19962934   Accuracy:  0.9609375\n",
      "Iteration:  4866  Loss:  0.22632343   Accuracy:  0.9453125\n",
      "Iteration:  4867  Loss:  0.22363494   Accuracy:  0.8984375\n",
      "Iteration:  4868  Loss:  0.22331007   Accuracy:  0.9375\n",
      "Iteration:  4869  Loss:  0.22478989   Accuracy:  0.921875\n",
      "Iteration:  4870  Loss:  0.35115606   Accuracy:  0.890625\n",
      "Iteration:  4871  Loss:  0.27223095   Accuracy:  0.9296875\n",
      "Iteration:  4872  Loss:  0.29790577   Accuracy:  0.9140625\n",
      "Iteration:  4873  Loss:  0.08425435   Accuracy:  0.984375\n",
      "Iteration:  4874  Loss:  0.17927796   Accuracy:  0.96875\n",
      "Iteration:  4875  Loss:  0.24600352   Accuracy:  0.9375\n",
      "Iteration:  4876  Loss:  0.207792   Accuracy:  0.921875\n",
      "Iteration:  4877  Loss:  0.26895195   Accuracy:  0.90625\n",
      "Iteration:  4878  Loss:  0.33213553   Accuracy:  0.9296875\n",
      "Iteration:  4879  Loss:  0.29029608   Accuracy:  0.9375\n",
      "Iteration:  4880  Loss:  0.25759006   Accuracy:  0.9296875\n",
      "Iteration:  4881  Loss:  0.17541015   Accuracy:  0.9453125\n",
      "Iteration:  4882  Loss:  0.21385574   Accuracy:  0.9375\n",
      "Iteration:  4883  Loss:  0.11479889   Accuracy:  0.9609375\n",
      "Iteration:  4884  Loss:  0.2266144   Accuracy:  0.90625\n",
      "Iteration:  4885  Loss:  0.10858515   Accuracy:  0.984375\n",
      "Iteration:  4886  Loss:  0.29220122   Accuracy:  0.921875\n",
      "Iteration:  4887  Loss:  0.18211864   Accuracy:  0.96875\n",
      "Iteration:  4888  Loss:  0.22599936   Accuracy:  0.9453125\n",
      "Iteration:  4889  Loss:  0.31789395   Accuracy:  0.890625\n",
      "Iteration:  4890  Loss:  0.21649191   Accuracy:  0.9296875\n",
      "Iteration:  4891  Loss:  0.1647051   Accuracy:  0.9609375\n",
      "Iteration:  4892  Loss:  0.2342865   Accuracy:  0.9296875\n",
      "Iteration:  4893  Loss:  0.36225823   Accuracy:  0.890625\n",
      "Iteration:  4894  Loss:  0.25749844   Accuracy:  0.9296875\n",
      "Iteration:  4895  Loss:  0.1897333   Accuracy:  0.953125\n",
      "Iteration:  4896  Loss:  0.20572266   Accuracy:  0.953125\n",
      "Iteration:  4897  Loss:  0.2595618   Accuracy:  0.90625\n",
      "Iteration:  4898  Loss:  0.35306323   Accuracy:  0.90625\n",
      "Iteration:  4899  Loss:  0.24019529   Accuracy:  0.921875\n",
      "Iteration:  4900  Loss:  0.40242514   Accuracy:  0.8984375\n",
      "Iteration:  4901  Loss:  0.2564212   Accuracy:  0.9375\n",
      "Iteration:  4902  Loss:  0.33344436   Accuracy:  0.9140625\n",
      "Iteration:  4903  Loss:  0.2716523   Accuracy:  0.9296875\n",
      "Iteration:  4904  Loss:  0.30385542   Accuracy:  0.9375\n",
      "Iteration:  4905  Loss:  0.31296685   Accuracy:  0.921875\n",
      "Iteration:  4906  Loss:  0.29060957   Accuracy:  0.9140625\n",
      "Iteration:  4907  Loss:  0.16295382   Accuracy:  0.953125\n",
      "Iteration:  4908  Loss:  0.264194   Accuracy:  0.9296875\n",
      "Iteration:  4909  Loss:  0.28919476   Accuracy:  0.9140625\n",
      "Iteration:  4910  Loss:  0.28114498   Accuracy:  0.8984375\n",
      "Iteration:  4911  Loss:  0.2128413   Accuracy:  0.9296875\n",
      "Iteration:  4912  Loss:  0.30850905   Accuracy:  0.9140625\n",
      "Iteration:  4913  Loss:  0.24731007   Accuracy:  0.90625\n",
      "Iteration:  4914  Loss:  0.26272845   Accuracy:  0.9140625\n",
      "Iteration:  4915  Loss:  0.23364854   Accuracy:  0.921875\n",
      "Iteration:  4916  Loss:  0.27317795   Accuracy:  0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4917  Loss:  0.19090527   Accuracy:  0.921875\n",
      "Iteration:  4918  Loss:  0.24748453   Accuracy:  0.9375\n",
      "Iteration:  4919  Loss:  0.27012056   Accuracy:  0.9140625\n",
      "Iteration:  4920  Loss:  0.43335143   Accuracy:  0.8984375\n",
      "Iteration:  4921  Loss:  0.3968981   Accuracy:  0.8984375\n",
      "Iteration:  4922  Loss:  0.17070565   Accuracy:  0.953125\n",
      "Iteration:  4923  Loss:  0.18410206   Accuracy:  0.9375\n",
      "Iteration:  4924  Loss:  0.20742634   Accuracy:  0.9609375\n",
      "Iteration:  4925  Loss:  0.4311788   Accuracy:  0.8828125\n",
      "Iteration:  4926  Loss:  0.16566113   Accuracy:  0.9453125\n",
      "Iteration:  4927  Loss:  0.22192287   Accuracy:  0.9296875\n",
      "Iteration:  4928  Loss:  0.19110744   Accuracy:  0.9609375\n",
      "Iteration:  4929  Loss:  0.13860658   Accuracy:  0.9765625\n",
      "Iteration:  4930  Loss:  0.14099643   Accuracy:  0.953125\n",
      "Iteration:  4931  Loss:  0.29931647   Accuracy:  0.8984375\n",
      "Iteration:  4932  Loss:  0.20232733   Accuracy:  0.921875\n",
      "Iteration:  4933  Loss:  0.20213951   Accuracy:  0.953125\n",
      "Iteration:  4934  Loss:  0.36817715   Accuracy:  0.90625\n",
      "Iteration:  4935  Loss:  0.1502819   Accuracy:  0.953125\n",
      "Iteration:  4936  Loss:  0.24057525   Accuracy:  0.9453125\n",
      "Iteration:  4937  Loss:  0.3102551   Accuracy:  0.9140625\n",
      "Iteration:  4938  Loss:  0.41641876   Accuracy:  0.890625\n",
      "Iteration:  4939  Loss:  0.30065534   Accuracy:  0.9140625\n",
      "Iteration:  4940  Loss:  0.31030732   Accuracy:  0.953125\n",
      "Iteration:  4941  Loss:  0.24586882   Accuracy:  0.9609375\n",
      "Iteration:  4942  Loss:  0.17346594   Accuracy:  0.9296875\n",
      "Iteration:  4943  Loss:  0.26401055   Accuracy:  0.9453125\n",
      "Iteration:  4944  Loss:  0.13449976   Accuracy:  0.96875\n",
      "Iteration:  4945  Loss:  0.35378262   Accuracy:  0.90625\n",
      "Iteration:  4946  Loss:  0.24128309   Accuracy:  0.9453125\n",
      "Iteration:  4947  Loss:  0.31464183   Accuracy:  0.9140625\n",
      "Iteration:  4948  Loss:  0.2308358   Accuracy:  0.9296875\n",
      "Iteration:  4949  Loss:  0.21510719   Accuracy:  0.9453125\n",
      "Iteration:  4950  Loss:  0.40620595   Accuracy:  0.890625\n",
      "Iteration:  4951  Loss:  0.18188424   Accuracy:  0.921875\n",
      "Iteration:  4952  Loss:  0.3009858   Accuracy:  0.8984375\n",
      "Iteration:  4953  Loss:  0.3110692   Accuracy:  0.9140625\n",
      "Iteration:  4954  Loss:  0.24687664   Accuracy:  0.921875\n",
      "Iteration:  4955  Loss:  0.23466334   Accuracy:  0.921875\n",
      "Iteration:  4956  Loss:  0.28566113   Accuracy:  0.9453125\n",
      "Iteration:  4957  Loss:  0.22807029   Accuracy:  0.9453125\n",
      "Iteration:  4958  Loss:  0.2490573   Accuracy:  0.890625\n",
      "Iteration:  4959  Loss:  0.19575086   Accuracy:  0.9296875\n",
      "Iteration:  4960  Loss:  0.25680518   Accuracy:  0.921875\n",
      "Iteration:  4961  Loss:  0.34710506   Accuracy:  0.90625\n",
      "Iteration:  4962  Loss:  0.4232056   Accuracy:  0.8984375\n",
      "Iteration:  4963  Loss:  0.23598675   Accuracy:  0.9296875\n",
      "Iteration:  4964  Loss:  0.38620415   Accuracy:  0.9375\n",
      "Iteration:  4965  Loss:  0.2513543   Accuracy:  0.9140625\n",
      "Iteration:  4966  Loss:  0.23859876   Accuracy:  0.921875\n",
      "Iteration:  4967  Loss:  0.34371114   Accuracy:  0.9375\n",
      "Iteration:  4968  Loss:  0.3019547   Accuracy:  0.921875\n",
      "Iteration:  4969  Loss:  0.24982521   Accuracy:  0.9296875\n",
      "Iteration:  4970  Loss:  0.19143865   Accuracy:  0.9296875\n",
      "Iteration:  4971  Loss:  0.18813622   Accuracy:  0.9453125\n",
      "Iteration:  4972  Loss:  0.30455977   Accuracy:  0.8828125\n",
      "Iteration:  4973  Loss:  0.21053709   Accuracy:  0.9375\n",
      "Iteration:  4974  Loss:  0.35372365   Accuracy:  0.9296875\n",
      "Iteration:  4975  Loss:  0.3044953   Accuracy:  0.8984375\n",
      "Iteration:  4976  Loss:  0.3076641   Accuracy:  0.9140625\n",
      "Iteration:  4977  Loss:  0.16250658   Accuracy:  0.9453125\n",
      "Iteration:  4978  Loss:  0.12159557   Accuracy:  0.96875\n",
      "Iteration:  4979  Loss:  0.18571314   Accuracy:  0.9453125\n",
      "Iteration:  4980  Loss:  0.29763532   Accuracy:  0.8984375\n",
      "Iteration:  4981  Loss:  0.292051   Accuracy:  0.9375\n",
      "Iteration:  4982  Loss:  0.12654701   Accuracy:  0.96875\n",
      "Iteration:  4983  Loss:  0.14167856   Accuracy:  0.9609375\n",
      "Iteration:  4984  Loss:  0.26849943   Accuracy:  0.921875\n",
      "Iteration:  4985  Loss:  0.2631468   Accuracy:  0.9296875\n",
      "Iteration:  4986  Loss:  0.27517048   Accuracy:  0.90625\n",
      "Iteration:  4987  Loss:  0.21788189   Accuracy:  0.9453125\n",
      "Iteration:  4988  Loss:  0.31392163   Accuracy:  0.9140625\n",
      "Iteration:  4989  Loss:  0.19545382   Accuracy:  0.953125\n",
      "Iteration:  4990  Loss:  0.2203624   Accuracy:  0.9453125\n",
      "Iteration:  4991  Loss:  0.19685136   Accuracy:  0.9609375\n",
      "Iteration:  4992  Loss:  0.20269972   Accuracy:  0.953125\n",
      "Iteration:  4993  Loss:  0.21642615   Accuracy:  0.9296875\n",
      "Iteration:  4994  Loss:  0.23949042   Accuracy:  0.921875\n",
      "Iteration:  4995  Loss:  0.23023286   Accuracy:  0.9140625\n",
      "Iteration:  4996  Loss:  0.26553366   Accuracy:  0.9140625\n",
      "Iteration:  4997  Loss:  0.3463569   Accuracy:  0.90625\n",
      "Iteration:  4998  Loss:  0.22815396   Accuracy:  0.9453125\n",
      "Iteration:  4999  Loss:  0.20515747   Accuracy:  0.9375\n"
     ]
    }
   ],
   "source": [
    "## This will find loss using Adam Optimizer\n",
    "\n",
    "loss_dir = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for _ in range(5000):\n",
    "        \n",
    "        batch_x, batch_y = data.train.next_batch(128)\n",
    "        loss_val, accuracy_val, ad = sess.run([loss, accuracy, adam_step], feed_dict = {x: batch_x / 255, y_true: batch_y})\n",
    "        loss_dir.append(loss_val)\n",
    "        print ('Iteration: ', _, ' Loss: ' , loss_val, '  Accuracy: ', accuracy_val)\n",
    "    accuracy_val = sess.run(accuracy, feed_dict = {x: data.test.images / 255, y_true: data.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26eed12aa58>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd4FNX+BvD3uyn0TuglIKCCSMQIKIgoCIgo1456r11+V7z2BooNy9WroqJeFbtexXLlKtIDIr0loQiEQAgloSVASCEJaef3x85utszsTpJNdmd5P8+TJ7uzs7Nntrxz5syZM6KUAhERhRdbsAtARESBx3AnIgpDDHciojDEcCciCkMMdyKiMMRwJyIKQwx3IqIwxHAnIgpDDHciojAUGawXbt26tYqNjQ3WyxMRWVJSUtJRpVSMv/mCFu6xsbFITEwM1ssTEVmSiOwzMx+bZYiIwhDDnYgoDDHciYjCEMOdiCgMMdyJiMIQw52IKAwx3ImIwpDlwj31cD7eWpSKowWngl0UIqKQZblw35WVj/d+T8PxkyXBLgoRUciyXLjbRAAAvK43EZExy4W7aP8rmO5ERIasF+5aujPbiYiMWTDctWYZMN2JiIxYL9y1/6y5ExEZs16484AqEZFflgt3m6PNnc0yRESG/Ia7iHQWkaUikiIi20TkIZ15holIrohs0v6eq53iVh5QrWC2ExEZMnMlpjIAjymlkkWkCYAkEUlQSm33mG+FUmps4IvoTuBolmG6ExEZ8VtzV0odUkola7fzAaQA6FjbBTPi7AoZrAIQEVlAldrcRSQWwHkA1uk8fKGIbBaR+SLSJwBlMyoDANbciYh8MX2BbBFpDOBnAA8rpfI8Hk4G0FUpVSAiYwD8AqCnzjImAJgAAF26dKlWgdkVkojIP1M1dxGJgj3Yv1VKzfJ8XCmVp5Qq0G7PAxAlIq115puhlIpXSsXHxMRUq8BsliEi8s9MbxkB8BmAFKXUNIN52mnzQUQGaMs9FsiCOjgGDqtgdxkiIkNmmmUGA/gbgD9FZJM27WkAXQBAKfURgOsB3CciZQCKAIxXtdQo7myWqY2FExGFCb/hrpRaicpMNZrnfQDvB6pQPnHgMCIivyx4hioHDiMi8sdy4c7eMkRE/lkv3DlwGBGRX5YLdw4cRkTkn+XCnQOHERH5Z7lwBwcOIyLyy3LhbuMZqkREflku3DlwGBGRf9YLd+0/s52IyJjlwt3GrpBERH5ZLtwre8sw3YmIjFgu3B0Y7URExiwX7sKBw4iI/LJcuDva3Fl3JyIyZrlw5xmqRET+WS/cwd4yRET+WC7cOXAYEZF/lgt3NssQEflnuXDnwGFERP5ZLtxt7ApJROSX5cI9Qkv3crbLEBEZsly4O/q5l7PqTkRkyHLh7qi5V7DmTkRkyLLhzpo7EZExy4W7o1mGNXciImOWC3ceUCUi8s964e48oBrkghARhTDLhbtNKzFPYiIiMma5cGezDBGRf5YLd/ZzJyLyz2+4i0hnEVkqIikisk1EHtKZR0RkuoikicgWEelfO8VlbxkiIjMiTcxTBuAxpVSyiDQBkCQiCUqp7S7zXAGgp/Y3EMCH2v+Aq2yWqY2lExGFB781d6XUIaVUsnY7H0AKgI4es40D8LWyWwuguYi0D3hpUTlwGJtliIiMVanNXURiAZwHYJ3HQx0BZLjcz4T3BgAiMkFEEkUkMTs7u2olrVwGbMJmGSIiX0yHu4g0BvAzgIeVUnmeD+s8xSt9lVIzlFLxSqn4mJiYqpXURYRNWHMnIvLBVLiLSBTswf6tUmqWziyZADq73O8E4GDNi6fPJsKaOxGRD2Z6ywiAzwCkKKWmGcw2G8BtWq+ZQQBylVKHAlhONxE2YT93IiIfzPSWGQzgbwD+FJFN2rSnAXQBAKXURwDmARgDIA1AIYA7A1/UShHCZhkiIl/8hrtSaiX029Rd51EA7g9Uofyx2dgsQ0Tki+XOUAXszTLMdiIiY5YMdxubZYiIfLJkuEfY2M+diMgXa4a7sLcMEZEvlgx3G09iIiLyyZLhHsHeMkREPlkz3EV4mT0iIh8sGe7s505E5Jslw50HVImIfLNkuPOAKhGRb9YMd47nTkTkkyXDneO5ExH5Zslwt7HNnYjIJ0uGe4RNwIo7EZExa4Y7a+5ERD5ZMtxtNrDNnYjIBzNXYgo5JWUVOFFUGuxiEBGFLEuGe/L+E8EuAhFRSLNkswwREfnGcCciCkMMdyKiMMRwJyIKQwx3IqIwZMlwrx9lLzYHDyMi0mfJcC8urQAAnCqrCHJJiIhCkyXD3aGCZ6kSEeliuBMRhSFrhztbZYiIdFk63Dl4GBGRPr/hLiKfi0iWiGw1eHyYiOSKyCbt77nAF1NfGavuRES6zAwc9iWA9wF87WOeFUqpsQEpURUw24mI9PmtuSullgM4XgdlqTI2yxAR6QtUm/uFIrJZROaLSJ8ALdOv8nKGOxGRnkCEezKArkqpfgDeA/CL0YwiMkFEEkUkMTs7u9oveG6nZgBYcyciMlLjcFdK5SmlCrTb8wBEiUhrg3lnKKXilVLxMTEx1X7Nu4d0AwBeR5WIyECNw11E2omIaLcHaMs8VtPl+hJpsxeb4U5EpM9vbxkRmQlgGIDWIpIJ4HkAUQCglPoIwPUA7hORMgBFAMYrVbvtJRHaJonhTkSkz2+4K6Vu9vP4+7B3lawzNvuOAsOdiMiAJc9QrRcVAQAoKS8PckmIiEKTJcO9YbQ93AtLGO5ERHosGe4NtJr7yVMMdyIiPZYM96gI9pYhIvLFkuHu7C3Dk5iIiHRZMty1bvWo5R6XRESWZclwj2BXSCIin6wZ7jZ7uDPbiYj0WTLctYo7KpjuRES6LBnujpo7D6gSEemzZLg7hh/gSUxERPosHe4vzdke5JIQEYUmS4a7AptjiIh8sWS488LYRES+WTLc60dZsthERHXGkinZvGE0AOCm+M5BLgkRUWiyZLgDQKtG0YiKlGAXg4goJFk23CNswuEHiIgMWDbcI22CsnKGOxGRHsuGe0QEa+5EREYsG+4Zx4swa+OBYBeDiCgkWTbciYjIGMOdiCgMWT7ci0s5eBgRkSfLh/uJwtJgF4GIKORYPtw5iBgRkTfLhzsREXmzfLgLOAQBEZEny4c7m2WIiLxZPtyJiMib33AXkc9FJEtEtho8LiIyXUTSRGSLiPQPfDGN8RrZRETezNTcvwQw2sfjVwDoqf1NAPBhzYvl3yvXnAMAHF+GiEiH33BXSi0HcNzHLOMAfK3s1gJoLiLtA1VAI/UjI7Ty1fYrERFZTyDa3DsCyHC5n6lN8yIiE0QkUUQSs7Oza/SiNq3kFUx3IiIvgQh3vb6IuomrlJqhlIpXSsXHxMTU6EVtYn/ZcoY7EZGXQIR7JgDXi5l2AnAwAMv1yRHuiuFOROQlEOE+G8BtWq+ZQQBylVKHArBcnxzhvmj7kdp+KSIiyzHTFXImgDUAzhSRTBG5W0T+LiJ/12aZByAdQBqATwBMrLXSurBpjUH/WpBaFy9HRGQpkf5mUErd7OdxBeD+gJXIpP3HC+v6JYmILMOyZ6hm5DDciYiMWDbceRyViMiYZcOdJ6YSERmzbLizCyQRkTHLhrsrXkeViMidZcNdpPLE2Fs/XRfEkhARhR7Lhnuvto2dt5P25QSxJEREocey4X5Jr5qNTUNEFM4sG+7dYxr7n4mI6DRl2XAnIiJjDHciojDEcCciCkNhE+75xaXBLgIRUcgIm3Dv+8KiYBeBiChkhE24A8DG/ezvTkQEWDzcO7ds4Hb/mn+vDlJJiIhCi6XDffb9Q4JdBCKikGTpcG/RKBqPjOgV7GIQEYUcS4c7AJRz6F8iIi+WD/fpS3YFuwhERCHH8uHuKWnf8WAXgYgo6MIu3K/7cA1yi0qxfs9xlJZXAADSsvJNneS0Ylc2Xl+wo7aLSERU6ywf7s0bRnlN6/fiItz48Rq8PGc7AGDEtOX4q4kLevzts/X48I/dAS8jEVFds3y4v3VDP8PHVqQddd7enJlbF8UhIgoJlg/3epERho+lZ5+s1jLHfbAKs5Izq1skopBQUaHw44YMZ/NkbcsvLkV5BXuvhQrLh3uDaN+roFy6Sl74zyV48bdtfpe5OeMEHv1xc43LRhRMszYewJM/b8GM5em1/loVFQp9X1iEybO21PprkTmWD/f+XVr4fLzb5HnO24dyi/HFqr21XCKiwMjKK8ZnK/e4VVCq4kRhCQDg+MmSQBZLl6OEPyVxjzdUWD7cRSSor5+eXYD/bQy9L/T6Pcfx4MyN1Q4GCr6J3ybjpTnbkX60es2Ljo8+uL8QChbLh3ttOnmqzO88o99dgUd+CL0mnNs/X4/Zmw+iqLS8Vl8nr7gUX6/ZG/Ibkd3ZBfivxWqVJ4rs3Xer246tUPefSYh/DU4rpsJdREaLSKqIpInIJJ3H7xCRbBHZpP3dE/iiBs4DMzei7/MLUewn+G6ascbvskrK6uZgVW3p+/xCXPHuimo//9lftuK5X7dh3Z7QPnls1NvL8fhPobcRrgt1sXMb6hv305HfcBeRCAAfALgCQG8AN4tIb51Zf1BKxWl/nwa4nAH12+aDyD9Vhps/Wetzvq0H8gL+2t+s2YslKUcCvlwj/n5z+afKkHKo+uvpaM89FeIbubI66MWRW1iKAhN7e1X13br91Xqes1kmgOn++44jiJ00FwdOFAVsmeHgVFk5dmcXBLsYbszU3AcASFNKpSulSgB8D2Bc7RarapKfvbxazzN7oCnlUB6ueHeF2w+3rLwCX6zaU+XXfPbXbbj7q0QMfu13U80+1VXXhyLCpV03K78YvabMx5bME1V+br+pizDwlcUBL9OXq/dW63mOzVmgPhulFO76MhEAsCXD/f0JxKZz+8E8bD8Y+AqVw6q0o4h/OQGHc4vx2I+bTW2Ij+QV496vE33+VrPzT+HMKQsw/K1lzoPYocBMuHcEkOFyP1Ob5uk6EdkiIv8Vkc4BKZ1JLRtFV+t5rl96ow8vO/8UXl+wAymH8rB+zzEAQGl5BabO2Y4Xf9terdcFgAMnirDdT425qKQc57+UgD9Ss6r9On2eX4j1JppMarpbHah68e87jqAswP2ycww24pk5hfh+vXuteMXOoygpq6h2r6qTJb6b+ioqVJ31OzerrLwCFSb2bFz3fmqj8jBm+gqMmW6+iXBt+jGsSz9mev7XF+zA0YISPPrjJvycnImvDDaah3KLnMdn3lqUioTtRzBny0Gv+RZvP4LVaUexenflyZKFfj7/umQm3PU+Rs9vwm8AYpVS5wJYDOAr3QWJTBCRRBFJzM7OrlpJa0lxaTke+n4j+jy/UPfxC15ZjLJy++r+NykTsZPmYtLPf+LrNfvc5kven4OiKn6w/n4f6UcLcOxkCV6bX7Pxbj5YmuY1La+4FLGT5jrv10arxbGCU4ahMX3JLox9z/2HvGxnNu76MtE50mdFhfJ7XMQhad9x3PNVou7Bx1sMhp646eO1mDTrT9Of2/82ZmLrgcoznbceyMULs7dVacN466fr0POZ+abnd1Vwqsz5fm4/mIeVu466PV5cWu52DEivWEp5v6c9npmPu7/aAABYl37MOQ5TSVkFjhWcMlW2QDa5p2XlY+eRfL/zjZ+xFjfN8N206srz95ZxvFB3vls/XYfHf7LX7B3r9d36DNz/bbLbfPd8nYhbPl0Hm8uWLsid99yYCfdMAK418U4A3DZjSqljSinHt+ATAOfrLUgpNUMpFa+Uio+JialOeQNu7pZD+HWT91bZlaOmNe/PwwCAXzcd8Jrn2n+vxtnPLcDHy7zHplmddhQJ273b2RVgOKBZxvFC/JRorz0cO1lSo+6Wnj96wN6H2lWFy68zr7gUP26w76wl7TuOid8mGYb0Ci1gPl2RjmSXa9hm55/C+S8vxtuLd7rN/+umA0jYfgTTEnZ6HdM4mm//Cu3KKkDspLnoOWU+znp2gamAv+WTdViccgS7swuw80g+cgsr31e9YwrFpeXOduMKpTDllz+x16XLod5v9JEfNmPseytdXnMtvly9F3lF+nt95RUKSz32utaYrGmmZeUjLauyDTe3qBTnPL8Q0xLs7+eY6Svw188qN1qzkjNx1rML3DaYzt4yLiszfUkaznp2gVeT5NLUbOQWleKmGWsxUQuxB2duxPkvVzYzuQd47aXYiGnLMfLt5T7nca2YmOU5BMn3GzJ0v1tZefbvYYWq7G+0OeME5v55SHe5oRTorsyE+wYAPUWkm4hEAxgPYLbrDCLS3uXu1QBSAlfE2rP3WCEeq0YPCpuPT/OfOrXsWz5dh3u/TvQK/ts/X4++LyzyqoFl5RVj3AernG2t2fmn8MgPm5Gd77sWVVxarjvk8bo9x3H1+yt1nlFp7PSVyMq3B/6kn7fgyZ+3YEvmCVz34RrM+/Ow34NFK3YdxbUu17A9qtX4XDdqhSVleOj7Tbj360SfyzpR6N4F0PEDrKhQhk02jgO636zZh5FvL8c1H64CYN/o6HE92eajZbvxn7X78cDMjT7LVVUfLduNO7/Y4Nzj06sUGBkxzT3cpvyyFQDw6+YDutcwcJxRvfNI5edU2c+98vvq2Ni+/7v33typMvv7nHLIXmtesO2w2+OuXStdfwIZxwuxtgrNI67eWbwTy3bW/l78UYM9EL0mS8eeWHFpOZabKJtbzT2Ejj75DXelVBmAfwBYCHto/6iU2iYiU0Xkam22B0Vkm4hsBvAggDtqq8DB4LorDgAlJttMPYPoNY/hhB3tc7O0WnlRSTkycwox4NUlugd7M3LcdyOT9+cgdtJc7D9mn373Vxtw3YdrsP9YoddXbMdh37u5qUfyMeCVJdhz9KRzIzLeZZf3co+alFIKizx+/O6Pe0+784sNPsvgeMq6Pe5BcSi3GA9/vxF3f7UBPTyaNE6eKkPSvhx4Ss8+iQMnivDGwlSvx04UlrjtybynBZ2Ie3vjqbJyZ+C5+nbdPueIo/Zy6+/V7Dtm3xN4/ld7MLs25X2zZq/X/BUVyrBP+2+b7XuXGceLnLV3s9Ky8jH6neXILarcm/lcrzOAn6YVo6aXoW8sxW2fr69SmbYdzEXspLl4Z/Eu3G7yuf+cl4L5BrVnPdOX7HJu3Cf9rD8sQo7HAVCllPO4yYBXliDLoELl+jm5/tZCqRYfaWYmpdQ8APM8pj3ncnsygMmBLVrVLH18GC59849aWba/g2R6th/Mw5jpK/DOTXHOaUY/jlnJB5Cw7Qjy/Ry9v/bfq5HwyFD0bNsEAJzNNivSsnFrq65YlWYPxTwTY9cbcW2H9HVw6MfEDDz1859e0/OKS/Hp8nSvXdiHv99o2Bf+vv8kYf7Ww3jj+nMBeLf/v75gB/5I1a9BGR0rAYAXZ+uPIxQ3NcHwOQ5bD+Yi7sUEFJWW44lRZ+L+S3s4H3vmf/awbtbAe7hpPY7vj+vv/rnZ23BVvw6Im5qAx0f2wsRhPXD1Byux9UAe9r52panlmrU4xd405LmHePvn691qzf/RulweLTiFa/+9yjk9M6cQnVo0dHvud+v2Y1SfdgDMtbfHTpqLmwd0wT+v7QsA+Gxl1XuafayNkWP2/XFsBAf3aO18DwD38nqW3dH0aqTgVBme+3UrZiVX7oX5quy9t2QXkvfn4Is7B5gqcyCFzRmq3Vo3CnYRnO77T5LzqP/DP2wy9Rx/we6QkVOIV+elIHbSXMzUenqcKCxFukuzibnag/5Mt32+Hhv2eteEPR08Uaw7/dwXFmH672nYrY3IueNwPvKKS/GLwXGNUW8vx/yt9h+UUV/56AjzX9MVuyrDqibH+HYeKXCe3atX+3cVNzUBaVnee0Y/JrofJ3HdfVcKWKkNSf3mop14KyE1YOdVbD2Qi8ve/MNrI79qt3u4ezaHuI6Emry/sqvjkNeXorS8AvNcNtjLdmYj5VAeftlovqlp5vr9hldK02s2cd3TcOV5/Gh3doFb2YpKynH/d5UHP32dpPfN2n1ue6AH/fTfP+f5hW7BDgAb9lau08BXl+BwbuVv462EnViamo1fNh5A7KS5NTqnpKrCJtxDiSOsasNdXyZ6jfL3xsJUXPbWMuf9id8m6+5tfLoiHb/vOILLpy2r0dCsOSdLqtQ9c7aPA9apLr0iHO3Knnwd4/C095h705XnU/01AVQYVEMnz/LeS3ENn9mbK8PFqKvjwVz34HCd74Ollcdjzn52gc8y+jMtYSfSj57EunT3IPXVjOZP/6kJXiOlXvHuCsPKyxM/bcbIt5d5Tb/uwzUoKavwCsindd7ffi8uwhXvrsCcLQfdjt30muLeNDf8rWXOg8AAMH/rIczdYq75JmlfDiZ8k2RqXiOe7eyOpqAdhyuD3PE+1eVQ4qaaZcha9h3T7+L18twUxDSph+z8Uzh20lwXN1efrdyD3dkFVT5j0qjd0izPWt2s5Exk5hRhcI9WPp+nl9O+Dt4JgCf/q982O3O9+XV+Y2Eqnh5zttf0zBxzZ3VWZTygrPxiZ1ddB0fUVPXcBV/lM7tn6eBrdEi9k4eM9tpSDuXhH9+ZO9B9JK/Y1ElQgW4X91zepyv3YMrY3hj9jvceQ10OdBhW4b7txVEAgLJyhX5TFwW5NKHJcbD0Dj8HN/W8NKd6J23p9e6oikSPA6aOGuQ0/03nddZ74fcdlTXLRdsOmxpDfe3umo/HM+CVJV7THAESrKuPeXZT3HbQvRz9XzLxwVXDwFft78WTo8/0Od/q3cY9ewI12JrRhvWbNft0N/y1IayaZRrVi0SjepFopnNdVXJn9QHPQo1re7ln05CRHxIz/M9UDYsNxi46WhCcU+OvnO67G26g/WuB72MkejJzzH1mejxPaASMD7LW9iitrsIq3IlcLd+ZXac/JvL2iMkOBXXR192XNxemIj27ABnHAzMg2sT/JPufqZZJsIbqjI+PV4mJvk9mqYnqnMFGRFQX3rj+XNwQX70huEQkSSkV72++sK2533FRbLCLQESkqzr9/KsqbMPd9aQTIqLTTdiGu0PrxtF47dq+GNm7bbCLQkRUZ8I+3AFg/IAumHFbZRPVwyN6BrE0RHS6q4tDnadFuHt6aDjDnYjCW9iGe+N69vOzbvQ4Ih0VIRARPHgZ2+SJKHyF1RmqrhpERyD15dFug06tmnQZGkRFBLFURERAVGTtnzkdtjV3AKgXGeE2lkPH5g2c11s9o01jt3lvjO+Eczs1q9PyEdHpqS4qmWFbc/fn6n4d0KF5AxzNP4VNGSfw8IheaBAd4XXyU/eYRkjPPmmwFCKiqqtfB+Ee1jV3X0QEF8S2xBV922PymLPRINr+Zv8wYRDGX1DZTv/bP4Zg1aTL0KSe/nawVaNoXNjd9+iEZiRNGVHjZRCRNTDcg2Bg91Z47bpznfcb1YtEx+YNsOjRoZh57yBE2uzNPE+POQsAEBkh+ODW/l7LqWq/erNDgT44vGdANiZEFDxREWxzDxntmzXAhWe0craV/eW8jgCA/l1aoEXDKFzYvRU+uS0e6a+OweMje+GN6/s5n5sydTSeGn1WlV/zkl4xXtNaNYrGBd1aVnMtQtsHt3hvJInC0b0Xd6/112C4G1j/9HCsePJSr+k/T7wIT44+E22a1Mdv/xiCaTfGQUQwc8IgXN67LWw2wT8u64lmDaPw2e3xmDjsDDSIjsB9w86o8rUxv7jjAuftx0f2AgC0aBRdoxHKP7nN73hD1XJ2+6ZIf3VMjZZx5bntA1QaotB2XpcWtf4aDHcDbZrWR+eWDb2m92rbBBOH2fvI9+3UzNlWr2f42W3xpEeNfcWTl+LLOy/wmrdepA3rnh5e+dyz2sBmq4zx/7vkDLw7Pg5X+QnAJvW9jw10a90IY/o6LmZceWrcr/cPBgB0atEAy5+41O0I/qg+lc1KZo7s3z2km1t5HdM8j1XMe/Bin8t5bmxv5zkKvmx5YaTPx+8bdgYAINIm+L+h7rWkZ8f29rv86jBqint3fBxeueacWnnNUGXmMzzdtGlSr05fj+Fexzq3bIhBLm3mNw/ogtWTLkOjepFo27Q+AHuwf3aH+wYgKsKGcXEdISKIj3Xf6g/tFYNf7h+Mva9dianj+jinO7p2CoCp487BnYNjcdlZbZyP9+3YDPcM6YaZ9w5Cl1YNkfLSaLw7Pg4AMOXKygD8/fFL8O09A32u11/iOgCwdzd1eGLUmfjtgSFu8/Xu0BSLHhnqNa/DXUO6Yat2RS1XZ7Vrgscu7+W837R+5QVZrtWayFxd3rstlj9xKba+OAqTPa58c1W/9mjWIArzHrwYU67UvyrOxT1b60438vVdA9yGuHBY+dSlGBfXEbcO7Kr7vO4GF3Y/p2PTKr0+oF/mR0ZUvmdntWuC7+4diGc83o9nx/bGdf076S5z8hX6zYkf/fV8PDFK/4pH/5t4EdY+PRxntzdeh+hIG85q18Tw8boypIf5z/nuId2qvHzX9yCqChd6DwSGe5C9NK4POriE3N7XrnQL9gtiW7jVogHg4p4xePsme5v+4kcvwVd3XoC4zs0BANec1wnvjo/DthdH4cO/ng8A6B7TGK0b18PzV/VBpMsXzGYTTBnb220PZVxcR+x97UrntIvOaIX2zRpgsMuP4PYLK4Pqk9visfn5kc7lTrvRXq7HLu+F+lERiG3dCHv+6d5c06ttE6S/OgZzH6wM/n/rHJR21bRBFB7wGDaiWYMoREUIpt0Uh7dv6ue2V1BRodClVUNnr4SFDw91PtamSX1sfn4kendoiqv7dXBb5oPDe+L3xy7BjL/F493xcXjUZYOiJ7ZVQ6x/ejiG6hwfAYBOLSrf2/Uue2YON12gP6b3nAcuxqVn2pfpusH25Ys7LsCwMyvLsfe1KzGid+XGfP5DF+OiM1rj3qHdsXbycMx5YAguOqMVbojvhLdu7Ke3SAw/u43u9NHntMP9l/bw2oN6bmxvnNelBRrXi9Tdi3R4aHhPt+NSRhsKhwkue1/Pju2NpgbLvnNwrM/lePrqrgF+55l57yA8cFkPrTnWXvuedmM//Ph/Fzrn0atgAMAjLuNY1eHlUwGcxv3cQ0F0pM0tbPX89PeLdKdfc14nXHOefm1rXJz9i9ZNmPiKAAAKM0lEQVSoXiS+umsAzu/qXtN/5ZpzsDrN+DqSDtunjtKtbbw47hw8d1Uf5BaVOk8KcxjYvRWWP3EpOres3GA5egK10/ZMAPuGpXnDaNPHIfR+FxueGeG85qXjvYjv2gKJ+3JQ4TEwUxedJjbA3vwW17k5NmWcAAC3MB8X1xGbM05gWsJO9GzTGLuyCrye/4/LeqKNy3olTRmBjftP4J6vvS9E06ZpfVzZtz12Zxdgx+F8AHAr51/iOuBoQQkO5dqvBuR477u0bIiER4bim7X78Nvmg8gpLMXAbi2xbo/7NVgjI2wY0qM1/kjNdlYI+nRohhev7oNRfdq59chq16w+2jWrj+/uHeS2jGYNopBbVOq836NNE3x4a3/c920ymjeMwonCUrf5m9aPwrf3DETzhlHo00H/JMBHL++FpalZOLdjM3ylXZLu6n4d3Jb190vOwPCz26B5g2i8s3gn+nRoigbRkXj8J/v1cof2jEH/Ls3xxsJU3HFRLG4d2AXTEnZ6Xav24eG98MWqvbrlcJU0ZQQKS8oRYROM6dsO8/487Pb4R3/tj6LScvTr1BzdYxrjwjPse9tntmuCrPxTGNG7rdve45s39MOsjQe8Xmf42W3x+MheWL83B2e2bYxPVtT+OO4ODPcgcPxo62J0Sr0eN7cO7GrYTOCqYbT712Nwj1ZYpW0UImziFewOXVp5B2nilBFV6tu797Ur3U4oc+TSXYO7Yat2weXoSO8Nj02b0fMKY45jI3pNF1/ccQHOM7hoc+8OTTG6Tzs8fHlPfPjHbvRq2wT3X9oDSftycN2HqzG4h3u31FaN6znX0/MxAM5us1sP5KJepA37tOutvjs+zrlRdnjlmr7oFtMIF/eMQYRNMHXcOXj+KnstvqC4DPd+nYj1e48jZepo5/rdObgbWjeu57ZHcrvJC9csfvQStGgYhZzCUoyYtsw5/Yq+7Z0bYb0rnA3207QxqHsrPDi8Jz5YmgYAmDjsDHRu2RAdmivcOrAL7rm4OyJsgrPa2ZswXLsiX92vA5btzMYQ7XMbfY79mFOELQJPjznbGe4rnrwUNpt4HQN7ZEQvxMe2QOvG9ZBxvNC50W3VuB4cn86bN/TDHRd1Q5P6kfgpMRMPjeiJZg30r8P8/i39kXIozxnsix8dCkBgswm2vDASd32xwe2C7hFaBwsAyDlZglnJB/DzffoVtoBTSgXl7/zzz1dkLUUlZepIblGdvd6R3CJVUFyqnp61RWUcP2nqOVsyTqix01eowlNlVXqtUW8vUx8s3VWdYnrZuD9HdX1qjnrip02m5k89nBeQ1w2krk/NUV2fmmN6up4bPlqtuj41R61LP6aUUuq9JTtV16fmqNfnpwSsnEn7jqvv1+/TLWe3Sd7lPJBTqHbW8vvteI9mbzpQK8sHkKhMZCxr7mRa/aiIOjmzzsHR3PHKNX1NP6dvp2ZeB3HNWODSJl9TcZ2b44Nb+rsdvPalV9vgH1j0dGN8J/yy6WCNlnHPkG5Yv+c4emrjOF13fif8mJiJmwd0CUQRAdjPM+mv061wwcMXo0VD7z3LDjoH8WvLVR7Hc+pa2F4gm4gCL/VwPhpGR+h2Eya7tenHkJlThOvP1z8mVlNmL5DNmjsRmXZmCHRfDHWDQmR4EHaFJCIKQ6bCXURGi0iqiKSJyCSdx+uJyA/a4+tEJDbQBSUiIvP8hruIRAD4AMAVAHoDuFlEPM/fvhtAjlKqB4C3Abwe6IISEZF5ZmruAwCkKaXSlVIlAL4HMM5jnnEAvtJu/xfAcDE7hi0REQWcmXDvCCDD5X6mNk13HqVUGYBcAF5HFURkgogkikhidnZ29UpMRER+mQl3vRq4Z/9JM/NAKTVDKRWvlIqPidEfi4OIiGrOTLhnAnAd3agTAM+zG5zziEgkgGYAjoOIiILCTLhvANBTRLqJSDSA8QBme8wzG8Dt2u3rAfyugnV2FBERmTtDVUTGAHgHQASAz5VSr4jIVNjHOJgtIvUBfAPgPNhr7OOVUunGSwREJBvAvmqWuzWAo9V8rlVxnU8PXOfTQ03WuatSym+7dtCGH6gJEUk0c/ptOOE6nx64zqeHulhnnqFKRBSGGO5ERGHIquE+I9gFCAKu8+mB63x6qPV1tmSbOxER+WbVmjsREflguXD3N0KllYjI5yKSJSJbXaa1FJEEEdml/W+hTRcRma6t9xYR6e/ynNu1+XeJyO16rxUKRKSziCwVkRQR2SYiD2nTw3md64vIehHZrK3zi9r0btoIqru0EVWjtemGI6yKyGRteqqIjArOGpknIhEislFE5mj3w3qdRWSviPwpIptEJFGbFrzvtplr8YXKH+z97HcD6A4gGsBmAL2DXa4arM9QAP0BbHWZ9i8Ak7TbkwC8rt0eA2A+7EM9DAKwTpveEkC69r+FdrtFsNfNYH3bA+iv3W4CYCfsI42G8zoLgMba7SgA67R1+RH280EA4CMA92m3JwL4SLs9HsAP2u3e2ve9HoBu2u8gItjr52fdHwXwHYA52v2wXmcAewG09pgWtO920N+QKr55FwJY6HJ/MoDJwS5XDdcp1iPcUwG01263B5Cq3f4YwM2e8wG4GcDHLtPd5gvlPwC/Arj8dFlnAA0BJAMYCPsJLJHadOf3GsBCABdqtyO1+cTzu+46Xyj+wT5MyRIAlwGYo61DuK+zXrgH7btttWYZMyNUWl1bpdQhAND+O66ybLTulnxPtF3v82CvyYb1OmvNE5sAZAFIgL0GekLZR1AF3MtvNMKqpdYZ9jPanwRQod1vhfBfZwVgkYgkicgEbVrQvttWu4aqqdEnw5TRulvuPRGRxgB+BvCwUipPjIf+D4t1VkqVA4gTkeYA/gfgbL3ZtP+WX2cRGQsgSymVJCLDHJN1Zg2bddYMVkodFJE2ABJEZIePeWt9na1WczczQqXVHRGR9gCg/c/Sphutu6XeExGJgj3Yv1VKzdImh/U6OyilTgD4A/Y21uZiH0EVcC+/0QirVlrnwQCuFpG9sF/c5zLYa/LhvM5QSh3U/mfBvhEfgCB+t60W7mZGqLQ61xE2b4e9Xdox/TbtKPsgALnabt5CACNFpIV2JH6kNi3kiL2K/hmAFKXUNJeHwnmdY7QaO0SkAYARAFIALIV9BFXAe531RlidDWC81rOkG4CeANbXzVpUjVJqslKqk1IqFvbf6O9KqVsRxussIo1EpInjNuzfya0I5nc72AchqnHQYgzsvSx2A3gm2OWp4brMBHAIQCnsW+y7YW9rXAJgl/a/pTavwH4t290A/gQQ77KcuwCkaX93Bnu9fKzvENh3MbcA2KT9jQnzdT4XwEZtnbcCeE6b3h32oEoD8BOAetr0+tr9NO3x7i7LekZ7L1IBXBHsdTO5/sNQ2VsmbNdZW7fN2t82RzYF87vNM1SJiMKQ1ZpliIjIBIY7EVEYYrgTEYUhhjsRURhiuBMRhSGGOxFRGGK4ExGFIYY7EVEY+n/4rSZYVcyj4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Testing data using Adam Algorithm:  92.72000193595886\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy on Testing data using Adam Algorithm: ' , accuracy_val * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
